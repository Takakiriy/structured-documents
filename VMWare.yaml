#keyword: VMWare.yaml
Docker: #keyword:  #ref: ${programming}/OS/VMWare.svg#Docker
    マニュアル:
        英語 URL の例:    https://docs.docker.com/docker-for-windows/
        日本語 URL の例:  https://docs.docker.jp/docker-for-windows/
    手順:  #// インストールします、イメージを作ります
        環境の比較:
            ホストOS が Windows か WSL2 かで性能比較:
                WSL2 が良い #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: Docker host compare
        注意 >> 非公開設定:
            デフォルトでは Docker は iptables を編集し、インターネットからアクセスできるようになってしまいます  #search: Docker iptables
        Docker 本体のインストール:  #keyword: install Docker
            #// ホストOSと同じ Docker イメージのサイズは小さいです
            Docker Engine for WSL2 Rocky Linux 8: #keyword: install Docker for Rocky
                #ref: https://docs.rockylinux.org/gemstones/containers/docker/
                #ref: https://docs.rockylinux.org/gemstones/docker/   #// 旧
            Docker Engine for WSL2 Ubuntu: #keyword: install Docker for WSL2,  WSL2 Docker
                （初回の場合）バックアップが無い場合:
                    公式: #ref: https://docs.docker.com/engine/install/ubuntu/
                    設定: #settings:
                        __DockerDistribution__: Ubuntu-20.04-docker
                    WSL2 の Ubuntu を初期状態で複製します:
                        ディストリビューション名は Ubuntu-20.04-docker とします(例)  #search: WSL2 restore  #template: __DockerDistribution__
                    Docker のリポジトリを設定します:
                        Linux のセキュリティ更新を適用します:
                            sudo apt-get update
                        GPG をインストールします:
                            sudo apt-get install -y  ca-certificates  curl  gnupg  lsb-release
                        Dockerの公式GPGキーを追加します:
                            sudo mkdir -p /etc/apt/keyrings
                            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
                        リポジトリを設定します (/etc/apt/sources.list.d/docker.list): |
                            echo \
                                "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
                                $(lsb_release -cs) stable" | sudo tee  /etc/apt/sources.list.d/docker.list  > /dev/null
                    Docker Engine をインストールします:
                        パッケージインデックスを更新します:
                            sudo apt-get update
                        Docker Engine, containerd, Docker Compose をインストールします:
                            sudo apt-get install -y  docker-ce  docker-ce-cli  containerd.io  docker-compose-plugin
                        （プロキシ環境の場合）(/etc/default/docker) : |  #// インデントを削除して実行してください
                                echo "
                                export no_proxy='127.0.0.1,localhost'
                                export http_proxy='http://__ProxyServer__:__ProxyPort__'
                                export https_proxy='http://__ProxyServer__:__ProxyPort__'
                                " | sudo tee -a  /etc/default/docker  > /dev/null
                            #ref: https://qiita.com/y-na-biz/items/a82b3642eff9947e6f37
                        Docker を起動します:
                            - sudo service docker start
                            - sudo docker version
                                #// Client のバージョンと Server のバージョンが表示されること
                        サンプルを動作させます:
                            sudo docker run  hello-world  #search: docker hello-world
                        sudo を入力しないで docker コマンドを使えるようにします:  #search: docker sudo
                            sudo gpasswd --add  $USER  docker
                            newgrp docker
                            docker run  hello-world
                        再起動しても docker を使えるようにします:
                            Windows 10 の場合:
                                設定します: |  #keyword: WSL2 service-start
                                    mkdir -p ~/bin
                                    echo  'sudo service docker status > /dev/null  ||  sudo service docker start > /dev/null' \
                                        >> ~/bin/service-start
                                    chmod +x ~/bin/service-start
                                #// （メモ）このコマンドを実行するときは、パスワードの入力が求められます
                                #//     wsl.exe を経由して実行する方法は失敗します  #seaerch: WSL2 wsl.exe root command 
                                #// 以下に続きます
                            Windows 11 の場合: | #keyword: WSL2 boot command  #// インデントを削除して実行してください
                                    echo '
                                    [boot]
                                    command="service docker start"
                                    ' | sudo tee -a  /etc/wsl.conf  > /dev/null
                                #ref: https://learn.microsoft.com/ja-jp/windows/wsl/wsl-config#boot-settings
                                #// 以下に続きます
                            シャットダウンします:
                                Visual Studio Code を閉じます:
                                (bash):  #// wsl コマンドで起動した PowerShell の端末
                                    exit
                                (PowerShell):  #// 指定のディストリビューションを終了します
                                    wsl --terminate  "Ubuntu-20.04-docker"  #template: __DockerDistribution__
                        起動します:  #keyword: service-start
                            WSL2 Ubuntu を起動します:
                                wsl -d "Ubuntu-20.04-docker"   #template: __DockerDistribution__
                                #// sudo service docker start のために、毎回パスワードが求められます
                            Windows 10 の場合:
                                Docker サービスを起動します:  #// Windows 11 では不要です
                                    service-start
                                    #// パスワードの入力が求められます
                            サンプルを動作させます:
                                docker run  hello-world
                    Docker compose をインストールします:
                        インストールします:
                            sudo apt install -y  docker-compose
                        動作確認をします:
                            docker-compose --version
                    （推奨）できた Docker compose 環境をバックアップします:
                        #search: back up WSL2
                        #search: restore Docker for WSL2
                    （参考）使わなかった手順:
                        プロキシ:
                            proxy client:
                                ~/.docker:
                                    mkdir ~/.docker
                                cat > ~/.docker/config.json : |
                                    {"proxies": {"default": {"httpProxy": "__Proxy__", "httpsProxy": "__Proxy__", "noProxy": "192.168.*,local*" }}}
                            proxy server:
                                ~/bin:
                                    mkdir -p ~/bin
                                cat > ~/bin/startdocker.sh : |
                                    #!/bin/bash
                                    export http_proxy=http://__ProxyServer__:__ProxyPort__
                                    export https_proxy=http://__ProxyServer__:__ProxyPort__
                                    sudo -bE dockerd
                        再起動しても docker を使えるようにします:  #keyword: WSL2 Ubuntu-20 enable service
                            失敗A:
                                sudo update-rc.d docker defaults
                                #ref: https://askubuntu.com/questions/9382/how-can-i-configure-a-service-to-run-at-startup
                            失敗B:
                                sudo systemctl enable docker
                            失敗C:
                                sudo vi /etc/wsl.conf
                                    [boot]
                                    command="service docker start"
                                #// Windows 11 以上なら可能  #search: WSL2 boot command
                            失敗D:  #keyword: WSL2 wsl.exe root command 
                                ~/.bashrc:
                                    wsl.exe -u root service docker status || wsl.exe -u root service docker start
                                エラー: |
                                    docker: unrecognized service
                                #ref: https://askubuntu.com/questions/1355633/how-to-start-a-specific-service-when-ubuntu-is-started-on-wsl2
                            成功:
                                echo "sudo service docker start" >> ~/.bashrc
                バックアップから復帰する場合: #keyword: restore Docker for WSL2
                    docker の WSL2 を復帰します:
                        #search: WSL2 restore
                    起動します:
                        #search: service-start
            Docker Desktop for Windows: #keyword: install Docker for Windows  #// Docker Desktop for Windows インストール
                注意: Docker Desktop は大企業では有料です
                新しい方法:  #2021-06-21
                    条件: Windows 10 64-bit Home, Pro, Enterprise, or Education, version 1903 (Build 18362 or higher).
                    ダウンロード:
                        https://docs.docker.com/docker-for-windows/install/ >>
                            Docker Desktop for Windows ボタン >>
                            ダウンロードした Docker Desktop Installer.exe を開きます
                    Installing Docker Desktop ウィンドウ:
                        デフォルトのまま OK ボタン:
                        デフォルト設定:
                            Install required Windows coponnets for WSL2: チェック
                            Add shortcut to desktop: チェック
                        （約3分後）Close and restart ボタン:  #// PC が再起動します
                    エラー WSL2 installation is incomplete:
                        表示された URL をクリック:
                            - https://aka.ms/wsl2kernel  #// Docker のエラー表示は閉じないこと
                            - x64 マシン用 WSL2 Linux カーネル更新プログラム パッケージ
                            - wsl_update_x64.msi を実行
                        Restart ボタン:  #// Docker だけ再起動します
                        エラーが表示されたウィンドウが閉じられてしまったとき:
                            デスクトップの Docker Desktop をダブルクリック
                    Docker のウィンドウ:
                        表示されたお試しコマンドを実行します:
                            PowerShell を開きます:
                                Windows スタート >> PowerShell（と入力）  #// Visual Studio Code の Terminal でも可能
                            コマンド:
                                docker run -d -p 80:80 docker/getting-started
                            ブラウザーで localhost を開きます:
                                アドレスバー: localhost
                            Docker の文書が表示されたら成功です:
                                Congratulations! You have started the container for this tutorial!
                        Docker のウィンドウを閉じても Docker は動き続けます:
                    Error response が表示されたら:
                        #// エラー表示の詳細： docker: Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers).
                        メニュー: Windows の通知領域にある Docker アイコンを右クリック >> Settings
                        Resources:
                            PROXIES:
                                Manual proxy configuration: オン
                                Web Server (HTTP):          http://___.___.___.___:____
                                Secure Web Server (HTTPS):  http://___.___.___.___:____
                                Bypass proxy settings for these host & domains:
                                    127.0.0.1, localhost, 192.168.*  #search: no_proxy
                                Apply & Restart ボタン:
                古い方法:
                    ダウンロード:
                        https://docs.docker.com/docker-for-windows/install/ >>
                            Download from Docker Hub >> Get Docker >>
                            （しばらくして）Close and restart ボタン
                    エラー WSL2 installation is incomplete:
                        - 表示された URL をクリック:
                            - https://aka.ms/wsl2kernel  #// Docker のエラー表示は閉じないこと
                            - x64 マシン用 WSL2 Linux カーネル更新プログラム パッケージ
                            - wsl_update_x64.msi を実行
                        - Restart ボタン  #// Docker だけ再起動します
                更新方法:  #keyword: Docker update for Windows
                    Windows の通知領域にある Docker のアイコンに(!)が付いているとき:
                        Download update:
                            Docker アイコン（を右クリック）>> Download update（上から3番目）
                        Update ready to download のウィンドウが表示されたとき:
                            Download update ボタン
                        （約10秒後）Update and Restart:
                            Docker アイコン（を右クリック）>> Update and Restart（下から2番目）
                メモリーの使用量を減らします・増やします:  #keyword: WSL2 Docker memory size
                    Docker for Windows の場合:
                        Docker を終了させます:
                            （Windows 通知領域） Docker アイコン（を右クリック）>> Quit Docker Desktop >>
                            （シェルを開きます）>>（Docker と WSL2 の終了を待ちます）>>
                        Git bash または PowerShell:
                            wsl --shutdown
                        C:\Users\__Name__\.wslconfig : |
                            [wsl2]
                            memory=1GB
                        Docker を起動します:
                            Windows スタート >> Docker Desktop
                    Docker for Linux (WSL2) の場合:
                        Git bash または PowerShell:
                            wsl --shutdown
                        C:\Users\__Name__\.wslconfig : |
                            [wsl2]
                            memory=1GB
                    指定できるメモリーサイズ:
                        - 1GB に設定すると約 1.3GB 消費します 2021-07-20
                        - 512MB, 0.5GB はできません（デフォルト値＝搭載量の半分になります）
                            https://docs.microsoft.com/en-us/windows/wsl/wsl-config#configure-global-options-with-wslconfig
                        - WSL2 を使う場合、Docker に設定できません。 WSL2 に設定します
                            https://docs.docker.jp/docker-for-windows/
                            https://docs.docker.com/docker-for-windows/
                    参考:
                        WSL2 + Docker をメモリを節約しながら使えるか  https://zenn.dev/takajun/articles/4f15d115548899
                    関連:  #search: Docker-compose mem_limit
                Docker を WSL2 へ最適化します:  #keyword: Docker WSL2 best experience
                    ！: 未確認
                        WSL2 + Ubuntu から docker run を実行すれば速いという意味かも
                    参考:
                        Docker 公式:  #ref: https://docs.docker.com/docker-for-windows/wsl/#develop-with-docker-and-wsl-2
                        WSL2 Ubuntu:  #search: install WSL2 Ubuntu
            Docker for CentOS など:  #// Docker for CentOS インストール  #keyword: Docker for Linux,  install Docker for CentOS Linux
                参考: #ref: https://docs.docker.com/engine/install/centos/
                Vagrant Ansible を使う場合:  #// おすすめ
                    multi_vm_ansible の docker ブランチの README を参照  #search: multi_vm_ansible
                        #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_docker/README.yaml
                        #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_docker/playbook.yml  #// 2023-11-24
                手動の場合:
                    Docker リポジトリを設定します:
                        #bash in CentOS, RockyLinux8
                        - sudo yum install -y yum-utils
                        - sudo yum-config-manager  --add-repo https://download.docker.com/linux/centos/docker-ce.repo
                    最新バージョンの Docker をインストールします:
                        sudo yum install -y docker-ce docker-ce-cli containerd.io
                    （プロキシがあるLANにいる場合）プロキシを設定します:
                        Docker サービスに対する設定:
                            すでに設定があるかチェックします:
                                sudo docker info
                            設定が無かったら:
                                概要:
                                    /etc/systemd/system/docker.service.d/http-proxy.conf : |
                                        [Service]
                                        Environment="HTTP_PROXY=http://___.___.___.___:____"
                                        Environment="HTTPS_PROXY=http://___.___.___.___:____"
                                        Environment="NO_PROXY=localhost, 127.0.0.1, 192.168.*, 192.168.34.51, centos7"
                                    リロード:
                                コマンドで設定する場合:
                                    - sudo mkdir -p /etc/systemd/system/docker.service.d
                                    - echo -e "[Service]\nEnvironment=\"HTTP_PROXY=http://___.___.___.___:____\"" | \
                                        sudo tee /etc/systemd/system/docker.service.d/http-proxy.conf
                                    - echo -e "Environment=\"HTTPS_PROXY=http://___.___.___.___:____\"" | \
                                        sudo tee -a /etc/systemd/system/docker.service.d/http-proxy.conf
                                    - echo -e "Environment=\"NO_PROXY=localhost, 127.0.0.1, 192.168.*, 192.168.34.51, centos7\"" | \
                                        sudo tee -a /etc/systemd/system/docker.service.d/http-proxy.conf
                                    - sudo systemctl daemon-reload
                                    - sudo systemctl restart docker
                                    - sudo docker info
                                #// 参考: https://docs.docker.jp/config/daemon/systemd.html#id6
                        コンテナーに対する設定:
                            docker-compose を使わない場合:
                                mkdir -p  ~/.docker :
                                ~/.docker/config.json : |
                                    {
                                        "proxies": {
                                            "default": {
                                                "httpProxy": "http://___.___.___.___:____"
                                            }
                                        }
                                    }
                    Docker を起動します:
                        sudo systemctl enable docker
                        sudo systemctl start docker  #search: systemctl
                    Hello world コンテナーを起動できることを確認します: #keyword: docker hello-world
                        sudo docker run  --name hello_world_1  hello-world
                            #// 成功すれば、Hello from Docker! と約20行のメッセージが表示され、終了します
                            #// hello_world_1 はコンテナーを削除するときなどに使います
                    Hello world コンテナーを削除します:
                        docker rm  hello_world_1
                    （必要なら）docker-compose を バージョン アップ します:  #keyword: upgrade docker-compose,  install docker-compose
                        最新のバージョン番号を確認します:
                            #ref: https://github.com/docker/compose/releases
                        インストールします: |  #// バージョン 2.16.0 の場合
                            curl -L https://github.com/docker/compose/releases/download/v2.16.0/docker-compose-linux-x86_64 > docker-compose
                            sudo mv docker-compose /usr/local/bin/docker-compose
                            sudo chmod +x /usr/local/bin/docker-compose
                            docker-compose --version
                関連 >> CentOS Docker イメージ:  #search: Docker CentOS
        OS イメージ:  #search: Docker OS image
        各種サービスのインストール:  #keyword: install service Docker container
            （一般）:
                - 公式のコンテナーをそのまま使います。ただし、README を参考にパラメーターを指定する必要があります。
                - 公式のコンテナーがエージェントなどの場合、エージェントが使うモジュールをインストールしたイメージを作ります  #search: making docker image
                - 公式のコンテナーが無い場合、OSの公式イメージからサービスのイメージを作ります  #search: Docker OS image
            MySQL:  #search: MySQL Docker
        バージョン:  #keyword: Docker version
            本体のバージョン:
                確認:
                    docker --version コマンド
                一覧:
                    #ref: https://docs.docker.com/engine/release-notes/
            イメージのバージョン:  #keyword: Docker image version
                タグに書いてある場合:  #// latest タグのイメージと バージョンが書いてあるタグのイメージは、別のイメージとして扱われます
                    ダウンロード済みの場合:
                        概要:
                            コマンド:
                                docker images
                            出力例: |  #// IMAGE ID が一致すれば latest と同じイメージです
                                REPOSITORY             TAG              IMAGE ID       CREATED       SIZE
                                gitlab/gitlab-runner   latest           761107f87481   3 days ago    760MB
                                gitlab/gitlab-runner   ubuntu-v16.6.0   761107f87481   3 days ago    760MB
                            IMAGE ID:  #keyword: Docker IMAGE ID
                                IMAGE ID は DockerHub の DIGEST とは異なる値です
                        詳細:
                            コマンド: #keyword: docker inspect version
                                - docker inspect gitlab/gitlab-runner
                                    #template: docker inspect __User__/__ImageName__
                                    #// タグが省略されると latest を指定したときと同じ動きをします  #search: search Docker image tag
                                - docker inspect --format='Image ID = {{.Id}}, Architecture = {{.Architecture}}, Labels = {{.Config.Labels}}' gitlab/gitlab-runner
                                    #template: __User__/__ImageName__
                    サンプル:
                        - gitlab/gitlab-runner:ubuntu-v16.6.0
                タグを調べます:  #keyword: search Docker image tag
                    Tags のページを開きます:
                        #// 以下のいずれか
                        - https://hub.docker.com  >>  gitlab/gitlab-runner（を検索）>>（イメージ）>> Tags タブ
                        - https://hub.docker.com/r/gitlab/gitlab-runner  >>  Tags タブ
                            #template: https://hub.docker.com/r/__User__/__ImageName__  >>  Tags タブ
                        - https://hub.docker.com/r/gitlab/gitlab-runner/tags
                            #template: https://hub.docker.com/r/__User__/__ImageName__/tags
                    Filter Tags（検索ボックス）にタグの一部を入力します:
                        サンプル:
                            - ubuntu-v  #// gitlab/gitlab-runner:ubuntu-v16.6.0
                            - alpine-v  #// gitlab/gitlab-runner:alpine-v16.6.0
            文書設定: #settings:
                __User__: gitlab
                __ImageName__: gitlab-runner
        コンテナー起動: #keyword: make Docker container  #// OS イメージ
            OS イメージから作る場合: #keyword: Docker OS image,  Docker image catalog
                関連 >> 各種サービスのインストール:  #search: install service Docker container
                （ベストプラクティス）:
                    公式の軽量なコンテナーを Dockerfile の FROM に指定し、yum 等でインストールします  #search: making docker image
                    #ref: https://qiita.com/yoshii0110/items/0accb7f21fa1c375e0d7
                Ubuntu:
                    公式:  #ref: https://hub.docker.com/_/ubuntu
                        ubuntu:20.04  #ref: https://hub.docker.com/layers/library/ubuntu/20.04/images/sha256-a4fab1802f08df089c4b2e0a1c8f1a06f573bd1775687d07fef4076d3a2e4900?context=explore
                Rocky: #keyword: Docker Rocky,  Docker rockylinux
                    公式:  #ref: https://hub.docker.com/_/rockylinux
                        rockylinux:8.8.20230518-minimal:  #ref: https://hub.docker.com/_/rockylinux/tags?page=1&name=8.8
                        rockylinux:8.8.20230518:  #ref: https://hub.docker.com/_/rockylinux/tags?page=1&name=8.8
                        サンプル Dockerfile: |
                            FROM rockylinux:8.8.20230518

                            RUN  sudo dnf install -y  git  git-lfs  findutils  iputils  procps  bind-utils  iproute  which  mariadb-devel  gettext
                                #// git  git-lfs  #// git command
                                #// findutils     #// xargs command
                                #// iputils       #// ping command
                                #// procps        #// ps, top, kill, free command
                                #// bind-utils    #// nslookup, dig command
                                #// iproute       #// ip addr command
                                #// which         #// which command
                                #// mariadb-devel #// mysql_config command
                                #// gettext       #// msgfmt command

                            ARG  DOCKER_CE_CLI_VERSION=25.0.4
                            RUN  sudo yum install -y yum-utils  && \
                                sudo yum-config-manager  --add-repo https://download.docker.com/linux/centos/docker-ce.repo  && \
                                sudo yum install -y  docker-ce-cli
                            
                            ARG  DOCKER_COMPOSE_VERSION=v2.24.7
                                #// https://github.com/docker/compose/releases
                            RUN  sudo curl -L "https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose  && \
                                sudo chmod +x /usr/local/bin/docker-compose

                            ARG  GOLANG_VERSION=1.22.5
                            RUN  sudo curl -L  "https://go.dev/dl/go${GOLANG_VERSION}.linux-amd64.tar.gz"  \
                                    --output "/usr/lib/go${GOLANG_VERSION}.linux-amd64.tar.gz"  ||  Error
                            RUN  sudo rm -f     "/usr/lib/golang"  ||  Error  #// Remove old version Go language
                            RUN  sudo tar -xzf  "/usr/lib/go${GOLANG_VERSION}.linux-amd64.tar.gz"  -C "/usr/lib"  ||  Error
                            RUN  sudo mv        "/usr/lib/go"  "/usr/lib/golang"  ||  Error
                            RUN  sudo rm -f     "/usr/lib/go${GOLANG_VERSION}.linux-amd64.tar.gz"  ||  Error
                            RUN  sudo ln -sf    "/usr/lib/golang/bin/go"  "/usr/bin/go"  ||  Error
                            RUN  sudo ln -sf    "/usr/lib/golang/bin/gofmt"  "/usr/bin/gofmt"  ||  Error
                            RUN  go version  |  grep "${GOLANG_VERSION}"  ||  Error

                            ARG  NVM_VERSION=0.39.3
                            ARG  NODE_JS_VERSION=12.16.1
                            ARG  NODE_JS_ANOTHER_VERSION=16.20.1
                            RUN  curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v${NVM_VERSION}/install.sh  | bash
                            RUN  source ~/.bashrc  &&  nvm install ${NODE_JS_VERSION}
                            RUN  source ~/.bashrc  &&  nvm install ${NODE_JS_ANOTHER_VERSION}
                            RUN  source ~/.bashrc  &&  nvm use ${NODE_JS_VERSION}
                            RUN  echo  'export NVM_DIR="/home/vagrant/.nvm"'                                                                 | sudo tee     /etc/profile.d/nvm.sh  && \
                                echo  '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm'                                   | sudo tee -a  /etc/profile.d/nvm.sh  && \
                                echo  '[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion' | sudo tee -a  /etc/profile.d/nvm.sh
                            RUN  source ~/.bashrc  &&  npm install --global yarn
                Alpine Linux: #keyword: Docker Alpine Linux  #// 軽量 Linux OS のコンテナーを作ります  #search: Alpine Linux
                    起動コマンド:
                        docker container run -it alpine /bin/ash
                            #search: container without Dockerfile
                    イメージ名: alpine
                    参考:
                        超軽量な Alpine Linux について調べた:  #ref: https://qiita.com/ryuichi1208/items/6020cfabc92bd8153654
                CentOS: #keyword: Docker CentOS  #// CentOS7 の Docker コンテナー を WSL2 内に起動します
                    公式:  #ref: https://hub.docker.com/_/centos
                        Dockerfile:  #ref: https://hub.docker.com/_/centos  >>  Dockerfile for systemd base image
                    OS 単体の場合: #keyword: Docker CentOS7  #// この CentOS7 に VSCode のリモート接続は使えません。WSL2 に対しては使えます
                        WSL2 と docker をインストールします:
                            Ubuntu 20.04: #search: WSL2 restore
                        イメージ名: centos:7
                        起動コマンドの場合:
                            -   docker run -it centos:7 /bin/bash
                                    #search: container without Dockerfile
                            -   docker run  -v "${PWD}:/root/host"  -it centos:7  /bin/bash
                        プロジェクトの場合:  #keyword: docker_centos7  #ref: ${GitHub}/MyPrivateCode/docker/docker_centos7
                        コンテナー内で使えるコマンド:
                            ping, curl, yum, python(2.7.5) その他は ls /bin で分かります
                        コンテナー内で使えないコマンド:  #// 使えるようにします
                            pip:  #search: Python2 pip docker
                    CentOS7 + SSH サーバー の場合: #keyword: Docker CentOS SSH
                        WSL2 と docker をインストールします:
                            Ubuntu 20.04: #search: WSL2 restore
                        CentOS7 + SSH サーバー の Docker イメージを作ります:
                            プロジェクトの場合:  #keyword: docker_centos7_ssh  #ref: ${GitHub}/MyPrivateCode/docker/docker_centos7_ssh
                            手動の場合:
                                Dockerfile: |  #ref: (WSL2) ~/docker_centos7/Dockerfile
                                    FROM centos:7

                                    ARG http_proxy
                                    ARG https_proxy

                                    RUN yum -y update && yum -y install openssh-server openssh-clients sudo
                                    RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -N '' \
                                        && sed -ri 's/^#PermitRootLogin\s+.*/PermitRootLogin yes/' /etc/ssh/sshd_config \
                                        && sed -ri 's/UsePAM yes/#UsePAM yes/g' /etc/ssh/sshd_config
                                    RUN useradd docker && echo "docker:docker" | chpasswd && echo "docker ALL=(ALL) ALL" >> etc/sudoers
                                    EXPOSE 22
                                    CMD ["/usr/sbin/sshd", "-D"]
                                WSL2 bash: |
                                    docker build \
                                        --build-arg  http_proxy=http://__ProxyServer__:__Port__ \
                                        --build-arg https_proxy=http://__ProxyServer__:__Port__ \
                                        -t centos7_ssh "."
                        （2回目以降）古いコンテナーなどを削除します:
                            (WSL2 bash):
                                docker system prune --force
                        SSH サーバー のコンテナーを起動します:
                            (WSL2 bash):
                                docker run -d  -p 5022:22  --name centos7_ssh-1  centos7_ssh
                        WSL2 から SSH サーバー にログインします:
                            (WSL2 bash):
                                ssh docker@localhost -p 5022  #// パスワードは docker
                        Windows から SSH サーバー にログインします:
                            (git bash):  #// WSL2 と同じコマンドです
                                ssh docker@localhost -p 5022  #// パスワードは docker
                    MySQL Docker:  #search: install MySQL Docker
            イメージを作る場合: #keyword: making docker image  #// コマンドを途中まで実行した結果をバックアップしてき、少しずつイメージを作っていきます
                設定: #settings:
                    __NewImageName__: example_service
                Docker をインストールします:
                    #search: install Docker
                公式と変わらないイメージを作ります:
                    参考:  #search: install service Docker container
                    サンプル:
                        ./Dockerfile:
                            FROM  centos:7  #// 例
                        (@host):
                            - docker build  -t example_service:s0  "."   #template: -t __NewImageName__:s0  #// step 0
                最初のコマンドを実験します:  #focus: yum install
                    (@host):
                        - docker container run -it example_service:s0  /bin/bash  #template: -it __NewImageName__
                    (@example_service):  #template: (@__NewImageName__)
                        - yum install -y java  #// 最初のコマンド
                        - exit
                最初のコマンドをイメージに入れます:
                    ./Dockerfile:  #focus: s0,  yum install
                        FROM  example_service:s0
                        RUN \
                            yum install -y \
                                java
                    (@host):  #focus: s1
                        - docker build  -t example_service:s1  "."   #template: -t __NewImageName__
                ２つ目のコマンドを実験します:  #focus: curl
                    (@host):  #focus: s1
                        - docker container run -it example_service:s1  /bin/bash
                    (@example_service):  #template: (@__NewImageName__)
                        -   mkdir -p ~/Downloads/wiremock  && \
                            cd       ~/Downloads/wiremock  && \
                            curl -O  https://repo1.maven.org/maven2/com/github/tomakehurst/wiremock-jre8-standalone/2.33.2/wiremock-jre8-standalone-2.33.2.jar
                        -   exit
                ２つ目のコマンドをイメージに入れます:
                    ./Dockerfile:  #focus: s1, curl  #// FROM のタグを s1 に変え、RUN を２つ目のコマンドに置き換えます
                        FROM  example_service:s1
                        RUN \
                            mkdir -p ~/Downloads/wiremock  && \
                            cd       ~/Downloads/wiremock  && \
                            curl -O  https://repo1.maven.org/maven2/com/github/tomakehurst/wiremock-jre8-standalone/2.33.2/wiremock-jre8-standalone-2.33.2.jar
                    (@host):  #focus: s2
                        - docker build  -t example_service:s2  "."   #template: -t __NewImageName__
                以上を最後のコマンドまで繰り返します:
                全てのコマンドを実行するイメージを作ります:
                    ./Dockerfile:  #focus: centos,  yum install,  curl
                        FROM  centos:7
                        RUN \
                            yum install -y \
                                java
                            mkdir -p ~/Downloads/wiremock  && \
                            cd       ~/Downloads/wiremock  && \
                            curl -O  https://repo1.maven.org/maven2/com/github/tomakehurst/wiremock-jre8-standalone/2.33.2/wiremock-jre8-standalone-2.33.2.jar
                    (@host):  #focus: 1.0.0
                        - docker build  -t example_service:1.0.0  "."   #template: -t __NewImageName__
                途中のイメージを削除します:
                    #search: delete docker image
            起動待ち:
                Linux nc:  #search:
                wait-for-it.sh:  #search: wait-for-it.sh
                HEALTHCHECK, 完了条件: #keyword: Dockerfile HEALTHCHECK
                    サンプル:  #// HTTP サーバーがアクセスできるようになったら起動完了とします
                        Dockerfile:
                            HEALTHCHECK --interval=5m --timeout=3s \
                                CMD curl -f http://localhost/ || exit 1
                    関連:
                        docker-compose:  #search: docker-compose healthcheck
                    参考:
                        #ref: https://docs.docker.com/engine/reference/builder/#/healthcheck
                        #ref: https://stackoverflow.com/questions/21183088/how-can-i-wait-for-a-docker-container-to-be-up-and-running
            無限 sleep:  #search: docker container run -d sleep
            (関連) >> Docker Hub:  #search: Docker Hub
        クリーン, prune:  #keyword: Docker prune clean
            docker system prune   #search: delete docker image
        アップロード: #keyword: upload Docker image
            GitLab: #keyword: GitLab upload Docker image
                Docker イメージを用意します:
                プライベート Docker リポジトリ を使えるようにします:  #keyword: プライベート Docker リポジトリ
                    GitLab リポジトリ >> Settings（左下）>> General >>
                    Visibility, project features, permissions >> Container registry（をオン、Everyone With Access に）>>
                    Save Changes（下）
                    #search: GitLab Docker permissions
                （レアケース）基本認証を使う場合:  #search: GitLab members
                    必要なロール: #search: GitLab Roles  #// Docker レジストリ への登録など
                        レジストリへの create, delete: Maintainer, ...
                        レジストリへの push: Developer, Maintainer, ...
                    ログインします:
                        docker login  registry.gitlab.com
                            基本認証を使います
                PAT を使う場合:
                    personal access token (PAT) を作ります:
                        メニュー: https://gitlab.com/-/profile/personal_access_tokens >> Add new token（右上）
                            #// URL は https://gitlab.com/ >> アカウント アイコン >> Preferences
                        Token name: __TokenName__
                        Select scopes:
                            Docker レジストリ―に登録する場合: api  #// これだけで OK
                            実験開始時: （すべてにチェック）  #// PAT は慎重に扱い、毎日削除・更新するなどしてください
                        Create personal access token ボタン:
                        （Copy personal access token）ボタン:
                        （ローカルの安全な場所に貼り付け）:  #search: ❗secret
                        （トークン名もコピペ）:
                        （開発環境へ保存する場合）:
                            ~/secret/GitLabPAT/__Name__
                        リロード（PAT を閉じます）:
                    ログインします: #keyword: docker login registry steps
                        (docker をインストールした VM の bash):
                            - docker login  registry.gitlab.com  -u Takakiriy  #// Password: と表示されたら __PAT__ を貼り付けて Enter キーを押します
                                #// または
                            - docker login  registry.gitlab.com  -u Takakiriy  -p __PAT__
                                #template: -u __GitLabAcount__  -p __PAT__
                            #// ホスト名は GitLab なら Container Registory の Web ページにあります
                        エラーが発生した場合:
                            メッセージ: |
                                dial unix /var/run/docker.sock: connect: permission denied
                            対処:
                                newgrp docker
                ローカルにある Docker イメージに ターゲット イメージ タグ が付いていることを確認します:
                    確認コマンド:
                        docker images
                    ターゲット イメージ タグ:  #search: Docker target image tag  #search: docker tag
                        docker tag  "__ImageName__:__TagName__"  __Host__/__User__/__Project__/__ImageName__:__TagName__
                push します:  #// アップロードします
                    docker push  __Host__/__User__/__Project__/__ImageName__:__TagName__
                        #// docker images コマンドで表示されたタグを貼り付けます
                        #// __Host__ は GitLab なら Container Registory の Web ページにあります
                登録を確認します:
                    プロジェクト URL: https://gitlab.com/takakiriy1/first  #template: __GitLabUser__/__Reposiroty__
                    メニュー: プロジェクト >> Deploy >> Container Repository
                        または  プロジェクト >> Packages & Registories >> Container Repository
                ログアウトします:
                    docker logout  #// パラメーターなし
                ログインしているか:
                    確認方法不明
                    #// cat ~/.docker/config.json | grep registry.gitlab.com はログアウトしても表示されます
                動作確認します:
                    #search: docker run
                （不要になったら）PAT を削除します:
                    メニュー: https://gitlab.com/-/profile/personal_access_tokens >> Personal Access Tokens >> ゴミ箱 ボタン
                #ref: https://docs.docker.com/engine/reference/commandline/login/#credential-stores
        ログイン:  #keyword: Docker login,  Docker log in,  Docker container login bash
            #snip:  docker exec  -it __ContainerName__  bash
            コンテナー(VM)にログインする場合:
                コンテナー名をメモします:
                    docker ps --format "{{.Names}}"  #// で表示された一覧の中の、対象のコンテナー名を __ContainerName__ とします
                ログインします:
                    コンテナーの起動に成功している場合:
                        コンテナーの中に bash が有る場合:
                            docker exec -it  __ContainerName__  bash
                        コンテナーの中に bash が無い場合:
                            - docker exec -it  __ContainerName__  sh
                            - docker exec -it  __ContainerName__  /bin/sh
                    コンテナー起動時に終了してしまう場合:  #// Dockerfile の CMD のデバッグ時など
                        docker run コマンドのコマンド引数に bash を指定するかコマンド引数を bash に変更します:  #search: docker run command argument
                            docker run -it --rm  --name __NewContainerName__  __DockerImageName__  bash
                        docker-compose.yml : |
                            entrypoint: '/bin/sh -c "sleep infinity"'
                        #// 既存の entrypoint は # でコメントアウトします
                参考: #ref: ${programming}/OS/VMWare.svg#Docker_exec
            docker-compose を使う場合:  #search: docker-compose login
            Docker リポジトリにログインする場合:  #// docker login コマンド  #search: docker login registry steps
        環境依存を無くす:  #// Docker コンテナー は Linux の種類やバージョンの影響を受けない
            環境判定:
                /.dockerenv: | #keyword: /.dockerenv,  IsInDockerContainer  #// Docker コンテナーの中なら /.dockerenv にファイルがあります
                    function  IsInDockerContainer() {
                        test  -f  "/.dockerenv"
                    }
            注意:
                GPU を使うプログラム: Linux では動かない可能性が高い
        ベストプラクティス: #keyword: Docker ベストプラクティス
            Qiita: #ref: https://qiita.com/yoshii0110/items/0accb7f21fa1c375e0d7
            公式: #ref: https://docs.docker.jp/engine/userguide/eng-image/dockerfile_best-practice.html
            コンテナごとに１つのプロセスだけ実行します:  #ref: https://docs.docker.jp/engine/userguide/eng-image/dockerfile_best-practice.html#id5
                水平スケールやコンテナの再利用を簡単にします。
                サービスとサービスに依存関係がある場合は、 コンテナのリンク を使います。
    画面, ダッシュボード:  #// 主に Windows 用、コンテナー、ボリューム、イメージを一覧するウィンドウです  #keyword: Docker Dashboard
        公式:
            開く: （Windows 通知領域）Docker（を右クリック）>> Dashboard
            画面構成:
                設定（歯車ボタン, 右上）:
                    Resources:
                        PROXIES: #🌟
                メニュー項目（左）:  #// コンテナーなどの CRUD 操作もできます
                    Containers / Apps:
                        コンテナー（行）:
                            （イメージ名）:  #// Dockerfile の内容の一部？
                            （行をクリック）:
                                LOGS: #🌟 #// 標準出力
                                INSPECT:  #// PATH, マウント（ボリューム）, ポート番号
                                STATS:  #// CPU 使用率、メモリー使用量、ディスク アクセス量、ネットワーク帯域使用量
                            OPEN IN BROWSER:  #// 右上への矢印 ボタン
                            CLI: #🌟  #// >_ ボタン
                            STOP:  #// ■ ボタン
                            RESTART:  #// 右回転矢印 ボタン
                            DELETE: #🌟  #// ゴミ箱 ボタン  #keyword: Docker Dashboard DELETE
                    Images:
                    Volumes:
        Dockhand: #keyword:  #ref: https://gigazine.net/news/20260117-dockhand/
    ファイル:
        Dockerfile: #glossary: Dockerfile  #keyword:  #// イメージを作る設定ファイル  #ref: ${programming}/OS/VMWare.svg#make_Docker_image_from_Dockerfile
            公式: #ref: http://docs.docker.jp/engine/reference/builder.html
            概要:  #search: 起動のしくみ, コンテナー型の仮想化技術
            手順:
                Dockerfile なしの場合:  #keyword: container without Dockerfile  #// Dockerfile を作らなくても、コマンドだけでコンテナーを起動できます
                    基本:
                        docker container run -it alpine /bin/ash
                            #// alpine イメージからコンテナーを起動して /bin/ash シェルを開きます
                Dockerfile ありの場合: #keyword: Dockerfile example1
                    基本:  #focus: docker build
                        ./Dockerfile を作ります:
                            FROM  centos:7
                            RUN   yum install -y  java
                        コマンド:
                            docker build  -t centos7_java  "."
                            docker run -it --rm  --name centos7_java-1  centos7_java
                            #search: docker build
                    一般的なイメージの作成手順: #search: making docker image
                docker-compose.yml に置き換える場合:  #search: Dockerfile to docker-compose.yml
                マルチ ステージ ビルド: #keyword: Docker multi stage build  #ref: https://matsuand.github.io/docs.docker.jp.onthefly/develop/develop-images/multistage-build/
                    概要: ある Dockerfile が作ったイメージ A の中の特定のフォルダーを、別の Dockerfile が作ったイメージ B の中にコピーし、
                        イメージ A を削除します。
                    関連:
                        Dockerfile の RUN をグループ化する場合:  #search: Docker RUN script
                    参考:  #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: multi Dockerfile
                Dockerfile を複数作る:  #// 1つのイメージを作る内容を複数の Dockerfile に分けて書くことができます
                    参考:  #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: multi Dockerfile
                    関連 >> マルチ ステージ ビルド: #search: Docker multi stage build
                デバッグ: #keyword: debug Dockerfile  #// Dockerfile の中のデバッグ
                    docker build 実行時にエラーになる場合:  #// RUN 命令 に書いたコマンドの終了コードが 0 以外のとき
                        docker build 実行時の出力の最後: |  #// 普通にコマンドを実行したときと同様のエラーメッセージが表示されます
                            Step 5/7 : RUN  echo "aaa"  |  sed 's/a/'
                             ---> Running in 9990f17e0b22
                            sed: -e expression #1, char 4: unterminated `s' command
                            The command '/bin/sh -c echo "aaa"  |  sed 's/a/'' returned a non-zero code: 1
                            ERROR
                        #// 次の Docker 命令は実行されません
                        #// Docker イメージは作られません
                        #// CMD 命令 に書いたコマンドの実行によるエラーは docker build 実行時に発生しません
                        Using cache が表示されたとき:
                            - コマンドの出力は表示されません。
                            - 出力されるようにするには docker build に --no-cache オプションを付けます。
                            - キャッシュを全削除する方法もありますが非推奨です  #search: delete docker image
                        デバッグ方法:  #search: debug Dockerfile  >>  RUN 命令 のデバッグ
                    docker run 実行時にエラーになる場合:  #// CMD 命令 または docker run に書いたコマンドの終了コードが 0 以外のとき
                        サンプル: |
                            $ docker run -d -p 5022:22 --name centos7_ssh-1 centos7_ssh
                            060d950192c9219c54efcf2d11cd1748d89b4f888f2df6065918165efcd0d39e
                            docker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: exec: "/usr/sbin/sshd": stat /usr/sbin/sshd: no such file or directory: unknown.
                            ERROR
                        デバッグ方法:  #search: debug Dockerfile  >>  CMD 命令 のデバッグ
                    docker ps の STATUS が Exited の場合:  #search: docker ps STATUS Exited
                    RUN 命令 のデバッグ:  #// エラーは docker build 実行時に発生します
                        echo デバッグ:  #// RUN 命令 に echo を入れると docker build 実行時に表示されます
                            Dockerfile の一部:
                                RUN  echo "aaa"  &&  echo "bbb"
                            docker build 実行時の出力の一部: |
                                Step 5/7 : RUN  echo "aaa"  &&  echo "bbb"
                                ---> Running in 9990f17e0b22
                                aaa
                                bbb
                            --progress=plain オプション:
                                docker build  --tag __DockerImageName__  __ProjectFolderPath__  --progress=plain
                    CMD 命令 のデバッグ:  #// エラーは docker run 実行時に発生します
                        ログイン デバッグ:  #// コンテナーのシェルを開いてコマンドを実行してみます
                            docker run コマンドを一時的に変更します:
                                docker run -it --rm  --name __NewContainerName__  __DockerImageName__  bash
                                #// docker run コマンドのコマンド引数に bash を指定するかコマンド引数を bash に変更します
                                #search: docker run command argument
                                #search: Docker login
                            ログインしたらコマンドを実行します:
                                CMD に書かれたコマンドや、その他の任意のコマンドを実行できます。
            サンプル:  #search: Dockerfile example1
            #// 以下は Dockerfile の命令
            FROM:  #// ベースとするイメージ  #ref: http://docs.docker.jp/engine/reference/builder.html#from
                書式: #keyword: docker image name,  __DockerImageName__  #search: docker tag
                    - FROM __DockerImageName__   #// :__TagOrVersion__ を省略すると :latest を指定したときと同じ指定になります
                    - FROM __DockerImageName__:__TagOrVersion__
                    - FROM __Author__/__DockerRepositoryName__:__TagOrVersion__
                    - FROM __Host__/__User__/__Project__/__ImageName__:__TagName__  #search: Docker target image tag
                サンプル:
                    - FROM  centos:7
                    - FROM  tiangolo/uwsgi-nginx-flask:python3.6
                ホスト, __Host__:  #// ホストであることの見分け方
                    最初の「スラッシュ」より左に、ピリオド（.）または、コロン（:）があれば、ホスト名（とポート番号）であると認識します。
                    スラッシュが無ければ、コロンがあってもホスト名であると認識しません。
                    ホスト名の指定が無ければ、Docker Hub (docker.io）が指定されたときと同じ動きをします。
                手順: #search: making docker image
                プロキシ:
                    FROM で使われるプロキシは、ホストマシン上での Docker デーモンの設定や 環境変数 http_proxy, https_proxy によって制御されます
            RUN:  #// コマンドを実行した結果のファイル構成が Docker イメージに入ります
                ベストプラクティス:
                    - RUN コマンドでイメージを作るのではなく、公式のイメージを使います
                    - docker-compose.yml に RUN 相当のフィールドが無いため、docker-compose.yml だけで完結せず、Dockerfile が必須です
                    - RUN コマンドを複数書くことができます。ただし、1つの RUN ごとにキャッシュが作られます
                    - RUN コマンドを書く前に、コンテナーの中のシェルから実験してみます #search: making docker image
                    - RUN コマンドをグループ化するときは、スクリプトを書きます  #search: Docker RUN script
                書式:
                    RUN __ShellCommand__
                    RUN __ShellCommand__  # __Comment__    #// コメントはシェルに渡された後で、コマンドから除外されます
                    #// RUN コマンドをならべていきます
                非推奨コマンド:
                    cd:  #search: Dockerfile WORKDIR
                    su:  #search: Dockerfile USER
                    変数定義, .bashrc:  #search: Dockerfile ENV  #search: Dockerfile ARG
                サンプル:  #//🌟 パッケージをインストールします。 Docker ホスト にある RPM をインストールします。 ユーザーを追加します。
                    基本:
                        - RUN  yum install -y  java
                        - RUN  yum install -y \
                            java
                        - RUN \
                            yum -y update  && \
                            yum install -y  java
                    Docker ホスト にある RPM をインストールします: #keyword: Docker install RPM
                        COPY \
                            your-package.rpm  \
                            /tmp/
                        RUN \
                            dnf install -y  /tmp/your-package.rpm  && \
                            rm  /tmp/your-package.rpm   #// Reduce image size
                        #search: Dockerfile COPY
                    ユーザーを追加します:  #search: Docker user
                出力を表示します: #keyword: echo docker build
                    概要: 終了コードを 0 以外にする（false を実行する）ことで、出力が表示されるようになります
                    docker build コマンドのオプションを指定する場合: | #keyword: --progress=plain
                        $ docker build  __Parameters__  --progress=plain
                        ...
                        #7 [4/4] RUN  python3 --version
                        #7 0.395 Python 3.8.10
                        #7 DONE 0.5s
                    RUN コマンドを編集する場合:
                        Dockerfile:
                            RUN  echo  $http_proxy;  python3 --version;  false
                            #// 表示したら続きを実行できません
                        出力: |  #focus: 192.168.1.111,  3.8.10
                            ...
                            => CACHED [4/5] RUN apt-get install -y python3
                            => ERROR [5/5] RUN  echo  http://192.168.1.111:8080;  python3 --version;  false
                            ------
                            > [5/5] RUN  echo  http://192.168.1.111:8080;  python3 --version;  false:
                            0.436 http://192.168.1.111:8080
                            0.439 Python 3.8.10
                プロキシ:  #// http_proxy, DNS
                    環境変数:
                        RUN で使われるプロキシは、Dockerfile ENV や ARG の http_proxy, https_proxy によって制御されます
                        #search: Docker proxy ENV
                スクリプトを実行する場合:  #keyword: Docker RUN script  #// モジュール化ができます
                    Dockerfile の一部:  #// スクリプトごとにまとめるとキャッシュが効きやすくなります  #focus: install_example
                        COPY  scripts_in_docker/install_example.sh  /share/
                        RUN   chmod +x  /share/install_example.sh
                        RUN   /share/install_example.sh

                        COPY  scripts_in_docker/install_example_2.sh  /share/
                        RUN   chmod +x  /share/install_example_2.sh
                        RUN   /share/install_example_2.sh
                    参考:  #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: multi Dockerfile
                手順: #search: making docker image
                サービスのポートが準備できるまで待つとき:
                    #search: wait-for-it.sh
                履歴:  #// これまで実行してきたコマンドを表示します。依存するイメージの中のコマンドも含みます。
                    #search: docker history
                トラブルシューティング (Dockerfile RUN):
                    - #// プロキシの設定
                        手順: docker build  -t __NewImageName__ "."
                        Dockerfile: |
                            FROM centos:7
                            RUN yum -y update && yum -y install openssh-server openssh-clients sudo
                        エラー: |
                            Could not retrieve mirrorlist ____
                        対処:  #search: Docker container proxy
            CMD:  #// コマンドを実行します。 Docker イメージの中のファイル構成は変わりません。Docker イメージ には CMD に関する情報は入ります
                概要: docker run コマンドに __Command__ 引数を指定しなかったときに実行されるコマンドです  #search: docker run command argument
                スコープ:
                    docker build コマンド実行時: CMD に指定したコマンドを実行しません
                    docker run コマンド実行時:
                        __Command__ 指定時: CMD に指定したコマンドを実行しません
                        __Command__ 指定なしの時: CMD に指定したコマンドを実行します
                起動パターンがいろいろあるとき:
                    スクリプトを Docker イメージ に入れて、そのスクリプトのオプションで起動パターンを選びます
                サンプル:  #// __Command__ を指定せずに docker run を実行してコンテナーを起動したときに実行するスクリプト
                    COPY ["__RelativePathInDockerHost__", "__FullPathInDockerImage__"]
                    RUN  sudo chown  __User__:__Group__  "./cmd.sh"
                    RUN  sudo chmod +x  "./cmd.sh"
                    CMD  ["./cmd.sh"]
                    #search: GitHub runner Dockerfile
            ENTRYPOINT:  #// コマンドを実行するためのコマンド。 Docker イメージの中のファイル構成は変わりません
                _: CMD に書かれたコマンドが、ENTRYPOINT で書かれたコマンドの引数になります
                サンプル:
                    Dockerfile が:
                        ENTRYPOINT ["/docker-entrypoint.sh"]
                        CMD        [ "--https-port", "8443", "--verbose" ]
                    なら、実行するコマンドは: |
                        /docker-entrypoint.sh  --https-port 8443  --verbose"
                参考: #ref: ${programming}/OS/VMWare.svg#Dockerfile_ENTRYPOINT
                ファイル構成:
                    Docker イメージの中のファイル構成は変わりません  #search: 起動のしくみ, コンテナー型の仮想化技術
            ENV:  #// 環境変数、値埋め込み  #ref: https://docs.docker.jp/engine/reference/builder.html#builder-env
                概要: 環境変数が定義されます
                スコープ: 環境変数の定義はイメージに入り、コンテナー起動時（実行開始時）にも設定されます
                基本:  #// Dockerfile
                    -   ENV MY_NAME John
                    -   ENV  MY_NAME  "John Doe"       #// ENV __Name__ __Value__  # __Comment__ はできません。 " " で囲まないと、空白区切りになります
                    -   ENV  MY_NAME  "John Doe"       # __Comment__   #// コメントは書けます
                    -   ENV  MY_NAME  "John ${MyARG}"  #// ARG などで定義した変数を含めることができます
                設定変更:  #// コンテナ―を起動するときに環境変数の値を変更します
                    docker run:  #// コンテナ―の環境変数を設定します
                        --env: 
                            docker run ____ --env __Key__=__Value__
                    docker exec:  #// プロセスの環境変数を設定します
                        -e, --env: #keyword: docker exec --env,  docker exec -e option  #// 環境変数
                            docker exec -it  -e http_proxy=${http_proxy}  -e https_proxy=${https_proxy}  __ContainerName__  __Command__
                        #// docker run で指定したら docker exec で指定しなくてもよいです。
                表示:
                    コンテナ―:  #// コンテナ―内の環境変数の値を表示します
                        docker inspect --format='{{range .Config.Env}}{{println .}}{{end}}' __ContainerName__
                    プロセス:  #// コンテナ―内のプロセスの環境変数の値を一覧します
                        docker exec -it  -e http_proxy=${http_proxy}  -e https_proxy=${https_proxy}  __ContainerName__  env
                参照, コマンドのパラメーター: #keyword: evaluate docker environment variable
                    ホスト OS の環境変数:
                        docker exec -it  --user __User__  __ContainerName__  echo  "$HOME"
                    コンテナーの環境変数:
                        echo "$HOME" の場合:  #// ~ も展開できます
                            docker exec -it  --user __User__  __ContainerName__  bash -c 'echo "$HOME"'
                        echo "$HOME" '$HOME' の場合: #keyword: docker exec single quote   #// シングルクォートを含む場合  #focus: $HOME
                            コマンド: docker exec -it  --user __User__  __ContainerName__  bash -c 'echo "$HOME" '"'"'$HOME'"'"
                            解説: |
                                - bash -c オプションは、[ 'echo "$HOME" ',  "'",  '$HOME',  "'" ] という構成になっています。
                                - '____' のすぐ右に "'" を書くと引数の値の続きとして ' を追加します。
                            ボツ:  #// \ でエスケープします（できません）
                                docker exec -it --user docker centos7_ssh-1 /bin/bash -c 'echo "$HOME" \'$HOME\''
                                #// コマンドが途中であると解釈され、続きの入力を要求されます
                        ホスト OS の環境変数と混合する場合:  #focus: $HOME
                            docker exec -it  --user __User__  __ContainerName__  bash -c 'echo "$HOME" '"$HOME"
                            #// コンテナーの HOME 変数と、ホスト OS の HOME 変数を表示します
                            #search: docker exec single quote
                    環境変数を展開しない:
                        docker exec -it  --user __User__  __ContainerName__  echo  '$HOME'
                .bashrc: #keyword: Docker .bashrc  #search: .bashrc  #// Docker を使わないときは .bashrc に環境変数を設定していた場合
                    変数定義:
                        #// 以下のような環境変数の定義であれば、Dockerfile RUN ではなく Dockerfile ENV を使います
                        Dockefile:  #// 以下は非推奨。docker run で変更できないため
                            RUN  echo  "export http_proxy=${http_proxy}\nexport https_proxy=${https_proxy}\n" >> /home/gitlab-runner/.bashrc
                    コンテナ―内 .bashrc: 読まれるのは、docker run または docker exec で bash を指定したとき。
                        なので、環境変数の定義であれば Dockerfile ENV を使います。
                        bash 以外を指定したときは読まれません
                他は ARG とほぼ同じです:  #search: Dockerfile ARG
            ARG:  #// ビルド時設定（コンテナー起動時には定義されません）
                スコープ:
                    - ARG による環境変数の定義はイメージに入りません。入れるには改めて ENV で定義してください  #search: Dockerfile ENV
                    - ~/.bashrc に変数定義を書いても docker run や docker exec で bash を起動しない限り、定義されません
                Dockerfile:
                    サンプル: | #focus: http_proxy,  https_proxy
                        FROM centos:7
                        ARG  http_proxy
                        ARG  https_proxy
                        ENV  http_proxy="${http_proxy}"
                        ENV  https_proxy="${https_proxy}"
                        ARG  UID=1000
                        ARG  GID=1000
                        RUN  yum -y update && yum -y install openssh-server openssh-clients sudo
                    補足:
                        デフォルト値:
                            ARG  http_proxy="__DefaultValue__"
                        ENV:  #// Dockerfile 内だけでなく、コマンドの中でも環境変数として参照できるようになります
                            ENV  http_proxy="${http_proxy}"
                bash: |  #// ARG で定義した変数に値を指定します。この値はできるイメージの中に入ります
                    docker build \
                        --build-arg http_proxy=http://__ProxyServer__:__Port__ \
                        --build-arg https_proxy=http://__ProxyServer__:__Port__ \
                        -t __NewImageName__ "."
                参照:  #ref: https://docs.docker.jp/engine/reference/builder.html#environment-replacement
                プロキシを設定する場合:  #search: Docker proxy ENV
                シークレットを変数に入れるとき:  #search: Dockerfile ARG
                環境変数を参照します:
                    できません。
                    下記はエラーになります。
                        bash
                            echo "493" > _env
                        Dockerfile
                            RUN  sudo groupadd  docker  --gid $(cat /____/_env | xargs)
                --build-arg オプションを必須にする:
                    Dockerfile: |
                        ARG MY_VARIABLE
                        RUN if [ -z "${MY_VARIABLE}" ]; then echo "ERROR: MY_VARIABLE is not set"; exit 1; fi
                参考:  #search: Docker proxy
            COPY:
                サンプル: |
                    COPY \
                        "files/image-1.0.0.tar.gz" \
                        "/in_container/"
                URL をコピー元にする:  #// できませんが、代わりの方法があります
                    RUN \
                        curl -OL https://example.com/file.tar.gz
                制限: #keyword: Docker build context
                    _: Build context の外（親フォルダー）を指定できません  #ref: https://stackoverflow.com/questions/24537340/docker-adding-a-file-from-a-parent-directory
                    対処: |  #// build context（カレント フォルダー）を HOME などに変えて実行します
                        if echo "$0" | grep "/" | grep -E -v "bash-debug|systemd" > /dev/null; then  cd "${0%/*}"  ;fi  # cd this file folder
                        ScriptPath="$0"
                        ScriptFolderRelativePath="${ScriptPath%/*}"
                        ScriptFolderPath="$( readlink -f "${ScriptFolderRelativePath}" )"
                        DockerFilePath="${ScriptFolderPath}/Dockerfile"

                        cd  "${HOME}"  #// Move Docker build context

                        docker build  -f "${DockerFilePath}"  -t service1  "."  ||  exit  1
                古いサンプル: COPY [ "files/image-1.0.0.tar.gz",  "/in_container/" ]
            ADD:  #// 非推奨。COPY と同じ。ただし、圧縮ファイルを指定したら展開します
                注意: COPY を使うことを推奨します
                ADD file: #keyword: Docker ADD file
                    概要:
                        - Docker Hub でこのコードが表示されます  #search: Docker Hub Dockerfile
                        - __ImageHash__ を検索することはできないようです
                    書式: |
                        ADD file: __ImageHash__ in /
                    #ref: https://stackoverflow.com/questions/63823884/docker-image-layer-what-does-add-filesome-hash-in-mean
            WORKDIR:  #// カレント フォルダー  #ref: https://docs.docker.com/engine/reference/run/#workdir
                Docker イメージの中で cd コマンド（カレント フォルダーの変更）を実行します。
                デフォルトは、ルート(/)
            EXPOSE:  #// ポート番号  公式: #ref: http://docs.docker.jp/engine/reference/builder.html#expose
                注意:
                    - EXPOSE を設定しなくても docker run -p オプションでポートにアクセスできます。
                    - 単なるコメントのようです。 #ref: http://docs.docker.jp/engine/reference/builder.html#expose
                書式:
                    EXPOSE __PortNumInContainer__
                サンプル:
                    EXPOSE 80
            VOLUME:  #// コンテナー内で保存しようとしたデータを保存できるようにします。ホストOS のストレージのどこかに保存します
                書式:
                    - VOLUME __FullPathInContainer__
                    - VOLUME __FullPathInContainer__ __FullPathInContainer__  #// 空白区切り
                    - VOLUME __JSON_Array__
                    - VOLUME __HostRelativePath__:__FullPathInContainer__  #// 使えません  #search: Docker shared folder
                サンプル:
                    - VOLUME /home/user/data
                    - VOLUME ["/home/user/data"]
                #ref: http://docs.docker.jp/engine/reference/builder.html#volume
                参考:  #search: Docker volume
            USER:  #search: Docker user  #// Docker コンテナー のサービスを VM 内で実行するユーザー
                docker build 実行時:  #// 現在のユーザーをスイッチします
                    USER コマンド: 現在のユーザーをスイッチします
                    ユーザーの作成:
                        Dockerfile のサンプル:  #focus: github-runner
                            FROM rockylinux:8.8.20230518
                            RUN  useradd  "github-runner"
                            RUN  echo  "github-runner:github-runner" | chpasswd
                            RUN  mkdir -p  "/home/github-runner"
                            RUN  chown  "github-runner:github-runner"  "/home/github-runner"
                            RUN  dnf install -y sudo
                            COPY [ "files/sudoers",  "/etc/sudoers" ]
                            USER github-runner
                            WORKDIR  /home/github-runner
                        files/sudoers: #keyword: Dockerfile sudoers  #search: sudo no password
                            パスワードなしに対応した /etc/sudoers
                        files/sudoers.old:  #// 編集内容が分かるようにするためのバックアップです
                            パスワードなしに対応する前の /etc/sudoers
                        #search: GitHub runner Dockerfile
                docker run 実行時: 最も下の USER がデフォルトのユーザーになります。docker run/exec の --user(-u) オプションで変更できます
        compose.yaml, docker-compose.yml:  #search: compose.yaml
        /etc/docker/daemon.json:
    コマンド: #glossary:  #keyword: docker command  #ref: https://docs.docker.com/engine/reference/commandline/cli/
        (sudo の入力を不要にします):  #keyword: sudo docker  #// docker コマンドを入力するときに sudo も一緒に入力する必要をなくします
            Vagrant Ansible を使う場合:
                Playbook で設定する場合:
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_docker/playbook.yml#sudo gpasswd
                        - gpasswd
                        - reboot
            手動で設定する場合:
                docker グループに所属させます:
                    #// @node1 で作業します
                    （必要なら）docker グループが存在することを確認します:
                        getent group docker
                    （必要なら）現在のユーザーが docker グループに所属していないことを確認します:
                        groups $USER
                    現在のユーザーを docker グループに所属させます:
                        sudo gpasswd --add  $USER  docker
                    （必要なら）現在のユーザーが docker グループに所属していることを確認します:
                        groups $USER
                    以下のいずれか:
                        docker グループにログインします:
                            newgrp docker
                        VM (@node1) を再起動します:  #// ユーザー プロファイル のリロードと、docker サービスの再起動
                （補足）: #// 以下ではうまくいきません
                    docker サービスの再起動:
                        sudo service docker restart
                    ユーザー プロファイル のリロード:
                        SSH 接続している VSCode の新しい Terminal:
                        SSH 接続している VSCode の再起動:
                        リモート上の VS Code サーバーのクリーンアップ:  #ref: https://code.visualstudio.com/docs/remote/troubleshooting#_cleaning-up-the-vs-code-server-on-the-remote
                            #// 以下は未確認。SSH 接続した VSCode では失敗します。Virtual Box のウィンドウではコピペができません（下記コマンドは試していません）。
                            kill -9 $(ps ax | grep "remoteExtensionHostAgent.js" | grep -v grep | awk '{print $1}')
                            kill -9 $(ps ax | grep "watcherService" | grep -v grep | awk '{print $1}')
                            rm -rf ~/.vscode-server 
        (コマンドが使えるかチェックします): | #keyword: check docker command,  docker: command not found
            docker --version > /dev/null  ||  Error "ERROR: docker command not found."
        WSL2 コマンド: #keyword: PowerShell WSL2 Docker command,  Docker PowerShell command  #// WSL2 内のコンテナ―に対して PowerShell などから docker コマンドを使います
            docker ps:  #// ファイルパスを指定しない場合
                #// Git bash または PowerShell
                wsl -d __Distro__ -- docker ps
                    または
                wsl -- docker ps
            ls:  #// ファイルパスを指定する場合
                Git bash の場合:
                    powershell "wsl -d __Distro__ -- ls /home"
                        または
                    powershell "wsl -- ls /home"
                    #// powershell を経由しないと、ls: cannot access 'C:/Program Files/Git/home': No such file or directory
                PowerShell の場合:
                    wsl -d __Distro__ -- ls /home
                        または
                    wsl -- ls /home
            その他の主なコマンド:
                #search: PowerShell WSL2 docker cp
                #search: PowerShell WSL2 docker exec
        docker run,  docker container run: #keyword:  #// コンテナーを新しく起動します。必要ならダウンロードします  #ref: https://docs.docker.com/engine/reference/commandline/run/
            #// docker container run は Docker 1.13 で可読性を上げるために導入されましたが、古いバージョンでは使えません。全く同じ機能です。
            手順:
                コンテナーを起動します:
                    フォアグランドの場合:  #// シェルがある場合
                        書式: docker run -it --rm  --name __NewContainerName__  __DockerImageName__  #search: docker image name
                        サンプル: docker run -it --rm  --name hello_world_1  hello-world
                        実行内容: RUN 命令 に書かれたコマンドと CMD 命令 に書かれたコマンドを実行します  #search: docker run command argument
                        __DockerImageName__:  #search: docker image name
                    バックグラウンドの場合:
                        子プロセスを作る場合:
                            書式: docker run -d  --name __NewContainerName__  __DockerImageName__  #search: docker image name
                            実行内容: RUN 命令 に書かれたコマンドと CMD 命令 に書かれたコマンドを実行します  #search: docker run command argument
                        現在のプロセスの場合:  #// unit file など TTY が無い環境の場合
                            書式: docker run -i --rm  --name __NewContainerName__  __DockerImageName__  #search: docker image name
                            実行内容: RUN 命令 に書かれたコマンドと CMD 命令 に書かれたコマンドを実行します  #search: docker run command argument
                        #search: docker container run -d sleep
                コンテナーを起動してコマンドを実行します: #keyword: docker run command argument
                    書式: docker run -it --rm  --name __NewContainerName__  __DockerImageName__  __Command__  #search: docker image name
                    実行内容: __Command__ があると RUN 命令 に書かれたコマンドと __Command__ を実行します。 CMD 命令 に書かれたコマンドは実行しません
                    起動済みのコンテナーの中でコマンドを実行します: #search: docker exec
                起動待ち:  #// サービスのポートが開くまで待ちます
                    #search: make Docker container
                終了します, Ctrl + C:  #keyword: docker ctrl+C
                    Ctrl + C で終了するプロセスの場合:
                        Ctrl + C を押します:
                        反応しない場合:
                            docker run コマンドに -it --rm オプションを付けます
                            #search: docker run -it --rm option
                        #// ターミナルを閉じても終了しません
                    それ以外の場合:
                        新しくシェルを開き、コンテナーを終了・削除させます:
                            #search: delete docker image
                docker-compose を使う場合:  #search: docker-compose build
            書式:  #// docker run コマンドの書式
                - docker run -it --rm  --name __NewContainerName__  __DockerImageName__
                - docker run -it --rm  --name __NewContainerName__  __DockerImageName__  __Command__
                #search: docker run  >>  手順
            ❗注意（オプション共通）:
                iptables の編集:  #search: Docker iptables  #// デフォルトでは、インターネットからコンテナーにアクセスできるようになります
                オプションの指定場所:
                    docker run -it --rm  --name ${ContainerName}  ${ImageName}
                    に下記のオプションを追加指定するときは、ImageName より左に指定してください。
            -d オプション:  #// デタッチド モード（バッググランド実行）
                _: |
                    docker run -it --rm  ____ の代わりに
                    docker run -d  ____  を使うと、バックグラウンドで動作します
                バックグラウンドで何もしない場合: #keyword: docker container run -d sleep,  docker container idle
                    起動:
                        docker run  --name __ContainerName__  -d  rockylinux:9.3  bash -c "trap 'exit 0' TERM;  sleep infinity  &  wait"
                            #// If sleep command only, docker stop command will be slow.
                            #// 主な処理は、trap 'exit 0' TERM;  sleep infinity  &  wait
                            #// sleep だけでは docker stop コマンドが遅くなります
                    起動待ち:
                        docker exec -it  __ContainerName__ bash -c 'ls /proc  |  xargs -I{} cat /proc/{}/comm  2> /dev/null  |  grep sleep'
                ログ:  #search: docker logs
                終了:  #search: docker stop
            -it --rm オプション: #keyword: docker run -it --rm option,  docker exec -it option  #// キー入力をコンテナーが受け取れるようにします
                概要:
                    キー入力や Ctrl + C を押して終了させることができるようになります
                    #search: docker ctrl+C
                詳細:
                    -i オプション: #keyword: docker i option  #// インタラクティブ。これがないとコンテナーが標準入力を受け取らない
                        リダイレクトもパイプも使わない場合:  #// -t オプションも追加します（tty を割り当てます）
                            docker run -it --rm  busybox  bash  または  /bin/bash
                        リダイレクトやパイプを使う場合:
                            echo test | docker run -i busybox cat
                    -t オプション: #keyword: docker t option  #// ターミナル。tty を使います。これがないとシェルから起動しないので Ctrl + C を受け取れない
                        #// 逆にターミナルがない環境で指定するとエラーになります
                    --rm オプション: 実行が完了したときにコンテナーを削除します
                公式: #ref: http://docs.docker.jp/engine/reference/run.html#foreground
            -e, --env オプション: #keyword: docker run --env  #// 環境変数を指定します  #ref: http://docs.docker.jp/v19.03/engine/reference/commandline/run.html#e-env-env-file
                変数名と値を指定する場合:
                    --env __VariableName__=__Value__
                ホストOSの値を使う場合:
                    --env __VariableName__
            -p オプション: #keyword: docker run -p option,  Docker port mapping  #// ホストOS とゲストOS の間で ポート マッピング します  #keyword: docker port forwarding
                書式:
                    -p __HostOSPortNum__:__GuestOSPortNum__
                    --publish __HostOSPortNum__:__GuestOSPortNum__
                関連:
                    Dockerfile EXPOSE: #search:
            -v オプション: #keyword: docker run -v option  #// ホストOS とゲストOS の間でフォルダーを共有します
                書式:
                    -v __PathInHost__:__PathInContainer__
                    --volume __PathInHost__:__PathInContainer__
                ❗注意 >> Docker ボリューム:  #search: Docker volume
            --restart: #keyword: docker run --restart option  #// ホストOS が再起動したときに自動的に起動します
                docker run -d --restart unless-stopped  --name gocd-server-1  -v /home/vagrant/godata:/godata  -v /home/vagrant:/home/go  -p8153:8153  gocd/gocd-server:v{{ gocdServerVersion }}
                #ref: https://docs.docker.com/config/containers/start-containers-automatically/
            --link:  #// 非推奨  #ref: https://qiita.com/tamanobi/items/8b8dd64ae1f959f9ff9f
            --name: コンテナー名  #// イメージ名より前に指定してください
            参考: #ref: ${programming}/OS/VMWare.svg#Docker_run
            起動のしくみ, コンテナー型の仮想化技術: #keyword:
                1. Dockerイメージから新しいコンテナを作成します。
                2. ネットワーキングを設定し（NAT、ブリッジ、など）、それぞれのコンテナにユニークなIPアドレスを割り当てます。
                3. ファイルシステムをマウントします。DockerはUnion File Systemという技術を使用して、
                    複数の層からなるイメージファイルシステムを一つの統一されたビューとして表示します。
                4. DockerイメージのCMDまたはENTRYPOINTで指定されたアプリケーションを開始します。
                    または、docker runコマンドの末尾に追加されたコマンドがある場合はそれを実行します。
                #search: Union File System
            関連:
                ダウンロードだけする場合:  #search: docker pull
                Ansible:  #search: Ansible docker_container module
        docker exec: #keyword:  #// 起動済みコンテナーの中で新しいプロセスを作ります。通常、並列する 2つ目のプロセスを起動するときに使います。 #ref: https://docs.docker.com/engine/reference/commandline/exec/
            起動済みのコンテナーにログインします: #keyword: Docker bash
                書式: docker exec -it  __ContainerName__  bash  または  /bin/bash
                #search: docker run -it --rm option
            起動済みのコンテナーでコマンドを実行します:  #// 新しいプロセスを作ます
                書式: docker exec  -it  __ContainerName__  __Command__  __Parameters__
                ユーザー指定, USER 環境変数:  #// 自動的には定義されません
                    docker exec  -u __User__  -e USER=__User__  __ContainerID__  bash
                ~/.bashrc:
                    自動的に呼ばれませんが、明示的に呼び出すことはできます。
                スクリプトを呼び出す場合: |  #// /share は docker run -v で共有してから
                    docker exec -it  --user docker  ${ContainerName}  \
                        /share/wait_for_it.sh  localhost  22  \
                スクリプトでコマンド列を作る場合: |
                    local  commands=""
                    commands="${commands}  mkdir -p  ~/.ssh  &&"
                    commands="${commands}  touch  ~/.ssh/authorized_keys  &&"
                    commands="${commands}  ls -l  ~/.ssh"
                    commands="$( echo "${commands}"  |  sed -E 's/&&/&\n/g' )"
                    echo  "$ ${commands}"

                    docker exec -it  --user docker  ${ContainerName}  bash -c "${commands}"  ||  Error
                バックグラウンドで実行する場合: #keyword: Docker exec background
                    docker exec  __ContainerIdOrName__  /bin/sh -c "__Command__  __Parameters__  2>&1"  > _.log &
                パラメーターやパイプなどをコンテナ―内で使う場合: #keyword: docker exec bash -c
                    docker exec -it  __ContainerName__ bash -c '__Command__ __Wildcard__ | __Command2__'
                    docker exec -it  Rocky9 bash -c 'ls /proc | xargs -I{} cat /proc/{}/comm 2> /dev/null | grep sleep'
                標準入力へ転送:  #keyword: docker exec stdin  #// シークレットを渡すときは、これが最も安全。パラメーターで渡すとログに残ってしまいます
                    ホスト側: |
                        printf '%s\n%s\n' "${VAULT_ROLE_ID}" "${VAULT_SECRET_ID}"  \
                        | docker exec -i app-container /usr/local/bin/vault-login-stdin.sh
                    コンテナー側:
                        vault-login-stdin.sh: |
                            echo  "Reading VAULT_ROLE_ID ..."
                            read  VAULT_ROLE_ID
                            read  VAULT_SECRET_ID
                            exec  0<&-  #// close stdin  または  exec < /dev/null  #// close stdin
                            echo  "Closed stdin."
                            echo  "${VAULT_ROLE_ID}"
                環境変数の設定:  #keyword: docker exec -e
                    docker exec  -u __User__  -e USER=__User__  __ContainerID__  bash
                環境変数の展開:  #search: evaluate docker environment variable
                WSL2 コマンド: #keyword: PowerShell WSL2 docker exec  #// Windows から WSL2 内のコンテナ―のコマンドを実行します  #search: PowerShell WSL2 Docker command
                    # (Git bash)
                    powershell "wsl -d __Distro__ -- docker exec -it __ContainerName__  __Command__  __Parameters__"
            その他のオプション:  #search: docker run
                _: docker run と同じものが使えます
                --env: #keyword: docker exec --env,  docker exec -e option  #// 環境変数
                    必要性: docker run で指定したら docker exec で指定しなくてもよいです。
                    サンプル: docker exec -it  -e http_proxy=${http_proxy}  -e https_proxy=${https_proxy}  __ContainerName__  env  #// コンテナー内の環境変数を一覧します
                ~, ~__User__:  #// ホームを表す ~
                    docker run のパラメーターに ~ を指定することはできません。
                    / (root) に ~ という名前のフォルダーができてしまいます。
                    /home/user1 のようにフルパスで指定してください。
            関連 >> ssh 経由でコマンド実行:  #search: ssh remote command
        docker ps:  #// コンテナーを一覧します  #ref: https://docs.docker.com/engine/reference/commandline/ps/
            コマンドの例:  docker ps -a
            コマンドの例の説明:
                sudo: Docker for Linux で必要です
                -a: 終了したコンテナーも表示します
            オプション:
                -a: #keyword: docker ps -a  #// 終了したコンテナーも表示します
                --filter:  #// 特定の行だけ表示します
                    name: docker ps -a --filter "name=__ContainerName__"  #// 指定した名前のコンテナ―の行だけ表示します
                --format:  #// 出力形式
                    シンプル:  #search: docker ps status
                        --format "{{.Status}}"   #// STATUS 列 の値だけ表示します
                    table:  #search: docker ps status
                        --format "table {{.Names}}\t{{.Status}}"  #// NAME 列と STATUS 列のタイトルと値を表示します
            表の説明:  #// docker ps の出力の見かた
                サンプル:
                    CONTAINER ID   IMAGE         COMMAND               CREATED         STATUS    PORTS                                   NAMES
                    77091483d5a6   centos7_ssh   "/usr/sbin/sshd -D"   2 minutes ago   Created   0.0.0.0:5022->22/tcp, :::5022->22/tcp   centos7_ssh-1
                STATUS: #glossary: docker ps STATUS
                    Running, Up (__Time__): コンテナが稼働中で、指定されたコマンドを実行しています。
                    Created: コンテナは作成されたがまだ開始されていないことを示しています。
                        CMD 命令が失敗してプロセスの生成が失敗したときも Created になります  #search: debug Dockerfile
                    Exited (__ExitCode__): コンテナが停止し、動作していません。これは、コンテナが正常に終了したか、何らかのエラーが発生した結果である可能性があります。
                        CMD 命令が成功した後でプロセスがエラーを発生したときは Exited です。プロセスのプログラムをデバッグします
                    Paused: コンテナが一時停止状態で、その実行は一時的に停止されています。
                    Restarting: コンテナが再起動中です。
                    Dead: コンテナが不適切な状態で、再起動や削除ができない状態です。
            コンテナー名を一覧します:  #keyword: docker ps container name
                docker ps --format "{{.Names}}"
            1つのコンテナー名を変数に代入します:
                ContainerName="$( docker ps --format "{{.Names}}"  |  grep "^__Header__" )"  &&  echo "${ContainerName}"
                docker exec -it  ${ContainerName}  bash   #// 利用サンプル
            1つのコンテナー、または 1つの属性を表示します:
                STATUS のみ: #keyword: docker ps status
                    docker ps --format "{{.Status}}" -f "name=__ContainerName__"
                    #// 指定したコンテナーが存在しなければ何も表示されません
                タイトル, ID, STATUS:
                    docker ps --format "table {{.ID}}\t{{.Status}}" -f "name=elastic-1"
            VSCode で一覧する:  #search: VSCode Dev Containers
            関連 >> 別のコンテナーを指すホストが見つからない:  #search: docker DNS trouble
        docker inspect: #// コンテナーの情報を詳しく表示します
            基本:
                docker inspect __ContainerName__
            バージョン:  #search: docker inspect version
            ネットワーク:  #search: docker network inspect
            ボリューム:  #search: docker inspect volume
        docker stop: #search:
        docker rm: #search:  #// コンテナーを削除します
        docker build:  #// イメージを作ります
            概要:
                - ビルドに成功すると、ローカルのどこかにイメージが作られます
                - イメージの一覧は、docker images コマンドで表示できます
                - できたイメージを実行するには、docker run コマンドを使います
                - docker build と docker run を繰り返すときは、スクリプトにするのが良いでしょう
            書式: |
                docker build  --tag __DockerImageName__  __ProjectFolderPath__  --progress=plain
            関連 >> キャッシュのクリア:  #// クリアして再ビルドしないと、ダウンロードが失敗することを検出できないことがあります
                docker system prune --all
            __DockerImageName__:  #// 作るイメージの名前。FROM に指定されます  #search: Dockerfile FROM
                タグ（コロンの右）を付けなかった場合、タグは latest になります。
                たとえば、--tag centos7_java は centos7_java:latest という名前のイメージができます。
            __ProjectFolderPath__:  #// Dockerfile があるフォルダーのパス
            --progress=plain: コマンドの出力を表示します
            -f, --file オプション:  #// Dockerfile のパスを指定します
            -t, --tag オプション:  #// Docker イメージの名前を指定します
            手順: #search: making docker image
        docker images:  #search: docker tag  #// ローカルにあるタグと image ID を一覧します
            #search: Docker image
            削除, docker image rm:  #keyword: docker image rm
                docker image rm  "__ImageName__:__Tag__"   #// 複数指定可能
        docker tag:  #ref: https://docs.docker.com/engine/reference/commandline/tag/
            手順:
                追加:  #// タグをローカルに追加します
                    docker tag  __SourceImage__:__TagName__  __TargetImage__:__TagName__
                    #// 追加できたら docker images で確認できます
                表示:  #// ローカルにあるタグと Docker イメージ ID を一覧します
                    docker images
                    #search: Docker image version
                バージョンを調べます:  #search: docker image version
            概念:
                ソース イメージ タグ, ローカル イメージ タグ: #keyword: Docker source image tag,  docker tag,  docker image tag
                    書式:  #focus: __TagName__
                        __SourceImage__:__TagName__
                    #search: docker image name
                ターゲット イメージ タグ, リモート イメージ タグ: #keyword: Docker target image tag
                    書式:
                        - __TargetImage__:__TagName__
                        - __Host__/__User__/__Project__/__ImageName__:__TagName__
                        - __Host__:__PortNum__/__User__/__Project__/__ImageName__:__TagName__
                    作成:  #// ターゲット イメージ タグ を追加します
                        docker images
                        docker tag  __SourceImage__:__TagName__  __TargetImage__:__TagName__
                    サンプル:
                        GitHub: ghcr.io/your-username/your-project/myimage:v1.0
                        GitLab: registry.gitlab.com/your-username/your-project/myimage:v1.0
                    キャッシュ的なリポジトリ:  #// プライベート Docker リポジトリ に DockerHub に公開されているイメージを配置するとき
                        __Host__/__User__/__Repository__ の部分を プライベート Docker リポジトリ に合わせます。
                        つまり、同じイメージに対して異なるタグを追加します。
                イメージとの関係:
                    1つのイメージに複数のタグを付けることができます
                リポジトリとの関係:
                    ダウンロード時:
                        ダウンロードしたときにイメージに設定する ソース イメージ タグ は、リポジトリの URL の末尾です
                    アップロード時:
                        リポジトリの URL と一致するように ターゲット イメージ タグ を設定します
                記憶場所:
                    ローカル Docker 環境:
                    リモート Docker レジストリ:
                    #// Docker イメージ には入っていません
        docker history:  #// これまで実行してきたコマンドを表示します。依存するイメージの中のコマンドも含みます。
            書式:
                docker history  __DockerImageName__  --no-trunc
                #// --no-trunc を外すと長い内容が省略され、表形式になります
            公式:
                #ref: https://docs.docker.jp/engine/reference/commandline/history.html
        docker commit:  #// 今動いてるコンテナーを image にします
            docker commit  "__Container__"  "__ImageName__:__Tag__"
            docker history  "__ImageName__:__Tag__"
                #// docker run に指定したイメージからの差分がイメージになります
        docker pull:  #ref: https://docs.docker.jp/engine/reference/commandline/pull.html
            -   docker pull debian
            -   docker pull mysql:8.0
        docker push:  #search: upload Docker image
        docker save:  #// ベースイメージの内容も含めて、すべてのレイヤーを保存します
            既存のイメージを保存する場合: |
                docker pull  "__ImageName__"
                    #// または docker pull  "__ImageName__:__Tag__"
                docker save  --output "__OutputFolder__/__ImageName__-__Tag__.tar"  "__ImageName__:__Tag__"
                    #// --output の短いオプション名は -o です
                #// scp などで転送します
            現在のコンテナーを保存する場合: |  #// イメージ化を含みます
                docker commit dev-container myimage:tmp
                docker save myimage:tmp > myimage.tar
        docker load: |
            #// scp などで転送してから
            docker load  --input "__TarFilePath__"
                #// --input の短いオプション名は -i です
            docker run  "__ImageName__"
        docker cp:  #ref: https://docs.docker.jp/engine/reference/commandline/cp.html
            コマンド: docker cp  "/path/to/file"  "my_container:/path/in/container"
            WSL2 コマンド: #keyword: PowerShell WSL2 docker cp  #// Windows のファイルを WSL2 内のコンテナ―にアップロードします  #search: PowerShell WSL2 Docker command
                コマンド:
                    # (Git bash)
                    powershell "wsl -d __Distro__ -- docker cp  '/mnt$( pwd )/README.yaml'  '__ContainerName__:/root'"
                トラブルシューティング:
                    - #// copying between containers is not supported
                        手順: wsl -d Rocky9 docker cp  "/mnt/c/path/to/file.txt"  "Rocky9:/path/"
                        ログ: copying between containers is not supported
                        対処: wsl の -- オプション を書いてください
            パーミッション:
                -a オプションなし: コマンドを実行する UID:GID
                -a オプションあり: ファイルの UID:GID
                修正:  #// コピーした後でパーミッションを変更できます  #focus: chown, id_rsa
                    docker exec -i  container-1  mkdir -p "/home/user2/.ssh"
                    docker cp  "/home/user1/.ssh/id_rsa"  "container-1:/home/user2/.ssh/id_rsa"
                    docker exec -i  container-1  sudo chown user2:user2  "/home/user2/.ssh/id_rsa"
        ボリューム関連のコマンド:  #search: Docker volume command
        ネットワーク関連のコマンド:  #search: Docker network command
    構成, 概念:
        イメージ:  #keyword: Docker image  #// パッケージ, ファイル システム
            ID:  #search: Docker IMAGE ID
            一覧: #keyword: docker images
                全部:
                    シェル: docker images
                    Dashboard:
                        Dashboard を開きます:  #search: Docker Dashboard
                        メニュー: Images（左）
                    関連:
                        イメージを削除します:
                自分が pull または build したイメージ全部: docker images  "*"
                一部にマッチするものだけ一覧する:
                    書式:
                        - docker images  "__Prefix__*"
                        - docker images  "[__RepositoryHost__/]__Prefix__*"
                    サンプル: docker images  "docker/k*"  #// "docker/kube-compose" にマッチします
                    __RepositoryHost__: ワイルドカードは指定できません
                イメージの構成:  #// イメージの依存関係を表示します
                    dive:
                        注意: dive を使っても FROM はハッシュ値です
                        dive インストール:
                            wget https://github.com/wagoodman/dive/releases/download/v0.9.2/dive_0.9.2_linux_amd64.deb
                            sudo apt install ./dive_0.9.2_linux_amd64.deb
                            rm ./dive_0.9.2_linux_amd64.deb
                            #ref: https://github.com/wagoodman/dive
                            #ref: https://stackoverflow.com/questions/32454679/how-to-see-tree-view-of-docker-images
            削除: #keyword: delete docker image,  delete docker container,  docker stop,  docker rm,  remove delete docker container
                Dockerイメージなどを削除します:  #// 停止についてもここに書いてあります。イメージ ＝ VM全体の内容。キャッシュにもなる
                    ダッシュボードを使う場合:  #search: Docker Dashboard
                    1つの Docker コンテナ―停止・イメージを削除します: #🌟
                        コンテナーの名前を調べます:
                            - docker ps -a   #// コンテナーを一覧します。表示された表の最も右の列にある対象のコンテナー名を __ContainerName__ とします
                            - docker ps -a | grep __DockerImageName__
                                #// -a オプションはプロセスが終了したコンテナーも表示します
                            #// または docker ps --format "{{.Names}}"
                        コンテナーを停止して削除します: #keyword: Docker delete command
                            -   docker stop __ContainerID__  #// STATUS が Exit ではない場合のみ stop します
                            -   docker rm   __ContainerID__
                            #// 複数指定することもできます  docker rm   __ContainerID_A__  __ContainerID_B__  __ContainerID_C__
                        #↓ 停止・削除をリクエスト後
                        動作中というエラーになった場合:
                            - docker stop  __ContainerName__  &&  docker rm  __ContainerName__
                        #// 強制削除するときは、docker rm に --force オプションを追加します
                        docker stop が遅い場合:
                            - フォアグランド実行して、Ctrl + C を押すと早く終了できます  #search: docker ctrl+C
                            - 無限 sleep している場合  #search: docker container run -d sleep
                        イメージを削除します:
                            - docker images  #// 存在するイメージを一覧します
                            - docker image rm __DockerImageName__:__Tag__  #keyword: docker image rm  #// イメージを削除します
                                #// docker rmi は docker image rm の古いコマンド名です。同じ機能です  #keyword: docker rmi
                                #// Untagged という表示だけで Deleted が表示されないときでも成功を表します
                                #// 同じイメージに関連付けられているすべてのタグが削除されると Deleted と表示されます
                    すべてのコンテナーを stop します:
                        docker stop $(docker ps -aq)
                    exit したすべてを削除します:
                        docker container prune
                    不要なものと最新バージョン以外を一括削除します: #keyword: docker system prune
                        - docker system prune --force
                            #// 停止したコンテナー、タグ無しイメージ、未使用ボリューム、未使用ネットワークを一括削除します
                            #// 最新バージョンのイメージは残ります。
                            #ref: https://docs.docker.jp/config/pruning.html
                    不要なものを全て削除します:
                        - docker system prune --all --force
                            #// すべてのイメージを削除します
                            #// --all または -a オプションを指定しないと、最新バージョンのイメージは残ります。
                    確認しないで削除します:
                        --force オプションを付けます
                トラブルシューティング:
                    - #// Error response from daemon: conflict: unable to delete __ImageID__ (cannot be forced) - image has dependent child images
                        手順: docker rmi __ImageID__
                        エラー: |
                            Error response from daemon: conflict: unable to delete __ImageID__ (cannot be forced) - image has dependent child images
                        対処:
                            コンテナーを停止・削除してからイメージを削除します
                参考:
                    #ref: https://docs.docker.com/storage/storagedriver/#images-and-layers
                    #ref: https://www.creationline.com/lab/35518
            カタログ:  #search: Docker image catalog
            バージョン:  #search: Docker image version
            hello-world: |  #keyword: docker hello-world
                $ sudo docker run  hello-world
                Unable to find image 'hello-world:latest' locally
                latest: Pulling from library/hello-world
                2db29710123e: Pull complete
                Digest: sha256:faa03e786c97f07ef34423fccceeec2398ec8a5759259f94d99078f264e9d7af
                Status: Downloaded newer image for hello-world:latest

                Hello from Docker!
                This message shows that your installation appears to be working correctly.

                To generate this message, Docker took the following steps:
                    1. The Docker client contacted the Docker daemon.
                    2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
                        (amd64)
                    3. The Docker daemon created a new container from that image which runs the
                        executable that produces the output you are currently reading.
                    4. The Docker daemon streamed that output to the Docker client, which sent it
                        to your terminal.

                To try something more ambitious, you can run an Ubuntu container with:
                    $ docker run -it ubuntu bash

                Share images, automate workflows, and more with a free Docker ID:
                    https://hub.docker.com/

                For more examples and ideas, visit:
                    https://docs.docker.com/get-started/
            カスタマイズ:  #search: making docker image
            ダウンロード:  #search: docker pull
            アップロード:  #search: upload Docker image
            エクスポート:  #search: docker save
            インポート:  #search: docker load
            Union File System, ユニオン ファイル システム:  #keyword: Union File System
                Docker における「ファイルシステム」はあいまいな用語です。
                Union File System という「ファイルシステム」は、複数の層（レイヤー）からなるイメージファイルシステムを一つの統一されたビューとして表示する
                ext4 などのファイルシステムをラップするファイルシステムです。
                docker run コマンドを実行したときにマウントする「ファイルシステム」は、「ファイル構成」を含んだものです。
                #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: Docker file system
                #search: 起動のしくみ, コンテナー型の仮想化技術
            ファイル構成:  #keyword: Docker file structure
                Dockerfile の RUN 命令を実行してファイルが作られたら、ファイル構成は変わり、レイヤーが作られます。
                ファイル構成が変わらなくても新しいレイヤーは作られます。
                #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: Docker no changed layer
        コンテナー:  #// Docker をベースとしたプロセス
            Docker コマンド: #search: docker command
            すべて停止します: #keyword: delete all docker container  #// すべてのコンテナーに対して docker stop, dpcker rm します
                docker stop $(docker ps -a -q)
                docker rm $(docker ps -a -q)
            削除:  #search: delete docker image
            起動のしくみ, コンテナー型の仮想化技術: #search:
            ログ: #search: docker logs
            Docker in Docker: #keyword:  #ref: https://zenn.dev/kesin11/articles/20230514_container_hooks
                概要:
                    Docker outside of Docker (DooD): #keyword: Docker outside of Docker,  DooD  #ref: ${my_images}/2024/docker-outside-of-docker.png
                        サンプル:  #search: GitHub runner DooD Dockerfile
                        docker コマンドの実行:
                            /var/run/docker.sock を Docker ホスト の VM と共有し、
                            コンテナーの docker コマンドを実行すると、Docker ホストの VM の Docker デーモン に指示が行きます
                        systemctl コマンドの実行:
                            かきかけ
                            DOCKER_HOST_IP_ADDRESS  #search: Docker DooD localhost
                        他のコンテナーへのアクセス:  #keyword: Docker DooD localhost
                            書式: __DockerHostIPAddress__:__Port__
                            解説:
                                Docker ホスト から localhost:3306 でコンテナーB へアクセスできる場合、
                                コンテナ―A 内の localhost:3306 では、外のコンテナーB へアクセスできません。
                                コンテナ―A 内からホストの IP アドレス 192.168.____.____:3306 でアクセスできます。
                            サンプル シェルスクリプト:
                                起動:
                                    DOCKER_HOST_IP_ADDRESS=192.168.0.111  ./curl-example.sh
                                curl-example.sh:  #focus: DOCKER_HOST_IP_ADDRESS
                                    #!/bin/bash
                                    if [ "${DOCKER_HOST_IP_ADDRESS}" == "" ]; then
                                        DOCKER_HOST_IP_ADDRESS="localhost"
                                    fi
                                    curl -f -X GET "http://${DOCKER_HOST_IP_ADDRESS}:123456"
                        バックグラウンド プロセス の起動:  #// systemctl start が使えない代わり  #search: Docker init system (PID 1)
                            docker コマンドが使える場合?: |
                                ThisContainerID="$( docker ps | grep __Pattern__ | awk '{print $1}' )"   #// 現在実行中のコンテナ―の ID
                                docker exec  ${ThisContainerID}  /bin/sh -c "__Command__  __Parameters__  2>&1"  > _.log &
                        注意 >> -v, --volume オプション: #keyword: DooD volume
                            ホスト側のパスのずれ:
                                -   コンテナー(1)からコンテナー(2)を起動するために、コンテナー(1)内で、
                                    docker run を実行したときの -v オプションのホスト側のパスに指定するパスは、
                                    Docker ホストのパスになります（DinD でも同じ） #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: DinD volume
                                -   そのややこしさを避けるため、ホストとコンテナ―で同じパスの Docker volume を設定します
                            設定例:
                                概要: -v オプションに ${PWD} を指定してフルパスにして、コンテナー内と同じフルパスをホストにも作ります
                                コンテナー内 -v:     $PWD/script:/script:ro
                                コンテナー起動時 -v: __CurrentInContainer__/script:__CurrentInContainer__/script
                            ホスト側の相対パス: 非推奨  #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: DooD volume
                            注意 >> フォルダーの busy:  #// コンテナ―の GitHub ランナーなど
                                説明: リポジトリからダウンロードしたフォルダーの一部を -v オプションで指定することは DooD ではできません。
                                    -v オプションで指定したフォルダーを削除できなくなるからです。
                                    GitHub ランナー では、前回 git clone したフォルダーを削除するときに失敗します
                                サンプル: |  #search: .github/workflows/.yml
                                    # drwxr-xr-x 3 root   root   4096 Mar 1 00:00 ci-test
                                    -   name: Get permission created folder by docker run volume option
                                        run: |
                                            sudo mkdir -p /home/github-runner/ci-test
                                            sudo chown -hR github-runner:github-runner /home/github-runner/ci-test
                                    -   uses: actions/checkout@v3
                                    # Error: File was unable to be removed Error: EBUSY: resource busy or locked, rmdir '/home/github-runner/ci-test/proj/proj/docker/build'
                        Nomad の DooD:  #search: Nomad DooD
                    Docker in Docker (DinD): #keyword:  #ref: ${my_images}/2024/docker-in-docker.png
                        #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: DinD volume
                        注意 >> -v, --volume オプション: #search: DooD volume
                    #ref: https://www.docswell.com/s/Kesin11/K98GJJ-cicd_testnight_6_github_actions#p36
                手順:
                    Docker outside of Docker (DooD) をインストールします:
                        bash の場合:
                            docker コマンドを使うコンテナーの起動時にボリュームを設定します:
                                docker run  -v /var/run/docker.sock:/var/run/docker.sock  __Parameters__
                            Docker CLI をインストールします:  #// コンテナー内
                                sudo yum install -y yum-utils
                                sudo yum-config-manager  --add-repo https://download.docker.com/linux/centos/docker-ce.repo
                                sudo yum install -y  docker-ce-cli
                                sudo docker run  hello-world
                            （必要なら）Docker Compose をインストールします:  #// コンテナー内
                                #ref: https://github.com/docker/compose/releases からダウンロードするリンク先 URL を指定します。バージョン番号の前の v の有無に注意
                                sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.7/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
                                sudo chmod +x /usr/local/bin/docker-compose
                        Dockerfile の場合: |  #// docker コマンドが使える Docker イメージ を作ります
                            ARG  dockerCeCliVersion=25.0.4
                            RUN  sudo yum install -y yum-utils  && \
                                sudo yum-config-manager  --add-repo https://download.docker.com/linux/centos/docker-ce.repo  && \
                                sudo yum install -y  docker-ce-cli
                            
                            ARG  dockerComposeVersion=v2.24.7
                                #// https://github.com/docker/compose/releases
                            RUN  sudo curl -L "https://github.com/docker/compose/releases/download/${dockerComposeVersion}/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose  && \
                                sudo chmod +x /usr/local/bin/docker-compose

                            # RUN  sudo docker pull mysql:8.0
                                # This fails in docker build command, because -v /var/run/docker.sock:/var/run/docker.sock option is not specified.
                    WSL2 へ Docker outside of Docker (DooD) のインストール:  #// エラーのため未確認
                        Docker Engine for WSL2 Ubuntu: #search: restore Docker for WSL2
                        起動:
                            wsl --unregister "Ubuntu-20.04-docker"
                            wsl --import  "Ubuntu-20.04-docker" `
                                "${HOME}\WSL_VMs\Ubuntu-20.04-docker" `
                                "${HOME}\WSL_back_up\Ubuntu-20.04-docker.tar"
                            wsl -d "Ubuntu-20.04-docker"
                            service-start
                            docker run -d --rm  --name container-1  rockylinux:8.8.20230518-minimal  sleep infinity
                            docker ps
                            docker run -it -v /var/run/docker.sock:/var/run/docker.sock docker
                        エラー: |
                            Certificate request self-signature ok
                            subject=CN = docker:dind server
                            /certs/server/cert.pem: OK
                            Certificate request self-signature ok
                            subject=CN = docker:dind client
                            /certs/client/cert.pem: OK
                            ip: can't find device 'nf_tables'
                            modprobe: can't change directory to '/lib/modules': No such file or directory
                            ip: can't find device 'ip_tables'
                            modprobe: can't change directory to '/lib/modules': No such file or directory
                            iptables v1.8.10 (nf_tables)
                            mount: permission denied (are you root?)
        環境変数: #keyword: Docker environment variable,  Docker env
            Dockerfile:  #search: Dockerfile ENV  #search: Dockerfile ARG  #search: Docker proxy ENV
            docker build コマンド:  #search: Docker proxy --build-arg
            docker run コマンド:  #search: docker run --env
                docker build コマンドで指定した環境変数は、Dockerfile にデフォルト値がなければ、docker run コマンドでも改めて指定する必要があります(?)
            docker exec コマンド:  #search: evaluate docker environment variable
            コンテナ―の環境変数の値:  #search: Dockerfile ENV
        ボリューム:  #keyword: Docker volume  #// ボリューム。コンテナーが使うストレージ。共有フォルダー
            手順:
                永続化します:
                    Dockerfile に VOLUME があるイメージを使う場合:
                        明示的に設定しなくてもボリュームが用意されます
                        匿名volume（ランダムな名前）が自動的に作られます
                    Dockerfile に VOLUME がないイメージを使う場合:
                        コンテナー内の特定のフォルダーをボリュームに接続しないと、コンテナー終了時にファイルの変更が失われます
                ボリュームを一覧します:  #search: docker volume ls
                コンテナ―との関連:  #search: docker inspect
                    docker inspect -f '{{ range .Mounts }}{{ .Name }} {{ end }}'  __ContainerName__
                ホストのフォルダーを共有する場合: #keyword: Docker shared folder
                    #ref: https://docs.docker.jp/engine/tutorials/dockervolumes.html#mount-a-host-directory-as-a-data-volume
                接続するときの注意: #keyword: Docker volume connection attention  #// コンテナーとボリュームを接続します
                    書式の例: docker run -v __PathInHost__:__PathInContainer__
                    注意1: __PathInHost__, __PathInContainer__ は両方ともフルパスを指定してください
                    注意2: __PathInHost__ は / または ./ から始めてください
                    注意3: ホストOS が Linux の場合、__PathInHost__ をあらかじめ作っておかないと、
                        フォルダーの所有者が root になってホストOS からアクセスしにくくなります
                Permission:  #keyword: Docker volume permission  #// 共有フォルダーのアクセス権
                    - UID と GID は、コンテナーとホストで共有します
                    - ユーザー名とグループ名は、コンテナーとホストで異なります。同じ UID, GID でも名前が違います
                    - root (UID=0) も共有しているので、コンテナーの root でもホストの root でも Permission を変更できます
                    - 通常、ホストのユーザーを、共有フォルダーの GID のグループに所属させます
            コマンド:  #keyword: Docker volume command  #glossary:
                コンテナーとの接続:  #// 永続化、または、ホストのフォルダーと共有
                    -v オプション:  #search: docker run -v option
                        書式: docker run  -v __PathInHost__:__PathInContainer__
                        注意:  #search: Docker volume connection attention
                ボリューム本体: #glossary:
                    docker volume ls:  #// ボリュームを一覧します
                        実行例:
                            $ docker volume ls
                            DRIVER    VOLUME NAME
                            local     try_kuromoji_data01
                        Dashboard でボリュームを一覧します:
                            Dashboard を開きます:  #search: Docker Dashboard
                            メニュー: Volumes（左）
                    docker volume rm: #keyword: Docker volume delete  #// ボリュームを削除します
                        1つ削除:
                            ボリューム名を確認します:
                                docker-compose.yml から探す場合:
                                    #search: docker-compose.yml volumes
                                一覧から探す場合:
                                    #search: docker volume ls
                                docker inspect コマンドで探す場合:  #keyword: docker inspect volume
                                    コマンド入力:
                                        - docker ps -a   #// NAMES がコンテナー名です
                                        - dockerc inspect __ContainerName__
                                    出力内容から調べます: |  #focus: Mounts, volume, Name  #// __VolumeName__ は 4fa95 ... です
                                        "Mounts": [
                                            {
                                                "Type": "volume",
                                                "Name": "4fa95bcd6041ba7db6a3a81afdbe7ba166ebf1e93336a52265f35f5ef7e6a50e",
                                                "Source": "/var/lib/docker/volumes/4fa95bcd6041ba7db6a3a81afdbe7ba166ebf1e93336a52265f35f5ef7e6a50e/_data",
                                                "Destination": "/var/lib/postgresql/data",
                            コンテナーを削除します:  #// 以下のいずれか
                                #search: docker rm
                                #search: docker-compose down
                            ボリュームを削除します:
                                docker volume rm __VolumeName__
                            トラブルシューティング:
                                - #// remove __Volume__: volume is in use
                                    手順: docker volume rm __Volume__
                                    エラー: |
                                        Error response from daemon: remove __Volume__: volume is in use - [__ContainerID__]
                                        docker-compose -f docker-compose.zabbix.yml  down --volumes
                                    対処:
                                        __ContainerID__ のコンテナーを終了させてください
                        使っていないすべて削除:
                            docker volume prune
                    docker volume create:  https://docs.docker.jp/engine/reference/commandline/volume_create.html
            構成:  #// ボリューム
                ボリューム:
                    共有:  #search: Docker shared folder
                    Permission:  #search: Docker volume permission
                    保存場所:  #search: docker volume ls
            ファイル:
                Dockerfile に書く場合: #search: Dockerfile VOLUME
                docker-compose.yml に書く場合: #search: docker-compose.yml volumes
            トラブルシューティング:
                Permission denied エラーになる場合: #keyword: Docker volume permission  #// ボリュームに指定したフォルダーにアクセスしたときのエラー
                    ホストOSのフォルダーの権限ユーザーを確認します:
                        ls -la  __Folder__
                    （ホストOSのフォルダーが root ユーザー権限の場合）:
                        手動で一時的に対応する場合:
                            一般ユーザー権限のフォルダーに作り直します:  #// コンテナー内のユーザーIDと同じIDのユーザーの権限にします
                                - sudo rm -rf __Folder__   #// フォルダーを削除します
                                - mkdir __Folder__
                        ユーザーID を恒久的に設定する場合: #keyword: Docker volume user  #// コンテナー内のユーザーIDを、ホストOSのユーザーIDに合わせます
                            docker-compose.yml に書く場合: #keyword: docker-compose volume user
                                __CurrentFolder__/.env:  #// 下記を追加します。ただし、ホストOSの UID, GID と同じになるように編集します。 #search: read UID:GID
                                    CONTAINER_UID=1000
                                    CONTAINER_GID=1000
                                __CurrentFolder__/docker-compose.yml: |  #// 下記 user を追加します
                                    services:
                                        __ServiceName__:
                                            user: "${CONTAINER_UID}:${CONTAINER_GID}"
                            参考:
                                設定しない場合の不具合例:
                                    #search: git checkout cannot create directory
                                docker-compose:
                                    #ref: https://stackoverflow.com/questions/56844746/how-to-set-uid-and-gid-in-docker-compose
                                Dockerfile:
                                    #ref: https://qiita.com/yohm/items/047b2e68d008ebb0f001
                root ユーザーのフォルダーができてしまう:
                    dockerでvolumeをマウントしたときのファイルのowner問題:  #ref: https://qiita.com/yohm/items/047b2e68d008ebb0f001
                    Docker-compose set user and group on mounted volume:  #ref: https://stackoverflow.com/questions/40462189/docker-compose-set-user-and-group-on-mounted-volume
                    WSL(Linux)のdocker-composeのコンテナを非rootユーザーで実行するには:  #ref: https://wonwon-eater.com/docker-non-root/
        ネットワーク:  #keyword: Docker network
            手順:
                セットアップ:
                    プロキシ:  #// プロキシがある LAN にいる場合、Docker 周りに設定等が必要です  #keyword: Docker proxy
                        クライアントの場所:  #// プロキシの参照元（クライアント）による選択
                            コンテナー内: #keyword: Docker container proxy  #// コンテナー内でダウンロードをするときに使うプロキシ。Dockerfile の RUN や CMD で yum や apt などを指定した場合
                                （以下のサンプルでプロキシを使うコマンド）: yum -y update
                                Dockerfile 内の RUN などで実行するコマンド:  #// Dockerfile に書いたコマンドがプロキシのクライアントの場合
                                    .bashrc などで定義済みの環境変数を使う場合:  #keyword: Docker proxy --build-arg,  docker build --build-arg  http_proxy  https_proxy
                                        Dockerfile: |  #// この中の RUN でプロキシが必要な場合
                                            FROM centos:7
                                            ARG http_proxy
                                            ARG https_proxy
                                            RUN \
                                                yum -y update  && \
                                                yum -y install openssh-server openssh-clients sudo
                                        #↓コンテナーを起動するコマンド
                                        docker コマンドの場合:
                                            名前解決できる場合: |  #// Docker コンテナー の中で http_proxy などの変数の値が http://__FQDN__:__Port__ でよい場合
                                                docker build \
                                                    --build-arg http_proxy=${http_proxy} \
                                                    --build-arg https_proxy=${https_proxy} \
                                                    -t __NewImageName__ "."  --progress=plain
                                            名前解決できない場合:  #// Docker コンテナー の中で http_proxy などの変数の値が http://__IPAddress__:__Port__ である必要がある場合
                                                概要:
                                                    Dockerfile: |
                                                        ARG  http_proxy
                                                        ARG  https_proxy
                                                        ENV  http_proxy="${http_proxy}"
                                                        ENV  https_proxy="${https_proxy}"
                                                    bash: |  #search: docker build with proxy IP address
                                                        http_proxy_ip="http://$( dig +short  "$( echo  "${http_proxy}"  |  sed -E  's|https?://([^:/]+).*|\1|' )"  |  grep -E '([0-9]{1,3}\.){3}' ):${http_proxy##*:}"
                                                        echo  "${http_proxy_ip}"
                                                        https_proxy_ip="http://$( dig +short  "$( echo  "${https_proxy}"  |  sed -E  's|https?://([^:/]+).*|\1|' )"  |  grep -E '([0-9]{1,3}\.){3}' ):${http_proxy##*:}"
                                                        echo  "${https_proxy_ip}"

                                                        docker build \
                                                            --build-arg http_proxy=${http_proxy_ip} \
                                                            --build-arg https_proxy=${https_proxy_ip} \
                                                            ,,,
                                                サンプル:
                                                    Python をインストールする場合:  #search: install Python Ubuntu Docker
                                        docker run コマンドの場合: #keyword: docker run  http_proxy  https_proxy
                                            -e オプションに指定します:
                                                docker run  -e http_proxy=${http_proxy}/  -e https_proxy=${https_proxy}/  __DockerRunOptions__
                                        docker-compose コマンドの場合:  #search: docker-compose.yml build
                                            compose.yaml: |  #focus: http_proxy
                                                version: '3'
                                                services:
                                                    ____:
                                                        build:
                                                            context: .
                                                            dockerfile: Dockerfile
                                                            args:
                                                                -   http_proxy=${http_proxy}
                                                                -   https_proxy=${https_proxy}
                                                                -   no_proxy=${no_proxy}
                                                        environment:
                                                            -   http_proxy=${http_proxy}
                                                            -   https_proxy=${https_proxy}
                                                            -   no_proxy=${no_proxy}
                                    Dockerfile に環境変数の値を設定する場合: | #keyword: Docker proxy ENV  #// 非推奨。コンテナー内では名前解決ができないことがあります
                                        FROM centos:7
                                        ENV http_proxy  http://__ProxyServer__:__Port__
                                        ENV https_proxy http://__ProxyServer__:__Port__
                                        RUN yum -y update && yum -y install openssh-server openssh-clients sudo
                                docker run コマンドで起動する bash で実行するコマンド:  #// コンテナ―内の CLI に入力するコマンドがプロキシのクライアントの場合
                                    _: bash 内で環境変数を定義します。
                                        Dockerfile の ENV や ARG に設定した環境変数は参照できません。
                                    サンプル:
                                        ホストOS:
                                            docker run -it --rm  --name __ContainerName__ __ImageName__
                                        コンテナー内:
                                            export http_proxy=http://__ProxyServer__:__Port__
                                            export https_proxy=http://__ProxyServer__:__Port__
                                            yum -y update
                                Ansible >> docker_container で起動する場合:  #search: Ansible docker_container proxy
                            ホスト OS 内:  #// Docker のホストの中。Docker イメージ のダウンロードをするときに使うプロキシ
                                Linux:  #// Docker for Linux のホストOS (?)
                                    ~/.docker/config.json ファイルに設定する場合:
                                        mkdir -p  ~/.docker :
                                        ~/.docker/config.json : |  #keyword: Docker proxy Linux
                                            {
                                                "proxies": {
                                                    "default": {
                                                        "httpProxy": "http://___.___.___.___:____",
                                                        "httpsProxy": "http://___.___.___.___:____"
                                                    }
                                                }
                                            }
                                        #// 次は下記
                                    環境変数に設定する場合:  #// ~/.docker/config.json が無いとき
                                        #search: Linux proxy 環境変数
                                    変更したら:
                                        docker-compose down して、新しいシェルで docker-compose up します
                                WSL2 Linux >> systemd 対応版: #keyword: proxy WSL2 Docker systemd
                                    #// Windows 10, WSL2 2.1.5.0 の中の Rocky Linux 8 が Docker ホストで確認 2024-04
                                    /etc/systemd/system/docker.service.d/override.conf : |
                                        [Service]
                                        Environment = 'http_proxy=http://___.___.___.___:____' 'https_proxy=http://___.___.___.___:____'
                                    WSL2 を再起動します: |
                                        exit
                                        wsl --shutdown  #// 全ディストリビューションを終了します
                                        wsl -d "__DistroName__"
                                    #// （補足）不要→ sudo systemctl daemon-reload;  sudo systemctl restart docker
                                    #ref: https://qiita.com/taoy/items/91321de576e1de4d9e7d
                                    #ref: https://qiita.com/dkoide/items/ca1f4549dc426eaf3735
                                Windows:  #// Docker for Windows のホストOS
                                    （Windows 通知領域）Docker（を右クリック）>> Dashboard >> Settings（歯車アイコン：上）>>
                                        Resources（左）>> PROXIES
                                公式:  #ref: https://docs.docker.com/network/proxy/
                        指定する場所:  #// プロキシの設定をする場所による選択
                            ホスト OS のコマンド内:  #search: Docker proxy --build-arg
                            Dockerfile 内:  #search: Docker proxy ENV
                            ホスト OS 内 ~/.docker/config.json :  #search: Docker proxy Linux
                        トラブルシューティング(Docker network):  #search: docker DNS trouble
                ホストとコンテナーの間の通信:  #search: docker run -p option
                コンテナーとコンテナーの通信:  #search: docker network create
                    仮想 ネットワーク アダプター:  #search: Docker network adapter
                セキュリティ, iptables などの操作: #keyword: Docker iptables  #// デフォルトでは、インターネットからコンテナーにアクセスできるようになります
                    公式 >> Packet filtering and firewalls:  #ref: https://docs.docker.com/network/packet-filtering-firewalls/
                    概要:
                        Docker は必要に応じて iptables と fiewalld, ufw の設定を変更します。
                        Docker の bridge ネットワーク モード で docker run を実行すると Docker は iptables を編集して、
                        デフォルトではインターネットからアクセスできるようになります  #search: Docker run -p option iptables
                    チェック リスト: #keyword: Docker iptables check list  #// セキュリティの問題が無いかチェックします
                        iptables:
                            ポート 2375, 2376:  #search: Docker Remote API
                            その他のポート:  #search: Docker run -p option iptables
                    iptables:
                        サンプル:
                            デフォルトの設定: |  #// 以下の iptables（一部）にセキュリティ上の問題はありません: |
                                *nat
                                :PREROUTING ACCEPT [999:99999]
                                :INPUT ACCEPT [999:99999]
                                :OUTPUT ACCEPT [999:99999]
                                :POSTROUTING ACCEPT [999:99999]
                                :DOCKER - [0:0]
                                -A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
                                -A OUTPUT ! -d 127.0.0.0/8 -m addrtype --dst-type LOCAL -j DOCKER
                                -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
                                -A DOCKER -i docker0 -j RETURN

                                *filter
                                :FORWARD DROP [999:99999]
                                :DOCKER - [0:0]
                                :DOCKER-ISOLATION-STAGE-1 - [0:0]
                                :DOCKER-ISOLATION-STAGE-2 - [0:0]
                                :DOCKER-USER - [0:0]
                                -A FORWARD -j DOCKER-USER
                                -A FORWARD -j DOCKER-ISOLATION-STAGE-1
                                -A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
                                -A FORWARD -o docker0 -j DOCKER
                                -A FORWARD -i docker0 ! -o docker0 -j ACCEPT
                                -A FORWARD -i docker0 -o docker0 -j ACCEPT
                                -A DOCKER-ISOLATION-STAGE-1 -i docker0 ! -o docker0 -j DOCKER-ISOLATION-STAGE-2
                                -A DOCKER-ISOLATION-STAGE-1 -j RETURN
                                -A DOCKER-ISOLATION-STAGE-2 -o docker0 -j DROP
                                -A DOCKER-ISOLATION-STAGE-2 -j RETURN
                                -A DOCKER-USER -j RETURN
                            注意が必要な設定:
                                ptables -I DOCKER-USER -i __SourceNicName__ -o __DestinationNicName__ -j ACCEPT
                        カスタム iptables チェーン:
                            構成: DOCKER-USER, DOCKER (Forward チェーン）
                            目的: 受信パケットが常に最初にこれら 2 つのチェーンによってチェックされるようにします。
                            注意: この構成を変更しないでください。
                                Do not manipulate this chain manually.  #ref: https://docs.docker.com/network/packet-filtering-firewalls/#add-iptables-policies-before-dockers-rules
                        Dockerがiptablesを操作しないようにする:  #// 非推奨
                            #ref: https://docs.docker.com/network/packet-filtering-firewalls/#prevent-docker-from-manipulating-iptables
                            /etc/docker/daemon.json :
                                {
                                "iptables":false,
                                "ip-forward": false,
                                "ip-masq": false,
                                "userland-proxy": false
                                }
                        リクエスト元 IP の照合:  #// 許可していない IP アドレス とポートから来たリクエストを拒否します
                            DNAT 変換済み IP アドレス:
                                変換前の IP アドレスにする場合:
                                    #ref: https://docs.docker.com/network/packet-filtering-firewalls/#match-the-original-ip-and-ports-for-requests
                            フィルタリング:
                                サンプル: iptables -I DOCKER-USER -i eth2 ! -s 192.168.1.0/24 -j DROP
                            -p オプション: #keyword: Docker run -p option iptables  #ref: https://docs.docker.com/network/packet-filtering-firewalls/#setting-the-default-bind-address-for-containers
                                ポート番号:
                                    -p オプションに指定したポートを開きます。
                                    docker run -p 8080:80 nginx コマンドの場合 0.0.0.0:8080 を ACCEPT します。
                                    #search: docker run -p option
                                IP アドレス:
                                    docker run コマンドの -p オプションを使うと、デフォルトでは 0.0.0.0:__HostPort__ （のINPUT?）を ACCEPT します。
                                    0.0.0.0 から変えることもできます。
                            ルーター機能対応:  #// 多くのコンテナーはルーターではないので設定不要です
                                デフォルト:  #// DROP
                                    Docker は、FORWARD チェーンのポリシーを DROP に設定します。
                                ACCEPT の追加: #keyword: add 
                                    iptables -I DOCKER-USER -i __SourceNicName__ -o __DestinationNicName__ -j ACCEPT
                                    #search: NIC name
                    fiewalld:  #// CentOS8 の fiewalld
                        Docker は firewalld に docker ゾーンを追加します
                        #ref: https://docs.docker.com/network/packet-filtering-firewalls/#integration-with-firewalld
                    ufw:  #// Debian や Ubuntu の Uncomplicated Firewall
                        #ref: https://docs.docker.com/network/packet-filtering-firewalls/#docker-and-ufw
                    Docker Remote API:
                        デフォルトでは開いていません  #search: Docker Remote API
            構成, 概念:
                ブリッジ ネットワーク, Docker network: #keyword: Docker bridge network,  Docker network  #// 仮想的な L2 スイッチ
                    デフォルト, docker0:
                        コンテナ作成時に何も指定しないと、docker0 というデフォルトの ブリッジ ネットワーク に接続されます。
                        Docker network といえば、通常これ。
                ホストのネットワークを直接使用:
                コンテナー:  #// コンテナーのホスト名と IP アドレス:
                    IP アドレス: #keyword: docker IP address  #// コンテナーに自動的に付く IP アドレス
                        ブリッジモードの場合: #keyword: Docker bridge mode
                            Docker ネットワーク 内:  #// Docker ホスト の中の Docker の中にあるネットワーク。外部へのアクセスは SNAT 経由になります
                                注意: IP アドレスはコンテナーを起動するたびに変わります
                                サンプル: #keyword: docker network deafult IP address
                                初めて起動したコンテナーの IP アドレス:  172.17.0.2/16  #keyword: 172.17.0.2/16
                                2つ目に起動したコンテナーの IP アドレス: 172.17.0.3/16
                                調べ方:
                                    全コンテナー:
                                        - docker network inspect bridge
                                    1つのコンテナー:  #// 以下のいずれか
                                        - docker inspect --format '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' __ContainerName__
                                        - docker inspect --format='{{(index (index .NetworkSettings.IPAddress))}}' __ContainerName__
                            外部ネットワーク:  #// 外部から見える Docker ホスト のサーバーの IP アドレス
                                コンテナー内からリクエストしたとき:
                                    プロキシがない環境の場合:
                                        SNAT 経由でのアクセスになり、外部から見える IP アドレスは、Docker ホスト のサーバーの IP アドレス になります
                                    プロキシがある環境の場合:
                                        SNAT 経由＋プロキシ経由でのアクセスになり、外部から見える IP アドレスは毎回異なります
                    サーバー名: #keyword: docker-compose servers  #// docker-compose が自動的に付けるホスト名
                        - サービス名、または、コンテナー名を指定できます。
                            #search: Docker container name
                            #search: Docker service name
                        - /etc/hosts に書いていなくても docker-compose の DNS が解決します。
                    Docker ホストの IP アドレス:
                        Docker ホスト で localhost:3306 で接続先にアクセスできる場合、
                        コンテナ―の中から __HostIpAddress__:3306 でアクセスできます。
                仮想 ネットワーク アダプター の種類: #keyword: Docker network adapter
                    種類:  #// bridge, host, none
                        bridge: #keyword: Docker bridge mode network  #// 🌟 VM とホストのそれぞれに ネットワーク アダプター があります。
                            （注意）iptables を編集し、インターネットからアクセスできるようになります  #search: Docker iptables
                        host: #keyword: Docker host mode network  #// VM の ネットワーク アダプター をホストの ネットワーク アダプター に設定します
                        none: VM に ネットワーク アダプター を付けません
            コマンド:  #keyword: Docker network command  #glossary:
                docker network create:  #// ネットワークを作ります。コンテナーを作ったネットワークに所属させると、コンテナー名でアクセスできます
                    注意: IP アドレス でアクセスする場合は、ネットワークを作らなくてもアクセスできます
                    コマンド, 手順:  #focus: network1
                        仮想のサブネット network1 を作ります:
                            #// 以下のいずれか
                            -   docker network create  network1  #// --driver bridge を指定したときと同じです
                            -   docker network create  --driver bridge  network1
                        コンテナ―をサブネット network1 に接続して起動します:
                            docker run -d  --network=network1  --name __ContainerName__  __ImageName__
                        疎通確認します: |  #keyword: docker-compose network 疎通確認
                            docker ps  #// コンテナー名を調べます。または  #search: docker network inspect
                            docker exec -it __ClientContainer__ /bin/sh
                            ping __ServerContainer__
                            exit
                docker network ls: #// ネットワークを一覧します
                docker network inspect __NetworkName__: #keyword: docker network inspect  #// IP アドレスなどを一覧します
                    __NetworkName__: docker network ls コマンドを実行したときの NAME 列。通常 bridge
                    実行例: |
                        $ docker network ls
                            NETWORK ID     NAME                  DRIVER    SCOPE
                            da20734a8180   bridge                bridge    local
                            afde740d8a78   host                  host      local
                            7e747602cf73   __Project___default   bridge    local
                        $ docker network inspect __Project___default
                        [
                            {
                                "Name": "default",
                                "Containers": {
                                    "c2000000000000000000000000000000000000000000000000000000000": {
                                        "Name": "project_mysql_1",
                                        "EndpointID": "a8000000000000000000000000000000000000000000000000000000000",
                                        "MacAddress": "02:42:c0:a8:00:02",
                                        "IPv4Address": "192.168.0.2/20",
                Docker Remote API: #keyword:  #// ネットワーク経由で docker コマンドでできること（コンテナーの起動など）を実行します
                    手順:
                        ポートを開きます:  #// デフォルトでは開いていません。信頼できるクライアントの IP アドレスだけに制限します
                            /etc/docker/daemon.json: |
                                "hosts": ["tcp://0.0.0.0:2375", "unix:///var/run/docker.sock"]
                            ファイアウォール:
                            TLS 通信: 推奨
                    概念:
                        ポート番号:
                            2375: 非暗号化通信用
                            2376: TLS/SSL 経由の暗号化通信用
                        Docker Swarm モード:  #// 複数のDockerホストがクラスタを形成し、単一の仮想Dockerホストのように動作します
            トラブルシューティング(Docker network):
                DNS:  #search: docker DNS trouble
                advertised listeners:  #search: Kafka advertised listeners
                conflicts with network:
                    ログ: |  #focus: conflicts with network
                        sudo systemctl start docker
                            Job for docker.service failed because the control process exited with error code.
                            See "systemctl status docker.service" and "journalctl -xe" for details.
                        sudo journalctl -u docker --no-pager | less
                            dockerd[2509]: failed to start daemon: Error initializing network controller: error creating default "bridge" network: cannot create network 094b3d55da40d765c1052c1676542d9931da00d07bbeb60449703525144801fd (docker0): conflicts with network 8b723c81a1f46ebab6468cb69be1d27183258052c5245105f5deb32cc488e83d (docker0): networks have same bridge name
                    対処: |  #// docker0 ネットワークを強制削除します
                        sudo systemctl stop docker
                        sudo ip link set dev docker0 down  # Remove the conflicting bridge
                        sudo ip link delete docker0
                        sudo rm -rf /var/lib/docker/network/
                        sudo systemctl start docker
        ユーザー:  #keyword: Docker user  #// Docker コンテナー のサービスを VM 内で実行するユーザー
            #// root ユーザー を使うべきではありませんが、Dockerfile 内では sudo を使うべきではありません。
            ユーザーを切り替えます:
                Dockerfile:  #search: Dockerfile sudo
                    USER user1
            sudo を使いたいとき:  #keyword: Dockerfile sudo  #// Dockerfile の RUN や CMD に sudo を指定したいとき
                _: USER コマンドの前に（root ユーザーで）sudo を使おうとしたコマンドを sudo を使わずに実行します。
                    sudo を使うべきではありません。sudo を実行するときにパスワードを入力することができませんし、入力不要にするのはセキュリティの問題があります
                Dockerfile:
                    FROM centos:7
                    ARG USER=user1
                    ARG GROUP=user1
                    ARG UID=1000
                    ARG GID=1000
                    RUN \
                        yum -y update  && \
                        yum install -y  __Package__  && \
                        yum clean all
                    RUN \
                        groupadd ${USER} --gid ${GID}  && \
                        useradd  ${GROUP} --uid ${UID} --gid ${GID}
                    USER user1
                #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: Docker user
        サービス:
            systemctl を使いたいとき:
    ログ: #search: docker logs
    トラブルシューティング(Docker):  #keyword: Docker troubleshooting
        - #// 今まで docker が動いていたのに systemctl start docker で失敗するようになってしまった
            手順: sudo systemctl start docker
            ログ: |
                Active: fail
            対処:  #ref: https://stackoverflow.com/questions/45798076/how-to-clean-up-docker
                #keyword: /var/lib/docker
                Docker のイメージ,ボリュームなどすべてを削除します
                sudo systemctl stop docker
                sudo rm -rf /var/lib/docker
                sudo mkdir  /var/lib/docker
                sudo systemctl start docker
        - #// メモリー不足  #search: Docker memory size
        - #// Docker コンテナー内でホスト名を名前解決ができない  #keyword: docker DNS trouble,  docker DNS container curl network host proxy server trouble not found host name
            調査手順:
                コンテナーにログインします:
                    docker exec -it  __ContainerName__  bash
                DNS や proxy が機能しているか確認するコマンドを選びます:  #keyword: name resolver commands
                    curl:
                    nslookup:
                    dig:
                    ping:
                インターネットの URL が名前解決できるか確認します:
                    コマンド:
                        curl https://gitlab.com/
                    解決できない場合:
                        エラー メッセージ の例: |
                            curl: (5) Could not resolve proxy: __ProxyFQDN__
                            #// これ以外の場合、プロキシや DNS が問題ではないかもしれません
                        処置:
                            #search: IP address https_proxy
                社内の URL が名前解決できるか確認します:
                    curl https://______/
                https_proxy 環境変数 の調査:
                    https_proxy 環境変数の値を調べます:
                        echo  $https_proxy
                    入っていない場合:
                        #search: Docker container proxy
                    FQDN が入っている場合:
                        https_proxy 環境変数の値を IP アドレスに変えます:
                            #search: IP address https_proxy
                        サービス固有のプロキシ設定を追加してみる:
                            Docker:  #search: docker.service.d proxy
                            GitLab ランナー: #search: install GitLab runner
                プロキシ サーバー の名前解決ができない場合: #keyword: resolve proxy server name Docker
                    基本:
                        /etc/hosts に追加:
                            10.146.100.12 proxy.example.com
                    Nomad Job ファイル:
                        config {
                            dns_servers = ["10.146.100.10", "10.146.100.11"]
                            extra_hosts = ["proxy.example.com:10.146.100.12"]
            補足:
                DNS の IP アドレス:
                    コマンド: コンテナー内で cat /etc/resolv.conf
                    出力例:
                        search ds.____.jp
                        nameserver 127.0.0.11
                        options ndots:0
            関連:  #search: Docker proxy
        - #// 別のコンテナーを指すホストが見つからない。ホスト名が Docker の DNS で解決できない
            手順: docker-compose up して起動したコンテナー内で curl __Host__ など
            エラー: |
                別のコンテナーを指すホスト名が Docker の DNS で解決できない
            対処:
                https_proxy 環境変数の値を IP アドレスに変えます:  #keyword: IP address https_proxy
                    サンプル:
                        https_proxy=http://10.131.100.100:8080/
                    調べ方:
                        （DNS が正常なシェルで）
                        nslookup __ProxyFQDN__  #search: name resolver commands
                    解決した場合:
                        #// 以下のいずれか
                        /etc/resolv.conf を正しく設定します:
                        IP アドレスをそのまま使い、すぐに更新できるようにします:
                docker-compose.yml のサービス名と合っているか確認します: |
                    services:
                        mysql:
                接続先のコンテナーが起動していることを確認します:
                    docker ps -a を使う場合:
                        コマンド: docker ps -a  #search: docker ps
                        出力のうち確認する列: STATUS 列  #// Exit になっていないこと
                            #// Exit になっていたらコンテナーをフォアグランドで起動して表示されるログを確認します
                            #search: docker-compose run
                    docker network inspect を使う場合:
                        コマンド: docker network inspect  __Project___default
                        出力のうち確認するフィールド: Containers の中の対象コンテナーが存在すること
                    docker-compose config を使う場合:  #// 非推奨
                        cd __FolderHasDockerComposeYaml__
                        docker-compose config --service  #// サービス名が一覧されるので、その一覧に存在すること。
                            #// ただし Exit になっていても表示されてしまいます
                接続先のコンテナーが DNS で名前解決できるかを確認します:
                    busybox ベースのコンテナーの場合:
                        コンテナーにログインします:
                            docker-compose run --rm  __ContainerName__  sh  など  #search: docker-compose run
                        nc コマンドで DNS に問い合わせします:
                            #search: Linux nc
        - #// すぐに終了してしまう  #keyword: Docker exited
            手順: docker run -d  --name __ContainerName__  __ImageName__
            エラー: |
                user1@pc01:~/docker_centos7 $ docker ps -a
                CONTAINER ID   IMAGE          COMMAND       CREATED         STATUS                     PORTS     NAMES
                7cebfcf9a0d7   centos7_only   "/bin/bash"   5 seconds ago   Exited (0) 5 seconds ago             centos7_only-1
            対処:
                OS イメージだけの場合:
                    フォアグランドでシェルを起動してください。バックグラウンドで bash を起動てもすぐに終了してしまいます。
                    #search: Docker CentOS7
                バックグラウンドの場合:  #// バックグラウンドでコンテナーを起動する場合
                    sleep infinity
                    または、待ちがあるサービスを起動してください
        - #// ログが表示されない  #keyword: no docker-compose logs
            手順: docker-compose logs -t | less
            エラー: |
                （なし）
            対処A:
                メモリー不足の可能性があります
                    #search: Exited (137)
            対処B:
                終了コードでググります
                    docker ps -a
                        Exited (137)
        - #// Dockerfile のデバッグ  #search: debug Dockerfile
        - 以下はエラーメッセージがあるもの
        - #// Failed to pull 'docker login': denied
            手順: Dockerfile FROM などに指定したイメージを処理するとき
            ログ: |
                Driver Failure: Failed to pull `service1:latest`: Error response from daemon: pull access denied for service1,
                repository does not exist or may require 'docker login': denied: requested access to the resource is denied
            対処:
                FROM にホストを指定します  #search: Dockerfile FROM
        - #// failed to solve: failed to compute cache key: failed to calculate checksum of ref failed to walk
            手順: docker build
            ログ: |
                ERROR: failed to solve: failed to compute cache key: failed to calculate checksum of ref __Hash1__::__Hash2__: failed to walk /var/lib/docker/tmp/buildkit-mount3575306905/home/user1/common-repo: lstat /var/lib/docker/tmp/buildkit-mount3575306905/home/user1/common-repo: no such file or directory
            対処:
                build context の外側にはアクセスできません
                #search: Docker build context
        - #// docker: Error response from daemon: Conflict
            手順: docker run コマンド
            ログ: |
                docker: Error response from daemon: Conflict. The container name "/__ContainerName__" is already in use by container "__ContainerID__". You have to remove (or rename) that container to be able to reuse that name.
            対処:
                停止中のコンテナ―を終了させるなどします  #search: docker ps -a
        - #// docker: permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock
            手順: docker コマンド
            ログ: |
                docker: permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Head "http://%2Fvar%2Frun%2Fdocker.sock/_ping": dial unix /var/run/docker.sock: connect: permission denied
            対処:
                root (sudo) 権限が必要です  #search: sudo docker 
        - #// the input device is not a TTY
            手順: docker run -t または docker exec -it
            エラー: |
                the input device is not a TTY
            対処:
                -t オプションを外してください  #search: docker t option
            原因:
                docker コマンドを実行するシェルがターミナルを持っていないため
        - #// System has not been booted with systemd as init system (PID 1). Can't operate.  #keyword: Docker init system (PID 1)
            手順: Docker outside of Docker (DooD) 環境のコンテナーで、systemctl
            ログ: |
                System has not been booted with systemd as init system (PID 1). Can't operate.
                Failed to connect to bus: Host is down
            #↓ systemd の代わりに Docker を使います
            対処A:
                systemctl (systemd) の unit ファイルを使わないで、Dockefile に移植します。
                RPM をインストールするコマンドは、Dockefile に書きます。
                インストールすると unit ファイルが配置されますが使いません。
                unit ファイルを参考に Dockerfile に移植します。
            対処B:  #// サービスを起動する場合や、systemctl コマンドを実行する場合
                docker exec を使ってサービスを起動します: |
                    ContainerID="$( docker ps | grep __Pattern__ | awk '{print $1}' )"
                    docker exec "${ContainerID}"  __Command__ __Parameters__
                候補:
                    - docker exec  #// ログは記録されません  #search: Docker exec background
                    - ジョブ  #// ログは記録されません。現在のシェルの環境変数を受け継いでしまいます  #search: Linux job log
                    - supervisord  #// インストールが必要です
                    - runit
            対処C:  #// 他のサービスへアクセスする場合
                他のコンテナーへアクセスします  #search: Docker DooD localhost
            原因:
                コンテナの PID 1 プロセスとして systemd が動いておらず、D-Bus 経由で systemd に接続できないために起こるエラーです。
                Docker コンテナは「アプリケーションをパッケージ化する環境」であり、VM のようなフルブローンの init システムは通常起動しません
        - #// permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get "http://%2Fvar%2Frun%2Fdocker.sock/v1.44/containers/json?all=1&filters=%7B%22label%22%3A%7B%22com.docker.compose.config-hash%22%3Atrue%2C%22com.docker.compose.project%3Dproj%22%3Atrue%7D%7D": dial unix /var/run/docker.sock: connect: permission denied
            手順: コンテナー内で docker コマンド
            エラー: |
                permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get "http://%2Fvar%2Frun%2Fdocker.sock/v1.44/containers/json?all=1&filters=%7B%22label%22%3A%7B%22com.docker.compose.config-hash%22%3Atrue%2C%22com.docker.compose.project%3Dproj%22%3Atrue%7D%7D": dial unix /var/run/docker.sock: connect: permission denied
            対処:
                Docker ホストにも github-runner ユーザー を作ります:
                    Dockerfile:
                        RUN  useradd  "github-runner"
                コンテナ―内で docker コマンド を実行するユーザーの UID と docker グループの GID をホストと合わせます:
                    Dockerfile:
                        RUN  useradd   "github-runner"  --uid __DockerHostUID__
                        RUN  groupadd  "docker"  --gid __DockerHostDockerGroupGID__
                docker コマンド を実行するユーザーを docker グループ に所属させます:
                    Dockerfile:
                        gpasswd --add "github-runner"  "docker"
                Docker ホストの /var/run/docker.sock の Permission をコンテナ―内で docker コマンド を実行する UID と GID に合わせます:
                    Docker ホスト:
                        sudo chown github-runner:docker /var/run/docker.sock
        - #// GitHub runner: level=warning msg="The \"__EnvironmentVariable__\" variable is not set. Defaulting to a blank string."
            手順: コンテナー内で docker-compose up コマンド
            エラー: |
                level=warning msg="The \"PWD\" variable is not set. Defaulting to a blank string."
            対処:
                コンテナー内で sudo を付けずに docker-compose コマンドや docker コマンド が使えるようにします
                #search: sudo docker
        - #// docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.
            手順: docker run 
            エラー: |  #keyword: Is the docker daemon running?.
                docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.
            対処A:
                Docker サービス が起動していることを確認します:
                    systemctl status docker
            対処B:
                Docker が使えることを確認します:
                    #search: docker hello-world
            対処C:
                DooD 環境になるように、コンテナを起動するコマンドを修正します:  #// この設定をすると DooD 環境 になります
                    -v /var/run/docker.sock:/var/run/docker.sock
                    #// Nomad の場合  #search: Nomad DooD
            対処D:
                Docker CLI をインストールします:
                    #search: Docker for Linux
                    sudo yum install -y  docker-ce-cli
                （必要なら）docker-compose コマンドをインストールします:
            原因:
                Dockerコンテナ内からDockerデーモンに接続できないことを示しています。
                これは、Dockerデーモンへの接続を可能にする/var/run/docker.sockソケットファイルをコンテナにマウントしていないか、
                適切に設定されていない場合に発生する典型的なエラーです。
        - #// Stderr: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
            手順: vagrant up --provider=docker
            エラー: |
                Command: ["docker", "version", {:notify=>[:stdout, :stderr]}]
                Stderr: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?
            対処:
                Windows 10 の場合: service-start 
        - #// docker run Error pulling image denied: access forbidden
            手順: docker run や docker pull
            エラー: |
                Error pulling image __URL__/__ImaneName__:__Tag__ - 500 Server Error for http+docker://localhost/v1.43/images/create?tag=
                __Tag__&fromImage=__URL__%2F__Image__: Internal Server Error (\"Head \"https://__Host__/v2/__Path__/__ImageName__/manifests/__Tag__\": ^\")"}
            対処:
                セキュリティを緩めます:
                    Container registry を Everyone With Access にします  #search: GitLab Docker permissions
        - #// Error response from daemon: error while removing network: network proj_default id __Hash__ has active endpoints
            手順: docker network rm や docker-compose down
            エラー: |
                Error response from daemon: error while removing network: network proj_default id __Hash__ has active endpoints
            対処:
                ネットワークをつかんでいるコンテナーを削除します。
                #search: delete all docker container
        - #// Failed to get D-Bus connection: Operation not permitted
            手順: systemctl start  mysqld.service
            エラー: |
                Failed to get D-Bus connection: Operation not permitted
            対処:
                systemd を使わずにサービスを起動します
                #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: Docker systemctl
        - #// bash: sudo: command not found
            手順: コンテナー内の bash で sudo __Command__
            エラー: |
                bash: sudo: command not found
            対処:
                #search: Dockerfile sudo
        - #// 標準入力をリダイレクトするとエラー the input device is not a TTY
            手順: docker exec -it __Container__ __Command__ < __InputFilePath__
            エラー: |
                the input device is not a TTY
            対処:
                -it オプションを -i オプションに修正します  #search: docker t option
        - #// manifest unknown
            手順:
                docker image tag ubuntu localhost:5000/myfirstimage
                docker push localhost:5000/myfirstimage
            エラー: |
                ERRO[0107] response completed with error  err.code="manifest unknown" err.detail="unknown tag=latest" 
            対処:
                docker image tag ubuntu localhost:5000/myfirstimage:latest
                docker push localhost:5000/myfirstimage:latest
        - #// Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:
            手順: docker コマンド
            エラー: |
                Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:
                Get "http://%2Fvar%2Frun%2Fdocker.sock/v1.24/containers/____": dial unix /var/run/docker.sock: connect: permission denied
            対処:
                sudo を付けて実行します。
                sudo を付けずに実行できるようにするには  #search: docker sudo
        - #// Error response from daemon: Get "https://____/v2/": Service Unavailable
            手順: docker コマンド
            エラー: |
                Error response from daemon: Get "https://____/v2/": Service Unavailable
            対処:
                サーバーの URL が正しいことをチェックします:
                プロキシの設定をします:
        - #// EXIT(137)
            手順: コンテナーを起動中など
            エラー: |
                EXIT(137)
            対処:
                ホストの空きメモリーを増やします
        - #// C%!(EXTRA string=is not a valid Windows path)
            手順: docker run
            エラー: |
                docker: Error response from daemon: .\data;C%!(EXTRA string=is not a valid Windows path).
            対処:
                手順: -v オプションの:より左側をフルパスで指定してください
                変更前: -v ./data:/fluentd/log
                変更後: -v ${HOME}/Desktop/fluentd_docker/data:/fluentd/log
        - #// Error response from daemon: Container ____ is not running
            手順: docker exec
            エラー: |
                Error response from daemon: Container ____ is not running
            対処:
                コンテナーを再起動します
            原因:
                コンテナーは残っていますが、コンテナーの実行が終了しているので docker exec を実行できません。
        - #// mount destination \Program Files\Git\____ not absolute: unknown
            手順: docker run
            エラー: |
                docker: Error response from daemon: OCI runtime create failed: invalid mount 
                {Destination:\Program Files\Git\fluentd\log Type:bind Source:/run/desktop/mnt/host/c/Users/____/Desktop/fluentd_docker/data;
                C Options:[rbind rprivate]}: mount destination \Program Files\Git\fluentd\log not absolute: unknown.
            対処:
                PowerShell を使ってみてください
        - #// Found orphan containers
            手順: docker-compose up
            エラー: |
                WARNING: Found orphan containers (__ContainerName__, __ContainerName__, ...) for this project.
                If you removed or renamed this service in your compose file,
                you can run this command with the --remove-orphans flag to clean it up.
            対処:
                docker-compose down --remove-orphans  #// 孤立したコンテナー（__ContainerName__）を削除（終了）します
        - #// java.net.ConnectException: Connection refused  #keyword: Java Connection refused
            手順: コンテナー内でプラグインをインストール（ネットワーク アクセス）
            エラー: |
                Exception in thread "main" java.net.ConnectException: Connection refused
            対処:
                docker-compose.yml :
                    environment:
                        - "ES_JAVA_OPTS=-Dhttp.proxyHost=____ -Dhttp.proxyPort=____ -Dhttps.proxyHost=____ -Dhttps.proxyPort=____"
                bash:
                    - docker-compose down
                    - docker-compose up -d
                その他の対策:  #search: Connection refused
        - #// max virtual memory areas vm.max_map_count is too low  #keyword: vm.max_map_count
            手順: docker-compose up
            エラー: |
                max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
            対処:
                Windows の場合:  #// Windows で docker-compose up を実行した場合  #keyword: Docker for Windows sysctl vm.max_map_count
                    # シェル
                    - wsl -d docker-desktop   #// Docker サービスの VM にログインします
                    - sysctl -w vm.max_map_count=262144
                    - exit  #// Docker サービスの VM からログアウトします
                Linux の場合:  #// Linux で docker-compose up を実行した場合
                    インストールします:
                        Rocky8: sudo dnf install -y  procps-ng
                    次回起動時の設定を変更します:
                        sudo nano  /etc/sysctl.conf : |
                            vm.max_map_count=262144
                    現在の設定を変更します:  #// 即時反映されます
                        sudo sysctl -w vm.max_map_count=262144
                    現在の設定値を表示します:
                        cat /proc/sys/vm/max_map_count
                    次回起動時の設定値を表示します:
                        cat /etc/sysctl.conf
                WSL2 Linux + Docker の場合:
                    コンテナ―内の vm.max_map_count も、Docker ホストである WSL2 Linux の設定が即時に採用されます
                関連 >> WSL2 Linux + Docker のメモリーサイズ:
                    #search: Docker memory size
            公式情報:
                #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_set_vm_max_map_count_to_at_least_262144
Docker compose: #keyword: Docker-compose,  docker compose  #ref: ${programming}/OS/VMWare.svg#DockerCompose
    概要:
        コンテナー名: #keyword: Docker container name,  container  #search: docker ps container name
            構造:
                version 2 以降: プロジェクト名 - サービス名 - 数字
                version 1 以前: プロジェクト名 _ サービス名 _ 数字
        サービス名: #keyword: Docker service name  #// docker-compose.yml ファイルの services キーの直下のキー
        プロジェクト名: #keyword: docker compose project name
            compose.yaml ファイルがあるフォルダー名
            または COMPOSE_PROJECT_NAME 環境変数
            または compose.yaml があるフォルダーにある .env ファイルの COMPOSE_PROJECT_NAME 環境変数
            環境変数が優先されます
    手順: #keyword: start Docker-compose  #// インストールします。コンテナーを起動します
        インストール:
            CentOS:
                #ref: https://github.com/docker/compose/releases からダウンロードするリンク先 URL を指定します。バージョン番号の前の v の有無に注意
                sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.7/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
                sudo chmod +x /usr/local/bin/docker-compose
                docker-compose --version
            Windows: Docker Desktop に入っています
        docker-compose を バージョン アップ します:  #search: upgrade docker-compose
        バージョン番号:  #// インストール済みのバージョン番号
            コマンド: docker-compose --version
            bashlib: GetDockerComposeMajorVersion
        Docker compose のサンプル:  #// サンプルとして ElasticSearch のコンテナーを起動します
            設定: #settings:
                __ImageURL__: docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                __LocalAndHostPort__: 9200:9200
                __EnvNameAndValue__:  discovery.type=single-node
            Docker をインストールします:
                #search: Docker install
            プロジェクト フォルダーを作ります:
            __Project__/docker-compose.yml ファイルを作ります:  #search: docker-compose.yml
                サンプル: |
                    version: '2.2'
                    services:
                        __HostName__:
                            image: docker.elastic.co/elasticsearch/elasticsearch:7.13.3  #template: __ImageURL__
                            environment:
                                -   discovery.type=single-node  #template: __EnvNameAndValue__
                            ports:
                                -   9200:9200  #template: __LocalAndHostPort__
            コンテナーを起動します:  #copy: docker-compose up
                カレントフォルダーを プロジェクト フォルダー に移動します:
                    - cd  __Project__  #// プロジェクト フォルダー は docker-compose.yml ファイルがあるフォルダーです
                （２回目以降）コンテナーをシャットダウンします:
                    - docker-compose down   #// これを実行するとコンテナーの再起動にはなります。もし不要ならスキップできます
                コンテナーを起動します:  #// 対象は docker-compose.yml ファイルに書かれたコンテナー
                    - docker-compose up --build -d
                        #// --build オプションを指定すると、docker-compose.yml ファイルの内容にしたがって暗黙的にイメージを作ります
                        #// -d オプションを指定すると、バックグラウンドで起動します。フォアグランドではログが表示されます
                参考:  #search: docker-compose up
            サービスにアクセスします:  #// ElasticSearch の API を呼び出します
                サンプル:
                    curl -X GET "localhost:9200/_cat/nodes?v=true&pretty"
            コンテナーを削除します（終了します）:  #search: docker-compose down
        コンテナーを起動します:  #search: docker-compose up
        ログイン:  #keyword: docker-compose login
            #snip:   docker-compose run -it --rm  __DockerImageName__  bash
            関連:  #search: Docker login
            コンテナーの起動に成功している場合:  #// docker-compose を使わない方法と同じです
                docker exec -it  __NewContainerName__  bash
            コンテナ―が起動していない場合:
                docker-compose run -it --rm  __DockerImageName__  bash
        依存関係:  #keyword: Docker-compose 依存関係
            並列して起動する場合:
                depends_on: #keyword: Docker-compose  depends_on  #ref: https://docs.docker.com/compose/compose-file/compose-file-v3/#depends_on
                    #ref: https://github.com/docker/compose/issues/5007#issuecomment-335815508
                    compose.yaml: |
                        services:
                            __Service__:
                                depends_on:
                                    - __ComponentService__
            順番に起動する場合:
                #search: wait-for-it.sh
        待ち: #keyword: Docker-compose wait-for-it  #// サービスが起動するまで待ちます
            起動待ち:
                ファイル バージョン 3 以上:
                    wait-for-it.sh:  #keyword:
                        概要: ポートにアクセスできるかどうかをテストし、使用可能な場合はコマンドを実行します
                        ダウンロード:
                            vishnubob 版: #ref: https://github.com/vishnubob/wait-for-it
                            curlimage 対応版: #ref: ${GitHub}/Snippets/for-bash/wait-for-it/wait-for-it.sh
                                #ref: https://hub.docker.com/r/curlimages/curl
                                #// ただし、124 行目の else と eval WAITFORIT_CLI=("$@") をコメントアウトする必要があります
                        サンプル:  #// docker-compose の中で使う場合
                            編集前: |
                                depends_on:
                                    - "db"
                                command: ["python", "app.py"]
                            編集後: |
                                depends_on:
                                    - "db"
                                entrypoint: "/scripts/wait-for-it.sh  elastic:9200 --"
                                command: ["python", "app.py"]
                        #ref: https://docs.docker.com/compose/startup-order/
                        関連 >> nc:  #search: Linux nc
                    #ref: https://stackoverflow.com/questions/71060072/docker-compose-depends-on-with-condition-invalid-type-should-be-an-array
                ファイル バージョン 2:  #// ファイル バージョン 3 未満
                    depends_on >> condition: #keyword: Docker-compose  depends_on  condition
                        サンプル:
                            version: '2.1'
                            depends_on:
                                db:
                                    condition: service_healthy  #// ファイル バージョン 3 以降の場合は  #search: wait-for-it.sh
                                redis:
                                    condition: service_started
                    #ref: https://stackoverflow.com/questions/31746182/docker-compose-wait-for-container-x-before-starting-y
                関連 >> Dockerfile の HEALTHCHECK:  #search: Dockerfile HEALTHCHECK
            終了待ち:
                --exit-code-from,  --abort-on-container-exit:
                    docker-compose up  --exit-code-from flyway
                    docker-compose up  --exit-code-from flyway  --abort-on-container-exit
                        flyway (docker-compose.yml に書かれた service) が終了するまで待ち、終了したら他のサービスも終了します。
    環境変数: __Project__/.env  #ref: ${programming}/OS/VMWare.svg#DockerCompose-env
    構成:
        プロジェクト:  #keyword: Docker-compose project
            概要:
                - プロジェクトが異なると:
                    - 別々に docker-compose up/down ができます 
                    - 同じ compose.yaml ファイルを使っても、別のコンテナーが起動します。ボリューム、ネットワークも同様です
                - docker コマンドにはプロジェクトの概念はありません
            手順:
                複数の compose.yaml:  #// 複数の compose.yaml に書かれたすべてのサービスを起動します
                    docker compose -f docker-compose.yaml -f docker-compose2.yaml up
                プロジェクトを指定する:
                    docker-compose up:
                        docker-compose -p myproject up
        ネットワーク:  #search: docker-compose servers
    compose.yaml ファイル:  #keyword: compose.yaml,  docker-compose.yml
        公式:
            #ref: https://docs.docker.jp/reference/compose-file/toc.html
            #ref: https://docs.docker.jp/compose/compose-file.html#compose-file-version-2
        補足: ファイル名 docker-compose.yml は、docker-compose コマンドが参照するファイル名のデフォルトです
        サンプル: |
            version: '2'
            services:
                web:  #// サービス名  #keyword: docker compose service name
                    build: .
                    ports:
                        - "5000:5000"
        ファイル名指定:  #search: docker-compose -f
        オーバーライド, docker-compose.override.yml:  #keyword: 
        フィールド: #keyword: Docker-compose fields  #// docker-compose.yml の設定  #glossary: docker-compose.yml
            build:  #// docker build コマンド相当
                （フィールド名無しの場合）: Dockerfile があるフォルダーのパス
                context: Dockerfile があるフォルダーのパス
                dockerfile: Dockerfile のファイル名
                args:  #// docker build コマンドの --build-arg オプション相当
                    サンプル:
                        ARG_NAME_1: value1
                        ARG_NAME_2: ${ENV_VAR_1}   #// docker-compose コマンドを実行している環境変数の値が設定されます
                    サンプル2:  #search: Docker proxy --build-arg
            command:
                サンプル:
                    command: >
                        bash -c '
                            pwd  &&
                            echo "end"
                        '
                内容:
                    - ユーザーがコンテナーを開始するときに実行するシェルのコマンドを実行します
                    - command を指定すると、Dockerfile の CMD は実行しなくなります。
                        docker run コマンドで実行するサンプルは CMD を実行していることが多いため、
                        docker-compose.yml ファイルには command フィールドを通常指定しません。
                    - 1つのサービスに 1つだけ指定できます。&& はコマンドの区切りになりません
                    - 複数のコマンドを実行するときは bash -c 'command-1 && command-2' を使います
            volumes:  #// コンテナーが使うストレージ
                注意:  #search: Docker volume connection attention
                パス:  #// ホストOS のフォルダーと共有します
                    docker-compose.yml/services/__VM__/volumes:  #keyword: docker-compose.yml volumes value
                        - __PathInHost__:__PathInContainer__  #// __PathInHost__ は / または ./ から始めます。__PathInContainer__ はフルパスのみ指定できます
                        #// または
                        - __VolumeName__:__PathInContainer__  #// __VolumeName__ は /volumes/__VolumeName__ を参照します
                        #ref: http://docs.docker.jp/engine/tutorials/dockervolumes.html#mount-a-host-directory-as-a-data-volume
                ボリューム:  #// コンテナー内で保存しようとしたデータを保存できるようにします。ホストOS のストレージのどこかに保存します
                    docker-compose.yml/volumes/__VolumeName__:  #ref: https://docs.docker.jp/compose/compose-file.html#volume-configuration-reference
                        設定例:
                            docker-compose.yml : |
                                volumes:
                                    volume1: {}
                            #// ボリューム名は __ProjectName___volume1 になります  #search: docker-compose project name
                        設定例2 docker-compose.yml : |
                            volumes:
                                volume1:
                                    driver: local
                    フォルダーの実体:
                        driver:
                            local:
                                Linux: /var/lib/docker/volumes
                                Windows WSL2: \\wsl$\docker-desktop-data\version-pack-data\community\docker\volumes
                                    #// エクスプローラーで見ることができます
                                    #参考: https://stackoverflow.com/questions/43181654/locating-data-volumes-in-docker-desktop-windows
                参考 >> Docker volume:  #search: Docker volume
            ports:  #// コンテナーが使うポート  #keyword: docker-compose ports
                /services/__VM__/ports:
                    - __PortOfHost__:__PortOfContainer__
            healthcheck: #keyword; docker-compose healthcheck  #// サービス開始まで待ちます
                サンプル:
                    version: "3.4"
                    services:
                        a:
                            image: ubuntu
                            command: sleep 100000
                            healthcheck:
                                test: ["CMD", "false"]
                                interval: "1s"
                                timeout: "1s"
                                retries: 0
                                start_period: "100s" # since docker-compose 3.4
                #ref: https://qiita.com/knjname/items/9c0a89af2d9e49749017
                #search: Docker-compose wait-for-it
            depends_on:  #// 依存関係  #search: Docker-compose depends_on
            deploy: #keyword: Docker-compose deploy
                サンプル: |  #// WSL2 ではこの方法でメモリーの空き容量は増えません。増やすには  #search: WSL Docker memory size
                    version: '3.8'
                    services:
                        __Service__:
                            deploy:
                                resources:
                                    limits:
                                        memory: 4G
            mem_limit: #keyword: Docker-compose mem_limit,  Docker-compose memory
                サンプル: |  #// WSL2 ではこの方法でメモリーの空き容量は増えません。増やすには  #search: WSL Docker memory size
                    version: '2.4'
                    services:
                        __Service__:
                            mem_limit: 4G
        Dockerfile やコマンドとの置き換え:  #keyword: docker command to docker-compose.yml
            #// docker コマンドのオプションを docker-compose.yml ファイルや Dockerfile に移動します
            Dockerfile から docker-compose.yml に置き換える場合:  #keyword: Dockerfile to docker-compose.yml
                関連:
                    Docker-compose.yml:  #search: Docker-compose fields
                    Dockerfile:  #search: Dockerfile
                    Docker コマンド:  #search: docker command
                docker-compose.yml と Dockerfile や docker コマンドの関係: #// 値は対応する Dockerfile の命令名です
                    version: '2'
                    services:
                        __ServiceName__:  #// サービス名  #keyword: docker compose service name
                            image: "Dockerfile の FROM 命令"  #search: Dockerfile FROM
                            build: "docker build コマンドのパラメーター・Dockerfile があるフォルダーのパス"
                            entrypoint: "Dockerfile の ENTRYPOINT 命令"  #search: Dockerfile ENTRYPOINT
                            command: "Dockerfile の CMD 命令,  docker run コマンド"  #search: Dockerfile CMD
                            environment:
                                __Name__: "Dockerfile の ENVIRONMENT 命令,  シェルの環境変数"  #search: Dockerfile ENVIRONMENT
                            ports:
                                - "docker run コマンド -p オプション"  #search: docker run -p option
                                #// 関連 "Dockerfile の EXPOSE 命令"  #search: Dockerfile EXPOSE
                            volumes:
                                - "docker run コマンド -v オプション"  #search: docker run -v option
                                #// 関連 "Dockerfile の VOLUME 命令"  #search: Dockerfile VOLUME
            既存のイメージから１つ以下のコマンドを実行する場合:  #// Dockerfile を使いません。 image キーに指定します
                設定: #settings:
                    __ImageURL__: docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                    __LocalAndHostPort__: 9200:9200
                    __EnvNameAndValue__:  discovery.type=single-node
                docker コマンド:
                    - docker pull  docker.elastic.co/elasticsearch/elasticsearch:7.13.3  #template: __ImageURL__
                    - docker run -p 9200:9200 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                        #template: -p __LocalAndHostPort__ -e "__EnvNameAndValue__" __ImageURL__
                docker-compose.yml と Dockerfile と docker-compose コマンド:
                    __Project__/docker-compose.yml:
                        version: '2.2'
                        services:
                            __HostName__:
                                image: docker.elastic.co/elasticsearch/elasticsearch:7.13.3  #template: __ImageURL__
                                environment:
                                    -   discovery.type=single-node  #template: __EnvNameAndValue__
                                ports:
                                    -   9200:9200  #template: __LocalAndHostPort__
                    docker-compose コマンド:
                        docker-compose up -d  #search: docker-compose up
            既存のイメージから２つ以上のコマンドを実行する場合:  #// Dockerfile を使います。 build キーに指定します
                #// docker-compose.yml に Dockerfile の RUN が使えないため、Dockerfile を使います。
                #// RUN について…  #ref: ${programming}/OS/VMWare.svg#Dockerfile_RUN 
                設定: #settings:
                    __ImageURL__: docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                    __LocalAndHostPort__: 9200:9200
                    __EnvNameAndValue__:  discovery.type=single-node
                docker コマンド:
                    - docker pull  docker.elastic.co/elasticsearch/elasticsearch:7.13.3  #template: __ImageURL__
                    - docker run -p 9200:9200 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                        #template: -p __LocalAndHostPort__ -e "__EnvNameAndValue__" __ImageURL__
                    - docker exec -it 立ち上げたコンテナID /bin/bash 
                docker-compose.yml と Dockerfile と docker-compose コマンド:
                    __Project__/docker-compose.yml:
                        version: '2.2'
                        services:
                            __HostName__:
                                build: ./elasticsearch
                                environment:
                                    -   discovery.type=single-node  #template: __EnvNameAndValue__
                                ports:
                                    -   9200:9200  #template: __LocalAndHostPort__
                    __Project__/elasticsearch/Dockerfile:
                        FROM  docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                    docker-compose コマンド:
                        docker-compose up --build -d  #search: docker-compose up
    コマンド: #glossary: docker-compose  #ref: https://docs.docker.jp/engine/reference/commandline/compose.html
        （分類）:
            起動:
                全部:  #search: docker-compose up
                    cd  __FolderHasDockerComposeYaml__
                    docker-compose down
                    docker-compose up --build -d
                １つ:  #search: docker-compose up one
                    cd __FolderHasDockerComposeYaml__
                    docker-compose up  __ServiceName__
            終了:
                全部:  #search: docker-compose down
                    cd  __FolderHasDockerComposeYaml__
                    docker-compose down
                １つ:  #search: docker-compose rm
                    cd __FolderHasDockerComposeYaml__
                    docker-compose rm -fsv  __ServiceName__
            再起動:
                １つ:  #search: docker-compose restart
                    cd __FolderHasDockerComposeYaml__
                    docker-compose restart  __ServiceName__
        up:  #// すべてまたは 1つのコンテナーを起動します  #keyword: docker-compose up
            基本:  #// すべてのコンテナーを起動します  #copy: docker-compose up
                カレントフォルダーを プロジェクト フォルダー に移動します:
                    - cd  __Project__  #// プロジェクト フォルダー は docker-compose.yml ファイルがあるフォルダーです
                （２回目以降）コンテナーをシャットダウンします:
                    - docker-compose down   #// これを実行するとコンテナーの再起動にはなります。もし不要ならスキップできます
                コンテナーを起動します:  #// 対象は docker-compose.yml ファイルに書かれたコンテナー
                    - docker-compose up --build -d
                        #// --build オプションを指定すると、docker-compose.yml ファイルの内容にしたがって暗黙的にイメージを作ります  #keyword: docker-compose build
                        #// -d オプションを指定すると、バックグラウンドで起動します。フォアグランドではログが表示されます  #keyword: docker-compose up -d
                参考:  #search: docker-compose up
            1つ起動: #keyword: docker-compose up one  #// １つのコンテナーを起動します
                コマンド:  #// 以下のいずれか
                    基本:
                        cd __FolderHasDockerComposeYaml__
                        docker-compose up -d  __ServiceName__
                    または:
                        docker-compose run -it --rm  __ServiceName__
                    -d オプション: バックグラウンドで起動します  #search: docker-compose up -d
                    オプションあり:  #// --build -d の部分は全部起動するときに指定したオプションを参考にしてください
                        cd __FolderHasDockerComposeYaml__
                        docker-compose up --build -d  __ServiceName__
                    replies が 0 のサービスを起動する場合:  #search: docker-compose 0 replicas
                コマンドの説明:
                    __ServiceName__: docker-compose.yml ファイルの services キーの直下のキー
            2つ起動:
                docker-compose up -d  __ServiceNameA__ __ServiceNameB__
            デフォルトでは起動しない: #keyword: docker-compose 0 replicas  #// 基本は docker-compose up ですべてのサービスを起動しますが、特定のサービスは起動しないようにします
                compose.yaml: |
                    __ServiceName__:
                        deploy:
                            replicas: 0  #// 0 = Not start by default. To start: docker-compose up -d __Service__  --scale __Service__=1
                replies が 0 のサービスを起動する場合:
                    docker-compose up -d  __Service__  --scale __Service__=1
            1つ以外を起動:
                docker-compose up -d  --scale __ServiceName__=0
                #ref: https://stackoverflow.com/questions/50848797/docker-compose-exclude-service-by-default
            1つ再起動: #keyword: docker-compose restart
                Dockerfile が無い場合:
                    注意: データはクリアされないようです。docker-compose down するとクリアされます
                    コマンド:
                        cd __FolderHasDockerComposeYaml__
                        docker-compose restart  __ServiceName__
                    コマンドの説明:
                        __ServiceName__: docker-compose.yml ファイルの services キーの直下のキー
                            コンテナー名ではありません
                Dockerfile がある場合:  #// docker-compose.yml がある場合ではありません
                    コマンド:
                        cd __FolderHasDockerComposeYaml__
                        docker-compose  rm -fsv  __ServiceName__
                        docker-compose  up --build  -d  __ServiceName__
            1つ終了:  #// １つのコンテナーをシャットダウンして削除します  #keyword: docker-compose rm
                down コマンド:  #// シャットダウンして削除します
                    cd __FolderHasDockerComposeYaml__
                    docker-compose down  __ServiceName__
                _:  #// 説明
                    __ServiceName__: docker-compose.yml ファイルの services キーの直下のキー
                        コンテナー名ではありません
                rm コマンド:  #// 削除します
                    -f: 確認プロンプトなしで実行
                        docker-compose rm -fsv  __ServiceName__
                    -s: 停止してから削除
                    -v: コンテナに関連付けられた匿名ボリュームを削除
            -f, compose.yaml の指定: #keyword: docker-compose -f  #// up などより左に -f オプションを書きます
                -   docker compose up  #// compose.yaml または docker-compose.yml 
                -   docker compose  -f docker-compose.yml  up
                -   docker compose  -f docker-compose.yml  -f docker-compose.admin.yml  up
            孤立したコンテナー:
                docker-compose down --remove-orphans  #// 孤立したコンテナー（__ContainerName__）を削除（終了）します
                #// 孤立したコンテナーとは、docker-compose.yml に書かれなくなったコンテナーのことです
            ログ: #keyword: docker-compose up log  #// 前回起動したときの標準出力を再表示します
                全てのコンテナー:
                    docker-compose logs -t | less
                    #// ログが出ない場合  #search: no docker-compose logs
                    #ref: https://docs.docker.jp/config/container/logging/index.html
                特定のコンテナー:  #keyword: docker logs
                    コンテナー名を調べます:
                        docker ps -a --format "{{.Names}}"  #// で表示された対象のコンテナー名を __ContainerName__ とします
                    最新のログを見る場合:  #// コマンドを実行した瞬間の最新
                        docker logs -t  __ContainerName__  2>&1 | less +G
                    -t オプション: ログのタイムスタンプも表示します
                    最新のログを見続ける場合:  #keyword: docker logs --follow
                        docker logs -t  __ContainerName__  --follow
                        （Ctrl + C で終了します）
                    ログ全体をファイルに保存する場合:
                        docker logs -t __ContainerName__ > ~/_tmp/__ContainerName__.log
                削除: #keyword: delete docker-compose up log  #// 特定のコンテナーのログを削除します
                    - docker ps --format "{{.Names}}"  #// で一覧されたコンテナーのうち、対象のコンテナー名を __ContainerName__ とします
                    - sudo truncate -s 0 $(docker inspect --format='{{.LogPath}}' __ContainerName__)
                    #// 参考: https://stackoverflow.com/questions/42510002/docker-how-to-clear-the-logs-properly-for-a-docker-container
            コンテナーの起動に関して詳細表示しながら起動します:  #// 標準出力は表示されません
                docker-compose --verbose up -d 
            プロジェクト名, -p, --project-name: #keyword: docker-compose -p --project-name
                コマンド:
                    docker-compose  --project-name proj2  up  -d 
                    docker-compose  --project-name proj2  down
                説明:
                    起動・終了するコンテナ名は、__ProjectName_____ServiceName___1 になります。
                __ProjectName__: --project-name オプションで指定します
                __ServiceName__: docker-compose.yml の service の子要素に指定します #search: docker compose service name
                参考: #ref: https://stackoverflow.com/questions/50947938/docker-compose-orphan-containers-warning
        down:  #// すべてのコンテナーを終了します  #keyword: docker-compose down
            全て終了: |
                cd  __FolderHasDockerComposeYaml__
                docker-compose down
            １つ終了:  #// １つのコンテナーをシャットダウンして削除します  #search: docker-compose rm
        stop:  #// すべてのコンテナーを終了します。ただし、ネットワークは削除しません。
            用途: 2つの docker-compose.yml ファイルがあるときに共有するネットワークを削除しないときに使います
        rm:  #// コンテナーをシャットダウンして削除します
            １つのコンテナーをシャットダウンして削除します:  #search: docker-compose rm
            すべてのコンテナーをシャットダウンして削除します:  #search: delete all docker container
        run:  #// 特定のコンテナーを起動します。または、そのコンテナーで指定したコマンドを実行します
            起動のみ:  #// CMD を実行します  #search: Dockerfile CMD
                cd  __FolderHasDockerComposeYaml__
                docker-compose run --rm  __ServiceName__

                docker-compose run -it   mysql
            起動してコマンド実行:
                cd  __FolderHasDockerComposeYaml__
                docker-compose run --rm  __ServiceName__  __CommandAndParameters__
        ps:  #// コンテナーの状態を一覧します
            一覧: docker-compose ps -a  #// -a オプションは終了したコンテナーも表示します
            １つ: #search: docker ps status
    トラブルシューティング(Docker):  #search: Docker troubleshooting
Docker Hub: #keyword: Docker Hub,  Docker image catalog  #ref: https://hub.docker.com/
    探します: 各種サービスの公式のホームページのインストール手順を探します。
        Docker Hub の検索では野良イメージが見つかるためあまりよくありません。
    バージョンを探します:
        特定のイメージのページ （例 https://hub.docker.com/_/centos ）>> tags タブ >> docker pull（をブラウザーで検索）
    ソースを見ます: #keyword: Docker Hub Dockerfile
        メニュー:
            特定のイメージのページ （例 https://hub.docker.com/_/centos ）>>
            Tags >>（バージョン）>>（行）  #// 行の全体は右半分に表示されます
        注意:
            - Dockerfile の FROM や RUN は表示されません  #search: Docker ADD file
            - そのため、ベースとしたイメージは分かりません
    レート制限:  #ref: https://www.docker.com/increase-rate-limit
        概要: docker pull が多すぎると実行できない制限がかかります。
        匿名ユーザー: 1 IPアドレス 6時間あたり 100 pulls
        無料ユーザー: 1 IPアドレス 6時間あたり 200 pulls
        有料ユーザー: 1 IPアドレス 1日あたり 5000 pulls
        参考:
            #ref: https://dev.classmethod.jp/articles/codebuild-has-to-use-dockerhub-login-to-avoid-ip-gacha/
            #ref: https://stackoverflow.com/questions/71217339/you-have-reached-your-pull-request-limit-docker#answer-71220346
        現在のカウント:  #ref: https://www.docker.com/blog/checking-your-current-docker-pull-rate-limits-and-status/
            WSL2 Ubuntu 20.04: |
                sudo yum install -y  jq
                curl "https://auth.docker.io/token?service=registry.docker.io&scope=repository:ratelimitpreview/test:pull" | jq -r .token
                出力を https://jwt.ms/ に貼り付け
                    "parameters": {
                        "pull_limit": "100",
                        "pull_limit_interval": "21600"
    ミラー, キャッシュ: #keyword: Docker registry mirror,  Docker cache registry
        キャッシュ:  #search: Docker image
            キャッシュは、ダウンロードしてローカルに保存した Docker イメージ です
        ミラー サーバー を構築します:
            WSL2 Ubuntu 20.04:  #// 効果は未確認
                参考:
                    #ref: https://blog.jp.square-enix.com/iteng-blog/posts/00029-easy-private-container-cache-registry/
                    #ref: https://docs.docker.com/registry/
                    #ref: https://docs.docker.com/registry/recipes/mirror/
                Ubuntu VM を作ります:  #search: WSL2 restore  #search: install Docker for WSL2
                    (PowerShell):
                        wsl --unregister "Ubuntu-20.04-docker-registry"
                        wsl --import  "Ubuntu-20.04-docker-registry" `
                            "${HOME}\WSL_VMs\Ubuntu-20.04-docker-registry" `
                            "${HOME}\WSL_back_up\Ubuntu-20.04-docker.tar"
                        wsl -d "Ubuntu-20.04-docker-registry"
                    (bash):
                        cd ~
                        ~/bin/service-start
                        code "."
                （必要なら）プロキシを設定します:
                    code  ~/.docker/config.json  #search: Docker proxy Linux
                    #// 必要な環境で設定しなかった場合のエラー:
                    #//     panic: Get "https://registry-1.docker.io/v2/": dial tcp 3.216.34.172:443: i/o timeout  (30秒後)
                    #search: Docker proxy
                docker コマンドが参照するレジストリを ミラー サーバー に変更します:
                    /etc/docker/daemon.json: |
                        {
                            "registry-mirrors": ["http://localhost:5000"]
                        }
                    Dockerデーモンを再起動します:
                        sudo service docker restart
                ミラー サーバー を起動します:
                    設定:
                        code  ~/config.yml: |  #// デフォルトから proxy: を追加したものです
                            version: 0.1
                            log:
                                fields:
                                    service: registry
                            storage:
                                cache:
                                    blobdescriptor: inmemory
                                filesystem:
                                    rootdirectory: /var/lib/registry
                            http:
                                addr: :5000
                                headers:
                                    X-Content-Type-Options: [nosniff]
                            health:
                                storagedriver:
                                    enabled: true
                                    interval: 10s
                                    threshold: 3                
                            proxy:
                                remoteurl: https://registry-1.docker.io
                                username: user1
                                password: user1
                    コマンド: |
                        mkdir -p ~/registry
                        docker run -it --rm  -p 5000:5000  -v ~/config.yml:/etc/docker/registry/config.yml  -v ~/registry:/var/lib/registry   --name registry  registry:2
                キャッシュの有無を表示します:
                    curl http://localhost:5000/v2/_catalog
                        {"repositories":[]}
                ubuntu でキャッシュの確認:  #// 失敗します  #ref: https://docs.docker.com/registry/
                    Pull (or build) some image from the hub:
                        docker pull ubuntu:12.04
                    Tag the image so that it points to your registry:
                        docker image tag ubuntu:12.04 localhost:5000/myfirstimage:latest
                    Push it:  #// 失敗します
                        docker push localhost:5000/myfirstimage:latest
                    エラー:
                        ミラー: |
                            err.message="The operation is unsupported."
                        docker: |
                            level=error msg="Upload failed, retrying: unsupported"
            参考:
                #ref: https://zenn.dev/kou64yama/articles/powerful-docker-build-cache
                #ref: https://docs.docker.com/build/cache/
                #ref: https://docs.docker.com/build/cache/backends/
Kubernetes (k8s): #keyword:  #// クーべネティス 「ク」にアクセント → #ref: https://www.youtube.com/watch?v=uMA7qqXIXBk >> 0:58 「kube（クーベ）」「K8s (ケーエイツ)」
    #// 複数ホストでコンテナを運用したい場合などの管理
    helm:  #// Kubernetes の パッケージ マネージャー
    コンパクトな Kubernetes:
        k3s: #keyword:  #ref: https://qiita.com/ynott/items/89941c36c606a8384028
        MicroK8s: #keyword:
Podman: #keywor:  #// デーモンレスの Docker 相当。Docker と排他
    #ref: https://qiita.com/arinko_arintyu/items/10465fa0765f70e77b12
    Docker は非推奨か:
        _: “RockyLinux が Docker を非推奨としている”と断言できる“公式な”一次資料は、調査では見つかりませんでした。
        #chat: RockyLinux がDockerを非推奨としている情報源は
VirtualBox:  #keyword: VirtualBox  #// 仮想化プロバイダーの 1つ
    注意: VirtualBox のバージョンを上げると Vagrant から作った VM はリストアできなくなります。
        ただし、6.1.34 ⇒ 6.1.36 はリストアできた。
        リストア  #search: Vagrant VirtualBox restore
    手順:
        インストール:
            Vagrant を使う場合:  #search: Vagrant
            VirtualBox + CentOS インストール(Windows):  #keyword: install VirtualBox+CentOS
                CentOS8:  #// CentOS 8 を VirtualBox にインストールします
                    設定: #settings:
                        __VM_UserName__: user1  #// SSH のユーザー名と合わせると SSH でユーザー名を省略できます
                    参考: https://qiita.com/yasushi-jp/items/01b4829a36272954719f
                    #// 以下は GUI が使える環境のインストールです
                    VirtualBox をインストールします:
                        - https://www.virtualbox.org/ >> Windows hosts
                        - ダウンロードしたファイル（例：VirtualBox-6.1.18-142142-Win.exe）を開きます
                        - インストール オプションはデフォルトを使用
                        - ドライバーはインストールします
                        - 日本語表示にします  VirtualBox >> File >> Preferenes >> Language >> 日本語（最下近く）
                    CentOS の .iso ファイルをダウンロードします:
                        #// サイズは約9.0GB
                        - https://www.centos.org/ >> Download >> ISO 列 >> x86_64
                        - 例 CentOS-8.3.2011-x86_64-dvd1.iso
                    仮想マシンを新規作成します:
                        メニュー: VirtualBox >> 新規（右上）
                        名前: CentOS-8.3.2011  #// 例
                        マシンフォルダー: （変更しない）
                        タイプ: Linux  #// 変更しない
                        バージョン: Red Hat (64-bit)   #// 変更しない
                        メモリーサイズ: 2048MB
                        仮想ハードディスクを作成する:
                        ハードディスクのファイルタイプ: VDI
                        可変サイズ:
                        ファイルの場所: C:\Users\____\VirtualBox VMs\____ （変更しない）
                        ハードディスクのサイズ: 16GB
                    CentOS をインストールします:
                        VM の周辺の設定:
                            メニュー: VirtualBox >> 設定（右上）
                            光学ドライブのディスク（.iso ファイル）を設定します:
                                設定 >> ストレージ（左）>> 光学ドライブの追加（コントローラー IDEの右） >>
                                    追加（左上）>> （例） CentOS-8.3.2011-x86_64-dvd1.iso >> 選択
                            ネットワークを設定します:
                                メニュー: 設定 >> ネットワーク（左）
                                割り当て: NAT  #// 参考: snote >> ネットワーク (VMware Player)
                            OK ボタン:
                        仮想マシンを起動してOSをインストールします:
                            メニュー: VirtualBox >> 起動（右上）>> Install CentOS Linux 8（カーソルキーで選択してEnterキー）
                            キャプチャー ボタン:  #// 仮想マシンをクリックするとボタンが表示されます
                                #// マウス統合機能がオフのとき（OSインストール前）に仮想マシンでマウスが操作できるようになります
                            （右側の）Ctrlキー: #// キャプチャーを終了します。Ctrlキーであることは VirtualBoxの右下に表示されています
                            Language: Japanese >> 日本語 >> 続行
                            インストール概要:
                                キーボード: 日本語
                                言語サポート: 日本語
                                インストール先:
                                    完了 ボタン（左上）:
                                ネットワーク:
                                    （接続）（右上）: オン
                                    ホスト名（左下）: CentOS
                                    適用 ボタン（下）:
                                    完了 ボタン（左上）:
                                時刻と日付:  #// ネットワークを設定した後で設定します
                                    地域: アジア/東京  #// 地図上をクリック
                                    歯車アイコン（右上）:
                                        - ntp1.jst.mfeed.ad.jp, プール（にチェック）, 使用（にチェック）
                                    ネットワーク時刻（右上）: オン
                                    完了 ボタン（左上）:
                                root パスワード: root
                                ユーザーの作成:
                                    フルネーム: user1  #template: __VM_UserName__
                                    ユーザー名: user1  #template: __VM_UserName__
                                    パスワード: user1  #template: __VM_UserName__
                                インストールの開始 ボタン:  #// 約10分待つ
                            システムの再起動 ボタン:
                            電源オフ:
                        仮想マシンを起動してOSを起動します:
                            メニュー: VirtualBox >> 設定（右上）
                            光学ドライブのディスク（.iso ファイル）を取り除きます:
                                設定 >> ストレージ（左）>> .iso ファイル（右クリック）>> 割り当てを除去
                                    #// 自動的に除去されているときは操作不要です
                            メニュー(2): VirtualBox >> 起動（右上）
                            License Information:
                                ライセンス契約に同意します: チェック
                                完了 ボタン（左上）:
                                設定の完了 ボタン（右下）:
                            サインイン:
                            ようこそ画面:
                                Welcome: 日本語
                                入力: 日本語
                                プライバシー:
                                    位置情報サービス: オフ
                                オンラインアカウント: スキップ
                                CentOS Linux を使い始める ボタン:
                            初めて使う方へ:
                                × ボタン（右上）:
                    Guest Additions をインストールします:  #// クリップボードの共有などができるようになります
                        参考: https://qiita.com/kichise/items/cd486ae6ea88efd88c20
                        必要なパッケージを追加します:
                            メニュー: CentOS >> アクティビティ（左上）>> 端末
                            bash:
                                - su -
                                - sudo dnf group install -y "Development Tools"  #// 約5分
                                - sudo dnf install -y  elfutils-libelf-devel
                        OSを最新に更新します:  #keyword: dnf upgrade
                            - sudo dnf clean all
                            - sudo dnf check-update
                            - sudo dnf -y upgrade  #// 約10分
                        再起動します:
                            - sudo shutdown -r now  #// 再起動に約3分
                        ログインします:
                        CDイメージを挿入します:
                            VirtualBox >> デバイス >> Guest Additions CD イメージの挿入  #// 約10秒待つ
                        自動起動しないとき:
                            CentOS >> アクティビティ >> ファイル >> VBox_GAs____ >> ソフトウェアの実行（右上）
                        インストールします:
                            - 自動起動したウィンドウ >> 実行する（右下）
                            - 管理者（root）のパスワードを入力  #// 約3分
                            - Press Return to close this window と表示されたら、Enter キーを押します
                            - CentOS >> ▼（右上）>> 電源 ボタン >> 再起動  #// 約1分
                        ログインします(2):
                        クリップボードを共有します:
                            VirtualBox >> デバイス >> クリップボードの共有 >> 双方向  #// 数秒待つ(?)
                        VirtualBox のウィンドウのサイズを適度な大きさに変更します:
                            #// CentOS の画面サイズが VirtualBox の ウィンドウ サイズ に追従します
                    下記「sudo が使えるかチェックします」:
                    （必要なら）下記「共有フォルダーを設定します」:
                CentOS7:  #// CentOS 7 を VirtualBox にインストールします。 Docker などのインストール手順もあります
                    設定: #settings:
                        __VM_UserName__: user1  #// SSH のユーザー名と合わせると SSH でユーザー名を省略できます
                        __VM_MemorySize__: 2048MB
                        __VM_HDD_Size__: 32GB
                        __SharedName__: share  #// 共有フォルダーの識別名
                    VirtualBox をインストールします:
                        - https://www.virtualbox.org/ >> Download VirtualBox X.X >> Windows hosts
                        - ダウンロードしたファイル（例：VirtualBox-6.1.18-142142-Win.exe）を開きます
                        - インストール オプションはデフォルトを使用
                        - ドライバーはインストールします
                        - 日本語表示にします  VirtualBox >> File >> Preferenes >> Language >> 日本語（最下近く）
                    CentOS の .iso ファイルをダウンロードします:
                        #// サイズは約4.5GB
                        - https://www.centos.org/ >> CentOS Linux >> 7 (2009) >> ISO 列 >> x86_64
                        - The following mirrors in your region should have the ISO images available 以下のいずれか
                        - 例 CentOS-7-x86_64-DVD-2009.iso
                    仮想マシンを新規作成します:
                        メニュー: VirtualBox >> 新規（右上）
                        名前: CentOS-7  #// 例
                        マシンフォルダー: （変更しない）
                        タイプ: Linux  #// 変更しない
                        バージョン: Red Hat (64-bit)   #// 変更しない
                        メモリーサイズ: 2048MB  #template: __VM_MemorySize__
                        仮想ハードディスクを作成する:
                        ハードディスクのファイルタイプ: VDI
                        チェックする: 固定サイズ
                        ファイルの場所: C:\Users\____\VirtualBox VMs\____ （変更しない）
                        ハードディスクのサイズ: 32GB  #template: __VM_HDD_Size__
                    CentOS をインストールします:
                        VM の周辺の設定:
                            メニュー: VirtualBox >> 設定（右上）
                            光学ドライブのディスク（.iso ファイル）を設定します:
                                設定 >> ストレージ（左）>> 光学ドライブの追加（コントローラー IDEの右） >>
                                    追加（左上）>> （例） CentOS-7-x86_64-DVD-2009.iso >> 選択
                            OK ボタン:
                        仮想マシンを起動してOSをインストールします:
                            メニュー: VirtualBox >> 起動（右上）>> Install CentOS Linux 7（カーソルキーで選択してEnterキー）
                            キャプチャー ボタン:  #// 仮想マシンをクリックするとボタンが表示されます
                                #// マウス統合機能がオフのとき（OSインストール前）に仮想マシンでマウスが操作できるようになります
                            （右側の）Ctrlキー: #// キャプチャーを終了します。Ctrlキーであることは VirtualBoxの右下に表示されています
                            Language: Japanese >> 日本語 >> 続行
                            インストール概要:
                                キーボード: 日本語
                                言語サポート: 日本語
                                続行 ボタン:
                                インストール先:
                                    完了 ボタン（左上）:
                                ネットワークとホスト名:
                                    （接続）（右上）: オン
                                    完了 ボタン（左上）:
                                時刻と日付:  #// ネットワークを設定した後で設定します
                                    地域: アジア/東京  #// 地図上をクリック
                                    （しなくてもよい）歯車アイコン（右上）:
                                        - ntp1.jst.mfeed.ad.jp, 使用（にチェック）
                                        - その他, 使用（のチェックを外す）
                                    ネットワーク時刻（右上）: オン
                                    完了 ボタン（左上）:
                                ソフトウェアの選択:
                                    ベース環境: サーバー(GUI 使用)
                                    選択した環境のアドオン: （チェックなし）
                                    完了 ボタン（左上）:
                                インストールの開始 ボタン:
                                    root パスワード: root
                                    ユーザーの作成:  #// SSH でログインするときのユーザー名に合わせると SSH でユーザー名を省略できます
                                        フルネーム: user1  #template: __VM_UserName__
                                        ユーザー名: user1  #template: __VM_UserName__
                                        チェック: このユーザーを管理者にする
                                        パスワード: user1  #template: __VM_UserName__
                                    #// 約10分待つ
                            再起動 ボタン:
                        VM（仮想マシン）の電源をオフにします:  #// 起動するOSを選択する画面になってから
                            （VMのウィンドウを閉じる） >> 仮想マシンの電源オフ >> OK
                        仮想マシンを起動してOSを起動します:
                            メニュー: VirtualBox >> 設定（上）
                            光学ドライブのディスク（.iso ファイル）を取り除きます:
                                設定 >> ストレージ（左）>> .iso ファイル（右クリック）>> 割り当てを除去
                            メニュー(2): VirtualBox >> 起動（上）
                            License Information:
                                ライセンス契約に同意します: チェック
                                完了 ボタン（左上）:
                                設定の完了 ボタン（右下）:
                    user1 ユーザーでログインします:  #template: __VM_UserName__
                    ようこそ画面に入力します:
                        ようこそ画面:
                            Welcome: 日本語
                            入力: 日本語
                            プライバシー:
                                位置情報サービス: オフ
                            オンラインアカウント: スキップ
                            CentOS Linux を使い始める ボタン:
                        初めて使う方へ:
                            × ボタン（右上）:
                    スクリーン セーバーを無効にします:
                        メニュー: CentOS >> アプリケーション >> システムツール >> 設定 >> 電源管理
                        ブランク スクリーン: しない
                    sudo が使えるかチェックします:
                        メニュー: CentOS >> アプリケーション >> システムツール >> 端末
                        shell: sudo pwd
                            #// sudo できないと「sudoers ファイル内にありません」エラーになります
                        （必要なら）現在のユーザーに sudo ができる権限を与えます:
                            - su -   #// 左記実行後、root のパスワードを入力します
                            - sudo visudo :
                                開いた vi で最も下に移動します: Ctrl+n, Ctrl+p, ix, Esc ZZ
                                下記 %wheel のを探します: |
                                    %wheel  ALL=(ALL)  ALL
                                見つかった行の下に下記を追加します。 __UserName__ は置き換えてください:
                                    __UserName__  ALL=(ALL)  ALL
                            - exit  #// root ユーザーを終了します
                    ネットワークが使えることを確認します:
                        メニュー: アプリケーション（左上） >> FireFox
                        VM（Guest OS）からのみ接続できないとき（Host OS はインターネットが見えるとき）は proxy の設定をします:
                            CentOS7 に proxy を設定します:  #keyword: CentOS7 Linux proxy, CentOS7 bash proxy
                                メニュー: CentOS >> アプリケーション >> システムツール >> 端末
                                sudo nano /etc/profile : | # 最終行に下記を追加。再起動時に有効になる環境変数を設定しているだけです
                                    #iidabashi
                                    MY_PROXY_URL="http://___.___.___.___:____/"
                                    HTTP_PROXY=$MY_PROXY_URL
                                    HTTPS_PROXY=$MY_PROXY_URL
                                    FTP_PROXY=$MY_PROXY_URL
                                    NO_PROXY=127.0.0.1, localhost, 192.168.___.___
                                    http_proxy=$MY_PROXY_URL
                                    https_proxy=$MY_PROXY_URL
                                    ftp_proxy=$MY_PROXY_URL
                                    no_proxy=127.0.0.1, localhost, 192.168.___.___

                                    export HTTP_PROXY HTTPS_PROXY FTP_PROXY NO_PROXY http_proxy https_proxy ftp_proxy no_proxy
                                no_proxy:  #keyword: CentOS7 no_proxy
                                    #search: no_proxy
                                    CSV 形式:
                                        サンプル:
                                            - no_proxy=127.0.0.1, localhost, 192.168.___.___
                                    ワイルドカード:  #// * は多くの場合無効です
                                        参考: https://access.redhat.com/documentation/ja-jp/openshift_container_platform/3.9/html/installation_and_configuration/install-config-http-proxies
                                        サンプル:
                                            - no_proxy=192.168.*  #// * は１つだけ指定できることがありますが、多くの場合無効です
                                    現在のシェル:
                                        export no_proxy="127.0.0.1, localhost, 192.168.___.___"
                                shell:
                                    - source /etc/profile
                                    - echo $http_proxy  #// プロキシの URL が表示されること
                                    - wget http://google.com/
                                    - cat index.html  #// 何か表示されること
                                    - rm index.html
                                    - reboot
                                同じユーザーでログインします:
                    CentOS を最新にします（yum update）:  #keyword: yum update
                        アプリケーション（左上） >> システムツール >> 端末:
                            - sudo rm /var/run/yum.pid
                            - yum clean all
                            - sudo yum update  #// すべて y を選びます
                        トラブルシューティング:
                            - ケース:
                                エラー: |
                                    "Failed to connect to 2001:____:___::_:__: ネットワークに届きません"
                                        :
                                    Cannot find a valid baseurl for repo: base/7/x86_64
                                対処:
                                    yum が使う proxy を設定します: #keyword: yum proxy  #// root ユーザー以外で sudo するときに必要？
                                        sudo vi /etc/yum.conf : | # 最終行に下記を追加
                                            proxy=http://___.___.___.___:____/
                                    yum lock を解除します:
                                        bash: sudo rm /var/run/yum.pid
                            - メモ:
                                エラー: "Failed to connect to ____:____:___::_:__: ネットワークに届きません"
                                原因: ____:____:___::_:__ は IPv6 アドレスです。 IPv6を無効にしてください
                                対処:
                                    IPv6 を無効にします:
                                        - sudo nano /etc/sysctl.conf : |  #// 最終行に下記を追加
                                            net.ipv6.conf.all.disable_ipv6 = 1
                                            net.ipv6.conf.default.disable_ipv6 = 1
                                        - shell: |
                                            sudo sysctl -p
                                            ifconfig | grep inet  #// inet6 がないこど
                                            sudo yum clean all
                                            reboot
                                    または:
                                        - echo "ip_resolve=4" >> sudo tee /etc/yum.conf
                                            #// echo "timeout=120"  >> sudo tee /etc/yum.conf
                                        - reboot  #// 必要？
                    Guest Additions をインストールします:  #// クリップボードの共有などができるようになります  #keyword: Guest Additions
                        参考: https://qiita.com/hiroseabook/items/dc7a9c9ce9e49f15ed45
                        shell:
                            sudo rm /var/run/yum.pid
                            sudo yum install -y bzip2 gcc make kernel kernel-devel kernel-headers dkms gcc-c++  #// 約2分
                        CDイメージを挿入します:
                            VirtualBox の VM のウィンドウ >> デバイス >> Guest Additions CD イメージの挿入  #// 自動実行しない
                        shell(2):
                            - sudo mkdir -p /mnt/cdrom/
                            - sudo mount -r /dev/cdrom/ /mnt/cdrom/
                            - sudo sh /mnt/cdrom/VBoxLinuxAdditions.run
                            - reboot  #// 起動に約2分かかります
                            - 同じユーザーでログインします:
                        VirtualBox のウィンドウのサイズを適度な大きさに変更します:
                            #// CentOS の画面サイズが VirtualBox の ウィンドウ サイズ に追従します
                        （必要なら）クリップボードを共有します:
                            #// ホストOS からゲストOS に SSH 接続するときは不要でしょう
                            VirtualBox の VM のウィンドウ >> デバイス >> クリップボードの共有 >> 双方向  #// 数秒待つ(?)
                            #// Windows のクリップボードが使えなくなったら、VM を再起動して、
                            #// 双方向の代わりに、ホストOSからゲストOSへ と ゲストOSからホストOSへ に適宜切り替えます
                    （必要なら）共有フォルダーを設定します:  #// Windows の C:\Users\____\share と Linux の ~/share を共有する場合
                        #keyword: VirtualBox shared folder
                        参考: https://jade.alt-area.jp/archives/769
                        ホストOS側の設定:
                            メニュー: VirtualBox >> VM >> 設定（上） >> 共有フォルダー（左下）>> 新規共有フォルダーを追加します（青いボタン）
                            フォルダーのパス: C:\Users\____\share  #// ホストOSに手動で作ってください
                            フォルダー名: share  #template: __SharedName__
                            #// チェックは入れない
                            OK ボタン:
                        ゲストOS側の設定:
                            #// Guest Additions がまだインストールしていなかったらインストールします  #search: Guest Additions
                            ユーザーを vboxsf グループに所属させます:
                                - su -
                                - gpasswd --add user1 vboxsf  #template: __VM_UserName__
                                - exit
                                - （Linux をサインアウト）
                                - （Linux にサインイン）
                            共有フォルダーを設定します:
                                - mkdir -p  ~/share
                                - id user1  #// uid, gid を表示します  #template: __VM_UserName__
                                - sudo nano /etc/fstab : |
                                        share  /home/user1/share  vboxsf  defaults,uid=__UID__,gid=__GID__  0  0
                                    #template-at(-1): __SharedName__  /home/__VM_UserName__/share
                                - sudo mount -a
                            共有フォルダーの内容を表示します:
                                - ls  ~/share
                            トラブルシューティング:
                                - #// 共有フォルダーにファイルが無い
                                    手順: ls /vagrant
                                        （出力なし）
                                    対処:
                                        sudo mount -a
                                        #// sudo mount -a は冪等性あり。VM を再起動しても問題なし（何もしなくてもマウント済み）
                                - #// /sbin/mount.vboxsf: mounting failed with the error: No such device
                                    手順: Linux 起動時
                                    エラー:
                                        emergency モードになり、ログを見ると、: |
                                            /sbin/mount.vboxsf: mounting failed with the error: No such device
                                    対処:
                                        上記 /etc/fstab から share の行をコメントアウトします
                    （必要なら）クリップボードを共有します: #search: Guest Additions
                    （必要なら）VM をバックアップします:
                        - VM の電源を切ります
                        - VirtualBox >> VM（を右クリック）>> クローン
                    （必要なら）Docker をインストールします:
                        参考: https://docs.docker.com/engine/install/centos/
                        Docker 本体をインストールします:
                            - sudo yum remove  docker  docker-client  docker-client-latest \
                                docker-common  docker-latest \
                                docker-latest-logrotate  docker-logrotate \
                                docker-engine  #// 初めて実行するときは何も削除されません
                            - sudo yum install -y yum-utils
                            - sudo yum-config-manager  --add-repo \
                                https://download.docker.com/linux/centos/docker-ce.repo
                            - sudo yum install docker-ce docker-ce-cli containerd.io  #// すべて y を選びます
                        プロキシがある LAN の場合:
                            - sudo systemctl edit docker : |
                                [Service]
                                Environment = 'http_proxy=http://___.___.___.___:____' 'https_proxy=http://___.___.___.___:____'
                            - mkdir ~/.docker
                            - nano ~/.docker/config.json : |  #search: Docker proxy Linux
                                {
                                    "proxies": {
                                        "default": {
                                        "httpProxy": "http://___.___.___.___:____",
                                        "httpsProxy": "http://___.___.___.___:____"
                                        }
                                    }
                                }
                        通常のユーザーで使えるようにします:
                            - sudo usermod -aG docker $USER
                            - newgrp docker
                        Docker を起動します:
                            - sudo systemctl start docker
                            - sudo systemctl enable docker
                            - service docker status  #// active (running) と緑色で表示されること
                            - docker run hello-world
                                #// 正常終了したら、表示内容の一部に下記が含まれます。
                                #// Hello from Docker!
                                #// This message shows that your installation appears to be working correctly.
                    （必要なら）Docker Compose をインストールします:
                        - curl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` > docker-compose
                        - sudo mv docker-compose /usr/local/bin/docker-compose
                        - sudo chmod +x /usr/local/bin/docker-compose
                        - docker-compose --version
                    （必要なら）ユーザーをもう１つ追加します(CentOS7):
                        参考: https://qiita.com/Zen-GoTo-May/items/3aab7b6c76e8a857e717
                        ユーザーを追加します: sudo useradd user2
                        パスワードを設定します: sudo passwd user2
                        （必要なら）sudo 権限を設定します: 上記「sudo が使えるかチェックします」
                        ユーザー一覧: sudo cat /etc/passwd
                        （必要なら）ユーザーを削除します: sudo userdel -r user2  #// -r オプションで /home/user2 も削除されます
                    （必要になったら）メモリーの容量を増やします(VirtualBox + CentOS7):  #keyword: VirtualBox memory size
                        VM の電源を切ります:
                        メニュー: VirtualBox >> (対象の VM) >> 設定（上）>> システム >> メインメモリー
                        #// Linux OS 側の設定はありません
                    （必要になったら）ハードディスクの容量を増やします(VirtualBox + CentOS7):  #search: VirtualBox VHDD size
                        参考: #ref: https://cream-worker.blog.jp/archives/1077340749.html
                        SSH で VM に接続できることを確認します:
                        VM の電源を切ります (2):
                        仮想ハードディスクの物理容量を増やします:  #keyword: increase VirtualBox VHDD size
                            .vdi の場合:  #// 仮想ハードディスクの拡張子が .vdi の場合
                                ❗注意: .vmdk に対して以降の操作を行うとディスクが使えなくなります
                                （必要なら）バックアップを取ります:
                                ディスクのサイズを増やします:
                                    VirtualBox >> ファイル >> ツール >> 仮想メディアマネージャー >> （対象の .vdi ファイル）>>
                                        属性 タブ（下） >> サイズ >> 適用（右下）
                                #// 以下に続きます
                            .vmdk の場合:  #// 仮想ハードディスクの拡張子が .vmdk の場合
                                （必要なら）バックアップを取ります:
                                ストレージ ファイル の容量を増やします:
                                    .vdi 形式に変換して容量を増やします:  #// .vmdk → .vdi  → resized .vdi → resized .vmdk
                                        Git bash:  #focus: __Name__, __Name__-2, 102400  #// 61440=100*1024=60GB  #template: __OldHddName__, __NewHddName__,
                                            （VM シャットダウン）>>
                                            (Git bash) cd  "$HOME/VirtualBox VMs/____"
                                            export PATH="/c/Program Files/Oracle/VirtualBox:$PATH"
                                            （2回目以降）
                                                VirtualBox のツール（左上）から "__Name__.vdi" があれば削除
                                                VirtualBox のツール（左上）から "__Name__-2.vmdk" を削除
                                            VBoxManage clonemedium  "__Name__.vmdk"  "__Name__.vdi"  --format vdi
                                            VBoxManage modifymedium "__Name__.vdi"  --resize 102400
                                            VBoxManage clonemedium  "__Name__.vdi"  "__Name__-2.vmdk"  --format vmdk
                                        #// テンプレート
                                            #// 書きかけ
                                            #template-at(-3): "__OldHddName__.vdi"  "__NewHddName__.vmdk"
                                    .vmdk ファイルを切り替えます:  #keyword: switch VirtualBox VHDD
                                        #// バックアップがあること
                                        VirtualBox: |
                                            VirtualBox のツール（左上）>> 
                                                "__Name__.vmdk"（__Name__-2.vmdk ではない）>> 解放（上）>> 解放 >>
                                            （VM）（左）>> 設定（上）>> ストレージ（左）>>（コントローラー:IDE の右）ハードディスクの追加 ボタン >>
                                                "__Name__-2.vmdk"（をダブルクリック）>> OK
                                        #// テンプレート
                                            #// 書きかけ
                                            #template-at(-3): "__NewHddName__.vmdk"
                                    古い .vmdk ファイルを削除します: #keyword: delete VirtualBox VHDD
                                        #// バックアップがあること
                                        VirtualBox: |
                                            VirtualBox のツール（左上）>> 
                                                "__Name__.vdi" >> 除去（上） >> 除去 >> 削除 >>
                                    文書設定: #settings:
                                        __OldHddName__: __Name__
                                        __NewHddName__: __Name__-2
                                    #// 以下に続きます
                                （2回目以降、やり直す場合）.vmdk ファイルをリストアします:  #// ツール（左上）での操作は不要かも？
                                    VM シャットダウン >>
                                    VirtualBox >> ツール（左上）>>（.vmdk ファイル）>> 解放（上）>> 除去（上）>>
                                    .vmdk ファイルを削除してコピー >>
                                    VirtualBox >>（VM）>> 設定（上）>> ストレージ（左）>> ハードディスクの追加 ボタン（コントローラー:IDE（上）の右）>>
                                    追加（上）>>（.vmdk ファイルをダブルクリック）>>（.vmdk ファイルをダブルクリック）>> OK >>
                                    VM 起動
                                #// 以下に続きます
                            VM を起動します:
                                VirtualBox の UI 操作で起動、または vagrant up
                            すでに OS に認識されているか調べます:
                                df  #// 使用率が減っていたら、すでに OS に認識されています
                            （必要なら）sda2 パーティションを削除します:  #// sda2 にファイルシステムとして使われていたパーティションがある場合は削除できます
                                ❗注意: sda2 の内容は消えます。自分で sda2 パーティションを作ったときだけ実行できます。
                                sda2 があるかどうか確認します: |  #// 下記は sda2 が表示されているので sda2 あり
                                    sudo fdisk /dev/sda
                                        コマンド (m でヘルプ): p
                                            Device Boot      Start         End      Blocks   Id  System
                                        /dev/sda1   *        2048    83886079    41942016   83  Linux
                                        /dev/sda2        83886080   125829119    20971520   8e  Linux LVM
                                    Ctrl + C
                                sda2 をアンマウントします: |  #// /sda2 にマウントしてあった場合
                                    sudo vi /etc/fstab  #// 下記をコメントアウト
                                        /dev/sda2 /sda2 xfs defaults 0 0
                                    sudo umount /dev/sda2
                                    sudo reboot
                                sda2 パーティション を削除します: |
                                    su -
                                    fdisk /dev/sda
                                        コマンド (m でヘルプ): d                #// パーティションを論理削除します
                                        パーティション番号 (1,2, default 2): 2  #// 論理削除するパーティション
                                        Command (m for help): w
                                    reboot
                            Rocky Linux 9 ext4 の場合: #keyword: increase Rocky Linux 9 ext4 VHDD size
                                ディスクの使用状況を確認します: |
                                    $ df -h    #focus: 100%
                                        Filesystem      Size  Used Avail Use% Mounted on
                                        devtmpfs        4.0M     0  4.0M   0% /dev
                                        tmpfs           3.8G     0  3.8G   0% /dev/shm
                                        tmpfs           1.6G   17M  1.5G   2% /run
                                        /dev/sda4       9.2G  8.8G     0 100% /
                                        /dev/sda3       469M  324M  116M  74% /boot
                                        /dev/sda2        63M  7.1M   56M  12% /boot/efi
                                        tmpfs           769M     0  769M   0% /run/user/1999
                                パーティションを拡張します:  #// /dev/sda4 を拡張する場合
                                    $ sudo growpart /dev/sda 4  #search: growpart
                                ファイルシステムの種類を表示します:
                                    $ mount | grep sda4
                                        /dev/sda4 on / type ext4 (rw,relatime)
                                type ext4 の場合にファイルシステム上での容量を増やします:
                                    $ sudo resize2fs /dev/sda4
                                状況を確認します: |
                                    $ df -h    #focus: 5%
                                        Filesystem      Size  Used Avail Use% Mounted on
                                        devtmpfs        4.0M     0  4.0M   0% /dev
                                        tmpfs           3.8G     0  3.8G   0% /dev/shm
                                        tmpfs           1.6G   17M  1.5G   2% /run
                                        /dev/sda4       188G  8.8G  172G   5% /
                                        /dev/sda3       469M  324M  116M  74% /boot
                                        /dev/sda2        63M  7.1M   56M  12% /boot/efi
                                        tmpfs           769M     0  769M   0% /run/user/1999
                                    $ lsblk
                                        NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
                                        sda      8:0    0 191.1G  0 disk
                                        ├─sda1   8:1    0     2M  0 part
                                        ├─sda2   8:2    0    64M  0 part /boot/efi
                                        ├─sda3   8:3    0   511M  0 part /boot
                                        └─sda4   8:4    0 190.5G  0 part /
                                    $ sudo fdisk -l
                                        Disk /dev/sda: 191.1 GiB, 205194919936 bytes, 400771328 sectors
                                        Disk model: VBOX HARDDISK
                                        Units: sectors of 1 * 512 = 512 bytes
                                        Sector size (logical/physical): 512 bytes / 512 bytes
                                        I/O size (minimum/optimal): 512 bytes / 512 bytes
                                        Disklabel type: gpt
                                        Disk identifier: F1F1F40B-2A76-42D7-AA4C-38ED8227DBD6

                                        Device       Start       End   Sectors   Size Type
                                        /dev/sda1       37      4095      4059     2M BIOS boot
                                        /dev/sda2     4096    135167    131072    64M EFI System
                                        /dev/sda3   135168   1181695   1046528   511M Linux filesystem
                                        /dev/sda4  1183754 400771294 399587541 190.5G Linux filesystem
                            LVM を使わない場合:  #// VM を新規作成したときに sda2 が無かった場合
                                sda1 パーティションを拡張します: |
                                    su -
                                    fdisk /dev/sda
                                        Command (m for help): d                #// パーティションを論理削除します
                                        Selected partition 1
                                        Partition 1 is deleted
                                        Command (m for help): n
                                        Partition type:
                                        p   primary (2 primary, 0 extended, 2 free)
                                        e   extended
                                        Select (default p): p
                                        Partition number (1-4, default 1):      #// Enter でよい
                                        First sector (2048-209715199, default 2048): 
                                        Using default value 2048
                                        Last sector, +sectors or +size{K,M,G} (2048-209715199, default 209715199): 
                                        Using default value 209715199
                                        Partition 1 of type Linux and of size 100 GiB is set
                                        Command (m for help): a                #// Boot フラグを立てます
                                        Selected partition 1
                                        Command (m for help): w
                                        The partition table has been altered!
                                        Calling ioctl() to re-read partition table.
                                        WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
                                        The kernel still uses the old table. The new table will be used at
                                        the next reboot or after you run partprobe(8) or kpartx(8)
                                        Syncing disks.
                                    reboot
                                ファイル システム のサイズを増やします:  #// OS が認識するディスク容量を パーティション サイズ に合わせます
                                    sudo xfs_growfs /dev/sda1
                                    df
                                #// 以上
                            LVM を使う場合:  #// 未確認
                                OS に認識させます:
                                    （参考）:
                                        ディスクの構造: #search: Linux storage partitions
                                        コマンド:  #search: Linux file system commands
                                    状況を確認します:
                                        sda2 に LVM があるかどうか確認します:
                                            pvs
                                                #// sda2 が表示されたら LVM あり
                                    sda2 が無い場合:
                                        sda2 パーティションを新規作成します: |  #// 途中で終了するときは Ctrl+C
                                            $ su -
                                            # fdisk /dev/sda
                                            コマンド (m でヘルプ): n
                                            Partition type:
                                            p   primary (2 primary, 0 extended, 2 free)
                                            e   extended
                                            Select (default p): p
                                            Partition number (2-4, default 2):      #// Enter でよい
                                            First sector (83886080-125829119, default 83886080):       #// Enter でよい
                                            Using default value 83886080
                                            Last sector, +sectors or +size{K,M,G} (83886080-125829119, default 125829119):       #// Enter でよい
                                            Using default value 125829119
                                            Partition 2 of type Linux and of size 20 GiB is set

                                            Command (m for help): t
                                            Partition number (1,2, default 2):       #// Enter でよい
                                            Hex code (type L to list all codes): 8e
                                            Changed type of partition 'Linux' to 'Linux LVM'

                                            コマンド (m でヘルプ): w                #// 保存して終了
                                            # reboot  #// 再起動します
                                        LVM の物理ボリュームと論理ボリュームを作ります:
                                            sudo yum install -y  lvm2
                                            su -
                                            pvcreate /dev/sda2
                                            vgcreate centos /dev/sda2
                                            lvcreate -l 100%FREE  -n roots  centos
                                        論理ボリュームを xfs ファイルシステムでフォーマットします:
                                            mkfs.xfs /dev/centos/roots
                                        マウントします: |
                                            mkdir /sda2
                                            mount -t xfs  /dev/centos/roots  /sda2
                                            df -T
                                                Filesystem                Type     1K-blocks     Used Available Use% Mounted on
                                                ...
                                                /dev/mapper/centos/roots  xfs       20957184    32992  20924192   1% /sda2
                                            exit   #// root ユーザー からログアウトします
                                        自動マウントを設定します:  #// OS を再起動したときにマウントします
                                            bash: |
                                                sudo vi /etc/fstab  #// #VAGRANT-BEGIN の上、または最終行に、下記を追加
                                                    /dev/mapper/centos/roots /sda2 xfs defaults 0 0
                                        #// 以下に続きます
                                    sda2 がある場合:  #// LVM ありなし両方
                                        #// fdisk /dev/sda の続き
                                        sda2 パーティションを拡張します: |  #// 途中で終了するときは Ctrl+C
                                            コマンド (m でヘルプ): d                #// パーティションを論理削除します
                                            パーティション番号 (1,2, default 2): 2  #// 削除するパーティション
                                            コマンド (m でヘルプ): n                #// パーティションを論理作成します
                                            Select (default p): p                   #// プライマリ
                                            パーティション番号 (2-4, default 2): 2  #// 上記と同じ
                                            初期 sector .... :                      #// Enter
                                            Last sector .... :                      #// Enter  #// ここが増えていないときは VirtualBox のストレージの設定を確認してください
                                            コマンド (m でヘルプ): w                #// 保存して終了
                                            # reboot  #// 再起動します
                                        #// 以下に続きます
                                    sda2 があり、sda2 に LVM がある場合:
                                        OS にディスクサイズの変更を設定します:  #// /dev/sda2 が増えた分 /dev/centos/root も増やします
                                            SSH で VM に接続します: #// VM を再起動すると GUI は表示されないため
                                                #// SSH 接続できないときは、不要なフォルダーを削除するなどして変更前のディスクの空き容量を増やします。
                                            SSH: |
                                                $ sudo yum install -y  lvm2  #// pvresize コマンドが使える場合は不要
                                                $ su -
                                                # pvresize /dev/sda2
                                                # lvextend -l +100%FREE /dev/centos/root
                                                # xfs_growfs /dev/centos/root
                                                # reboot
                                            （エラーになる場合）lvextend コマンドで "centos" not found エラーになるとき:
                                        #// 以下に続きます
                                    sda2 があり、sda2 に LVM が無い場合:
                                        #// 未確認
                                        #// 以下に続きます
                                sda2 にユーザーのフォルダーを作ります:
                                    bash: |
                                        $ sudo mkdir -p  /sda2/vagrant
                                        $ sudo chown  vagrant:vagrant  /sda2/vagrant
                                （必要なら）sda2 の中へ git clone します: #keyword: mkdir sda2,  ln sda2  #snippet-depth: 2  #// ホームにフォルダーを作るコマンドにも応用できます
                                    bash: |
                                        $ cd  /sda2/vagrant
                                        $ git clone __URL__
                                        $ ln -sf  /sda2/vagrant/__Project__  ~/__Project__
                                        $ cd  ~/__Project__
                                新しい .vmdk を作った場合:
                                    古い仮想ハードディスク（.vdi）を削除します:
                                        VirtualBox >> ファイル >> ツール >> ハードディスク タブ >>
                                            （対象の .vdi または .vmdk ファイルを右クリック）>>
                                            除去
                                #// 以下に続きます
                                ハードディスクの容量が増えた VM の動作確認をします:
                                    例） GUI が表示されることを確認します:
                            旧） .vdi の場合:  #// 仮想ハードディスクの拡張子が .vdi の場合
                                ❗注意: .vmdk に対して以降の操作を行うとディスクが使えなくなります
                                （必要なら）バックアップを取ります:
                                ディスクのサイズを増やします:
                                    VirtualBox >> ファイル >> ツール >> 仮想メディアマネージャー >> （対象の .vdi ファイル）>>
                                        属性 タブ（下） >> サイズ >> 適用（右下）
                                ディスクのパーティションを増やします:  #// /dev/sda2 のサイズを増やします
                                    VM 起動 >> 一般ユーザーでログイン: |
                                        $ su -
                                        # fdisk /dev/sda
                                        コマンド (m でヘルプ): p  #// パーティションを一覧します
                                        デバイス ブート      始点        終点     ブロック   Id  システム
                                        /dev/sda1   *        2048     2099199     1048576   83  Linux
                                        /dev/sda2         2099200    32108863    32504832   83  Linux VM
                                        #// 途中で終了するときは Ctrl+C
                                        コマンド (m でヘルプ): d                #// パーティションを論理削除します
                                        パーティション番号 (1,2, default 2): 2  #// サイズ変更するパーティション
                                        コマンド (m でヘルプ): n                #// パーティションを論理作成します
                                        Select (default p): p                   #// プライマリ
                                        パーティション番号 (2-4, default 2): 2  #// 上記と同じ
                                        初期 sector .... :                      #// Enter
                                        Last sector .... :                      #// Enter  #// ここが増えていないときは VirtualBox のストレージの設定を確認してください
                                        コマンド (m でヘルプ): w                #// 保存して終了
                                        # reboot
                                OS にディスクサイズの変更を設定します:  #// /dev/sda2 が増えた分 /dev/centos/root も増やします
                                    SSH で VM に接続します: #// VM を再起動すると GUI は表示されないため
                                        #// SSH 接続できないときは、不要なフォルダーを削除するなどして変更前のディスクの空き容量を増やします。
                                    SSH: |
                                        $ su -
                                        # pvresize /dev/sda2
                                        # lvextend -l +100%FREE /dev/centos/root
                                        # xfs_growfs /dev/centos/root
                                        # reboot
                                    （エラーになる場合）lvextend コマンドで "centos" not found エラーになるとき:
                                        対処: centos は ls /dev で表示される名前に合わせます。例 centos_10
                                        参考 >> ボリュームグループ: #ref: https://atmarkit.itmedia.co.jp/ait/articles/1910/04/news021.html
                                #// 以下に続きます
                            トラブルシューティング:
                                エラー: Resizing to new size ____ is not yet supported for medium
                                対処法:
                                    可変サイズの VDI を新規作成してコピーします:
                                        仮想メディアマネージャー >> （対象の .vdi ファイル）>> コピー（上）>>
                                        エキスパートモード（ガイド付きモードのボタンが表示される）>>
                                        VDI >> 可変サイズ >> コピー ボタン
                                    仮想ハードディスク(.vdi)を切り替えます:
                                        VirtualBox >>（VM）>> 設定（上）>> ストレージ >>
                                        ハードディスクの追加（SATA をクリックして表示される右側のボタン）>>
                                        （新しい .vdi）>> 選択 >>（古い .vdi を右クリック）>> 割り当てを除去 >> OK
                                （不要）.vdi を使うように切り替えます: #keyword: switch VirtualBox storage
                                    VirtualBox >>（VM）>> 設定（上）>> ストレージ >>（ハードディスク名 .vmdk：中央）>>
                                    ハードディスク アイコン（ハードディスク（右上）の右端）>>
                                    ディスクファイルを選択 >> ____.vdi
                            関連 >> :  #search: reduce VirtualBox VHDD file size
                CentOS6: #keyword:
                    Docker を使う場合:  #// 確認済み CentOS7 (2024-03-12)
                        共通部分: |
                            mkdir ~/centos6
                            cd    ~/centos6
                            code  Dockerfile
                                FROM centos:centos6

                                #// Change to archive repository
                                RUN  sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-Base.repo
                                RUN  sed -i 's|#baseurl=http://mirror.centos.org/centos/$releasever|baseurl=http://vault.centos.org/6.9|g' /etc/yum.repos.d/CentOS-Base.repo
                                RUN  yum clean all

                                RUN  yum install -y initscripts
                            docker build  --tag my/centos6  "."  --progress=plain
                        #// 以下に続きます
                        フォアグランドの場合:
                            docker run -it --rm  my/centos6  /bin/bash
                        バックグラウンドの場合:
                            docker run -d  --name centos6  my/centos6  sleep infinity
                            docker exec -it  centos6  bash
                    VirtualBox を使う場合: #// 未確認
                        ダウンロード: CentOS-6.9-x86_64-bin-DVD1.iso  #// 理研 → #ref: https://ftp.riken.jp/Linux/centos-vault/6.9/isos/x86_64/
                        メニュー: VirtualBox >> 仮想マシン メニュー >> 新規
                        Virtual machine Name and Operating System:
                            名前: centos6
                            ISO image: （ダウンロードしたもの）
                            次へ ボタン:
                        Unattached Guest OS Install Setup:
                            Username: user1  #// サンプル
                            Password: user1  #// サンプル
                            次へ ボタン x3:
                            完了 ボタン:
                        #// ログイン プロンプト が出るまでしばらく待ちます
                        VM をバックアップします:
                            #search: VirtualBox back up VM
                        ネットワークに ホスト オンリー アダプター を追加します:
                            #search: VirtualBox host-only networking
                        ログインします:
                            VirutalBox >>（新しい VM を右クリック）>> 表示 >>（ユーザー名）>>（パスワード）
                        VBoxGuestAdditions をインストールします:  #// 未確認
                            sudo mkdir -p /mnt/cdrom
                            sudo mount /dev/cdrom /mnt/cdrom
                            cd /mnt/cdrom
                            sudo sh ./VBoxLinuxAdditions.run
                            sudo reboot
                        SSH サーバー を開始します: |  #// 未確認
                            su -
                            setenforce 0
                            service sshd start
                            vi /etc/ssh/sshd_config
                                PasswordAuthentication yes
                            service sshd restart
                            chkconfig sshd on
                            iptables -I INPUT -p tcp --dport 22 -j ACCEPT
                            service iptables save
                            service iptables restart
                            # vi /etc/sysconfig/network-scripts/ifcfg-eth0
                            #     値の変更
                            #         BOOTPROTO=static
                            #         ONBOOT=yes
                            #     追加
                            #         IPADDR=192.168.34.6     #// Windows Git bash の ipconfig コマンドで確認し、34 を修正
                            #         NETMASK=255.255.255.0
                            #         GATEWAY=192.168.1.1
                            vi /etc/sysconfig/network-scripts/ifcfg-eth1
                                DEVICE=eth1
                                BOOTPROTO=static
                                ONBOOT=yes
                                IPADDR=192.168.148.6
                                NETMASK=255.255.255.0
                                GATEWAY=192.168.148.1
                            ip address add 192.168.148.6/24 dev eth1    #// VM の ホスト オンリー と ipconfig /all で確認
                            service network restart
                            ifconfig eth0
                            setenforce 0
                            vi /etc/sysconfig/selinux
                                SELINUX=disabled
                            reboot
                            ネットワーク >> アダプター2 タブ >> ホスト オンリー アダプター 
                        SSH クライアント から接続します:
                            ssh user1@192.168.36.21
                            つながらない
            VirtualBox mac M1:
                2021-02現在未対応  https://dacekinger.net/m1macminivirtualbox/?
            関連 >> Docker:  #search: Docker install
        VBoxManage:  #keyword: VBoxManage  #// シェルから VirtualBox を操作します
            関連: #search: Ansible
            概要: ホストOSのシェルから VirtualBox を操作します。 VirtualBox のウィンドウでできることと同じことができます。
            手順:
                VirtualBox をインストールします:
                VBoxManage コマンドを使えるように PATH を設定します:
                    (Git bash):
                        export PATH="/c/Program Files/Oracle/VirtualBox:$PATH"
                        VBoxManage  #// ヘルプ表示
                    (PowerShell):
                        $env:PATH = "C:\Program Files\Oracle\VirtualBox;$env:PATH"
                        VBoxManage  #// ヘルプ表示
                VM に対するコマンド:  #search: VBoxManage list  #// など
                VM 名:  #// VBoxManage コマンド に指定する VM 名
                    ~/VirtualBox VMs フォルダー の中のフォルダー名
    コマンド:  #search: VBoxManage
    概念:
        ウィンドウ, 仮想画面:  #// ホスト側のウィンドウ
            日本語表示にします:
                VirtualBox >> File >> Preferenes >> Language >> 日本語（最下近く）
            キャプチャーを解除するキーを変更します:  #keyword: VirtualBox exit capture hot key
                VirtualBox >> File >> 環境設定 >> 入力 >> 仮想マシン >> ホストキーの組み合わせ >>（解除するキーボードのキー）
        VM:  #// 仮想マシン, メモリー, ハード ディスク
            一覧: |  #keyword: VBoxManage list
                VBoxManage list vms
                    "__VmName__" {__VmGUID__}
                VBoxManage list runningvms
                    "__VmName__" {__VmGUID__}
            情報表示:
                コマンド: VBoxManage showvminfo "__VmName__" --machinereadable
                終了コード:  #search: PowerShell 終了コード
                    成功: $? == 0
                    指定した VM が無い:  $? == 1
            VM をクローンします:  #// VM（仮想マシン）を複製します  #keyword: VirtualBox clone
                バックアップします: #keyword: VirtualBox back up VM  #// VirtualBox のクローン機能は使いません
                    ❗注意: Vagrant から作った VM の場合  #search: Vagrant VirtualBox back up VM
                    シャットダウンします:
                        #search: VirtualBox shutdown
                    VirtualBox VMs フォルダーのサブフォルダーをコピーします:
                        - VirtualBox の VM を右クリック >> エクスプローラーに表示
                        - C:\Users\__User__\VirtualBox VMs\____ フォルダー（１つ以上）を
                            バックアップへコピーします
                    VM の電源を入れます:
                        #search: VirtualBox VM start
                別の PC に VM をコピーします:
                    VM のフォルダーを開きます:
                        VirtualBox >> （VM を右クリック）>> エクスプローラーに表示
                            #// C:\Users\__User__\VirtualBox VMs\__VM_Name__ が開きます
                    .vdi ファイルを 512MB ごとに分割します:  #// 512MB でなくても構いません  #search: ファイル分割、結合
                    VM のフォルダーをコピーします:
                        RDP 接続している場合:  #search: TSClient
                    VirtualBox のウィンドウにコピーした VM を表示させます: 
                        VirtualBox >> 仮想マシン >> 追加 >>（フォルダーを指定）
                同じ PC の中でクローンします: #copy: VirtualBox clone from back up
                    注意❗: クローンした VM は SSH 接続できません。対処法は未検討。
                        VSCode からクローン元に接続できなくなったら、VSCode >> Remote Explorer（左）から開いてください
                    既存の VM の電源を落とします:
                        VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> 電源オフ
                    既存の VM の名前をメモしておきます:
                        VirtualBox マネージャー >>（対象のVM）>> 名前（中央上）>> Ctrl + A, Ctrl + C >> メモに張り付け
                    既存の VM を削除（除去）します:
                        VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 除去 >> すべてのファイルを削除
                    VM をコピー（クローン）します:
                        メニュー: VitrualBox マネージャー >>（対象のVM。複数選択可能）（右クリック） クローン >>
                        名前: バックアップ___Name__ (例)
                        #// オプションは、特にこだわりがなければデフォルトで構いません
                        VM の順番を整理します:
                            ドラッグ&ドロップで VM の順番を変更できます
                関連:
                    vSphere: #search:
                    snapshot: #keyword: Linux snapshot
                        Btrfs や ZFS などのファイルシステムの場合:
                            btrfs subvolume snapshot /source /destination
                        論理ボリュームマネージャー（LVM）を使用している場合:
                            lvcreate --size 1G --snapshot --name snapshot_name /dev/vg_name/lv_name
            VM のバックアップからコピーして復帰します:  #// VirtualBox のクローン機能は使いません
                ❗注意: Vagrant から作った VM の場合  #search: Vagrant VirtualBox restore
                （必要なら）既存の VM を削除します:  #copy: VirtualBox delete VM
                    既存の VM の電源を落とします:
                        VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> 電源オフ
                    VirtualBox マネージャーから VM を削除します:
                        VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 除去 >>
                            すべてのファイルを削除
                VirtualBox VMs フォルダーのサブフォルダーをコピーします:
                    - C:\Users\__User__\VirtualBox VMs\____ フォルダー（１つ以上）を
                        バックアップからコピーします
                VirtualBox マネージャーに VM のフォルダーを認識させます:
                    仮想マシンを VirtualBox に追加します:
                        - VirtualBox マネージャー >> 仮想マシン >> 追加（１つ以上も可能）
                            #// *.vmdk ファイルを選びます  #keyword: *.vmdk
            VM の電源を入れます: #keyword: VirtualBox VM start
                起動します, 保存状態のVMから復帰します:
                    VirtualBox >>（VM を右クリック）>> 起動 >> ヘッドレス起動（など）
                VM が保存状態と表示されれいなければ VM を追加しなおします:
                    - VirtualBox >>（VM を右クリック）>> 除去
                    - VirtualBox >> 仮想マシン（メニュー）>> 追加
                #// サービスはアクティブ状態で復帰します。サービスの再起動は行われません。
                #// VSCode などから接続していた SSH シェルを閉じていたら、環境変数などを再設定してください。
            VM をシャットダウンします: #keyword: VirtualBox shutdown
                VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> ACPI シャットダウン
            VM を削除します: #keyword: VirtualBox delete VM
                Window:
                    既存の VM の電源を落とします:
                        VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> 電源オフ
                    VirtualBox VMs フォルダーのサブフォルダーを削除します:
                        - C:\Users\__User__\VirtualBox VMs\____ フォルダー（１つ以上も可能）を
                            削除します  #// シフト キー を押しながら削除するとごみ箱に入らずに削除します
                CLI:
                    VBoxManage unregistervm __VmFullName__ --delete
                        #// すでに無かったらエラーになります
            保存状態: #keyword: VirtualBox 保存状態
                ❗注意: date コマンドで表示される日時が保存したときの日時のままになります
            メモリーやハードディスクの容量を増やします:  #keyword: VirtualBox size
                メモリー:  #search: VirtualBox memory size
                ハードディスク:  #search: Linux df
        VirtualBox Guest Additions: #keyword: Vagrant VirtualBox Guest Additions
            使わないようにする:
                Vagrant.configure("2") do |config|
                    config.vm.provider "virtualbox" do |vb|
                        vb.check_guest_additions = false
                        vb.functional_vboxsf = false
                    end
                    if Vagrant.has_plugin?("vagrant-vbguest") then
                        config.vbguest.auto_update = false
                    end
        ネットワーク:  #keyword: VirtualBox network
            IP アドレス:  #// 192.168.___.___ や 172.___.___.___ など
                #search: IP address
                （操作, 表示）:
                    ホスト OS (Windows) の IP アドレス:
                        (PowerShell): |
                            ipconfig
                        出力例:  #// 該当するサブネットを参照します
                            イーサネット アダプター VirtualBox Host-Only Network:
                                IPv4 アドレス . . . . . . . . . . . .: 192.168.56.1
                    バインド: #keyword: bind IP address,  bind  #// ネットワーク インターフェース にバインドします。自ホストが応答を受けつけるクライアントの範囲の設定
                        （注意）: バインドできるのは ローカル ホスト の ネットワーク インターフェース に限定されます
                        0.0.0.0: #keyword:  #search: bind IP address  #// IPv4 の全ての ネットワーク インターフェース
                        ([::]): #keyword: [::]  #// IPv6 の全ての ネットワーク インターフェース
                        127.0.0.1:  #// ローカル ループバック にバインドします。ローカルから来るリクエストだけ応答します
                        ([fe80::1]): #keyword: [fe80::1]  #// リンクローカル
                        __NetworkInterfaceIPAddress__:  #// 指定した ネットワーク インターフェース にバインドします。LAN 内から来るリクエストだけ応答します
                        __MyHostName__:  #// ローカル ホスト の ネットワーク インターフェース につけられた DNS 名  #search: DNS 名
                プライベート アドレス: #keyword: IP private address
                    クラスC: 192.168.0.0/16,  192.168.x.x    #ref: ${programming}/ネットワーク・セキュリティ/IPアドレスの設定.svg#ip192_168  #keyword:
                    クラスB: 172.16.0.0/12,   172.16.x.x～172.20.x.x
                    クラスA: 10.0.0.0/8,      10.x.x.x    #ref: ${programming}/ネットワーク・セキュリティ/IPアドレスの設定.svg#ip_10  #keyword:
                    #// 詳細は下記
                VirtualBox のホスト: #keyword: VirtualBox host IP address
                    VM がどのアダプターを使っているかによります:
                        調べ方:  #search: VirtualBox network adapter window
                    VM が ホスト オンリー アダプター を使っている場合: |  #search: set VirtualBox host-only adapter
                        VirtualBox >> ツール（左上）>> ホストオンリーネットワーク タブ >>
                        VirtualBox Host-Only Ethernet Adapter #2 （など）>>
                        IPv4 アドレス
                192.168.___.___: #keyword:  #// クラス C のネットワーク
                    サンプル: 192.168.34.47/24
                    192.168.x.x になった理由:  #ref: https://gigazine.net/news/20250909-private-ip-address-192-168/
                    #ref: ${programming}/ネットワーク・セキュリティ/IPアドレスの設定.svg#ip192_168
                    #search: CIDR
                127.0.0.1: #keyword: 127.0.0.1, localhost, ループバック アドレス
                    - リクエストを自分のマシンにループバックします。
                    - ポート番号が異なれば、別のサービスが応答します。
                    - 127.0.0.1 と localhost は同じホストを指します。
                    #ref: ${programming}/ネットワーク・セキュリティ/IPアドレスの設定.svg#localhost
                172.___.___.___: #keyword:  #// 172.16.0.0 から 172.31.255.255  #// クラス B のネットワーク
                    範囲: 172.16.0.0 ～ 172.31.255.255
                    サンプル: 172.31.255.15/24  #// このサンプルのサブネットマスクは VirtualBox で使える範囲より狭くなっています
                172.17.0.1, host.docker.internal:
                    Docker 内部の デフォルト ゲートウェイ
                    Docker の ホスト OS
                10.0.2.2:
                    VM 環境内部の デフォルト ゲートウェイ
                    VirtualBox などの ホスト OS
                10.___.___.___:  #// クラス A のネットワーク
                0.0.0.0:  #// IPv4 の全ての ネットワーク インターフェース  #search: bind IP address
                ([::]): #// IPv6 の全ての ネットワーク インターフェース  #search: [::]
                ([fe80::1]):  #// リンクローカル  #search: [fe80::1]
                224.0.0.1: 全てのホスト向けマルチキャスト
                224.0.0.2: 全ルータ向けマルチキャスト
            アダプター: #keyword: VirtualBox network adapter  #// VM に刺さっている仮想的な NIC  #search: ネットワーク アダプター
                表示: VirtualBox >>（VM：左半分のどれか）>> 設定（上）>> ネットワーク（左）  #keyword: VirtualBox network adapter window
                通常の構成: #// NAT + ホスト オンリー アダプター
                    アダプター1: NAT                         #search: VirtualBox NAT
                    アダプター2: ホスト オンリー アダプター  #search: VirtualBox host-only adapter
                種類, 割り当ての種類:  #// NAT, ホスト オンリー アダプター
                    NAT: #keyword: VirtualBox NAT  #// アダプターを NAT に割り当てた場合
                        このアダプターに設定された IP アドレスのサブネットに対する通信は、インターネット等に接続します
                    ホスト オンリー アダプター: #keyword: VirtualBox host-only adapter
                        #// アダプターを ホスト オンリー ネットワーク に割り当てた場合  #keyword: VirtualBox host-only networking
                        _: 通常、NAT と ホスト オンリー アダプター の 2つのアダプターを 1つの VM に挿します  #search: default NAT NAT network
                        通信可能: ホストOS, 他のVM
                        通信禁止: インターネットや外部ネットワーク
                            #// インターネット等へのアクセスは、まず NAT に対してアクセスします  #search: VirtualBox NAT
                        設定:  #search: set VirtualBox host-only adapter
                        VirtualBox を再インストールしたとき >> エラーになる場合: 一度別の設定をしてから、再設定してください
                    NAT ネットワーク: #keyword: VirtualBox NAT network  #// アダプターを NAT ネットワーク に割り当てた場合
                        _: 通常使いません  #search: default NAT NAT network
                        コマンド:
                            一覧: #keyword: VBoxManage list natnets
                                VBoxManage list natnets
                            作成: #keyword: VBoxManage natnetwork add
                                コマンド: VBoxManage natnetwork add --netname NatNetwork --network "10.0.2.0/24" --enable
                                --network オプション:
                                    通常、プライベートネットワークアドレス範囲である以下のいずれかを使用します：
                                        10.0.0.0/8（10.0.0.0 から 10.255.255.255）
                                        172.16.0.0/12（172.16.0.0 から 172.31.255.255）
                                        192.168.0.0/16（192.168.0.0 から 192.168.255.255）
                                    これらの範囲から、他のネットワークと重複しないサブネットを選択して使用します。
                                    VirtualBoxのデフォルトNATモードで設定されたと思われる VM の既存の IP アドレスに
                                    --network オプション を合わせるのが良いのでしょうか
                                    10.0.0.0/8 は社内LAN、172.31.255.0/24 と 192.168.34.0/24 は既存の VirtualBox が使っています。
                                    --network オプション に 192.168.34.0/24 を設定してよいでしょうか
                    （種類の比較）:
                        NAT + ホスト オンリー アダプター の構成との違い: #keyword: default NAT NAT network   #focus: NAT_HostOnly, NAT_Network
                            ネットワークアダプターの数:
                                NAT_HostOnly: 2
                                NAT_Network: 1
                            通信の流れ:
                                NAT_HostOnly: VM 内で分岐
                                NAT_Network: NATネットワークで分岐
                            #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: default NAT network
                選択:
                    NAT を使うか ホスト オンリー アダプター を使うか:
                        接続先として指定した IP アドレスによって、どのアダプターを使うかが自動的に選択されます
                    どの ホスト オンリー アダプター を使うか: #keyword: set VirtualBox host-only adapter
                        #// 手動で選択します
                        メニュー: VirtualBox >>（VM：左）>> ネットワーク（中央）>> アダプター 2（割り当て＝ホストオンリーアダプターが選ばれているもの）
                        名前のサンプル:
                            - VirtualBox Host-Only Ethernet Adapter
                            - VirtualBox Host-Only Ethernet Adapter #2
                            - ...
                        どのアダプターを使うか:
                            VM の IP アドレスを調べます: |
                                ip addr
                                    192.168.___.___
                            Windows の IP アドレスを調べます: |
                                ipconfig /all
                                    イーサネット アダプター イーサネット 3:
                                        説明. . . . . . . . . . . . . . . . .: VirtualBox Host-Only Ethernet Adapter
                                        IPv4 アドレス . . . . . . . . . . . .: 192.168.56.1(優先)
                                        ...
                                    イーサネット アダプター イーサネット 4:
                                        説明. . . . . . . . . . . . . . . . .: VirtualBox Host-Only Ethernet Adapter #2
                                        IPv4 アドレス . . . . . . . . . . . .: 192.168.34.1(優先)
                                        ...
                            同じサブネットのアダプターを選びます:  #// 今まで選んでいた名前から変える場合もあります。IPv4 アドレスを合わせます
                                OK ボタンを押します:
                                これまでの接続: すぐに切断されます
                                新しい接続: 20秒近くたってから接続できます
                            （未確認）対応するアダプターが Windows に無い場合:
                                作成: VirtualBox >> ツール（左上）>> ホストオンリーネットワーク タブ >> 作成（上）
                                設定変更: （アダプターを選ぶ）>> プロパティ（上）>> IPv4 アドレス（を編集）
            DHCPサーバー: #keyword: VirtualBox DHCP
                dig 対応: #keyword: VirtualBox dig  #// 不可
                    - DHCP サーバーの標準機能が DNS の一部の機能に該当しますが、dig コマンドには応答できません。
                    - インターネットの先の接続先に対しては dig コマンドは使えます。
                探します:
                    PowerShell:
                        VBoxManage list hostonlyifs  #search: VBoxManage
                    DHCP フィールド:
                        IP アドレスの場合: DHCP サーバーの IP アドレス  #// 未確認
                        すべてのアダプターで Disabled の場合: DHCP サーバーはありません
            共有フォルダー:  #search: VirtualBox shared folder 
            (VMWare の資料):  #ref: ${programming}/OS/VMWare.svg#vmware_net
        ストレージ:  #// 「ディスク イメージ ファイル」
            手順:
                使用量を減らします:  #keyword: reduce VirtualBox VHDD file size
                    VM 内:  #// Linux の df コマンド による使用量を減らします
                        #search: Linux 容量不足
                    ホスト:  #// ディスク イメージ ファイル のサイズを減らします
                        VM 内の大きいフォルダーを削除します:
                            bash in VM:
                                rm -rf ____
                                df
                                #search: Linux 容量不足
                        仮想ディスクの空きセクターをゼロで埋めます:
                            bash in VM: |
                                date
                                sudo dd if=/dev/zero of=/tmp/zero.fill bs=1M
                                    dd: error writing ‘/tmp/zero.fill’: No space left on device
                                    83251+0 records in
                                    83250+0 records out
                                    87294017536 bytes (87 GB) copied, 616.272 s, 142 MB/s
                                date    #// dd の次に実行するコマンドを入力しておきます
                                    （+10分）
                                sudo rm -f /tmp/zero.fill
                                date
                                    （+1秒）
                        .vmdk ファイルを小さくします:
                            VM シャットダウン:
                            Git bash: |
                                cd  __VM__  #// .vmdk ファイルがある場所
                                export PATH="/c/Program Files/Oracle/VirtualBox:$PATH"
                                （2回目以降）
                                    VirtualBox のツール（左上）から "centos-7-1-1.x86_64-3.vdi" を削除
                                    VirtualBox のツール（左上）から "centos-7-1-1.x86_64-4.vmdk" を削除
                                date
                                VBoxManage clonemedium  "centos-7-1-1.x86_64-3.vmdk"  "centos-7-1-1.x86_64-3.vdi"  --format vdi
                                date
                                VBoxManage modifymedium "centos-7-1-1.x86_64-3.vdi"  --compact
                                date  #// 2分
                                VBoxManage clonemedium  "centos-7-1-1.x86_64-3.vdi"  "centos-7-1-1.x86_64-4.vmdk"  --format vmdk
                                date
                        .vmdk ファイルを切り替えます:
                            #search: switch VirtualBox VHDD
                        古い .vmdk ファイルを削除します:
                            #search: delete VirtualBox VHDD
                容量を増やします:  #search: increase VirtualBox VHDD size
                切り替えます:  #search: switch VirtualBox VHDD  #// VM が使う ディスク イメージ ファイル を切り替えます
            ファイルの種類:
                VDI, .vdi: #keyword:  #// Virtual Disk Image。VirtualBox の標準
                VMDK, .vmdk: #keyword:  #// VDI より高速。サイズ変更できない（VDI 経由ならできる）。VMWare の標準
                    #ref: https://www.parallels.com/blogs/ras/vdi-vs-vhd-vs-vmdk/
                （関連）:
                    WSL2:  #search: VHDX ファイル
    ファイル:
        OVA ファイル (.ova):  #// Open Virtualization Format (OVF)。 VirtualBox などの仮想マシンの構成や状態が丸ごと入ったファイル
            対応仮想化プロバイダー:
                Oracle VirtualBox
                VMware Workstation, VMware Fusion, VMware vSphere/ESXi
            変換によって対応できる仮想化プロバイダー:
                QEMU/KVM
                Microsoft Hyper-V
            関連: #search: .qcow2 ファイル  #search: .box ファイル
    コード:
        bash: #glossary: VirtualBox bash
            ShutdownVM:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/install.sh#function  ShutdownVM
            BackUpVM:    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/install.sh#function  BackUpVM
            RestoreVM:   #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/install.sh#function  RestoreVM
            DestroyVM:   #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/install.sh#function  DestroyVM
            HaltVM:      #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/install.sh#function  HaltVM
    トラブルシューティング:
        - VirtualBox に対する Ansible の実行で止まる:  #search: knock-ssh.sh
        - Windows から SSH アクセスを繰り返してしてみる: #keyword: knock-ssh.sh
            コマンド:
                ./knock-ssh.sh  &  #// Prevent VirtualBox CPU stuck
            コード: |
                #!/bin/bash
                for i in {1..60}; do 
                    ssh vm-local_server-1  hostname
                    sleep  30s
                    ssh vm-local_server-2  hostname
                    sleep  30s
                done
        - IRQ 例外:
            L [___.067007], R[____.178072]
            R で例外発生後、表示していた R の画面を閉じたら動き出した
            SSH アクセスすると続きを実行できそう  #search: knock-ssh.sh
        - #// VERR_INTNET_FLT_IF_NOT_FOUND
            手順: vagrant up
            ログ: |  #focus: Failed to open/create the internal network,  Host-Only Ethernet Adapter
                Stderr: VBoxManage.exe: error: Failed to open/create the internal network 'HostInterfaceNetworking-VirtualBox Host-Only Ethernet Adapter #4' (VERR_INTNET_FLT_IF_NOT_FOUND).
                VBoxManage.exe: error: Failed to attach the network LUN (VERR_INTNET_FLT_IF_NOT_FOUND)
                VBoxManage.exe: error: Details: code E_FAIL (0x80004005), component ConsoleWrap, interface IConsole
            対処: #keyword: VirtualBox Windows IPv6
                Windows の ネットワーク アダプター の IPv6 を無効にして、
                ネットワーク アダプター を 無効 にして 有効 にします。
                #search: Windows IPv6
        - #// VSCode から VM に SSH 接続できない  #search: VSCode SSH trouble
        - #// Windows のブラウザーなどから VM にアクセスできない #keyword: VirtualBox network trouble Windows and VM 
            ホスト オンリー アダプター を正しく設定します: #search: set VirtualBox host-only adapter
            iptables: #search:
        - #// 瞑想中（システムエラー）
            手順: VirtualBox のウィンドウの中の VM 一覧の中の VM のステータス
            エラー: |
                瞑想中（システムエラー）
            対処:
                書式: VBoxManage.exe controlvm  __VMFolderName__  poweroff
                __VMName__: ~/VirtualBox VMs フォルダー の中のフォルダー名
            サンプル (PowerShell):
                $env:PATH = "C:\Program Files\Oracle\VirtualBox;$env:PATH"
                VBoxManage.exe controlvm  project_name_1685936563514_93307  poweroff
        - #// ネットワークの設定ができない
            手順: VirtualBox >> 設定 >> ネットワーク
            状況: グレーアウト
            対処: VM の電源をオフにしてください
        - #// VERR_NEM_INIT_FAILED
            手順: VM を起動したとき
            エラー: |
                仮想マシン"____"のセッションを開けませんでした。
                Call to NEMR0InitVMPart2 failed: VERR_NEM_INIT_FAILED (VERR_NEM_VM_CREATE_FAILED).
                終了コード : E_FAIL (0x80004005)
                コンポーネント: ConsoleWrap
                インターフェース: IConsole {________-____-____-____-____________}
            対処A:
                VirtualBox 6.1.28 の場合: VirtualBox 6.1.26 に戻します
            対処B:
                Hyper-V をオフにします（副作用あり）  #search: Hyper-V
    関連:  #search: Vagrant
VMware:
    vSphere: #keyword:  #// データセンター全体を仮想化し、仮想マシン（VM）の作成、管理、監視を容易にするためのツールとサービスのスイート
        構成:
            vCenter Server:
                vSphere環境の中心となる管理コンポーネントで、複数のESXiホストと仮想マシンを一元的に管理します。vCenter Serverを使用すると、リソースの割り当て、パフォーマンスの監視、テンプレートの管理などが可能です。
            ESXiホスト:
                vSphere環境のハイパーバイザーコンポーネントであり、物理サーバー上で直接動作します。ESXiホストは仮想マシンの作成と実行をサポートし、物理リソースを仮想マシンに割り当てます。
            vSphere Client:
                管理者がvSphere環境にアクセスし、操作を行うためのGUIベースのインターフェースです。WebベースのvSphere Web Clientや、旧来のWindows用vSphere Clientが含まれます。
            vSphere HA (High Availability):
                仮想マシンの可用性を高めるための機能で、ESXiホストに障害が発生した場合に自動的に仮想マシンを別のホストに再起動します。
            vSphere DRS (Distributed Resource Scheduler):
                クラスタ内のリソースを効率的に分散するための機能で、負荷分散を行い、リソースの利用効率を最大化します。DRSは、仮想マシンを自動的に最適なホストに移動させます。
            vSphere vMotion:
                ダウンタイムなしで仮想マシンを一つのESXiホストから別のホストに移動させる機能です。メンテナンスや負荷分散の際に利用されます。
            vSphere Storage vMotion:
                ダウンタイムなしで仮想マシンのディスクファイルを一つのデータストアから別のデータストアに移動する機能です。
            vSphere Replication:
                仮想マシンのデータを別の場所にレプリケートし、災害復旧のためのデータ保護を提供します。
        関連: #search: VirtualBox back up VM
名前空間機能: #keyword: Linux name space
    概要:
        名前空間は、特定のプロセスと関連付けられます。名前空間内で実行されるプロセスは、他の名前空間にはアクセスできません。
        プロセスが終了すると、その名前空間も削除されます（ただし、他のプロセスが名前空間を使用していない場合に限ります）。
    構成:
        UTS 名前空間: ホスト名やドメイン名を分離。
        PID 名前空間: プロセス ID を分離。
        Mount 名前空間: マウントポイントを分離。
        IPC 名前空間: システム V IPC や POSIX メッセージキューを分離。
        User 名前空間: ユーザーやグループ ID を分離。
        Network 名前空間: #// ネットワークスタック（インターフェース、ルーティングテーブル、ポートなど）を分離
            構成:
                ネットワークインターフェース（仮想インターフェースも含む）
                IP アドレス
                ルーティングテーブル
                ファイアウォールルール（iptables）
                ポートバインド
            名前空間間で通信: 仮想ネットワークインターフェース（veth）やブリッジを設定します
            WSL2 の localhost は名前空間で分かれません:  #search: WSL2 automatic port forwarding
WSL, Windows Subsystem for Linux:  #keyword: WSL, WSL2
    参考:  #ref: ${programming}/OS/VMWare.svg#WSL
    手順:
        インストール, アンインストール:  #keyword: install WSL2  #// ここは、初めて WSL をインストールする場合について書かれています
            #ref: https://qiita.com/Takakiri/items/41d0d1ed67e9505598a1
            Ubuntu-24.04.1 LTS: #keyword: install WSL2 Ubuntu VSCode  #// WSL2 Ubuntu
                ストア版:
                    インストール:
                        メニュー:
                            Windows11 Start >> Microsoft Store >> wsl（を検索）>> Ubuntu 24.04.1 >> インストール
                        ユーザーを作ります:  #ref: https://learn.microsoft.com/ja-jp/windows/wsl/setup/environment#set-up-your-linux-username-and-password
                            Enter new UNIX username: __UserName__  #// Linux から SSH するときのデフォルトのユーザー名になります（未確認）
                            New password: __Password__
                            Retype New password: __Password__
                    VSCode で開きます:
                        VSCode に WSL 拡張機能 をインストールして、
                        code コマンドを使います
                    再インストールします: #keyword: reinstall Ubuntu-24.04  #// ユーザーの再入力をします
                        Windows 11 設定 >> アプリ >> インストールされているアプリ >>
                        Ubuntu-24.04.1 LTS >> ...（右）>> 詳細オプション >> リセット >> アンインストール >>
                        PowerShell >> wsl -l >>  wsl --unregister Ubuntu-24.04 >>
                        Windows11 Start >> Microsoft Store >> wsl（を検索）>> Ubuntu 24.04.1 >> インストール
            Ubuntu-20.04:
                ストア版:
                    インストール:  #focus: wsl.exe --update
                        催促メッセージ: |  #// WSL インストール後に WSL を起動したとき
                            PS C:\Users\user1> wsl -d Ubuntu-20.04-docker
                            Linux 用 Windows サブシステムが Microsoft Store で入手可能になりました。
                            'wsl.exe --update' を実行するか、https://aka.ms/wslstorepage にアクセスしてアップグレードできます
                            Microsoft Store から WSL をインストールすると、最新の WSL 更新がより速く提供されます。
                            詳細については、https://aka.ms/wslstoreinfo
                            をご覧ください。
                        更新: |
                            user1@pc01:/mnt/c/Users/user1 $ wsl.exe --update
                            インストール中: Linux 用 Windows サブシステム
                            Linux 用 Windows サブシステム  はインストールされました。
                            user1@pc01:/mnt/c/Users/user1 $
                Windows 10 21H1:  #// 2022-10.  Windows 11 22H2 は未確認,  Ubuntu-20.04
                    参考:
                        Microsoft:
                            #ref: https://learn.microsoft.com/ja-jp/windows/wsl/install
                            #ref: https://learn.microsoft.com/ja-jp/windows/wsl/tutorials/wsl-vscode
                            #ref: https://learn.microsoft.com/ja-jp/windows/wsl/setup/environment#set-up-your-linux-username-and-password
                        Ubuntu:  #ref: https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10
                    インストール:  #// WSL2 と Ubuntu 20.04 をインストールします
                        #ref: ${typrm_files}/Qiita下書き/15_BashDebug/15_BashDebug.md  #ref: https://qiita.com/Takakiri/items/41d0d1ed67e9505598a1
                        メニュー:
                            PowerShell（を右クリック）>> 管理者として実行する
                        wsl --install でオプション一覧が表示される場合:
                            (PowerShell in Windows Terminal):
                                - wsl --list --online  #// ディストリビューションを一覧します
                                - wsl --install -d "Ubuntu-20.04"  #template: -d "__DistributionName__"  #// FRIENDLY NAME ではないほう。 distro name ともいう
                                    #// Ubuntu-20.04 の場合、1分半待ちます
                                #// wsl --install (-d オプションなし) では、Linux はインストールされず WSL だけインストールされるようです
                        再起動を要求された場合:
                            メッセージ:
                                要求された操作は正常に終了しました。変更を有効にするには、システムを再起動する必要があります。
                            Windows を再起動します:
                                #// wsl --install (-d オプションなし) を実行したときは、ここで完了です。
                    初期設定:  #// Ubuntu の初期設定をします
                        アカウントを作ります:  #ref: https://learn.microsoft.com/ja-jp/windows/wsl/setup/environment#set-up-your-linux-username-and-password
                            Enter new UNIX username: __UserName__  #// Linux から SSH するときのデフォルトのユーザー名になります（未確認）
                            New password: __Password__
                            Retype New password: __Password__
                        パッケージを更新します:
                            プロキシがある環境の場合:
                                sudo したときもプロキシに関する環境変数を継承するように設定します:  #keyword: Ubuntu env_keep
                                    コマンド:
                                        (bash$):
                                            sudo visudo
                                    編集前:
                                        Defaults        env_reset
                                    編集後:
                                        Defaults        env_reset
                                        Defaults        env_keep = "http_proxy ftp_proxy ftp_proxy DISPLAY XAUTHORITY"
                                    #// Ctrl + X キーと Y Enter で保存して終了します
                                プロキシの URL を設定します:
                                    sudo nano /etc/apt/apt.conf : |  #search: __Company__ Ubuntu
                                        Acquire::http::Proxy "http://____";
                                #ref: https://askubuntu.com/questions/7470/how-to-run-sudo-apt-get-update-through-proxy-in-commandline
                            (bash$): #keyword: apt update upgrade
                                sudo apt update -y && sudo apt upgrade -y
                                #// 約3分半待ちます
                        Ubuntu のウィンドウと、管理者の PowerShell を閉じます:
                            閉じる ボタン 2つ
                            #// Ubuntu のインストール前にシステムの再起動が要求されたときは、管理者の PowerShell はすでに閉じられています
                    （通常不要、初回のみ）起動スクリプトを作ります: #keyword: WSL start script  #// 特定のディストリビューションのシェルを開く PowerShell のコマンドを作ります:
                        #// デフォルトのディストリビューション（バージョン）を起動するときは、この起動スクリプトは不要です
                        Windows スタート >> PowerShell（と入力）:
                            💤 Ubuntu 16.04 の場合:  #template-if: $settings.__WSL_StartScriptName__ == ubuntu16
                                (PowerShell>): |  #keyword: ubuntu16 command
                                    ${script} = "${HOME}\AppData\Local\Microsoft\WindowsApps\ubuntu16.ps1"
                                    echo  "wsl -d Ubuntu-16.04" > ${script}
                                    Set-ExecutionPolicy  RemoteSigned  -Scope CurrentUser  #// スクリプトを実行できるようにします。警告されても y を入力します
                            🌟 Ubuntu 20.04 の場合:  #template-if: $settings.__WSL_StartScriptName__ == ubuntu20
                                (PowerShell>): |  #keyword: ubuntu20 command
                                    ${script} = "${HOME}\AppData\Local\Microsoft\WindowsApps\ubuntu20.ps1"
                                    echo  "wsl -d Ubuntu-20.04" > ${script}
                                    Set-ExecutionPolicy  RemoteSigned  -Scope CurrentUser  #// スクリプトを実行できるようにします。警告されても y を入力します
                        PowerShell を閉じます:
                            閉じる
                    WSL 内の bash を起動します:
                        デフォルトのディストリビューション（バージョン）を起動する場合:
                            新しい PowerShell> で:
                                wsl
                        指定のディストリビューション（バージョン）を起動する場合:
                            新しい PowerShell> で:
                                - ubuntu20  #template: __WSL_StartScriptName__
                                # または
                                - wsl -l
                                - wsl -d "Ubuntu-20.04"  #template: __DistributionName__
                                #search: WSL start script
                    ターミナルの初期設定をします:
                        フォルダーが暗い青で見にくい問題を解消します: #keyword: Ubuntu terminal colors
                            プロンプト: #search: Ubuntu prompt customize
                            ls コマンド: #search: Ubuntu ls customize
                        bin に PATH を通します: #search: ~/bin
                    プロキシがある環境の場合:  #keyword: Ubuntu Linux proxy
                        環境変数を設定します:
                            (bash$):
                                nano  ~/.bashrc  : |  #// 最も下へ追記  #search: __Company__ Ubuntu
                                    export  http_proxy="http://____"
                                    export  https_proxy="http://____"
                                    export  no_proxy="127.0.0.1, localhost"
                                #ref: https://code.visualstudio.com/docs/setup/network
                        設定をすぐに有効にします:
                            (bash$):
                                source ~/.bashrc
                    （必要なら）バージョン確認:  #// Ubuntu のバージョンを確認します: #keyword: Ubuntu version
                        (bash$):
                            lsb_release -a
                        出力例: |
                            No LSB modules are available.
                            Distributor ID: Ubuntu
                            Description:    Ubuntu 20.04.6 LTS
                            Release:        20.04
                            Codename:       focal
                        補足:
                            lsb_release -d は Description だけ表示します
                    Visual Studio Code をインストールします: #keyword: WSL VSCode
                        プロキシがある環境の場合:
                            #search: Ubuntu Linux proxy  #// 手順通りなら設定済み
                        本体をインストールします:
                            Windows:
                                Windows 版 Visual Studio Code をインストールします:
                                    #search: VSCode install
                                拡張機能(Extensions)をインストールします:
                                    - Remote Development  #// WSL 拡張機能が含まれています
                            (bash$):
                                プロキシがない環境の場合:
                                    code ~
                                プロキシがある環境の場合:
                                    code --proxy-server="http=$http_proxy;https=$https_proxy" --proxy-bypass-list="$no_proxy" ~
                                    #// 内部で実行するインストーラーは、http_proxy 環境変数を参照しないようです。
                                    #// インストールした後は --proxy-server オプションと --proxy-bypass-list オプションは不要です。
                                    #// 末尾の ~ は /home/__UserName__ に相当します。インストール直後に開くフォルダーです。
                                    #// code をエイリアスにすると VSCode の Terminal から code コマンドが使えなくなります
                                        #ref: https://github.com/microsoft/vscode/issues/46348   ←誤った提案
                        PowerShell を閉じるか最小化します:
                        ターミナル (bash$) を開きます:
                            VSCode >> Treminal メニュー >> New Terminal
                        ホームを確認します:
                            (bash$):
                                - pwd
                                - ls -a ~             #// Linux の /home/__UserName__
                        （必要なら）USERPROFILE 環境変数を設定します:  #keyword: WSL USERPROFILE example
                            設定します:
                                code  ~/.bashrc  : |  #// 最も下へ追記
                                    export  USERPROFILE=/mnt/c/Users/__UserName__
                                設定をすぐに有効にします:
                                    source ~/.bashrc
                            確認します:
                                ls ${USERPROFILE}
                        その他の設定:
                            #ref: https://learn.microsoft.com/ja-jp/windows/wsl/setup/environment#use-visual-studio-code
                        VSCode を閉じます:
                            閉じる
                    Ubuntu を起動し、 Visual Studio Code を開きます:
                        (新しい PowerShell>):
                            ubuntu20  #template: __WSL_StartScriptName__  #search: WSL start script
                        (bash$):
                            code ~  #// ~ は /home/__UserName__ に相当します。 ~ を Visual Studio Code で開きます
                        PowerShell を閉じます:
                    （必要なら）root ユーザーにログインできるようにします: #keyword: WSL2 root password
                        #// Ubuntu 20.04
                        - sudo passwd  #// root ユーザーのパスワードを設定します
                        - su -  #// root ユーザーでログインできることを確認します
                        - exit  #// root ユーザーからログアウトします
                        #ref: https://askubuntu.com/questions/931940/unable-to-change-the-root-password-in-windows-10-wsl
                    （必要なら）git を バージョン アップ します:  #keyword: update Ubuntu git,  install Ubuntu git
                        プロキシ環境の場合:
                            sudo http_proxy=${http_proxy} https_proxy=${https_proxy}  add-apt-repository ppa:git-core/ppa -y
                        プロキシ環境ではない場合:
                            sudo add-apt-repository ppa:git-core/ppa -y
                        共通:
                            sudo apt-get update
                            sudo apt-get install git -y
                            git --version  #// 2.38.0 in 2022-10-04
                        #ref: https://unix.stackexchange.com/questions/33617/how-can-i-update-to-a-newer-version-of-git-using-apt-get
                    ディストリビューション一覧:  #// WSL にインストール済みのディストリビューションを一覧します
                        コマンド:
                            (PowerShell>):
                                wsl --list
                        実行例: |
                            > wsl --list
                            Linux 用 Windows サブシステム ディストリビューション:
                            Ubuntu-20.04 (既定)
                            Ubuntu-16.04
                    電源オフ, アンインストール: #keyword: WSL shutdown,  WSL2 delete terminate
                        全終了: #keyword: wsl --shutdown,  restart WSL2  #// すべてのディストリビューションと、WSL を終了します
                            (PowerShell>):
                                wsl --shutdown
                            #// WSL2 Linux にアクセスすると起動します（全終了と合わせて、再起動に相当します）
                        1つ終了: #keyword: wsl --terminate  #// 指定のディストリビューションを終了します。電源オフ相当
                            (PowerShell>):
                                wsl --terminate  "Ubuntu-20.04-____"  #template: "__DistributionName__-____"
                        アンインストール: #keyword: wsl --unregister,  WSL uninstall distribution  #// 指定のディストリビューションをアンインストールします
                            (PowerShell>): #// 管理者でなくてもよい
                                wsl --unregister "Ubuntu-20.04-____"  #template: "__DistributionName__-____"
                Windows 10 2004 以降: #ref: https://www.yokoweb.net/2020/05/29/windows10-wsl2-ubuntu-20_04/
                    #// 2022-10 現在、Microsoft Store で 起動 ボタンを押すとエラーになるようになってしまいました。
                    #// Windows 10 20H2 までは同様らしい（未確認） #ref: https://atmarkit.itmedia.co.jp/ait/articles/2102/03/news020.html
                    （初回のみ）WSL2 のモジュールをインストールします:
                        メニュー: Windows 10 2004 >> スタート >> 設定 >> アプリ（6つ目）>> プログラムと機能（右上）>>
                            Windowsの機能の有効化または無効化（左上3つ目）
                        Linux 用 Windows サブシステム: オン
                        仮想マシンプラットフォーム: オン
                    （初回のみ）デフォルトを WSL2 に設定します:
                        Powershell: wsl --set-default-version 2
                    Ubuntu をインストールします:  #// Microsoft ストア版
                        メニュー: Windows 10 2004 >> スタート >> Microsoft Store（と入力して選択）>>
                            （右上の検索に）Ubuntu（と入力して Enter キー）>>
                            Ubuntu 20.04 LTS >> 入手（右上）>>（複数のデバイスで使用する）必要ありません >>
                            （ダウンロードとインストールを待つ）>> 起動（右上）
                        Enter new UNIX username: vagrant  #// SSH のユーザー名と合わせると SSH でユーザー名を省略できます
                        New password: vagrant
                        プロキシがある LAN にいる場合:
                            sudo nano /etc/apt/apt.conf : |
                                Acquire::http::proxy  "http://proxy.____:____/";
                                Acquire::https::proxy "http://proxy.____:____/";
                    Ubuntu のパッケージを更新します:
                        Ubuntu シェル:
                            - sudo apt update
                            - sudo apt upgrade
                    IP アドレスを調べます:  #search: Linux ip route
                Windows 10 1909: #ref: https://mseeeen.msen.jp/windows-terminal-with-ubuntu/
            Rocky Linux 9: #keyword: install WSL2 Rocky Linux 9  #ref: https://rockylinux.org/download/
                Windows 11 23H2:
                    手動の場合:
                        コンテナーの rootfs (.tar.xz) をダウンロードします:  #ref: https://docs.rockylinux.org/guides/interoperability/import_rocky_to_wsl/
                            Base: 標準
                            UBI: Base とほぼ同じサイズ  #search: Red Hat Universal Base Image
                            Minimal: 最小
                        #// かきかけ  #search: install WSL2 Rocky Linux 8
            Rocky Linux 8: #keyword: install WSL2 Rocky Linux 8  #ref: https://rockylinux.org/download/
                Windows 10 22H2:  #ref: https://docs.rockylinux.org/guides/interoperability/import_rocky_to_wsl/
                    自動の場合:
                        #ref: ${GitHub}/MyPrivateCode/bash/Rocky8/install-dev.sh  #keyword: install-dev.sh
                        #ref: ${GitHub}/MyPrivateCode/bash/Rocky8/Rocky8/remote-setup.sh
                    手動の場合:
                        コンテナーの rootfs (.tar.xz) をダウンロードします:  #ref: https://docs.rockylinux.org/guides/interoperability/import_rocky_to_wsl/
                            Base: 標準
                            UBI: Base とほぼ同じサイズ  #search: Red Hat Universal Base Image
                            Minimal: 最小
                        7zip で .tar.xz ファイルを展開します:
                        インポートします:
                            PowerShell コマンド: |
                                    wsl --unregister Rocky8  #// 再インストールする場合
                                    wsl --import Rocky8  $HOME/WSL_VMs/Rocky8  $HOME/WSL_back_up/Rocky-8-Container-Base.latest.x86_64.tar  --version 2
                                #template_: wsl --import __VmName__ __NewVmFolderPath__ __TarGzFilePath__ --version 2
                            __VmName__: Rocky8  #// 例
                            __NewVmFolderPath__: $HOME/WSL_VMs/__VmName__  
                            __TarGzFilePath__: $HOME/WSL_back_up/____.tar.gz
                        インポートできたことを確認します:
                            wsl -l   #// __VmName__
                        起動します:
                            wsl -d  "Rocky8"   #// __VmName__
                        user1 ユーザーを作ります: |  #// root ユーザーで作業しないため
                            useradd -m  "user1"
                            echo "proxy=http://___.___.___.___:____/"  >> /etc/yum.conf
                            yum install -y  passwd
                            passwd  "user1"  < <(echo -e "user1\nuser1\n")
                            usermod -aG wheel  "user1"  #// for sudo
                            echo "[user]"        >  /etc/wsl.conf
                            echo "default=user1" >> /etc/wsl.conf
                        ディストリビューションを終了します:
                            exit
                            wsl --terminate  "Rocky8"
                        ディストリビューションを起動してログインします:
                            wsl -d  "Rocky8"  #// 一般ユーザーでログインできたことを確認します
                        スクリプトをインストールして実行します:
                            Git bash:
                                cat  "Rocky8/remote-setup.sh"  >  //wsl.localhost/Rocky8/root/test.sh
                                wsl -d "Rocky8"  bash  //root/test.sh
                                rm  //wsl.localhost/Rocky8/root/test.sh
            Docker:  #search: install Docker for WSL2
            SSH: #keyword: WSL2 SSH
                #search: WSL2 URL
        バックアップ, リストア:  #keyword: back up WSL2,  WSL2 export import  #// ここは、初期状態の VM を複製（リストア）する場合についても書かれています
            #// 仮想ハードディスクのみバックアップ, リストアします。通常それで十分です。
            バックアップ:
                初回のみ:
                    フォルダーを作ります:  #// バックアップ ファイル を入れるフォルダーの親フォルダーを作る必要があるため
                        (PowerShell>):
                            mkdir -ea 0  "${HOME}\WSL_back_up"
                現在のディストリビューションを初めてバックアップする場合:
                    ログインするときのユーザーを設定します:  #keyword: WSL login user
                        #// 設定しないと、リストアしたときに root ユーザーでログインしてしまい危険です。VMを再起動したときは設定しなくてもこれまでのユーザーでログインできます。
                        #ref: https://superuser.com/questions/1566022/how-to-set-default-user-for-manually-installed-wsl-distro
                        設定します:
                            (bash$):
                                sudo nano /etc/wsl.conf : |
                                    [user]
                                    default=__UserName__
                        確認します:
                            (bash$):
                                exit
                            (PowerShell>):
                                VM を再起動します:
                                    - wsl --terminate  "Ubuntu-20.04"  #template: "__DistributionName__"
                                    - ubuntu20  #template: __WSL_StartScriptName__  #search: WSL start script
                            (bash$)(2):
                                プロンプトに表示されるユーザーを確認します
                        #ref: https://learn.microsoft.com/en-us/windows/wsl/wsl-config#user-settings
                バックアップします:
                    （スキップできます）:
                        (PowerShell>):
                            wsl --terminate  "Ubuntu-20.04"  #// スキップできます。ただし、export しようとすると VM は終了(terminate)します
                                #template: --terminate  "__DistributionName__"
                    バックアップします:  #// VHDX ファイルを圧縮するだけのようです
                        (PowerShell>):
                            wsl --export  "Ubuntu-20.04"  "${HOME}\WSL_back_up\Ubuntu-20.04-1.tar"
                            #template-at(-1): --export  "__DistributionName__"
                            #template-at(-2): WSL_back_up\__BackUpFileName__.tar
                            #// 2.9GB の VHDX ファイルは 2.3GB に圧縮されます
                    （必要なら）日付やサイズを確認します:
                        (PowerShell>):
                            start "${HOME}\WSL_back_up"  #// フォルダーが開きます
            リストア: #keyword: WSL2 restore  #// 既存のディストリビューションではない、新しいディストリビューション（=ストレージ=VHDX ファイル）を追加することもできます
                新しくディストリビューション（VM）を作る場合:  #// または、以前、新しく作ったディストリビューションをリセットする場合
                    （初めての場合）WSL_VMs フォルダーを作ります:  #// VHDX ファイルを入れるフォルダーの親フォルダーを作る必要があるため
                        (PowerShell>):
                            mkdir -ea 0  "${HOME}\WSL_VMs"
                    バックアップ ファイル の名前を調べます:
                        #// 上記の手順でバックアップした場合、${HOME}\WSL_back_up にあります
                        __BackUpFileName__.tar: Ubuntu-20.04-1.tar  #template: __BackUpFileName__.tar
                    （必要なら）同じ名前の古い VM を削除します:
                        (PowerShell>):
                            wsl --unregister "Ubuntu-20.04-____"
                    インポートします: #keyword: WSL2 restore user VM
                        #// 下記 __DistributionName__-New を編集してから実行します
                        #// バックアップしたときの __DistributionName__ と異なる新しい __DistributionName__ を指定できます
                        #// wsl --list で表示される __DistributionName__ を指定した場合、エラーになります
                        (PowerShell>):
                            mkdir -p "${HOME}\WSL_VMs"

                            wsl --import  "Ubuntu-20.04-New" `
                                "${HOME}\WSL_VMs\Ubuntu-20.04-New" `
                                "${HOME}\WSL_back_up\Ubuntu-20.04-1.tar"
                            #template-at(-3): --import  "__DistributionName__-New"
                            #template-at(-3): WSL_VMs\__DistributionName__-New
                            #template-at(-3): WSL_back_up\__BackUpFileName__.tar
                        #// VHDX ファイルを復帰するだけで起動できます。Packages 以下にあるその他のファイルが無くても起動できます。
                    #// 続く
                上書きする場合:  #// WSL2 に初めから提供されているディストリビューションに上書きする場合
                    登録を外します:  #// 既存のディストリビューション名を置き換える場合は外します。 新しくディストリビューション（VM）を作るときは外しません。
                        (PowerShell>):
                            wsl --unregister "Ubuntu-16.04"  #// VHDX ファイルが削除されます
                                #// unrewsl --unregister "Ubgister しないと import するときにエラー「指定された名前のディストリビューションは既に存在します。」になります
                    バックアップ ファイル の名前を調べます:
                        __BackUpFileName__.tar: Ubuntu-20.04-1.tar  #template: __BackUpFileName__.tar
                    （既存のディストリビューションに上書きする場合）:  #// 既存とは、自分でバックアップしたものではないものを指します
                        PackageFamilyName を調べて設定します:  #// 既存のディストリビューション名を置き換える場合のみ
                            (PowerShell>):
                                Get-AppxPackage -Name "*Ubuntu*" | Select PackageFamilyName
                                    #template__: -Name "*__DistributionWithoutVersion__*"
                                    #// PackageFamilyName を表示します。
                                    #// Ubuntu-16.04 を指定してもヒットしません
                        PackageFamilyName を設定します:
                            Ubuntu16.04 の場合:
                                (PowerShell>):
                                    ${PackageFamilyName} = "CanonicalGroupLimited.Ubuntu16.04onWindows_79rhkp1fndgsc"
                            #// Get-AppxPackage で表示された一覧から該当するバージョンを選んで設定します
                            #// 79rhkp1fndgsc は PublisherId です。Get-AppxPackage -Name "*Ubuntu*" で確認できます。
                            #// 固定値なので、Ubuntu16.04 なら 79rhkp1fndgsc 固定です。
                            #// wsl --install の内部で使われる PackageFamilyName
                            #ref: https://learn.microsoft.com/en-us/windows/wsl/vhd-size
                            #ref: https://stackoverflow.com/questions/64185560/where-are-the-files-inside-wsl2-physically-stored
                        インポートします:
                            wsl --import  "Ubuntu-20.04" `
                                "${HOME}\AppData\Local\Packages\${PackageFamilyName}\LocalState" `
                                "${HOME}\WSL_back_up\Ubuntu-20.04-1.tar"
                                #template-at(-3): --import  "__DistributionName__"
                                #template-at(-2): WSL_back_up\__BackUpFileName__.tar
                            #// VHDX ファイルを復帰するだけで起動できます。Packages 以下にあるその他のファイルが無くても起動できます。
                    （既存のディストリビューション以外に上書きする場合）:  #// 既存とは、自分でバックアップしたものではないものを指します
                        #search: WSL2 restore user VM
                起動します:
                    (PowerShell>):
                        - wsl -d "Ubuntu-20.04"  #// 必要ならディストリビューション名に変えてください
                        # または
                        - ubuntu20  #template: __WSL_StartScriptName__  #search: WSL start script
                    (bash$):
                        code ~  #// ~ は /home/__UserName__ に相当します。 ~ を Visual Studio Code で開きます
                    root ユーザーになってしまう場合:  #// 上記 code コマンドは失敗する場合
                        ログインするときのユーザーを設定します:
                            #search: WSL login user
            リセット:
                Windows 10 2004 >> Ubuntu:  #// Ubuntu を作り直します
                    メニュー:
                        Windows 10 2004 >> 設定 >> アプリ（6つ目）>> Ubuntu（を検索：中央）>>
                        Ubuntu 20.04 LTS >> アンインストール
                        （再インストールします） #search: install WSL2 Ubuntu
                    メモ:
                        失敗した方法:
                            Ubuntu 20.04 LTS >> 詳細オプション >> リセット（下へスクロール）>>
                            （起動できない）
            削除:  #// ディストリビューションの一覧から削除し、VHDX ファイル も削除します
                ディストリビューションの登録を外します:
                    (PowerShell>):  #// サンプル
                        wsl --list
                        wsl --unregister "Ubuntu-16.04-nginx"  #// Ubuntu-16.04-nginx の VHDX ファイルが削除されます
                    #search: wsl --unregister
            #ref: https://www.virtualizationhowto.com/2021/01/wsl2-backup-and-restore-images-using-import-and-export/
            #ref: https://learn.microsoft.com/ja-jp/windows/wsl/use-custom-distro
        起動:  #// VM の電源を入れることに相当します
            PowerShell の場合:  #keyword: start WSL
                既定:  #// 既定のディストリビューションとユーザー:
                    wsl
                選んで開きます:
                    （必要なら）既定のディストリビューションをメモします:
                        (PowerShell) wsl -l
                    エクスプローラーで \\wsl$ を開きます:
                        Windows Start >> \\wsl$ （を入力して Enter）
                    開くフォルダーをエクスプローラーで開きます:
                        home/user1 など
                    VSCode でフォルダーを開きます:
                        (PowerShell) code --remote wsl+__Distro__  "home/user1"
                ディストリビューション:
                    ディストリビューションを指定してログイン:
                        wsl --distribution  __DistributionName__
                    既定のディストリビューション:
                        #search: WSL setdefault
                ユーザー:
                    ユーザーを指定してログイン:
                        wsl --user __UsernameInLinux__  #// --user の短いオプション名は -u です
                    既定のユーザーの変更:
                        #ref: https://docs.microsoft.com/ja-jp/windows/wsl/wsl-config#change-the-default-user-for-a-distribution
            VSCode で開きます:  #// Ubuntu にログインします
                Windows スタート >> Ubuntu 20.04 LTS（と入力し選択）>>
                VSCode >> ><（左下端の緑）>> New WSL Window using Distro >> Ubuntu-20.04
        電源オフ, アンインストール:
            - wsl --shutdown  #// すべてのディストリビューションと、WSL を終了します
            - wsl --terminate  "Ubuntu-20.04-____"  #// 指定のディストリビューションを終了します:
            - wsl --unregister "Ubuntu-20.04-____"  #// 指定のディストリビューションをアンインストールします:
            #search: WSL shutdown
        コピーします:  #search: copy WSL2  #// Windows と WSL2 Linux の間でコピーします
        コンテナーを扱います:
            #search: install Docker for WSL2
            Docker を WSL2 へ最適化します:  未確認  #search: Docker WSL2 best experience
        Vmmem.exe のメモリー使用量を減らします:  #keyword: Vmmem.exe
            #search: Docker memory size
        CallFromWindows, SetUpInLinuxUser: #keyword:  #// Windows の中にあるスクリプトを起動して、WSL2 の中の Linux で関数を呼び出します
            #keyword: install-dev.sh CallFromWindows   #search: install-dev.sh
            CallFromWindows:
                install-dev.sh:       #ref: ${GitHub}/MyPrivateCode/bash/Rocky8/install-dev.sh#CallFromWindows()
                specifications.yaml:  #ref: ${GitHub}/MyPrivateCode/bash/Rocky8/specifications.yaml#CallFromWindows
            SetUpInLinuxUser:
                install-dev.sh:       #ref: ${GitHub}/MyPrivateCode/bash/Rocky8/install-dev.sh#SetUpInLinuxUser()
                specifications.yaml:  #ref: ${GitHub}/MyPrivateCode/bash/Rocky8/specifications.yaml#SetUpInLinuxUser
    コマンド:
        wsl:  #// 起動します  #search: start WSL
            --list:  #// インストール済みのディストリビューションを一覧します
                PowerShell:
                    wsl --list  #// --list の短いオプション名は -l
            --setdefault:  #// 既定のディストリビューションを変更します  #keyword: wsl --setdefault
                PowerShell:
                    - wsl --list  #// __DistributionName__ を調べます
                    - wsl --setdefault __DistributionName__
            --shutdown:  #search: WSL shutdown  #// WSL を終了します
            -d: #keyword: wsl -d  #// ディストリビューション指定
                - wsl -d __Distribution__
                - wsl --distribution __Distribution__
            コマンド実行: #keyword: WSL2 command,  WSL2 run exec bash  #// WSL2 のディストリビューション内で、指定したシェルのコマンドを実行します
                サンプル:
                    - wsl  __CommandLine__
                    - wsl -d __Distribution__  __CommandLine__
                    - wsl  pwd
                    - wsl  echo '@@@ $USER, $OTHER, $http_proxy, $https_proxy, $no_proxy'  #// ~/.bashrc は読み込まれません  #search: WSL2 command ~/.bashrc
                    - wsl -d __Distribution__  -- __Command1__  "&&"  __Command2__
                    - wsl -d __Distribution__  -- cd //home/user1  "&&"  ls -l
                ~/.bashrc の設定: #keyword: WSL2 command ~/.bashrc  #// ❗注意 >> そのまま実行すると ~/.bashrc は読み込まれません
                    状況:
                        Distribution="Rocky9"
                        wsl -d ${Distribution}  echo '@@@ $USER, $OTHER, $http_proxy, $https_proxy, $no_proxy'
                        #// たとえば ~/.bashrc に no_proxy が定義されている場合、no_proxy は定義されません
                    対処A: #keyword: ~/source_bashrc  #// wsl コマンドなどで実行するときでも、~/.bashrc をロードします。コマンドのテストに適しています
                        ~/source_bashrc の内容:
                            source ~/.bashrc
                            "$@"
                        サンプル:  #focus: no_proxy
                            作るコマンド:
                                echo  "source ~/.bashrc"  >  ~/source_bashrc
                                echo  '"$@"'             >>  ~/source_bashrc
                                chmod +x                     ~/source_bashrc
                            Linux に テスト スクリプト を作ります:
                                echo  'echo  @@@ ${USER}, ${OTHER}, ${http_proxy}, ${https_proxy}, ${no_proxy}'  >  ~/_test.sh
                                chmod +x  ~/_test.sh
                            Windows から実験します: |  #// bash -c は不要です
                                Distribution="Rocky9"
                                wsl -d ${Distribution}  '~/source_bashrc'  '~/_test.sh'  #// ~/.bashrc がロードされます。' ' で囲むと Linux にそのまま渡り、Linux の中で展開されます
                                wsl -d ${Distribution}  '~/_test.sh'  #// ~/.bashrc がロードされません
                    対処B:  #// bash -c が必要
                        Linux に テスト スクリプト を作ります:
                            echo  'echo  @@@ ${USER}, ${OTHER}, ${http_proxy}, ${https_proxy}, ${no_proxy}'  >  ~/_test.sh
                            chmod +x  ~/_test.sh
                        Windows から実験します: |  #// bash -c が必要で、"__Command__ __Parameters__" のように "" などで囲む必要があります
                            Distribution="Rocky9"
                            wsl -d ${Distribution}  bash -c 'source ~/.bashrc  &&  ${HOME}/_test.sh'  #// ロードされます
                            wsl -d ${Distribution}  bash -c '${HOME}/_test.sh'  #// ロードされません
                            wsl -d ${Distribution}  '${HOME}/_test.sh'  #// ロードされません
                        ❗注意:
                            wsl -d ${Distribution}  bash -c 'source ~/.bashrc  &&  echo  @@@ ${USER}, ${OTHER}, ${http_proxy}, ${https_proxy}, ${no_proxy}'
                                #// ロード前に変数が展開されるため、表示されません
                    対処C:  #// 実施したが解決しない（すぐに反映されない？だとしても扱いにくい）
                        ~/.bash_profile,  ~/profile
                #ref: https://learn.microsoft.com/en-us/windows/wsl/filesystems#mixing-linux-and-windows-commands
            その他のコマンド:  #ref: https://learn.microsoft.com/en-us/windows/wsl/basic-commands
        Git bash: |  #// WSL2 Linux から Windows の Git bash でコマンドを実行します
                # RunInGitBash
                # Example:
                #    - RunInGitBash  pwd
                #    - RunInGitBash  ls  '/c/Program Files (x86)'
                function  RunInGitBash() {
                    echo  "$ cd ${PWD}"
                    echo  "$ $( GetArgumentsString "$@" )"
                    if [ "${USERPROFILE:0:5}" == "/mnt/" ]; then  #// WSL2
                        local  commandLine=""
                        until [ "$1" == "" ]; do
                            commandLine="${commandLine} \"$1\""
                            shift
                        done

                        "/mnt/c/Program Files/Git/bin/bash.exe" -c  "$commandLine"
                    else  #// Git bash
                        "$@"
                    fi
                }
            #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/centos7/install.sh#function  RunInGitBash
    概念:
        WSL2:
            WSL1との違い:
                #ref: https://www.virtualizationhowto.com/2021/01/wsl2-backup-and-restore-images-using-import-and-export/
                ファイルアクセスが速い:
                #// 出典不明
                動的メモリ割り当て:
                起動時間: コンテナのコールドスタートが 1分から 10秒へ
        共有フォルダー: #keyword: WSL2 shared folder,  WSL2 path  #// Windows と Linux の間でファイルのやり取りをします
            場所:
                Windows → Linux:  #keyword: \\wsl$\  #// ホストOS からゲストOS のフォルダーを表示します
                    Windows エクスプローラーで開きます:
                        書式: \\wsl$\__DistoributionName__  #// Linux のルート
                        サンプル: \\wsl$\Ubuntu-20.04
                    ReadWrite: 可能
                Linux → Windows:  #keyword: /mnt/c/  #// ゲストOS からホストOS のフォルダーを表示します
                    ls:
                        ls /mnt/c/
                    ReadWrite: 可能
                    Windows の ThisScriptFullPath: #keyword: /mnt/c/ ThisScriptFullPath,  /mnt/c/ ThisFolderFullPath
                        概要:
                            Windows Git bash で実行している スクリプト ファイル に Linux からアクセスするときのパスは、
                            Windows Git bash での フル パス の前に //mnt を付けるだけで得られます。
                            #search: ThisScriptFullPath
                            #search: ThisFolderFullPath
                        サンプル:
                            (Windows Git bash): |
                                ThisScriptFullPath="$( readlink -f "${0##*/}" )"    #// "/c/Users/user1/project"
                                wsl -d __DistroName__  bash  "//mnt${ThisScriptFullPath}"
                            (Linux): |
                                ThisScriptFullPath="$( readlink -f "${0##*/}" )"    #// "//mnt/c/Users/user1/project"
                #ref: https://qiita.com/Takakiri/items/41d0d1ed67e9505598a1#windows-と-wsl2-と-git-bash-のパスの関係
            IP アドレスを調べます:  #search: Linux ip route
            コピー:  #keyword: WSL2 copy,  cp WSL2  #// Windows と WSL2 Linux の間でコピーします
                Linux bash:  #// Linux でコピーする場合
                    コマンド:
                        -   mkdir -p  "__PathInLinux__"
                        -   cp -ap  "/mnt/c/__PathInWindows__/"*  "__PathInLinux__"
                Windows Git bash:  #// Windows でコピーする場合
                    コマンド:
                        -   wsl -d "__DistroName__"  mkdir -p  "/__PathInLinux__"   #// /root/bin を作る場合は //root/bin を指定します
                        -   wsl -d "__DistroName__"  cp -ap  "/mnt/c/__PathInWindows__/"*  "/__PathInLinux__"
                    補足:
                        //wsl.localhost へのコピーはできません: |
                            $ cp -ap  "folderA/"*  "//wsl.localhost/__DistroName__/__PathInLinux__"
                            cannot create directory ‘//wsl.localhost’: Read-only file system
                RDP:  #// リモート デスクトップ 経由で WSL2 内にコピーする場合。Windows 11
                    コピー先が WSL2 Linux の場合:
                        コピー先の Linux フォルダーを開きます:
                            code --remote wsl+__Distro__  "home/user1"  #search: code wsl
                        コピー元のフォルダーを開きます:  #// WSL2 内 または Windows
                            code --remote wsl+__Distro__  "home/user1"  #search: code wsl
                        コピー元のフォルダーを .tar.gz 形式で圧縮します:  #// Windows のフォルダーでも Git bash の機能により、実行フラグを正しく .tar.gz の中に記録します
                            cd  "__ParentFolder__"
                            tar cvzf  "__Folder__.tar.gz"  "__Folder__"  #// .tar ファイルの中の直下はフォルダーの内容ではなく、フォルダーになります
                        .tar ファイルをコピーします:
                            ファイルを右クリック >> Reveal in File Explorer >> 最新の情報に更新（アドレス バー の左）>>
                            .tar ファイル（をクリック）>> Ctrl + C
                        コピー先へ貼り付けます:  #// .tar ファイルをコピー先へ貼り付けます
                            Ctrl + V >> 最新の情報に更新（アドレス バー の左）
                        展開します:  #// コピー先の .tar ファイルをフォルダーに展開します
                            cd  __ParentFolder__
                            rm -rf  __Project__
                            tar xvf  __Project__.tar.gz
                            #// .tar ファイルの中の直下がフォルダーである場合
                        双方の .tar ファイルを削除します:  #// コピー先の .tar ファイルと、コピー元の .tar ファイルを削除します:
                            .tar ファイル（を右クリック）>> 削除  #// コピー先とコピー元
                        （補足）:
                            - エクスプローラーで .tar 形式に圧縮すると、実行属性が記録されません
                            - エクスプローラーで展開すると Zone.Identifier ファイル が大量にできてしまいます
                    コピー先が Windows11 の場合:
                        コピー先の Windows フォルダーを開きます:
                            エクスプローラーで開きます
                        コピー元のフォルダーを開きます:  #// WSL2 内 または Windows
                            エクスプローラー >> \\wsl$\____
                        コピー元のフォルダーを .7z 形式で圧縮します:
                            フォルダーを右クリック >> 圧縮先 >> 7z ファイル >> 最新の情報に更新（アドレス バー の左）
                        .7z ファイルをコピーします:
                            .7z ファイル（をクリック）>> Ctrl + C
                        コピー先へ貼り付けます:  #// .7z ファイルをコピー先へ貼り付けます
                            Ctrl + V
                        展開します:  #// コピー先の .7z ファイルをフォルダーに展開します
                            展開先にフォルダーがあるときは、削除してから、
                            .7z ファイル（を右クリック）>> すべて展開 >>（パスを親フォルダーに編集します）>> 展開 ボタン
                        双方の .7z ファイルを削除します:  #// コピー先の .7z ファイルと、コピー元の .7z ファイルを削除します:
                            .7z ファイル（を右クリック）>> 削除  #// コピー先とコピー元
        VHDX ファイル, ストレージ: #keyword:  #// VM が使うストレージの内容が書かれたファイル
            場所の例: '%userprofile%\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu16.04onWindows_79rhkp1fndgsc\LocalState\ext4.vhdx'
            （関連）:
                VirtualBox:  #search: VMDK  #search: VDI
        URL, ホスト名, ポート番号: #keyword: WSL2 URL,  WSL2 ネットワーク SSH
            自動ポートフォワーディング:  #keyword: WSL2 automatic port forwarding,  WSL localhost  #ref: https://learn.microsoft.com/en-us/windows/wsl/networking
                概要: WSL2 の Linux が公開している ネットワーク サービス にアクセスするときは、
                    localhost に同じポート番号で自動的にフォワーディングする機能を使います
                サンプル:
                    docker run -p 127.0.0.1:8080:80 nginx
                    #// Windows からでも http://127.0.0.1;8080 や http://localhost:8080/ で見えます
                無効化:
                    (@Windows) ~/.wslconfig : | #keyword: WSL2 localhostForwarding
                        [wsl2]
                        localhostForwarding=false
                    再起動:
                        wsl --shutdown
                        （WSL2 にアクセス）
                ポートの衝突: #keyword: WSL2 localhost 衝突
                    症状: 2つのディストリビューションで、同じポートを使うと衝突します。127.0.0.1 にバインドしても衝突します。
                        WSL2 Ubuntu) docker run -p 127.0.0.1:8080:80 nginx
                        WSL2 CentOS) docker run -p 127.0.0.1:8080:80 nginx
                    対策:
                        ポート番号を変えます
                    ボツ:
                        localhostForwarding:  #// 衝突します  #search: WSL2 localhostForwarding
                            localhostForwarding=false
                        Linux の名前空間機能:  #// 衝突します  #search: Linux name space
                            名前空間機能で分けても衝突します。
                                sudo ip netns add net1
                                sudo ip netns exec net1 ip link set lo up
                                sudo ip netns exec net1 ip addr add 127.0.0.1/8 dev lo
                                sudo ip netns exec net1 docker run -p 127.0.0.1:8080:80 nginx
                                sudo ip netns delete net1
                        Docker ネットワーク:  #// 衝突します
                            独自ネットワークの場合:  #// 衝突します
                                docker network create mynetwork
                                docker run --network mynetwork -p 127.0.0.1:8080:80 nginx
                                docker network rm mynetwork
                                #// もう1つの WSL2 ディストリビューション では mynetwork2 を使っても同様です
                            host ネットワークの場合:  #// -p オプションは無視され、ポート 80 が使われます。同じ Docker イメージの複数インスタンスがあると苦労します
                                docker run --network host -p 127.0.0.1:8080:80 nginx
                            none ネットワークの場合:  #// 衝突はしないがネットワークは使えない
                                (@dist1) docker run --network none -p 127.0.0.1:8080:80 nginx
                                (@dist2) docker run --network none -p 127.0.0.1:8080:80 nginx
                        ミラーリング モード WSL2 ネットワーク:  #ref: https://superuser.com/questions/1679757/accessing-windows-localhost-from-wsl2  >> ミラーリング モード WSL2 ネットワーク
                            目的が違いそう
        IP アドレス: #keyword: WSL2 IP address
            推奨:  #search: WSL2 URL
            表示:
                - hostname -I  #ref: https://qiita.com/masato930/items/f50ad3df302290d1f544
                - ip a show dev eth0  #ref: https://qiita.com/neko_the_shadow/items/25b797cb436078b9e832
            静的 IP アドレス: #keyword: WSL2 static IP address
                設定方法: できない  #ref: https://superuser.com/questions/1582234/make-ip-address-of-wsl2-static
                非推奨）WSL2 での静的 IP アドレスの割り当て スクリプト:  #ref: https://gist.github.com/wllmsash/1636b86eed45e4024fb9b7ecd25378ce
            v4tov4 localhostForwarding: #keyword: WSL2 v4tov4 localhostForwarding  #// ホストOSの localhost でもポートをリッスンします
                #ref: https://learn.microsoft.com/en-us/windows/wsl/networking#accessing-a-wsl-2-distribution-from-your-local-area-network-lan
                推奨: これは Windows で localhost 以外からリクエストを受け付けるときに標準的なポート番号が必要などきに使うようです。
                    開発用に localhost からリクエストを受け付ける場合は、 #search: WSL2 URL
                netsh コマンド:
                    netsh interface portproxy add v4tov4 listenport=<yourPortToForward> listenaddress=0.0.0.0 connectport=<yourPortToConnectToInWSL> connectaddress=(wsl hostname -I)
                WSL2 の localhostForwarding 機能がうまくうごかない:  #ref: https://mrk21.hatenablog.com/entry/2022/01/30/183331
    ファイル, 場所:
        共有フォルダー: #search: WSL2 shared folder
    トラブルシューティング（WSL）:
        エラー, address already in use 0.0.0.0:2181:172.19.0.11:2181/tcp:
            手順:
                docker-compose up
            ログ: |
                Error response from daemon: failed to set up container networking: driver failed programming external connectivity on endpoint __ContainerName__ (f70b47f16.....): failed to bind host port for 0.0.0.0:2181:172.19.0.11:2181/tcp: address already in use
            対処: |
                wsl --shutdown
        ext4.vhdx' を WSL2 にアタッチできませんでした:
            ログ: |
                ディスク 'C:\Users\aa\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu24.04LTS_79rhkp1fndgsc\LocalState\ext4.vhdx' を WSL2 にアタッチできませんでした: 指定されたファイルが見つかりません。
                エラー コード: Wsl/Service/CreateInstance/MountDisk/HCS/ERROR_FILE_NOT_FOUND
                Press any key to continue...
            対処:
                wsl --unregister Ubuntu-24.04
                #search: reinstall Ubuntu-24.04
        The host 'wsl.localhost' was not found in the list of allowed hosts. Do you want to allow it anyway?:
            手順: WSL2 の中を code コマンドで開く
            ログ: |
                Visual Studio Code
                ⚠️ The host 'wsl.localhost' was not found in the list of allowed hosts. Do you want to allow it anyway?
                The path '¥¥wsl.localhost¥____' uses a host that is not allowed. Unless you trust the host, you should press 'Cancel'
                ☐ Permanently allow host 'wsl.localhost'
                [Allow]  [Learn More]  [Cancel]
            対処:
                WSL2 を使おうとしてるのなら、Allow を押します
                #// セキュリティ警告です
        Error 0xc004000d:
            手順: wsl --install -d "Ubuntu-20.04"
            エラー: |
                インストール中: 仮想マシン プラットフォーム
                インストール中に回復不能なエラーが発生しました。コンポーネント: '仮想マシン プラットフォーム' エラーコード: 0xc004000d
                Error: 0xc004000d
            対処:
                Windows を再起動します。その際、更新して再起動 を選びます
        Cannot initiate the connection to in.archive.ubuntu.com:80:
            手順: Ubuntu シェルで sudo apt update
            エラー: |
                Cannot initiate the connection to in.archive.ubuntu.com:80
            対処:
                プロキシを設定します  #search: install WSL2 Ubuntu
        command substitution; ignored null byte in input:
            手順: local  distros="$( wsl -l )"
            エラー: |
                warning: command substitution: ignored null byte in input
            対処:
                local  distros="$( wsl -l  |  tr -d '\0' )"
    設定: #settings:
        __DistributionName__: Ubuntu-20.04
        __WSL_StartScriptName__: ubuntu20
        __BackUpFileName__: Ubuntu-20.04-1
        template-if(yes): 🌟
        template-if(no):  💤
QEMU: #keyword:  #// 仮想化プロバイダーの 1つ
    .qcow2 ファイル: #keyword:  #// QEMU などの仮想マシンの構成や状態が丸ごと入ったファイル
Vagrant: #keyword:  #// ベイグラントと読みます  #ref: https://www.vagrantup.com/
    手順とサンプル:
        本体のインストール:  #search: Vagrant Windows
        プロジェクトのインストール:  #keyword: Vagrant project examples,  install Vagrant
            CentOS7 のみ:  #keyword: CentOS7 Vagrant
                スクリプト版:
                    公開:  #ref: ${GitHub}/ansible_vagrant  #// single_vm_ansible_centos7 ブランチ
                        #ref: https://github.com/Takakiriy/ansible_vagrant/tree/single_vm_ansible_centos7
                    未公開:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/centos7
                手動の場合:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/centos7
            Vagrant と Ansible:
                #search: install CentOS7
            Vagrant と WSL2:
                うごきません。 #ref: https://developer.hashicorp.com/vagrant/docs/other/wsl
            VM のカスタマイズ:  #search: Vagrant VM options
            その他:  #search: Vagrant 仮想化プロバイダー
        成功時のログ:  #ref: ${typrm_files}/2022/vagrant/log/success-2.log
        新規作成: #keyword: Vagrant Windows  #// Vagrant, VirtualBox を Windows にインストールして CentOS がインストールされた VM をプロビジョニングします:
            #// 注意: Ansible は使いません。 Ansible を使う環境は #search: Ansible example Apache
            参考: #ref: https://qiita.com/ozawan/items/160728f7c6b10c73b97e
            設定: #settings:
                __ProjectName__: centos7
                __VagrantBox__: centos/7
            VirtualBox をインストールします:  #keyword: install Vagrant VirtualBox
                - https://www.virtualbox.org/ >> Download VirtualBox X.X >> Windows hosts
                - ダウンロードしたファイル（例：VirtualBox-6.1.22-144080-Win.exe）を開きます
                - インストール オプションはデフォルトを使用
                - ドライバーはインストールします
            Vagrant をインストールします:  #keyword: install Vagrant Windows
                - https://www.vagrantup.com/downloads.html >> Windows（タブ）>> 64-bit (Amd64)
                - ダウンロードしたファイル（例：vagrant_2.2.16_x86_64.msi）を開きます
                - インストール オプションはデフォルトを使用
                - PC を再起動します
            Git for Windows をインストールします:
                - https://git-scm.com/ >> Downloads >> Windows
                - ダウンロードしたファイル（例：Git-2.33.0.2-64-bit.exe）を開く
                - Next を9回押す
                - Configuring the line ending conversions: Checkout as-is, commit as-is
                - 他のインストール オプションはデフォルトを使用
            Visual Studio Code をインストールします:
                #search: VSCode install
            （必要なら）Box ファイルを探します:
                - 検索例: https://app.vagrantup.com/boxes/search >> centos（と入力して Enter）
                - 使う Box 名: centos/7  #template: __VagrantBox__
                - 他の Box 名の例:
                    - centos/7
                    - bento/centos-6.7
            vagrant プロジェクトを新規作成します(vagrant init コマンド):
                #bash
                - mkdir -p  ~/vagrant/centos7  #// __Project__ とする  #template: __ProjectName__
                - cd        ~/vagrant/centos7  #template: __ProjectName__
                - vagrant init centos/7  #// 30秒  #template: __VagrantBox__
                    #// Vagrantfile が作られます。 vargrant init コマンドを使わないで Vargrantfile を作っても構いません
                - code "."  #// Visual Studio Code で __Project__ フォルダーを開きます（しなくてもよい）
            仮想マシン名を設定します:
                __Project__/Vagrantfile: |  #// config.vm.box の行の下に追加
                    config.vm.box = "centos/7"

                    # hostname
                    config.vm.hostname = "centos7"

                    # VirtualBox VM name
                    config.vm.provider "virtualbox" do |virtualbox|
                        virtualbox.name = config.vm.box.gsub(/\//, "_") + "_" + config.vm.hostname
                    end

                    #template-at(-10): __VagrantBox__
                    #template-at(-8): __ProjectName__
            Vagrantfile の config.vm.network "private_network" ____ の部分を有効にします（コメントではなくします）:
            ホストOSがプロキシがあるLANにいるとき:  #keyword: Vagrant proxy, Vagrant config.proxy.no_proxy
                http_proxy, https_proxy 環境変数をホストOSに設定します:
                    #search: Windows proxy
                    #// これが必要な理由は、後で Vagrantfile からこの標準的な環境変数を参照するようにしているからです
                vagrant-proxyconf プラグインをインストールします:  #keyword: vagrant-proxyconf
                    #Git bash  #// VSCode >> Terminal >> New Terminal >> ＋の右の↓（シェルの右上）>> Git bash
                    vagrant plugin list
                    vagrant plugin install vagrant-proxyconf
                Vagrantfile の最後の end の直前にプロキシの設定を追加します: |  #// 下記は環境変数 http_proxy, https_proxy を使う設定です
                    :
                        #// Proxy
                        if Vagrant.has_plugin?("vagrant-proxyconf") && ENV['http_proxy'] && ENV['https_proxy']
                            config.proxy.http     = ENV['http_proxy']
                            config.proxy.https    = ENV['https_proxy']
                            config.proxy.no_proxy = "localhost, 127.0.0.1, 192.168.*, control, node*, db*"
                        end
                    end
            仮想マシンを作って起動します（プロビジョニングします）:  #// 既存の仮想マシンの電源オンも同じです  #keyword: vagrant up example
                #Git bash
                - cd  __Project__
                - rm -rf .vagrant
                - vagrant up  #// プロンプトに戻ると完了です
                - vagrant status  #// 仮想マシンが動作していることを確認します
            VirtualBox マネージャーを開き、仮想マシンが作られていることを確認します:
            vagrant プロジェクトを削除します:
                #bash
                cd  ~/vagrant
                rm -rf  ~/vagrant/centos7  #template: __ProjectName__
            Vagrantfile の初版に書かれているコメントの和訳: |
                The most common configuration options are documented and commented below. For a complete reference, please see the online documentation at https://docs.vagrantup.com.

                Every Vagrant development environment requires a box. You can search for boxes at https://vagrantcloud.com/search.

                Disable automatic box update checking. If you disable this, then boxes will only be checked for updates when the user runs `vagrant box outdated`. This is not recommended.

                    config.vm.box_check_update = false


                最も一般的な構成オプションは、以下に文書化され、コメントが付けられています。 完全なリファレンスについては、https：//docs.vagrantup.comのオンラインドキュメントを参照してください。

                すべてのVagrant開発環境にはボックスが必要です。 ボックスはhttps://vagrantcloud.com/searchで検索できます。

                自動ボックス更新チェックを無効にします。 これを無効にすると、ユーザーが「vagrant boxdeadted」を実行した場合にのみボックスの更新がチェックされます。 これはお勧めしません。

                    config.vm.box_check_update = false 

                -------------------------------------------------------

                Create a forwarded port mapping which allows access to a specific port within the machine from a port on the host machine. In the example below, accessing "localhost:8080" will access port 80 on the guest machine. NOTE: This will enable public access to the opened port

                    config.vm.network "forwarded_port", guest: 80, host: 8080

                Create a forwarded port mapping which allows access to a specific port within the machine from a port on the host machine and only allow access via 127.0.0.1 to disable public access

                    config.vm.network "forwarded_port", guest: 80, host: 8080, host_ip: "127.0.0.1"

                Create a private network, which allows host-only access to the machine using a specific IP.

                    config.vm.network "private_network", ip: "192.168.33.10"

                Create a public network, which generally matched to bridged network. Bridged networks make the machine appear as another physical device on your network.

                    config.vm.network "public_network"


                ホストマシンのポートからマシン内の特定のポートにアクセスできるようにする転送ポートマッピングを作成します。 以下の例では、「localhost：8080」にアクセスすると、ゲストマシンのポート80にアクセスします。 注：これにより、開いているポートへのパブリックアクセスが有効になります

                    config.vm.network "forwarded_port", guest: 80, host: 8080

                ホストマシンのポートからマシン内の特定のポートへのアクセスを許可し、パブリックアクセスを無効にするために127.0.0.1経由のアクセスのみを許可する転送ポートマッピングを作成します

                    config.vm.network "forwarded_port", guest: 80, host: 8080, host_ip: "127.0.0.1"

                特定のIPを使用してマシンへのホストのみのアクセスを許可するプライベートネットワークを作成します。

                    config.vm.network "private_network", ip: "192.168.33.10"

                パブリックネットワークを作成します。これは通常、ブリッジネットワークに一致します。 ブリッジネットワークにより、マシンはネットワーク上の別の物理デバイスとして表示されます。

                    config.vm.network "public_network"

                -------------------------------------------------------

                Share an additional folder to the guest VM. The first argument is the path on the host to the actual folder. The second argument is the path on the guest to mount the folder. And the optional third argument is a set of non-required options.

                    config.vm.synced_folder "../data", "/vagrant_data"

                Provider-specific configuration so you can fine-tune various backing providers for Vagrant. These expose provider-specific options.

                Example for VirtualBox:

                    config.vm.provider "virtualbox" do |vb|
                    # Display the VirtualBox GUI when booting the machine
                    vb.gui = true

                    # Customize the amount of memory on the VM:
                    vb.memory = "1024"
                    end


                追加のフォルダーをゲストVMと共有します。 最初の引数は、ホスト上の実際のフォルダーへのパスです。 2番目の引数は、フォルダーをマウントするゲストのパスです。 また、オプションの3番目の引数は、不要なオプションのセットです。

                    config.vm.synced_folder "../data"、 "/ vagrant_data"

                Vagrantのさまざまなバッキングプロバイダーを微調整できるようにするプロバイダー固有の構成。 これらはプロバイダー固有のオプションを公開します。

                VirtualBoxの例：

                    config.vm.provider "virtualbox" do |vb|
                    ＃マシンの起動時にVirtualBoxGUIを表示する
                    vb.gui = true

                    ＃VMのメモリ量をカスタマイズします。
                    vb.memory = "1024"
                    end

                -------------------------------------------------------

                View the documentation for the provider you are using for more information on available options.

                Enable provisioning with a shell script. Additional provisioners such as Ansible, Chef, Docker, Puppet and Salt are also available. Please see the documentation for more information about their specific syntax and use.

                    config.vm.provision "shell", inline: <<-SHELL
                    apt-get update
                    apt-get install -y apache2
                    SHELL


                使用可能なオプションの詳細については、使用しているプロバイダーのドキュメントを参照してください。

                シェルスクリプトを使用してプロビジョニングを有効にします。 Ansible、Chef、Docker、Puppet、Saltなどの追加のプロビジョナーも利用できます。 特定の構文と使用法の詳細については、ドキュメントを参照してください。

                    config.vm.provision "shell", inline: <<-SHELL
                    apt-get update
                    apt-get install -y apache2
                    SHELL
        VM の操作: #keyword: Vagrant VM operation
            ログイン >> VirtualBox から:  #// SSH で仮想マシンにログインします
                - vagrant ユーザーのパスワードは vagrant です
                - root ユーザーのパスワードは vagrant です
                - 他のユーザーのパスワードを知らなくても root 経由ならログインできます
            ログイン >> SSH で:  #keyword: Vagrant SSH  #// SSH で仮想マシンにログインします
                （仮想マシンが起動していなかったら）起動します:  #search: vagrant up
                VSCode を使う場合:  #// Visual Studio Code を Vagrant が管理するゲストOSと SSH 接続します:
                    初めて使う接続先の場合:
                        VSCode の Remote Development 拡張機能をインストールします:
                            VSCode >> 拡張機能 ボタン（左） >> Remote Development
                        ホストOS の bash:
                            - cd  __VagrantProject__
                            - vagrant ssh-config  #// SSH の接続に必要な設定が表示されます  #keyword: vagrant ssh-config
                            - code ~/.ssh/config  #// vagrant ssh-config の出力を最後に貼り付けます
                            - （ただし、~/.ssh/config の Host をプロジェクト名 centos7 に変更します） #template: __ProjectName__
                    Visual Studio Code で SSH 接続します:
                        SSH 接続します:
                            ホスト名（の右のフォルダー）ボタン を押します:  #search: VSCode Remote-SSH
                        ただし:
                            ユーザー名: vagrant
                            パスワード: （なし）
                        SSH 接続した Visual Studio Code でフォルダーを開きます:
                            VSCode >> File >> Open Folder ...
                        シェルを開けることを確認します:
                            VSCode >> Terminal >> New Terminal
                                #// [vagrant@localhost vagrant]$ と表示されます
                        開けたら Visual Studio Code を閉じます:
                        Remote Explorer で開いたフォルダーを表示させます:
                            VSCode >> Remote Explorer（左のアイコン）>> Reflesh ボタン（右上）
                        次回からログインするときの操作:  #keyword: VSCode SSH Remote Explorer
                            - タスクバーの VSCode を右クリック >> __Folder__ [SSH:__Server__]  #// または
                            - VSCode >> File >> Open Recent >> __Folder__ [SSH:__Server__]  #// または
                            - VSCode >> Remote Explorer ボタン（左）>> REMOTE EXPLORER= Remote（左上）>> SSH >> __Server__ >> __Folder__
                vagrant ssh を使う場合:
                    #// 以下の方法では Playbook などを Visual Studio Code で編集できません。
                    #ホストOS の bash
                    - cd  __Project__
                    - （仮想マシンが起動していなかったら） vagrant up
                    - vagrant ssh  #// 約 10秒
                    #// [vagrant@localhost ~]$ と表示されます
                    #// 関連：  #search: Ansible SSH
                シェルにコマンドが入力できることを確認します:
                    - pwd  #// /home/vagrant
                    - exit  #// 仮想マシンからログアウトします（VSCode で接続している場合は、VSCode を閉じるとログアウトします）
            状態表示: #search: vagrant status
            電源オフ: #search: vagrant halt  #// Vagrant が管理している仮想マシンの電源をオフにします
            VM 削除: #search: vagrant destroy,  vagrant reset  #// Vagrant が管理している仮想マシンを削除します
        既存の Vagrantfile:  #// 既存の Vagrantfile を使ってプロビジョニングします:
            関連 >> 既存の Vagrant+Ansible プロジェクトをプロビジョニングします:  #search: install Ansible project
            VirtualBox をインストールします:  #search: install Vagrant VirtualBox
            Vagrant をインストールします:  #search: install Vagrant Windows
            vagrant プロジェクトのフォルダーを作ります:
                #bash
                - mkdir -p  ~/vagrant/__ProjectName__  #// __Project__ とする
                - cd        ~/vagrant/__ProjectName__
                - （__Project__/Vagrantfile にコピーします）
            ホストOSがプロキシがあるLANにいるとき:  #search: Vagrant proxy
            仮想マシンを作って起動します（プロビジョニングします）:  #search: vagrant up example
        任意のコマンド実行: |  #// 任意のコマンドをサーバーで実行します  #// 未確認
            config.vm.define "ansible-server" do |node|
                node.vm.provision "shell", inline: <<-SSH
                    ssh-keygen コマンドなど
                SSH
        バックアップ:  #keyword: Vagrant VirtualBox back up VM
            VM の電源を切ります:  #keyword: shutdown via SSH,  shutdown VM 電源 via vagrant SSH
                VirtualBox ウィンドウで実行する場合:
                    #search: VirtualBox shutdown
                CLI で実行する場合:
                    ssh  vagrant@localhost  -p __PortNum__  -i .vagrant/machines/__MachineName__/virtualbox/private_key \
                        'sudo shutdown -h now'
            VirtualBox VMs フォルダーのサブフォルダーをコピーします:
                - C:\Users\__User__\VirtualBox VMs\____ フォルダー（１つ以上）を
                    バックアップへコピーします
            .vagrant フォルダーをコピーします:
                #// 既存のバックアップから変わらないようなので、バックアップがあれば、改めてバックアップする必要がないかもしれません
                - __Project__/.vagrant フォルダーをバックアップへコピーします
                #// .vagrant フォルダーは、リポジトリにコミットしても構いません
            VM の電源を入れます:
                #search: VirtualBox VM start
        リストア, クリーン: #keyword: Vagrant clean VM  #// VM を戻します
            VM のない状態に戻します:  #keyword: Vagrant from no VM
                __Project__/.vagrant フォルダーを削除します:
                対象の VM を削除します: #search: VirtualBox delete VM
            リストアします:  #// VM のフォルダーのバックアップを使ってクリーンな VM に戻します:
                コピーする場合:  #keyword: Vagrant VirtualBox restore  #// .vmdk ファイル が入ったフォルダーをコピーします
                    注意: Vagrant で VM を作ったときの VirtualBox のバージョンと現在の VirtualBox のバージョンが
                        異なるとリストアできません。
                        エラーの例：GuestAdditions versions on your host (6.1.32) and guest (6.1.30) do not match.
                        対処法 https://stackoverflow.com/questions/38010519/guestadditions-version-mismatch
                    早い方法を使う場合:  #🌟
                        （必要なら）既存の VM を削除します:  #copy: VirtualBox delete VM
                            既存の VM の電源を落とします:
                                VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> 電源オフ
                            VirtualBox マネージャーから VM を削除します:
                                VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 除去 >>
                                    すべてのファイルを削除
                        VM のバックアップから復帰します:
                            VirtualBox VMs フォルダーをコピーします:
                                - C:\Users\__User__\VirtualBox VMs\____ フォルダー（複数選択可能）を
                                    バックアップからコピーします
                            VirtualBox マネージャーに VM のフォルダーを認識させます:
                                仮想マシンを追加します:
                                    VirtualBox マネージャー >> 仮想マシン >> 追加（複数選択可能）
                            .vagrant フォルダーをコピーします:  #// .vagrant フォルダーは、リポジトリにコミットしても構いません
                                - __Project__/.vagrant フォルダーをバックアップからコピーします
                        VM の電源を入れます:  #search: vagrant up
                    バックアップからクローンして復帰する場合:
                        ❗: 以下の方法は失敗します。UUID を合わせても Vagrant は新しい VM を作ろうとします。
                        バックアップが VirtualBox マネージャーに登録されていない場合:
                            ${HOME}/VirtualBox VMs/____ フォルダーにコピーします:
                            登録します: VirtualBox マネージャー >> 仮想マシン（メニュー）>> 追加
                        バックアップからクローンします: #copy: VirtualBox clone from back up
                            注意❗: クローンした VM は SSH 接続できません。対処法は未検討。
                                VSCode からクローン元に接続できなくなったら、VSCode >> Remote Explorer（左）から開いてください
                            既存の VM の電源を落とします:
                                VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> 電源オフ
                            既存の VM の名前をメモしておきます:
                                VirtualBox マネージャー >>（対象のVM）>> 名前（中央上）>> Ctrl + A, Ctrl + C >> メモに張り付け
                            既存の VM を削除（除去）します:
                                VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 除去 >> すべてのファイルを削除
                            VM をコピー（クローン）します:
                                メニュー: VitrualBox マネージャー >>（対象のVM。複数選択可能）（右クリック） クローン >>
                                名前: バックアップ___Name__ (例)
                                #// オプションは、特にこだわりがなければデフォルトで構いません
                                VM の順番を整理します:
                                    ドラッグ&ドロップで VM の順番を変更できます
                        action_provision ファイルの内容を、対応する VM の UUID に修正します:
                            .vagrant/machines/__MachineName__/virtualbox/action_provision :
                                変更箇所: 1.5:__UUID__
                                内容:  #ref: ${HOME}/VirtualBox VMs/__VM_Name__/__VM_Name__.vbox
                                    <Machine uuid="{__UUID__}"
                    その他の方法:
                        ❗: ACPI シャットダウンはドライバーの設定が悪いと不安定になります
                        既存の VM の電源を落として、削除します:  #keyword: VirtualBox ACPI shutdown
                            メニュー: VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> 電源オフ >>
                                VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 除去 >> すべてのファイルを削除
                            ACPI シャットダウンをする場合:
                                注意: VM の再起動ができなくて、ホストOSを再起動が要求されることがあります
                                メニュー: VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> ACPI シャットダウン >>
                                    VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 除去 >> すべてのファイルを削除
                                もし、VirtualBox が固まったら:
                                    （タスクバーを右クリック）>> タスクマネージャー >> 詳細（タブ）>> VBoxSVC.exe（を右クリック）>> タスクの終了、
                                    タスクマネージャー >> プロセス（タブ）>> VirtualBox マネージャー（を右クリック）>> タスクの終了
                                もし、VM が起動できなくなったら:
                                    ホストOSを再起動します
                        VirtualBox VMs フォルダー:
                            - C:\Users\__User__\VirtualBox VMs\____ フォルダー（１つ以上）をバックアップからコピーします
                        .vagrant フォルダー:  #// リポジトリにコミットしても構いません
                            - __Project__/.vagrant フォルダーをバックアップからコピーします
                        仮想マシンを追加します:
                            - VirtualBox マネージャー >> 仮想マシン >> 追加（１つ以上）
                パッケージを使う場合:
                    参考: 
                （関連）SSH 接続します:  #// 新しい VM  
                    vagrant up >> 新しい Git bash を開き、VM の電源を入れます:
                        - #Git bash であること。PowerShell では失敗します。VirtualBox で電源を入れると共有フォルダーができません
                        - cd  __Project__
                        - vagrant up
                    vagrant ssh-config >> ホストOSから SSH 接続できるようにします:
                        SSH の設定を表示します:
                            #bash
                            - vagrant ssh-config
                        C:\Users\__User__\.ssh\config に貼り付けます:
                            #// Visual Studio Code の Remote Explorer（左）にサーバーが表示されます
            VM のフォルダーのバックアップがない場合:  #// vagrant up
                注意: 作り直すのに約10分かかります
                既存の VM の電源を落として、削除します:
                    VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 閉じる >> ACPI シャットダウン >>
                    VirtualBox マネージャー >>（対象のVM。複数選択可能）（右クリック）>> 除去 >> すべてのファイルを削除
                    対象のVMは、__FolderName_____ServerName__
                __Project__/.vagrant フォルダーを削除します:
                新しい Git bash を開き、VM の電源を入れます:  #see-above: vagrant up
                ホストOSから SSH 接続できるようにします:  #see-above: vagrant ssh-config
        プロビジョニング オプション:
            公式: https://www.vagrantup.com/docs/provisioning
            並列起動:  #keyword: vagrant provision parallel
                VirtualBox ではサポートしていません
                https://www.vagrantup.com/docs/providers/virtualbox/usage
                https://stackoverflow.com/questions/45823630/vagrant-multi-machine-parallel-start
        その他: #search: Vagrantfile
    コマンド(Vagrant):  #keyword: Vagrant commands  #ref: https://developer.hashicorp.com/vagrant/docs/cli
        vagrant up:  #// 電源を入れ、プロビジョニングを行います。起動します  #keyword: vagrant up
            VM が無い場合:
                vagrant up
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/1_multi_vm_ansible/README.yaml#vagrant up
            共有フォルダーを使わない場合:  #keyword: VirtualBox headless start without vagrant up
                VirtualBox マネージャー >> VM を複数選択 >> VM（どれでもよい）を右クリック >> 起動 >> ヘッドレス起動
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/1_multi_vm_ansible/README.yaml#ヘッドレス起動
            プロキシの設定:  #// vagrant up を実行すると vagrant-proxyconf によってプロキシの設定も行われます
                #search: vagrant up trouble Configuring proxy for npm
            VAGRANT_LOG=info  vagrant up : #keyword: VAGRANT_LOG,  Vagrant up debug  #// 詳細なログを表示して起動します
                バリエーション:
                    VAGRANT_LOG=debug  vagrant up 
            VAGRANT_VAGRANTFILE="${PWD%/*}/Vagrantfile"  vagrant up : #keyword: VAGRANT_VAGRANTFILE  #// Vagrantfile のパスを指定します
                - ${PWD%/*}/Vagrantfile は親フォルダーの Vagrantfile です
                - .vagrant フォルダーは VAGRANT_VAGRANTFILE の値に関わらず カレント フォルダー にできます
                - VirtualBox に表示される VM の名前は、VAGRANT_VAGRANTFILE 環境変数が指すファイルがあるフォルダー名が先頭に付きます
                - vagrant ssh-config コマンドなども VAGRANT_VAGRANTFILE 環境変数が指す Vagrantfile の設定が使われます
            Machine booted and ready! と表示された直後の処理:  #search: Vagrant shell Provisioner
            control_only=1  vagrant up :  #// （独自）control サーバーだけ起動します  #keyword: control_only=1  vagrant up
                control_only=1  vagrant up
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/1_multi_vm_ansible/README.yaml#control_only=1
            vagrant up --provision:  #// プロビジョニングを実行します。途中に独自処理を追加します
                Vagrant のプロビジョニングは、プロビジョナー と呼ばれるものをいくつか実行することです。
                vagrant up --provision が途中でエラーになった場合、vagrant reload --provision でプロビジョニングの続きを実行します
                #search: Ansible プロビジョナー
            タイムアウトする場合:  #search: vagrant up time out
            デバッグする場合:  #search: vagrant up debug
                #snip: vagrant up  --debug --timestamp
        vagrant reload:  #// 再起動してハードウェアの構成を更新します  #keyword: vagrant reload
            - vagrant reload --provision  // 起動済みの仮想マシンを再起動する
                vagrant up --provision が途中でエラーになった場合、vagrant reload --provision でプロビジョニングの続きを実行します
                vagrant up より遅いです
                共有フォルダーは接続できます
            #// ❗以下は OS が壊れる可能性があるので注意
            - vagrant reload  #// 単一のVMのとき
            - vagrant reload __VM_Name__  #// 複数のVMが定義された環境で1つのVMに対して実行するとき
                #// __VM_Name__ は複数 VM 環境のときに指定可能で、config.vm.define の第1引数
            - vagrant reload コマンドは vagrant provision コマンドの処理は行われません
        vagrant provision:  #// 起動中の VM にプロビジョニングします  #keyword: vagrant provision
            - 共有フォルダーは接続できません
            - 書式は vagrant reload と同じです
            - メモリーサイズの変更などはプロビジョニングではなく、再起動（vagrant reload）しないと反映されません  
        vagrant suspend:  #// VM を保存状態にします。ホストOSのメモリーも解放されます  #keyword: vagrant suspend
            早く保存状態にする:
                VirtualBox マネージャー >> VM を複数選択 >> VM（どれでもよい）を右クリック >> 閉じる >> 保存状態
            保存状態から復帰できないとき:
                VirtualBox >>（VM を右クリック）>> 除去 >> 除去のみ >>
                仮想マシン メニュー >> 追加
        vagrant resume:   #// VM を保存状態から復帰します  #keyword: vagrant resume
            - すでに起動していたらエラーになります。vagrant up でも保存状態から復帰でき、すでに起動していてもエラーになりません
            - ヘッドレス起動と同じです（GUI がない VM では？）
            - 早く復帰するには、
                VirtualBox マネージャー >> VM を複数選択 >> VM（どれでもよい）を右クリック >> 起動 >> ヘッドレス起動
        vagrant status:   #// VM の状態を表示します  #keyword: vagrant status
            コマンド:
                cd  __VagrantFileFolder__
                vagrant status
            実行例 --machine-readable: | #keyword: vagrant status --machine-readable  #// カレント フォルダー に関連付けられた 1つの VM に関する情報です
                $ vagrant status --machine-readable
                    1720489483,centos7_62,metadata,provider,virtualbox
                    1720489483,centos7_62,provider-name,virtualbox
                    1720489483,centos7_62,state,not_created
                    1720489483,centos7_62,state-human-short,not created
                    1720489483,centos7_62,state-human-long,The environment has not yet been created. Run `vagrant up` to\ncreate the environment. If a machine is not created%!(VAGRANT_COMMA) only the\ndefault provider will be shown. So if a provider is not listed%!(VAGRANT_COMMA)\nthen the machine is not created for that environment.
                    1720489483,,ui,info,Current machine states:\n\ncentos7_62                not created (virtualbox)\n\nThe environment has not yet been created. Run `vagrant up` to\ncreate the environment. If a machine is not created%!(VAGRANT_COMMA) only the\ndefault provider will be shown. So if a provider is not listed%!(VAGRANT_COMMA)\nthen the machine is not created for that environment.
            実行例: |
                $ vagrant status
                    Current machine states:

                    centos7_62                not created (virtualbox)

                    The environment has not yet been created. Run `vagrant up` to
                    create the environment. If a machine is not created, only the
                    default provider will be shown. So if a provider is not listed,
                    then the machine is not created for that environment.
            注意:
                VM があるときに vagrant status --machine-readable を実行した後、VM を削除して再実行しても、表示内容は変わらないことがありました。
            ヘルプ表示: |
                $ vagrant status --help
                    Usage: vagrant status [name|id]
                            --[no-]color                 Enable or disable color output
                            --machine-readable           Enable machine readable output
                        -v, --version                    Display Vagrant version
                            --debug                      Enable debug output
                            --timestamp                  Enable timestamps on log output
                            --debug-timestamp            Enable debug output with timestamps
                            --no-tty                     Enable non-interactive output
                        -h, --help                       Print this help
        vagrant halt:     #// VM の電源を切ります（強制終了）  #keyword: vagrant halt
            書式: vagrant halt __VMName__
            __VMName__:
                Vagrantfile:
                    config.vm.define "__VMName__" 
            memo:
                #bash
                - cd  ~/vagrant/centos7  #template: __ProjectName__
                - vagrant status  #// __HostName__ と 起動状態 と 仮想化ソフト名 が表示されます
                - vagrant halt  __HostName__       #// 仮想マシンの電源をオフにします
                #// vagrant suspend  __HostName__  #// サスペンド状態に移行してホストOSのメモリーを解放します
                #// vagrant resume  __HostName__   #// サスペンド状態から復帰します
            注意: 実行には .vagrant フォルダーが必要です
            #ref: https://developer.hashicorp.com/vagrant/docs/cli/halt
        vagrant destroy: #keyword: vagrant destroy,  delete vagrant VM  #// VM を削除します
            基本:
                cd __VagrantFileFolder__
                vagrant destroy --force   #// --force はユーザーの確認をしません
            vagrant global-status を使う場合:  #// 既存の VM が検出されないことがあります
                #// 削除した VM は、VirtualBox マネージャーから無くなり、VM のフォルダーも削除されます
                - vagrant global-status --prune  #// __VM_ID__ が表示されます
                - vagrant destroy -f __VM_ID__
                #// 強制終了もします。-f はユーザーに確認せずに削除します
                - rm -rf .vagrant  #// 秘密鍵なども削除します
                #// VirtualBox を開いて、同様の作りかけの VM のインスタンスがあれば手動で削除してください
            オプション: |
                $ vagrant destroy --help
                Usage: vagrant destroy [options] [name|id]
                Options:
                    -f, --force                      Destroy without confirmation.
                        --[no-]parallel              Enable or disable parallelism if provider supports it (automatically enables force)
                    -g, --graceful                   Gracefully poweroff of VM
                        --[no-]color                 Enable or disable color output
                        --machine-readable           Enable machine readable output
                    -v, --version                    Display Vagrant version
                        --debug                      Enable debug output
                        --timestamp                  Enable timestamps on log output
                        --debug-timestamp            Enable debug output with timestamps
                        --no-tty                     Enable non-interactive output
                    -h, --help                       Print this help
    ファイル:
        Vagrantfile: #keyword:  #// Vagrantfile は Ruby 言語で書きます
            VM の基本設定:  #keyword: Vagrant vb.memory, Vagrant vb.cpus
                #// 下記のように変更したら vagrant reload してください:
                #// デフォルトは、1CPU, memory: 512MB
                単一VMの場合: |
                    Vagrant.configure("2") do |config|
                        config.vm.provider "virtualbox" do |vb|
                            vb.cpus = 2
                            vb.memory = 2048  #// MB
                        end
                マルチVMの場合: |  #keyword: vm.network ip address port
                    Vagrant.configure("2") do |config|
                        config.vm.box = "ubuntu/trusty64"  #keyword: config.vm.box  #// vagrant box list で表示される box から選べます

                        config.vm.define :web do |web_config|
                            web_config.vm.host_name = "web"
                            web_config.vm.network :private_network, ip:"192.168.100.10"
                            web_config.vm.network :forwarded_port, guest: 22, host: 2222, id: "ssh"
                            web_config.vm.provider :virtualbox do |vb|
                                vb.customize ["modifyvm", :id, "--memory", "2048"]
                                vb.customize ["modifyvm", :id, "--cpus", "2"]
                            end
                        end
                    end
                    #// ip と host は VM ごとに変えてください
                    #// host はホストOSから SSH アクセスするときのポートフォワーディングされたポート番号です。
                    #// forwarded_port の行を書かないときは、host が自動的に割り当てられます。
                    #// １つ目は 2222, ２つ目は 2200, ...
                .box ファイルをダウンロードする場合: |  #keyword: Vagrantfile box_url  #focus: box_url
                    Vagrant.configure("2") do |config|
                        config.vm.define "linux_49" do |config|
                            config.vm.network :private_network, ip: "192.168.34.49"
                            config.vm.network :forwarded_port, guest: 22, host: 2249, id: "ssh"
                            config.vm.box = "linux-20230314"
                            config.vm.box_url = 'http://example.com/linux/20230314/linux.box'
                            config.vm.box_check_update = false
                            config.vm.synced_folder ".", "/vagrant", disabled: true
                            config.ssh.insert_key = false
                            config.ssh.private_key_path = "C:/Users/____/.ssh/id_ed25519"
                            config.ssh.username = "vagrant"
                            # config.ssh.password = "This setting will be ignored."
                        end
                        config.vm.provider "virtualbox" do |vb|
                            vb.memory = "8192"
                            vb.check_guest_additions = false
                            vb.functional_vboxsf = false
                        end
                        if Vagrant.has_plugin?("vagrant-vbguest") then
                            config.vbguest.auto_update = false
                        end

                        #// Proxy
                        if Vagrant.has_plugin?("vagrant-proxyconf") && ENV['HTTP_PROXY'] && ENV['HTTPS_PROXY']
                            config.proxy.http     = ENV['HTTP_PROXY']
                            config.proxy.https    = ENV['HTTPS_PROXY']
                            config.proxy.no_proxy = "localhost, 127.0.0.1, 192.168.*, 192.168.34.49, linux-20230314"
                        end
                    end
            マルチ サーバー構成のサンプル:  #keyword: Vagrant config.vm.define
                参考: https://www.vagrantup.com/docs/multi-machine
                最小限の Vagrantfile: |
                    Vagrant.configure("2") do |config|

                        def configure(server, address)
                            server.vm.box = "centos/7"  #// vagrant box list で表示される box から選べます
                            server.vm.network :private_network, ip: address
                            server.vbguest.installer_options = { allow_kernel_upgrade: true }  #// vagrant-vbguest plug-in
                        end

                        config.vm.define "db1" do |server|
                            configure server, "192.168.33.101"
                        end
                        config.vm.define "db2" do |server|
                            configure server, "192.168.33.102"
                        end
                    end
                Ansible が使えるマルチ サーバー構成の Vagrantfile: |
                    Vagrant.configure("2") do |config|
                        config.vm.provider "virtualbox" do |vb|
                            vb.memory = 256  #// MB
                        end

                        config.vm.synced_folder ".", "/vagrant",  create: true, owner: "vagrant", group: "vagrant", type:"virtualbox"

                        def configure(server, address)
                            server.vm.box = "centos/7"
                            server.vm.network :private_network, ip: address
                            server.vbguest.installer_options = { allow_kernel_upgrade: true }  #// vagrant-vbguest plug-in
                        end

                        #ref: https://www.vagrantup.com/docs/multi-machine
                        config.vm.define "db1" do |server|
                            configure server, "192.168.33.101"
                        end
                        config.vm.define "orc" do |server|
                            configure server, "192.168.33.104"

                            server.vm.provision "ansible_local" do |ansible|
                                ansible.playbook = "playbook.yml"
                                ansible.compatibility_mode = '2.0'
                            end
                        end
                    end
            Vagrantfile の場所:  #// vagrant up コマンドのオプション  #search: VAGRANT_VAGRANTFILE
            Vagrantfile のオプション: |  #focus: sub_port_num  #// Vagrant にパラメーターを指定する。Ruby 言語の機能
                sub_port_num = ENV['SUB_PORT_NUM'] || "21"
                ...
                    config.vm.network :private_network, ip: "192.168.34."+ sub_port_num
                    config.vm.network :forwarded_port, guest: 22, host: 2200 + sub_port_num.to_i, id: "ssh"
            その他 VM のオプション:  #// CPU 数, メモリー サイズ, ストレージ サイズ  #search: Vagrant VM options
        .box ファイル: #keyword:  #// Vagrant で使える仮想マシン環境のパッケージフォーマット
            対応状況:
                Vagrant がサポートしている仮想化プロバイダーのうち、
                特定の .box ファイルがサポートしている仮想化プロバイダーは一部である可能性があります。
                たとえば、centos/7 は Docker をサポートしていません
                #ref: https://app.vagrantup.com/centos/boxes/7/versions/2004.01
                #search: 仮想化プロバイダー
            プロビジョニング:  #search: Vagrantfile box_url
        .vagrant フォルダー: #keyword:
    概念:
        VM: #keyword: Vagrant VM options  #// VM の初期設定
            VM の操作:
                #search: Vagrant VM operation
                #search: Vagrant commands
            VM のグループ: #keyword: Vagrant VM group  #// VirtualBox の仮想マシンのグループに所属させます
                #focus: __Group__
                Vagrant.configure("2") do |config|
                    config.vm.provider "virtualbox" do |vb|
                        vb.customize ["modifyvm", :id, "--groups", "/__Group__"]
            電源, 保存状態: #keyword:  #search: VirtualBox 保存状態
                #search: vagrant up
                #search: vagrant halt
                #search: vagrant suspend
                #search: vagrant resume
            CPU 数: |
                Vagrant.configure("2") do |config|
                    config.vm.provider "virtualbox" do |vb|
                        vb.cpus = 2
            メモリーサイズ: |
                Vagrant.configure("2") do |config|
                    config.vm.provider "virtualbox" do |vb|
                        vb.memory = 8922  #// MB
            ストレージ: #keyword: Vagrant storage
                サイズ:
                    プラグインを使う場合:
                        bash:
                            vagrant plugin install vagrant-disksize
                        Vagrantfile: |
                            Vagrant.configure("2") do |config|
                                if Vagrant.has_plugin?("vagrant-disksize") then
                                    config.disksize.size = '100GB'
                                end
                        副作用:
                            ディスク イメージ ファイルは .vmdk 形式ではなく .vdi 形式になります。
                            通常、これが問題になることはありません。
                        #ref: https://qiita.com/yut_h1979/items/c84c490053877beee5c1
                    使用量を減らす、または手動で増やす場合:
                        #search: disk size
                ファイルのアップロード:  #keyword: Vagrant vm.provision file upload
                    Vagrantfile: |
                        config.vm.provision "file", source: "~/.gitconfig", destination: ".gitconfig"
                    秘密鍵のアップロード:
                        ただし、Vagrant が自動的に作る秘密鍵をアップロードすることはできません。
                            File upload source file ____/.vagrant/machines/control/virtualbox/private_key must exist
                        シェルスクリプトでアップロードできます  #search: ansible_vagrant 1_multi_vm_ansible
            ネットワーク: #keyword: Vagrant network
                アダプター, アドレス: |
                    Vagrant.configure("2") do |config|
                        config.vm.define "centos7_52" do |config|
                            config.vm.network :private_network, ip: "192.168.34.52"
                            config.vm.network :forwarded_port, guest: 22, host: 2352, id: "ssh"
                プロキシ:
                    bash:
                        vagrant.exe  plugin install vagrant-proxyconf
                    Vagrantfile: |
                        Vagrant.configure("2") do |config|
                            if Vagrant.has_plugin?("vagrant-proxyconf") && ENV['HTTP_PROXY'] && ENV['HTTPS_PROXY']
                                config.proxy.http     = ENV['HTTP_PROXY']
                                config.proxy.https    = ENV['HTTPS_PROXY']
                                config.proxy.no_proxy = "localhost, 127.0.0.1, 192.168.*, 192.168.34.52, centos7_52"
                            end
            共有フォルダー: #keyword: Vagrant 共有フォルダー
                場所:
                    VM 内: /vagrant
                    ホスト内: Vagrantfile が置かれているフォルダー
                インストール:
                    bash:
                        vagrant plugin install vagrant-vbguest
                    Vagrantfile: |
                        Vagrant.configure("2") do |config|
                            config.vm.synced_folder ".", "/vagrant",  create: true, owner: "vagrant", group: "vagrant", type:"virtualbox"
                無効設定:
                    Vagrantfile: |
                        Vagrant.configure("2") do |config|
                            config.vm.synced_folder ".", "/vagrant", disabled: true
                    代わり: scp コマンド
        box:
            ダウンロード済みの Box を一覧します:
                vagrant box list  #// Box 名 （仮想化ソフト名） が表示されます
            Box を削除してディスクの空き容量を増やします:
                - vagrant box list  #// Box 名 （仮想化ソフト名） が表示されます
                - vagrant box remove  __BoxName__
        仮想化プロバイダー: #keyword: Vagrant 仮想化プロバイダー  #// 仮想マシンを動かすソフトウェア。Vagrant の操作対象
            対応: Oracle VirtualBox, VMware Workstation / VMware Fusion, Hyper-V, Docker, Parallels(mac), KVM
        プロビジョナー:  #keyword: Ansible プロビジョナー, Ansible provisioner, プロビジョニング, config.vm.provision
            概要: Vagrant がプロビジョニングの一部を移譲するツール。プロビジョニングとは、サーバーにインストール等をすることです。
            参考:
                - https://www.vagrantup.com/docs/provisioning/ansible_local
                - https://docs.ansible.com/ansible/2.9_ja/scenario_guides/guide_vagrant.html
            ansible_local (Ansible Local Provisioner): #keyword: ansible_local
                概要:
                    - プロビジョニングを行うゲスト マシーン上で ansible-playbook を実行します。 #search: ansible-playbook
                    - Vagrant から実行します  #see-above: server.vm.provision "ansible_local"
                    - ゲストマシンに Ansible がまだ存在しない場合、Vagrant は自動的に Ansible をインストールします。
                    - 自動的につくられるインベントリー ファイルには、ansible_local を入れたサーバーだけでなく
                        別のサーバーの情報も入ります  #search: Vagrant Ansible SSH
                サンプル1 Vagrantfile: |
                    node.vm.provision :ansible_local do |ansible|
                        ansible.playbook = "playbook.yml"
                            #// ゲスト マシーンの /vagrant/playbook.yml を実行します。
                            #// ただし、Vagrantfile の中の config.vm.synced_folder によって playbook.yml があると想定しています
                        ansible.compatibility_mode = '2.0'
                        ansible.verbose = "v"
                            #// ansible.verbose の行が無くても Ansible のタスクが変更をプロビジョニングしたかどうかは表示されます
                            #// ansible.verbose = "v" を書くと、Ansible のタスクの詳細も表示されます
                        ansible.raw_arguments = ['--check']
                            #// dry run します  #search: ansible check
                    end
                サンプル2 Vagrantfile: |
                    node.vm.provision :ansible_local do |ansible|
                        ansible.compatibility_mode = '2.0'
                        ansible.playbook = '/home/vagrant/ansible/all.yml'
                        ansible.inventory_path = '/home/vagrant/ansible/inventories/hosts'
                        ansible.limit = 'clients'
                    end
            ansible: #// ホスト マシーン上で ansible-playbook を実行し、ゲスト マシーンに対してプロビジョニングします。
                #// 注意: ホスト マシーンが Windows のときは使えません。Vagrant for Windows から実行しても使えません。
            /vagrant: #keyword:  #// ansible_local をインストールすると作られるホスト OS との共有フォルダー
            file:  #// ファイルをアップロードします  #keyword: Vagrant File Provisioner
                参考: https://www.vagrantup.com/docs/provisioning/file
                サンプル: |
                    config.vm.provision "file", source: private_key, destination: "/home/vagrant/.ssh/id_rsa"
                #search: ansible_vagrant 1_multi_vm_ansible
            shell: #keyword: Vagrant shell Provisioner  #// シェル コマンド を実行します
                #ref: https://developer.hashicorp.com/vagrant/docs/provisioning/shell
                サンプル: |  #focus: shell
                    Vagrant.configure("2") do |config|
                        config.vm.define "centos7_62" do |config|
                            config.vm.provision "attach-repository-patch", type: "shell", run: "always", inline: <<-'__HERE_DOCUMENT__'
                                sudo sed -i 's/mirrorlist=/#mirrorlist=/g' /etc/yum.repos.d/CentOS-*
                                sudo sed -i 's/#baseurl=/baseurl=/g' /etc/yum.repos.d/CentOS-*
                                sudo sed -i 's/mirror.centos.org/vault.centos.org/g' /etc/yum.repos.d/CentOS-*
                                yum clean all
                                yum makecache
                            __HERE_DOCUMENT__
                vagrant up の出力: |
                    ==> centos7_62: Running provisioner: attach-repository-patch (shell)...
                        centos7_62: Running: inline script
                        centos7_62: __InlineScriptStdOut__
                実行タイミング:
                    vagrant up を実行している途中で Machine booted and ready! と表示され、
                    Guest Additions のインストールや共有フォルダーの設定などが行われた後、
                    shell (inline script) が実行されます。
                    それらより前にしたい場合は、
                        preprovision = ENV['PREPROVISION'] || "false"
                        if preprovision == "true"
                    のように書いて、以下のように 2段階でコマンドを実行します。
                        1. PREPROVISION=true  vagrant up --provision
                        2. vagrant reload
                実行条件: #keyword: Vagrant provisioning condition  #// プロビジョニング（provision shell も含む）を実行する条件
                    -   VM を新規作成するとき  （削除してから再作成すると実行されないことが多いです）
                        #// または
                    -   --provision オプションが指定されたとき
                            vagrant up --provision
                    -   #// または
                        vagrant provision コマンドを実行したとき
                    - | #// または
                        run: "always" が指定されているとき
                            config.vm.provision "attach-repository-patch", type: "shell", run: "always"
                    -   #// かつ
                        VM の電源が入っていないとき
                    #// shell プロビジョナー より前に実行される Guest Additions のインストールや共有フォルダーで
                    #// エラーが発生すると、vagrant provision コマンドや --provision オプションが指定されていても
                    #// プロビジョナーが実行する前にエラーで終了してしまいます
        Box:  #// Vagrant がベースにする OS などの大きいパッケージ、仮想マシンのテンプレート（雛形）です。 #keyword: Vagrant box
            #ref: https://www.vagrantup.com/docs/cli/box
            検索: #ref: https://app.vagrantup.com/boxes/search
            一覧:  #// ダウンロード済みの Box を一覧します
                vagrant box list  #// Box 名 （仮想化ソフト名） が表示されます
            追加:
                vagrant box add __FilePath__
            保存場所:
                .box ファイルを展開したもの: #ref: ${HOME}/.vagrant.d/boxes/__Name__/__Version__
            作成:
                #ref: https://qiita.com/kon_yu/items/ac7fb2c5af1cc0844225
            ファイル構造:
                .tar.gz 形式
                #ref: https://www.vagrantup.com/docs/boxes/format
        vagrant-vbguest プラグイン:  #// Guest Additions のバージョンを自動的に合わせます  #keyword: vagrant-vbguest plug-in
            URL: https://github.com/dotless-de/vagrant-vbguest
            インストール手順:
                bash:
                    vagrant plugin install vagrant-vbguest
                Vagrantfile: |
                    config.vbguest.installer_options = { allow_kernel_upgrade: true }  #search: vagrant-vbguest plug-in
    トラブルシューティング:
        print デバッグ: |
            puts "Message"
            puts "config.vm.box の値: #{config.vm.box}"
        デバッグする場合: #keyword: vagrant up debug
            vagrant up  --debug --timestamp
        タイムアウトする場合: #keyword: vagrant up time out
            ログ: |
                $ "vagrant.exe" up
                ...
                vm-local: SSH auth method: private key
                ...
                If the box appears to be booting properly, you may want to increase
                the timeout ("config.vm.boot_timeout") value.
                ERROR  #breadcrumb: 2025-10-15T04:02:55.429129200+0900 (PID=1682, ParentPID=1535) To continue, input the command like: /c/Users/m-toda/vagrant/single_vm_ansible/ci-local/vm-local/install-vm.sh  --start-at " >> Main >> SetUpVMsAndAnsibleProject >> CreateBaseVMs (VM1) >> CreateBaseVMs >> installBaseScript, ./install-vm.sh >> Main >> CreateVM (A) >> [2] >> CreateVM  sever9900R-local, 22 >> CreateSTUBLxVM  server9900R-local, 22, STUBL9 >> vagrant up"
            もう一度実行するか、Windows を再起動する:
            vagrant up のタイムアウトを伸ばす:  #ref: https://stackoverflow.com/questions/73589100/how-do-i-increase-the-config-vm-boot-timeout-in-vagrant
                config.vm.boot_timeout = 300  #// second   #// 300 はデフォルト値
                #// Warning: Connection reset. Retrying... が表示されるまでの時間ではありません
        #↓ エラー メッセージ
        Could not retrieve mirrorlist:
            手順: vagrant up
            エラー: |  #keyword: Could not retrieve mirrorlist
                Could not retrieve mirrorlist http://mirrorlist.centos.org/?release=7&arch=x86_64&repo=os&infra=vag error was
                14: HTTP Error 503 - Service Unavailable
            対処:
                CentOS7:  #ref: https://serverfault.com/questions/1161816/mirrorlist-centos-org-no-longer-resolve
                    Vagrant の場合:
                        Vagrantfile: |
                            config.vm.provision "attach-repository-patch", type: "shell", run: "always", inline: <<-'__HERE_DOCUMENT__'
                                echo 'Changing OS mirror URL ...'
                                sudo sed -i 's/mirrorlist=/#mirrorlist=/g' /etc/yum.repos.d/CentOS-*
                                sudo sed -i 's/#baseurl=/baseurl=/g' /etc/yum.repos.d/CentOS-*
                                sudo sed -i 's/mirror.centos.org/vault.centos.org/g' /etc/yum.repos.d/CentOS-*
                                yum clean all
                                yum makecache
                            __HERE_DOCUMENT__
                        #search: Vagrant shell Provisioner
                    関連情報:
                        ミラー リスト:
                            変更前: http://mirrorlist.centos.org/
                            変更後: https://mirrormanager.fedoraproject.org/mirrors/CentOS
                            対処: http://mirrorlist.centos.org/?release=7&arch=x86_64&repo=os&infra=vag
                                でエラーになったら、
                                https://mirrormanager.fedoraproject.org/mirrors/CentOS?release=7&arch=x86_64&repo=os&infra=vag
                                をブラウザーで開く >> JP（日本）を検索 >> http のリンク先？
                            #ref: https://stackoverflow.com/questions/78692851/could-not-retrieve-mirrorlist-http-mirrorlist-centos-org-release-7arch-x86-6
                        ミラー:
                            sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*
                            sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*
                            #ref: https://stackoverflow.com/questions/78692851/could-not-retrieve-mirrorlist-http-mirrorlist-centos-org-release-7arch-x86-6
                CentOS6:
                    ミラー:
                        sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-Base.repo
                        sed -i 's|#baseurl=http://mirror.centos.org/centos/$releasever|baseurl=http://vault.centos.org/6.9|g' /etc/yum.repos.d/CentOS-Base.repo
                        yum clean all
            原因: ミラー リスト サーバー が変わった。 OS のサポート期限切れによる切り替え
        To fix this, modify your current project's Vagrantfile to use another port.:
            手順: vagrant up
            エラー: |  #focus: 2362, 1234
                ==> __VM_Name__: Setting the name of the VM: vm_1713148553979_52432
                Vagrant cannot forward the specified ports on this VM, since they
                would collide with some other application that is already listening
                on these ports. The forwarded port to 2362 is already in use
                on the host machine.

                To fix this, modify your current project's Vagrantfile to use another
                port. Example, where '1234' would be replaced by a unique host port:

                config.vm.network :forwarded_port, guest: 22, host: 1234

                Sometimes, Vagrant will attempt to auto-correct this for you. In this
                case, Vagrant was unable to. This is usually because the guest machine
                is in a state which doesn't allow modifying port forwarding. You could
                try 'vagrant reload' (equivalent of running a halt followed by an up)
                so vagrant can attempt to auto-correct this upon booting. Be warned
                that any unsaved work might be lost.
            対処A: |
                使っているポート 2362 を閉じます
            対処B: |
                config.vm.network :forwarded_port, guest: 22, host: 1234
                の 1234 を vagrant ホストで使っていないポートに変更します
        vagrant up しても Machine booted and ready! で止まり続ける:
            手順: vagrant up
            状況: Machine booted and ready! で止まり続ける
            対処:
                VirtualBox のネットワーク内に DNS を立てている場合:
                    DNS の VM の電源を入れます。date コマンドで表示される現在日時を正しくします
        ERROR! the playbook:;; playbook-0.yml could not be found:
            手順: vagrant up
            エラー: |
                ERROR! the playbook: playbook-0.yml could not be found
            対処:
                sudo mount -a  #search: VirtualBox shared folder
        Error message given during initialization:;; Unable to resolve dependency:; user requested 'vagrant-proxyconf (= 2.0.10)':
            手順: vagrant up --provider=docker
            エラー: |
                Vagrant failed to initialize at a very early stage:
                The plugins failed to initialize correctly.
                ...
                Error message given during initialization: Unable to resolve dependency: user requested 'vagrant-proxyconf (= 2.0.10)'
            対処:
                vagrant plugin install vagrant-proxyconf --plugin-version 2.0.10
        Vagrant is unable to use the VirtualBox provider from the Windows Subsystem for Linux without access to the Windows environment:
            手順: vagrant up
            エラー: |
                Vagrant failed to initialize at a very early stage:
                Vagrant is unable to use the VirtualBox provider from the Windows Subsystem for Linux without access to the Windows environment.
                Enabling this access must be done with caution and an understanding of the implications.
                For more information on enabling Windows access and using VirtualBox from the Windows Subsystem for Linux,
            #ref: https://stackoverflow.com/questions/66875692/vagrant-with-virtualbox-on-wsl-unable-to-access-windows-environment
        equested provider:;; [:docker]:
            手順: vagrant up --provider=docker
            エラー: |
                Bringing machine 'default' up with 'docker' provider...
                ==> default: Box 'centos/7' could not be found. Attempting to find and install...
                    default: Box Provider: docker
                    default: Box Version: 2004.01
                ==> default: Loading metadata for box 'centos/7'
                    default: URL: https://vagrantcloud.com/centos/7
                The box you're attempting to add doesn't support the provider
                you requested. Please find an alternate box or use an alternate
                provider. Double-check your requested provider to verify you didn't
                simply misspell it.

                If you're adding a box from HashiCorp's Vagrant Cloud, make sure the box is
                released.

                Name: centos/7
                Address: https://vagrantcloud.com/centos/7
                Requested provider: [:docker]
            原因:
                指定した .box には Docker 用のイメージが入っていません。
                Vagrant boxにはさまざまなプロバイダ（VirtualBox, Hyper-V, VMware, Dockerなど）用のバージョンがあり、それぞれのプロバイダ用に異なるboxが存在することが多いです。
            対処:
                Docker用の別のBoxを探す: vagrantcloud.comでDockerに対応したCentOSのboxを探してみてください。検索やフィルタリングを使用して、Dockerプロバイダに対応するboxを探すことができます。
                別のプロバイダを使用する: Dockerではなく、VirtualBoxや他のプロバイダを使用してcentos/7を起動することも考慮してみてください。
                手動でDockerイメージを作成: Docker HubからCentOS 7の公式イメージを取得して、それをベースに必要な設定やアプリケーションを追加して、独自のDockerイメージを作成することもできます。そして、そのイメージをVagrantで管理することも可能です。
        Configuring proxy for npm...  /usr/bin/env:;; node:;; No such file or directory:
            手順: vagrant up  #keyword: vagrant up trouble Configuring proxy for npm
            エラー: |
                Configuring proxy for npm...
                /home/vagrant/.nvm/versions/node/v__NodeVersion__/bin/npm config --global set proxy http://__ProxyServer__:__Port__
                /usr/bin/env: node: No such file or directory
            対処:
                下記 /etc/profile.d/nvm.sh を作ります。
            /etc/profile.d/nvm.sh: |
                export NVM_DIR="/home/vagrant/.nvm"
                [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
                [ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion
            原因:
                vagrant-proxyconf がプロキシを設定する際、root ユーザーで npm を実行しようとします。
            メモ:
                vagrant up を実行する間に /etc/profile.d/nvm.sh が数回呼ばれます。そのユーザーは root または vagrant です。
        SSL_connect SYSCALL returned=5 errno=0 state=SSLv3/TLS write client hello (https://gems.hashicorp.com/specs.4.8.gz):
            手順: vagrant.exe  plugin install vagrant-vbguest
            エラー: |
                Installing the 'vagrant-vbguest' plugin. This can take a few minutes...
                Vagrant failed to load a configured plugin source. This can be caused
                by a variety of issues including: transient connectivity issues, proxy
                filtering rejecting access to a configured plugin source, or a configured
                plugin source not responding correctly. Please review the error message
                below to help resolve the issue:

                SSL_connect SYSCALL returned=5 errno=0 state=SSLv3/TLS write client hello (https://gems.hashicorp.com/specs.4.8.gz)

                Source: https://gems.hashicorp.com/
                PS C:\Users\____> vagrant.exe  plugin install vagrant-vbguest
                ==> vagrant: A new version of Vagrant is available: 2.3.6 (installed version: 2.3.4)!
                ==> vagrant: To upgrade visit: https://www.vagrantup.com/downloads.html

                Installing the 'vagrant-vbguest' plugin. This can take a few minutes...
            対処:
                gems.hashicorp.com への接続ができないようです。1日待ったら直ったことがあります。
                Note PC ではネットワークにつながっていないと上記のエラーが出た。つなぐと動いた。
        Unknown configuration section 'proxy':
            手順: vagrant up コマンド >> Vagrantfile >> config.proxy
            エラー: |
                Unknown configuration section 'proxy'
            対処:
                vagrant-proxyconf プラグインをインストールしてください
        The provider for this Vagrant-managed machine is reporting that it is not yet ready for SSH:
            手順: vagrant ssh-config
            エラー: |
                The provider for this Vagrant-managed machine is reporting that it
                is not yet ready for SSH. Depending on your provider this can carry
                different meanings. Make sure your machine is created and running and
                try again. Additionally, check the output of `vagrant status` to verify
                that the machine is in the state that you expect. If you continue to
                get this error message, please view the documentation for the provider
                you're using.
            対処A:
                Vagrant ファイルが定義しているすべてのサーバーの電源を入れてください。
            対処B:
                vagrant up が失敗しているようです。
                たとえば、.vagrant フォルダーを削除してもう一度 vagrant up してください。
        PC の再起動しようとすると Has active connections:
            手順: PC の再起動
            エラー: VirtualBox Interface >> Has active connections と表示されて PC を再起動できない
            対処: （タスクバーを右クリック）>> タスクマネージャー >> 詳細（タブ）>> VBoxSVC.exe（を右クリック）>> タスクの終了
        Vagrant >> Guest Additions のバージョンが違う:
            手順: vagrant up
            エラー: |
                No guest additions were detected on the base box for this VM!
                The guest additions on this VM do not match the installed version of VirtualBox!
                https://qiita.com/chubura/items/4166585cf3f44e33271d
            原因:
                VM が持っている Guest Additions のバージョンと VirtualBox が期待する Guest Additions のバージョンが違います
            対処:
                vagrant-vbguest プラグインをインストールします  #search: vagrant-vbguest
Ansible: #keyword: Ansible, an
    概要:
        基本:
            #ref: ${programming}/ネットワーク・セキュリティ/Cloud/Cloud.svg#Ansible
            - https://docs.ansible.com/ansible/2.9_ja/network/getting_started/basic_concepts.html  #template: __DocumentVersion__
            - https://docs.ansible.com/ansible/latest/network/getting_started/basic_concepts.html
            - https://qiita.com/elu_jaune/items/d3223922df42d9d4b45b
        このドキュメントの Ansible バージョン:
            - https://docs.ansible.com/ansible/2.9_ja/  #template: __DocumentVersion__
        日本語版がある 2.9:
            - https://docs.ansible.com/ansible/2.9_ja/  #// コード部分は、レイアウトが崩れます。
            - https://docs.ansible.com/ansible/2.9/
    手順、サンプル:
        サンプル プロジェクト:  #keyword: Ansible project examples
            非公開:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant
                Playbook サンプル集:
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/playbooks
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/file_example/text_file/replace/1st/playbook.yml
                multi_vm_ansible/branch_all:  #keyword: multi_vm_ansible,  ansible vagrant,  ansible .git.zip
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_all
                    #search: .git.zip checkout
            公開:  #ref: ${GitHub}/multi_vm_ansible
                multi_vm_ansible:
                    #ref: https://github.com/Takakiriy/multi_vm_ansible
                    #ref: https://qiita.com/Takakiri/items/64011adc99bf95acdfec
            #// これらのプロジェクトを使うときは、
            #// #search: install Ansible project
            #// .git.zip の場合、ブランチをチェックアウトします  #search: .git.zip checkout
            #// また、プロジェクト内の README を参照
            (deprecated):
                1_multi_vm_ansible:  #keyword: 1_multi_vm_ansible  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/1_multi_vm_ansible
                MySQL_1_multi_vm_ansible:  #keyword:  MySQL_1_multi_vm_ansible  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_MySQL_Flyway
        インストール:
            CentOS7:
                単体: #keyword: install Ansible CentOS7  #// Vagrant で作った CentOS7 の VM に Ansible をインストールします
                    新しい手順:  #// Ansbile が使う Python は 2.7.5
                        - sudo yum update -y
                        - sudo yum install -y  centos-release-ansible-29  #search: centos-release-ansible-29
                        - sudo yum install -y  ansible
                    centos.org, centos-release-ansible-29:
                        how do I install ansible in centos 7:  #ref: https://forums.centos.org/viewtopic.php?f=48&t=80180
                        安全性: #// centos-release-ansible-29 は安全でしょう
                            wiki.centos.org/SpecialInterestGroup/ConfigManagementSIG が作ったものは安全でしょうか？:
                                #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: safety centos-release-ansible-29
                    古い手順:
                        sudo yum update -y
                        sudo yum install -y  epel-release
                        sudo yum install -y  ansible
                Vagrant の Ansible プロビジョナー:  #search: Ansible プロビジョナー
                    single_vm_ansible:  #// single_vm_ansible/centos7 プロジェクト  #ref: https://github.com/Takakiriy/MyPrivateCode/blob/master/ansible_vagrant/single_vm_ansible/centos7/README.yaml
                    1_multi_vm_ansible:  #// 旧 既存の Vagrant+Ansible プロジェクトをプロビジョニングします:  #keyword: install Ansible project
                        プロジェクト: 1_multi_vm_ansible
                        公開情報: #ref: https://qiita.com/Takakiri/items/64011adc99bf95acdfec#付録構造化文書による手順書
                        設定: #settings:
                            __ControlNode__: control
                            __TargetNode__: node1
                        開発ツールとプロジェクトをインストールします:
                            VirtualBox をインストールします:
                                - https://www.virtualbox.org/ >> Download VirtualBox X.X >> Windows hosts
                                - ダウンロードしたファイル（例：VirtualBox-6.1.22-144080-Win.exe）を開きます
                                - インストール オプションはデフォルトを使用
                                - ドライバーはインストールします
                            Vagrant をインストールします:
                                - https://www.vagrantup.com/downloads.html >> Windows（タブ）>> 64-bit
                                - ダウンロードしたファイル（例：vagrant_2.2.16_x86_64.msi）を開きます
                                - インストール オプションはデフォルトを使用
                                - PC を再起動します
                            Git for Windows をインストールします:
                                - https://git-scm.com/ >> Download for Windows（右下）
                                - ダウンロードしたファイル（例：Git-2.33.0.2-64-bit.exe）を開く
                                - Next を9回押す
                                - Configuring the line ending conversions: Checkout as-is, commit as-is
                                - 他のインストール オプションはデフォルトを使用
                            Visual Studio Code をインストールします:
                                - https://code.visualstudio.com/
                                - ダウンロードしたファイル（例：VSCodeUserSetup-x64-1.50.1.exe）を開きます
                                - インストール オプションはデフォルトを使用
                                - Git bash シェルをデフォルトで開くようにします:
                                    VSCode >> Terminal >> New Terminal >> ＋の右の↓（シェルの右上）>>
                                    Select Default Profile >> Git bash >> ゴミ箱 ボタン（シェルの右上）
                                - （推奨）VSCode (Visual Studio Code をタスクバーにピン止めします:
                                - （推奨）Ctrl + S キーを押したときに全てのファイルを保存するように設定します: |
                                    VSCode >> File >> Preferences >> Keyboard Shortcuts >> save all （と入力） >>
                                        File: Save All （をダブルクリック） >> Ctrl + S キー >> Enter キー
                            ホストOSがプロキシがあるLANにいるとき:
                                #search: Windows proxy
                            vbguest プラグインをインストールします:  #// Ansible Local と Vagrant を接続するプラグインです
                                #// MyPrivateCode/ansible_vagrant にあるプロジェクトは Ansible Local を使っています
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant
                                #bash (VSCode >> Terminal >> New Terminal)
                                (@host) Git bash:  #// VSCode >> Terminal >> New Terminal
                                    - vagrant plugin install vagrant-vbguest
                            プロジェクト フォルダーを取得します:
                                コピーする場合:
                                    #search: Ansible project examples
                                ダウンロードする場合:
                                    (@host) Git bash:  #// 1_multi_vm_ansible プロジェクトをダウンロードします
                                        - cd ${GitHub}  #// ~/Desktop でもよい
                                        - git clone https://github.com/Takakiriy/MyPrivateCode
                                        - mkdir -p ~/Desktop/new_ansible
                                        - cp -rapT  "MyPrivateCode/ansible_vagrant/1_multi_vm_ansible/"  ~/Desktop/new_ansible/
                                            #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/1_multi_vm_ansible
                                            #// プロジェクト フォルダー __Project__ は、~/Desktop/new_ansible になります
                            Visual Studio Code で プロジェクト フォルダーを開きます:
                                (@host) Git bash:
                                    - code __Project__
                                #// VSCode 内で上記のコマンドを入力したら、コマンドを入力した VSCode を閉じます
                            Git bash シェルを開きます:
                                (@host) VSCode >> Terminal >> New Terminal
                            仮想マシンを作って起動します:
                                (@host) Git bash:
                                    - cd  __Project__  #// 不要の場合あり。以後も同様
                                    - vagrant up  #// 初回は約 5分。内部で Ansible Local による Playbook も動きます
                                        #// Vagrant プロジェクトがあるフォルダーは、VM の /vagrant/ フォルダーと共有します。
                                    - vagrant status  #// 仮想マシンが動作していることを確認します
                                        #// 必要なら、仮想マシン名を確認し、__ControlNode__, __TargetNode__ の値を編集します
                                参考: #search: vagrant up
                            SSH で仮想マシンにログインできるように設定します（VSCode用）:
                                VSCode の Remote Development 拡張機能をインストールします:
                                    インストールします:
                                        (@host) VSCode >> 拡張機能 ボタン（左） >> Remote Development
                                    SSH Targets を表示します:
                                        メニュー: (@host) VSCode >> Remote Explorer（アイコン：左）
                                        REMOTE EXPLORER（上）: SSH Targets
                                SSH の設定を VSCode に追加します:
                                    (@host) VSCode Git bash:
                                        - vagrant ssh-config  #// SSH の接続に必要な設定が表示されます
                                        - code ~/.ssh/config  #// vagrant ssh-config の出力を最後に貼り付けます
                                Visual Studio Code で SSH 接続します:
                                    vagrant / フォルダーが表示されているか確認します:
                                        (@host) VSCode >> Remote Explorer（左のアイコン）>> control >> vagrant /
                                    vagrant / フォルダーが表示されていない場合:
                                        SSH 接続します:
                                            control（の右のフォルダー）ボタン  #template: __ControlNode__
                                        (@control) platform: Linux
                                            #// 接続できない時は、vagrant ssh-config を再実行してください
                                        SSH 接続した Visual Studio Code でフォルダーを開きます:
                                            (@control) VSCode >> File >> Open Folder ... >> /vagrant/
                                    vagrant / フォルダーが表示されている場合:
                                        (@host) vagrant / フォルダー（の右のフォルダー）ボタン
                                    シェルを開けることを確認します:
                                        (@control) VSCode >> Terminal >> New Terminal
                                            #// [vagrant@localhost vagrant]$ と表示されます
                                            #// 次回プロジェクトを開いたときにシェルが開いた状態になります
                                    開けたら Visual Studio Code を閉じます:
                                    Remote Explorer で開いたフォルダーを表示させます:
                                        (@host) VSCode >> Remote Explorer（左のアイコン）>> Reflesh ボタン（右上）
                                    次回からログインするときの操作:
                                        - (@host) タスクバーの VSCode を右クリック >> __Folder__ [SSH:__Server__]  #// または
                                        - (@host) VSCode >> File >> Open Recent >> __Folder__ [SSH:__Server__]  #// または
                                        - (@host) VSCode >> Remote Explorer ボタン（左）>> REMOTE EXPLORER= SSH Targets >> __Server__ >> __Folder__
                                    以上を @node1 についても行ます:
                            ansible_local がインストールされた VM から他の VM に SSH 接続できるようにします:
                                プロジェクト内に upload_SSH_keys.sh ファイルがある場合:
                                    プロジェクト内にある README をキーワード upload_SSH_keys.sh で検索してください。
                                    以後の操作は、README に従ってください。
                                プロジェクト内に upload_SSH_keys.sh ファイルがない場合:
                                    control にログインします >> ansible_local がインストールされた VM に SSH 接続します:  #search: Vagrant SSH  #template: __ControlNode__ に
                                        ~/.ssh/id_rsa ファイルを作ります:
                                            #bash
                                            code ~/.ssh/id_rsa
                                            #// 内容は、ホストOS の __Project__/.vagrant/machines/control/virtualbox/private_key の内容です
                                        ~/.ssh/id_rsa ファイルのパーミッションを設定します:
                                            #bash
                                            chmod 600 ~/.ssh/id_rsa
                                        /etc/hosts ファイルにサーバー名を登録します:
                                            sudo vi /etc/hosts : |
                                                :
                                                192.168.33.101  node1
                                            #template: __TargetNode__
                                    node1 にログインします（controlからSSH接続する VM）:  #search: Vagrant SSH  #template: __TargetNode__ にログインします（__ControlNode__から
                                        control サーバーの ~/.ssh/id_rsa ファイルに対応する公開鍵を調べます:
                                            #// ホストOS の秘密鍵 __Project__/.vagrant/machines/control/virtualbox/private_key と同じ鍵の公開鍵です
                                            #ホスト OS Git bash
                                            ssh-keygen -yf  __SecretKeyFilePath__
                                        ~/.ssh/authorized_keys ファイルに __CypherType__ __ClientPublicKey__ __ServerUserName__ を追加します:
                                            __SSH_KeygenOutput__ vagrant
                                    control から node1 に SSH で一度ログインしてサーバーとの接続を許可します:  #template: __ControlNode__ から __TargetNode__
                                        #bash
                                        - ssh vagrant@node1  #// IP アドレスは Vagrantfile に書いてあります  #template: @__TargetNode__
                                        - exit
                            すべての Visual Stuido Code を閉じます:
                            作成したすべての VM の電源を切ります:
                                VirtualBox マネージャー >> __ProjectFolderName___control____ などを選択して右クリック >>
                                    閉じる >> 電源オフ
                            必要なら Vagrant プロジェクトと VM のフォルダーをバックアップします:
                        VM の電源を入れます:  #// VM の電源を入れてホストOS と SSH 接続できるようにします
                            （必要なら）VM のバックアップから復帰させます:  #search: Vagrant VirtualBox restore
                            #// 現在の VM が電源オフの状態でも中断の状態（ホストOSをシャットダウンした後の状態）でも同じ手順です
                            ホストOS の Vagrant プロジェクトを開きます:
                                メニュー: タスクバーの VSCode を右クリック >> __Project__
                            vagrant を起動します:
                                bash: vagrant up
                                #// 起動が完了するとプロンプトに戻ります
                                #// 先に VirtualBox で VM を起動すると共有フォルダーが使えません
                                #// 共有フォルダーが必要なのは コントロール ノード だけです
                        control ノードの Ansible プロジェクトを開きます:  #template: __ControlNode__ ノード
                            （必要なら）VM のバックアップから復帰させます:  #search: Vagrant VirtualBox restore
                            メニュー: タスクバーの VSCode を右クリック >> vagrant [SSH:control]  #template: SSH:__ControlNode__
                            bash:
                                - export ANSIBLE_INVENTORY="/tmp/vagrant-ansible/inventory/vagrant_ansible_local_inventory"
                                - ansible-playbook  playbook.yml  --list-tasks
                                - ansible-playbook  playbook.yml  --diff -vv  #// プロビジョニングします
                                - ansible-playbook  playbook.yml  --diff -vvv --step  --limit "__HostName__"  --start-at-task "__TaskName__"
                                    #// １つのタスクだけ実行します
                        MySQL command shell:  #// ターゲット ノード が MySQL の場合
                            (@controler) $ mysql  --user "mysql_user" --password='Pass44##'  -h node1  #template: __TargetNode__
                    手動:  #// Ansible Playbook を Windows で実行します。CentOS と Apache をプロビジョニングします  #keyword: Ansible example Apache
                        Vagrant, VirtualBox を Windows にインストールして CentOS がインストールされた VM をプロビジョニングします:  #search: Vagrant Windows
                        vbguest プラグインをインストールします:  #// Ansible Local と Vagrant を接続するプラグインです
                            #bash
                            vagrant plugin install vagrant-vbguest
                        Ansible/Vagrant プロジェクトを新規作成します:
                            bash:
                                - mkdir -p  ~/vagrant/centos_apache  #// __Project__ とする
                                - cd        ~/vagrant/centos_apache
                            仮想マシンと OS をインストールする Vagrant の設定ファイルを作ります:
                                __Project__/Vagrantfile : |
                                    Vagrant.configure("2") do |config|
                                        if Vagrant.has_plugin?("vagrant-vbguest") then

                                            # Guest Additions の自動更新は無効
                                            config.vbguest.auto_update = false
                                        end

                                        # Vagrant の Box を指定します
                                        config.vm.box = "centos/7"

                                        # 共有フォルダーの設定（ホストOSとゲストOS間のファイル同期実施）  #keyword: config.vm.synced_folder,  Vagrant 共有フォルダー
                                        config.vm.synced_folder ".", "/vagrant",  create: true, owner: "vagrant", group: "vagrant", type:"virtualbox"
                                            #// "." がホストOS 側のフォルダー。Vagrant ファイルがあるフォルダーからの相対パスです
                                            #// "/vagrant" がゲストOS 側のフォルダー
                                            #// 起動時に更新されます。 #search: vagrant reload
                                            #// type が指定されるとリアルタイムで同期します

                                        config.vm.define "ansibletest" do |server|

                                            # 仮想マシンのホスト名とIPアドレス
                                            server.vm.hostname = "ansibletest"
                                            server.vm.network :private_network, ip: "192.168.33.20"

                                            # VirtualBox に表示される仮想マシン名
                                            server.vm.provider "virtualbox" do |vb|
                                                vb.name = config.vm.box.gsub(/\//, "_") + "_" + server.vm.hostname
                                            end

                                            # Ansibleを利用したプロビジョニング実施  #search: ansible_local
                                            server.vm.provision "ansible_local" do |ansible|
                                                ansible.playbook = "playbook.yml"
                                                ansible.compatibility_mode = '2.0'
                                            end
                                        end

                                        # proxy
                                        if Vagrant.has_plugin?("vagrant-proxyconf") && ENV['http_proxy'] && ENV['https_proxy']
                                            config.proxy.http     = ENV['http_proxy']
                                            config.proxy.https    = ENV['https_proxy']
                                            config.proxy.no_proxy = "localhost,127.0.0.1,control,node1"
                                        end
                                    end
                            Apache HTTP サーバーをインストールする Ansible Playbook の設定ファイルを作ります:
                                __Project__/playbook.yml :
                                    -   hosts: all
                                        become: true
                                        tasks:
                                            -   name: install httpd
                                                yum: name=httpd state=latest
                                            -   name: apache start / enable
                                                service: name=httpd state=started enabled=yes
                        仮想マシンを作って起動します（プロビジョニングします）:  #search: vagrant up
                            #bash
                            - cd  __Project__
                            - vagrant up  #// 初回は約 5分。内部で Ansible Local による Ansible Playbook も動きます
                            - vagrant status  #// 仮想マシンが動作していることを確認します
                        Apache が動作していることを確認します:
                            ブラウザーのアドレス バーに 192.168.33.20 と入力します。
                            IP アドレスは、Vagrantfile の中の server.vm.network に書かれています。
                        再度プロビジョニングします（Vagrant 経由で Ansible を使用）:
                            #bash
                            - cd  __Project__
                            - vagrant reload --provision
                                #// VM の再起動も発生しますが、Ansible Playbook ファイルや、copy モジュールのコピー元のファイルの更新も行われます
                            - vagrant provision  #// Ansible Playbook の更新は行われません
                        仮想マシンにログインしてプロビジョニングします（Ansible を直接使用）:  #keyword: Vagrant Ansible SSH
                            ログインします:  #search: Vagrant SSH
                            プロビジョニングします（ゲストOS 内）:
                                - cd /vagrant  #// ホストOSのプロジェクト フォルダーと共有するフォルダー。Vagrantfile の config.vm.synced_folder による
                                - export ANSIBLE_INVENTORY="/tmp/vagrant-ansible/inventory/vagrant_ansible_local_inventory"
                                    #// Vagrant の ansble_local を使うときの設定
                                - ansible-playbook  playbook.yml  --list-tasks  #// list tasks
                                - ansible-playbook  playbook.yml  --check  --diff  -vvv  #// dry run
                                - ansible-playbook  playbook.yml  #// deploy
                        終了します:  #see-above: Vagrant が管理している仮想マシンの電源をオフにします
                    CentOS7 の VM が 2台、そのうち 1台に Vagrant の ansible_local がインストールされた環境をプロビジョニングします:  #keyword: Ansible multi VM example
                        #search: install Ansible project
                        ただし、プロジェクトは  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/1_multi_vm_ansible
            Ubuntu20.04:  #keyword: install WSL2 Ansible
                WSL2 Ubuntu の VM を作ります:
                    #search: WSL2 restore
                    - wsl --unregister "Ubuntu-20.04-Ansible"  #// 2回目以降のみ
                    - wsl --import  "Ubuntu-20.04-Ansible" `
                        "${HOME}\WSL_VMs\Ubuntu-20.04-Ansible" `
                        "${HOME}\WSL_back_up\Ubuntu-20.04-1.tar"
                    - wsl -d Ubuntu-20.04-Ansible  #search: WSL2 command
                Ubuntu に Ansible をインストールします:
                    Ubuntu bash:
                        - sudo http_proxy=${http_proxy} https_proxy=${https_proxy} add-apt-repository -y  ppa:ansible/ansible
                        - sudo apt update
                        - sudo apt install -y  ansible
                        - ansible --version
                        - hostname -I  #search: WSL2 IP address
                            #// 以下はここで 172.21.129.76 と表示された場合  #template: __WSL2_IPAddress__
                        - sudo nano  /etc/ansible/hosts : |
                            [servers]
                            ubuntu20_04_Ansible ansible_host=172.21.129.76

                            [all:vars]
                            ansible_python_interpreter=/usr/bin/python3
                        - ansible-inventory --list --yaml
                        #template-at(-5): __WSL2_VM_Name__ ansible_host=__WSL2_IPAddress__
                SSH でアクセスできるようにします:
                    SSH サービス を起動します:
                        Ubuntu bash:
                            sudo service ssh restart
                    Windows の SSH クライアント からアクセスできるようにします:
                        Ubuntu bash:
                            mkdir -p ~/.ssh  #// 次の Windows での作業に必要です
                        Windows Git bash:
                            - echo  ${USERPROFILE}
                                #// /c/Users/m-toda と表示されたとします  #template: Users/__UserName__
                            - cd  ${USERPROFILE}/vagrant/single_vm_ansible/centos7  #template: __Project__
                            - #search: WSL2 SSH client set up   #// .wsl/ubuntu20_04_Ansible が作られます  #template: __WSL2_VM_Name__
                                ただし、__Project__ = c/Users/m-toda/vagrant/single_vm_ansible/centos7  #template: c/Users/__UserName__/__Project__
                    Linux の SSH クライアント からアクセスできるようにします:
                        Ubuntu bash:
                            cp  /mnt/c/Users/m-toda/vagrant/single_vm_ansible/centos7/.wsl/ubuntu20_04_Ansible/id_rsa  ~/.ssh/id_rsa
                            chmod 600  ~/.ssh/id_rsa
                            ssh  -o 'StrictHostKeyChecking no'  user1@172.21.129.76
                            exit
                        #template-at(-2): @__WSL2_IPAddress__
                        #template-at(-5): .wsl/__WSL2_VM_Name__/
                        #template-at(-6): Users/__UserName__/__Project__
                Ansible を実行します:
                    ホスト名を編集します:
                        playbook または 変数の値: |
                                hosts: ubuntu20_04_Ansible
                            #template: __WSL2_VM_Name__
                    Windows Git bash の場合:
                        ./run_playbook.sh  playbook-0.yml
                    Linux bash の場合:
                        - cd  /mnt/c/Users/m-toda/vagrant/single_vm_ansible/centos7  #template: Users/__UserName__/__Project__
                        - ansible-playbook  playbook-0.yml  --diff -v
                #ref: https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-ansible-on-ubuntu-20-04
                設定: #settings:
                    __UserName__: m-toda
                    __Project__: vagrant/single_vm_ansible/centos7
                    __WSL2_IPAddress__: 172.21.129.76
                    __WSL2_VM_Name__: ubuntu20_04_Ansible  #original: ubuntu20_04_2351
            クリーンな VM に戻します:  #search: vagrant clean VM  #keyword: Ansible clean VM
            内部で使っている Python:  #search: Ansible Python
        実験環境 >> ローカルのインベントリー: #keyword: Ansible local inventory
            概要: |  #// 実際のサーバーにアクセスする前にローカルの VM で動作確認をします。
                次の構成要素をローカル用に新規作成します。
                - インベントリ ファイル  #search: Ansible inventory file
                - group vars  #search: Ansible group_vars
            関連:
                #search: --connection=local  ansible-playbook  #// SSH 接続しません
        構成の設計: #keyword: Ansible 設計
            早く動作確認します:  #search: Ansible fast development
            実験環境 >> ローカルのインベントリー:  #search: Ansible local inventory
            Web サービス: Web サービスを import する playbook に書きます。API サーバーごと  #search: ansible import_playbook
            使うソフトウェア:  ロールに書きます。 nginx, MySQL, PHP など。ロールに書かなくても構いません
                ロールのタスクの一覧(tasks)は、シェル コマンドの実行順序に相当します
                #search: ansible role
            設定ファイルの構成:  #search: Ansible files
            設定後の再起動:  #search: Ansible role handlers
            Linux サービスの設定: ロールに書きます。 firewalld など。ロールに書かなくても構いません
            冪等性:  #// idempotent（アイデムポーテント）  #keyword: Ansible 冪等性
                概要:
                    再実行してもエラーにならず同じ状態になること
                開発を早くするには: 冪等性の確保は、典型的な動作ができたことを確認した後で行います  #search: Ansible fast development
                インストール タスク:  #// インストールするタスクの場合
                    - インストールされていないときだけインストールするコマンドが内部で実行されます。
                        インストール済みのときはインストールするコマンドを実行しません。
                    - Ansible のタスクを削除しても、サーバーからアンインストールされるわけではありません
                        absent state にするタスクを実行するとアンインストールします  #search: Ansible yum state
                コマンド タスク:  #// コマンドを実行するタスクの場合
                    - 冪等性があるようにコマンドやスクリプトを作らなければなりません
                再起動 タスク: #keyword: Ansible restart task  #// サービスを再起動するタスクの場合
                    - インストール時に再起動が必要なために再起動するタスクの場合、
                        サブ プロセス などが終了してしまわないように、冪等性があるように条件を設定しなければなりません
                        #search: register Ansible changed
                    - インストールや設定変更などのタスクのうち、1つでも変更があったら再起動が必要になる場合、
                        そのすべてのタスクの実行結果を、条件判定で使われるようにします
                        #search: register Ansible changed
                    - 初めてインストールするときにしかコマンドが実行されないタスクは、
                        その中の代表的な１つのタスクだけ register します
                    - スクリプトを使ったほうがシンプルかもしれません
            ホストの分類:  #keyword: Ansible host classification  #// グループ化
                名前指定 >> ホスト グループ:  #search: Ansible inventory format
                パターン指定 >> constructed:  #search: constructed
                切り替え >> インベントリー ファイル, フォルダー:  DEV, STG, PRD, DEV-2 など。1つ選ぶことや全部選ぶことができます
                    #search: Ansible inventory path
        開発 >> 早く動作確認します: #// 方針  #keyword: Ansible fast development
            方針:
                - 冪等性を持たせる必要はありません。その代わり、VM をある地点まで戻せるようにバックアップします
                - 手動で動作確認するサンプルと同様のコマンド copy, shell モジュールを使います
                - template も後で作ります
            手段:
                Git で管理するようにします:
                    MyPrivateCode の場合:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible
                    ローカル リポジトリの場合: #search: Git local
                ルートの Playbook.yml にタスクを書きます:  #search: ansible playbook  #search: ansible modules catalog
                    shell モジュールを使うように書きます:  #search: Ansible shell
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: ____
                                shell: somecommand parameters
                    複数のサーバーに同じタスクを実行するとき:
                        hosts に列挙し inventory_hostname 変数を使います  #search: Ansible hosts
                ステップ実行します: ansible-playbook の --step オプション
                VM のバックアップを適宜取ります:
            動作確認後:
                - 動作確認ができたら、Git のコミットに Git のタグをつけます
                - タスクに copy, shell モジュールを使わないようにして冪等性を持たせます  #search: ansible modules catalog
                - 変数の値は動作確認するまで動作確認できた値のままにしておきます
            よりよくする:
                - 変数の値をリファクタリングして動作確認します
        既存の Ansible を解析する:
            Ansible のバージョンを確認します:
                $ ansible --version
                ansible 2.7.10
                    config file = /var/lib/jenkins/work/ansible.cfg
                    configured module search path = [u'/var/lib/jenkins/plugins/library']
                    ansible python module location = /var/lib/jenkins/local/python_env/lib/python2.7/site-packages/ansible
                    executable location = /var/lib/jenkins/local/python_env/bin/ansible
                    python version = 2.7.15 (default, Dec 11 2018, 15:07:33) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)]
            デフォルトから変更があったコンフィグを確認します:  #search: ansible.cfg
                $ ansible-config dump --only-changed
                ANSIBLE_NOCOWS(____/ansible.cfg) = True
                ANSIBLE_PIPELINING(____/ansible.cfg) = True
                ANSIBLE_SSH_ARGS(____/ansible.cfg) = -o ControlMaster=auto -o ControlPersist=900s
                CACHE_PLUGIN(____/ansible.cfg) = jsonfile
                CACHE_PLUGIN_CONNECTION(____/ansible.cfg) = ./facts_cache
                CACHE_PLUGIN_TIMEOUT(____/ansible.cfg) = 600
                DEFAULT_ACTION_PLUGIN_PATH(____/ansible.cfg) = [u'____/plugins/action']
                DEFAULT_CALLBACK_PLUGIN_PATH(____/ansible.cfg) = [u'____/plugins/callback']
                DEFAULT_FILTER_PLUGIN_PATH(____/ansible.cfg) = [u'____/plugins/filter']
                DEFAULT_FORKS(____/ansible.cfg) = 5
                DEFAULT_GATHERING(____/ansible.cfg) = smart
                DEFAULT_LOOKUP_PLUGIN_PATH(____/ansible.cfg) = [u'____/plugins/lookup']
                DEFAULT_MODULE_PATH(____/ansible.cfg) = [u'____/plugins/library']
                DEFAULT_REMOTE_USER(____/ansible.cfg) = jenkins
                DEFAULT_ROLES_PATH(____/ansible.cfg) = [u'____/roles']
                DEFAULT_STDOUT_CALLBACK(____/ansible.cfg) = custom
                DEFAULT_VARS_PLUGIN_PATH(____/ansible.cfg) = [u'____/plugins/vars']
                HOST_KEY_CHECKING(____/ansible.cfg) = False
                INVENTORY_ENABLED(____/ansible.cfg) = [u'host_list', u'script', u'yaml', u'ini', u'constructed']
                RETRY_FILES_ENABLED(____/ansible.cfg) = False
        tar.gz を展開してインストールするサンプル:  #keyword: Ansible tar example
            推奨 >> unarchive:  #search: ansible unarchive
            #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_kafka/playbook.yml
            サンプル:
                -   name:  install Kafka
                    become: yes
                    shell:
                        chdir: /opt
                        cmd: tar -xzf kafka_{{ ScalaKafkaVersion }}.tgz
        ターゲット ホスト のヘルスチェック:  #search: 
        上書きチェック:  #search: Ansible APPROVED  #// Ansible が上書きするファイルの内容を目視で確認させてからデプロイします
        その他の公式サンプル: #ref: https://github.com/ansible/ansible-examples
    コマンド（シェル）:  #keyword: ansible command
        バージョンの確認方法:  #keyword: Ansible version,  Ansible Python  #// 以下のいずれか
            Ansible-core と Python と Jinja2:
                コマンド:
                    - ansible --version
                    - ansible-playbook  --version
                    #// ansible コマンドが使えないときは #search: Ansible が使う Python 仮想環境をアクティベートしてください
                表示内容:
                    $ ansible --version
                    ansible [core 2.16.2]
                        config file = /home/user1/ansible-project/ansible.cfg
                        configured module search path = ['/home/user1/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
                        ansible python module location = /home/user1/bin/ansible-venv/lib/python3.11/site-packages/ansible
                        ansible collection location = /home/user1/.ansible/collections:/usr/share/ansible/collections
                        executable location = /home/user1/bin/ansible-venv/bin/ansible
                        python version = 3.11.7 (main, Jan 19 2024, 13:54:29) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)] (/home/user1/bin/ansible-venv/bin/python3.11)
                        jinja version = 3.1.3
                        libyaml = True
            Ansible Community Package:
                - pip show ansible
            最新バージョン:
                Ansible-core:  #// 最小限のモジュールとプラグイン
                    #ref: https://github.com/ansible/ansible/releases
                    2.16 リリース:
                        #ref: https://docs.ansible.com/ansible-core/devel/roadmap/ROADMAP_2_16.html
                Ansible Community Package:  #// Ansible-core + 厳選された幅広いコミュニティ コレクション
                    9.0 リリース:
                        #ref: https://docs.ansible.com/ansible/latest/roadmap/COLLECTIONS_9.html
                        #ref: https://groups.google.com/g/ansible-devel/c/TSCXj6hEPow
            パス:  #search: Ansible Python path
        ansible コマンド:  #// playbook.yml を使わずにタスクを実行します
            公式: #ref: https://docs.ansible.com/ansible/2.9_ja/cli/ansible.html  #template: __DocumentVersion__
            疎通確認: #keyword: ansible ping  #// ping
                内容: Ansible が ターゲット ホスト と接続できるかどうかを確認します。 ICMP ping ではなく、SSH の接続と Python の動作確認を行います
                コマンド:
                    _: ansible  __HostNameOrIpAddress__  -i __HostNameOrIpAddress__,  -m ping
                    -i オプション:  #// インベントリ
                        - 末尾にコンマがあると、インライン インベントリ（ホスト名 または IP アドレス）を指定したことになります
                        - 末尾にコンマがないと、インベントリ ファイル を指定したことになります
                        - ansible の第1引数と -i オプション の値は、同じにしてください。
                            -i オプションで Ansible の管理対象であると設定してから、第1引数 のホストにアクセスします。
                            -i オプションを指定しないと、管理対象外であるエラーになります
            サンプル:
                debug 表示:  #// debug モジュールのタスクを実行して、node1 ホストが参照できるすべての変数を表示します:
                    サンプル: ansible  node1  -m debug  -a 'var=vars'  #search: ansible debug
                    書式:
                        - ansible __HostName__  -m __ModuleName__  -a __Parameters__  #// インベントリーは環境変数に指定  #search: ANSIBLE_INVENTORY
                        - ansible __HostName__  -m __ModuleName__  -a __Parameters__  -i __InventoryFile__  #search: Ansible inventory path
        ansible-playbook コマンド:  #// プロビジョニングします  #keyword: ansible-playbook
            公式: #ref: https://docs.ansible.com/ansible/2.9_ja/cli/ansible-playbook.html  #template: __DocumentVersion__
            コマンド, 書式:
                基本的な書式: #keyword: first ansible-playbook command
                    - ansible-playbook  __PlayBook__.yml  -i __InventoryFile__  __Options__
                    - ansible-playbook  -i __InventoryFile__  playbook.yml --diff -vvv
                Vagrant の ansible 環境での ansible-playbook コマンドを実行します:  #search: Vagrant Ansible SSH
                -i オプションを省略できるようにするとき:  #keyword: ANSIBLE_INVENTORY
                    export ANSIBLE_INVENTORY="__InventoryFile__"
                    ansible-playbook  __PlayBook__.yml  __Options__
            コマンド, オプション: #glossary: ansible-playbook  #keyword: ansible-playbook options
                --check:  #search: Ansible --check
                --connection=local:  #search: ansible-playbook --connection=local
                --diff:  #search: Ansible --diff
                -e, --extra-vars:  #search: Ansible --extra-vars
                -f:  #// 並列処理レベル
                    - ansible-playbook  playbook.yml -f 10  #// 並列処理レベル 10 で Playbook ファイル playbook.yml を実行します
                        #search: Playbook ファイル
                -i:  #// インベントリ ファイル の場所を指定します  #search: Ansible inventory file
                --flush-cache: #keyword: flush Ansible cache  #// リモートのファイルの構成などをスキャンします  #search: Gathering Facts
                    --flush-cache オプションは、sudo yum clean all コマンドに相当する処理をするらしい。
                --limit:  #search: Ansible --limit  #// 指定したホストまたはホストグループだけ実行します
                --list-hosts:  #search: Ansible --list-hosts
                --list-tags:  #search: Ansible --list-tags
                --list-tasks:  #search: Ansible --list-tasks
                --start-at-task:  #search: Ansible --start-at-task
                --step:  #search: Ansible --step
                --syntax-check:  #search: Ansible --syntax-check
                --tag:  #search: Ansible --tag
                -v, -vv, -vvv, --verbose: #search:
            手順:
                ローカルで実行する場合: Vagrant を使うとよいでしょう  #search: Vagrant Ansible SSH
                標準出力の内容:  #keyword: Ansible stdout,  Ansible output  #// すべてのタスクが変更を検出したかどうかを確認できます
                    関連:
                        変数の値の表示:  #search: Ansible vars print
                        標準出力を変数に:  #search: Ansible register
                    Ansible の標準出力:  #// デフォルトではタスクの標準出力は非表示なようです
                        サンプル: |
                            TASK [system-yum-repo : clean metadata] *****
                            changed: [server1]] => {"changed": true, "dest": 
                        関連 >> タスクの標準出力:  #search: Ansible task stdout
                        --verbose オプション, -v オプション:
                            - ansible-playbook  playbook.yml --verbose --check
                                #// プロビジョニングする内容の表示を詳しくします
                    エラーを発生させる:  #// Ansible が呼び出すコマンドの標準出力
                        Ansible 側でエラーを発生させれば stdout や stderr の内容が表示されます
                    タスクの標準出力:  #keyword: Ansible task stdout
                        -v オプションを追加します:  #// エラー時の JSON の中に、改行文字が \n で表示されます
                            ansible-playbook  playbook.yml  -v
                            #// エラーが発生したときの "stdout": や "stderr": の右にあります。改行文字が \n で表示されます
                            #// -v だけで十分ですが -vv などどの比較は  #search: Ansible -vvv オプション
                        また、エラーを発生させます: |
                            failed_when: true
                            ignore_errors: true
                        止まる場合: #keyword: Ansible フリーズ
                            timeout を使う場合:  #// 内部で入力待ちしている可能性があります
                                timeout コマンドを shell フィールド の中に指定します。
                                timeout 10 __Command__
                            exit を使う場合:
                                呼び出すスクリプトの中で echo "@@@"; exit 1 を実行します
                            VirtualBox の場合:
                                VM を再起動します
                        ネットワークエラーになる場合:
                            https_proxy や no_proxy 環境変数を表示させて確認してください。
                            全環境変数を表示してもよいでしょう  #search: printenv
                        register:  #search: Ansible register
                            -   __TaskName__:
                                register: output
                            -   debug: 'msg="${{ output }}"'
                    ファイルの内容を非表示にします:  #keyword: Ansible no_log,  Ansible secret password
                        tasks:
                            -   name: copy to __PathInServer__
                                copy:
                                    _____
                                no_log: true
                        #ref: https://docs.ansible.com/ansible/latest/reference_appendices/faq.html#keep-secret-data
                        関連: Ansible Vault 
                    色を付けて標準出力の内容内容を保存します:  #keyword: ansible-playbook color
                        bash: ANSIBLE_FORCE_COLOR=true  ansible-playbook  __Parameters__ | tee __LogFileName__
                        参考: https://docs.ansible.com/ansible/latest/reference_appendices/config.html#ansible-force-color
                        関連:
                            色情報付きのテキストをコピペします: #search: copy colored text
                    色情報が入ったテキストを扱います:  #search: echo color
                    大量の標準出力を扱います:
                        VSCode の Terminal の最大行数を長くします  #search: VSCode terminal
                    対象の Playbook ファイルを探します:
                        #// ansible-playbook コマンドの標準出力にロール名とタスク名が書かれているので、それらを grep します
                        標準出力のサンプル: |
                            TASK [system-yum-repo : clean metadata] *****
                            #template) TASK [__RoleName__ : __TaskName__] *****
                        Playbook ファイルのサンプル:
                            roles/__RoleName__/tasks/*.yml : |  #// roles フォルダーは #search: ansible roles
                                name: __TaskName__
                チェック、デバッグ:  #glossary: Ansible
                    --syntax-check オプション:  #// 文法チェックだけ早く行います
                    --list-tasks:
                        サンプル:
                            コマンド:
                                ansible-playbook  __PlayBook__.yml  -i __InventoryFile__  --list-tasks  --list-hosts
                            出力: |  #search: Ansible example Apache
                                playbook: playbook.yml
                                    play #1 (all): all    TAGS: []
                                        hosts: (2)
                                            server1
                                            server2
                                        tasks:
                                            install httpd     TAGS: []
                                            apache start / enable     TAGS: []
                                            copy index.html   TAGS: []
                        タグを指定して実行するときのタスクの一覧:
                            ansible-playbook  playbook.yml  --list-tasks  --tag __TaskName__
                        １つのホストのタスク一覧: （不明。右記になし） https://docs.ansible.com/ansible/2.9_ja/cli/ansible-playbook.html  #template: __DocumentVersion__
                    --list-hosts: #// ホストを表示します
                        サンプルA:
                            ansible all  -i __InventoryFile_  --list-hosts
                        サンプルB:
                            #search: Ansible --list-tasks
                        ホスト名をパターンで指定した場合、展開されます:
                    --list-tags:
                        サンプル:
                            コマンド:
                                ansible-playbook  __PlayBook__.yml  -i __InventoryFile__  --list-tags
                            出力: |  #focus: TAGS
                                playbook: playbook.yml
                                    play #1 (all): guard    TAGS: []
                                        TASK TAGS: []
                                    play #2 (all): main    TAGS: [main]   #// play 付いたタグを実行すると、play の中のすべてのタスクを実行します
                                        TASK TAGS: [main]
                    --check オプション:  #// dry run
                        - ansible-playbook  -i __InventoryFile__  playbook.yml --diff -vvv --check
                            #// dry run. 実際にプロビジョニングしないで実行します  #keyword: ansible check, ansible dry run
                            #// 変更があったかどうかの結果はログに出力しますが、プロビジョニングはしません
                            #// 参考  #search: 設定ファイルの監視
                    --diff オプション:  #// --check オプションと一緒に指定すると、詳細が表示されます
                        #// テンプレートによってリモートファイルにどのような変更が行われるかも事前に確認できるようになります
                        --diff オプションなしの出力例: |
                            TASK [__Role__ : __Task__] ************************************
                            ok: [server.net]

                            TASK [__Role__ : __Task__] ************************************
                            changed: [server.net]
                        --diff オプションありの出力例: |
                            TASK [__Role__ : __Task__] ************************************
                            ok: [server.net]

                            TASK [__Role__ : __Task__] ************************************
                            changed: [server.net]
                            --- before: /etc/example.conf
                            +++ after: /var/lib/jenkins/.ansible/tmp/ansible-local-3532rK62j6/tmpQfZr6X/example.conf.j2
                            @@ -11,7 +11,6 @@
                            -    path /var/service/*.log
                            +    path /etc/service/*.log
                        差分表示が長すぎるとき: |  #keyword: disable Ansible diff
                            ansible-playbook の --diff オプションを指定したときに差分表示が多すぎて終わらないときは、
                            そのタスクの diff フィールドを false または no にします。
                            -   __Module__: ...
                                diff: false
                    -vvv オプション, -v オプション:  #// ゲストOSとの接続コマンドの詳細が表示されます
                        #// dry run のときもプロジェクションするときも使えます
                        #// -vvv オプションのほうが詳細です
                        出力の有無: |
                            >              -v なし   -v   -vv    -vvv
                            --------------------------------------------------
                            config           なし   簡易   中     詳細
                            比較要素JSON              v     v
                            比較要素JSON 整形済み                   v
                            SSH コマンド                           v
                        特定のタスクだけ詳細表示:
                            できません  #ref: https://www.reddit.com/r/ansible/comments/nq382v/how_to_display_verbose_only_for_a_particular_task/?rdt=37635
                        関連:
                            タスクの標準出力:  #search: Ansible task stdout
                    上書きチェック:  #search: Ansible APPROVED  #// Ansible が上書きするファイルの内容を目視で確認させてからデプロイします
                実行します（インストールします）:  #search: first ansible-playbook command
                一部を実行します: #keyword: next ansible-playbook command
                    １つのタスクだけ実行します:
                        手段A: --step と --start-at-task を指定し、対象のタスクを実行し（y と答えて）、
                            次のタスクの開始前でブレークしたら、Ctrl-C で終了させます。
                        手段B: 一時的なタグを追加して --tag オプションを付けて実行します
                        参考: https://stackoverflow.com/questions/23945201/how-to-run-only-one-task-in-ansible-playbook
                    指定したタスクから再開します:  #search: Ansible --start-at-task
                    指定したタスクまで: | #keyword: Ansible stop  #search: ansible failed_when   #// 指定したタスクを実行したらエラー停止させます
                        #snip:
                            -   name: temporary exit
                                debug: msg="temporary exit"
                                failed_when: true
                    複数のタスクを実行します:  #search: ansible tags
                        一時的なタグを追加して --tag オプションを付けて実行します
                    --limit オプション: #keyword: ansible-playbook --limit  #// 指定したホストまたはホストグループだけ実行します
                        --limit  "__ServerNameCSV__"
                    --start-at-task オプション: #keyword: Ansible --start-at-task  #// 指定したタスクとそれ以降のタスクを実行します
                        実行する前:
                            タスク名が重複していないかチェックします:
                                ansible-playbook  __Playbook__.yml --list-tasks | grep "__TaskName__"
                        コマンド: ansible-playbook  __Playbook__.yml --start-at-task  "__TaskName__"
                            #// エラーが発生したタスク名は、ログの下記のフォーマットから知ることができます
                            #//    TASK [__TaskName__] *************************************
                            #// または
                            #//    TASK [__RoleName__ : __TaskName__] *************************************
                            #// ロール名の指定は不要です
                        参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_startnstep.html  #template: __DocumentVersion__
                    --step オプション:  #keyword: Ansible --step  #// 対話形式で実行します  #search: Ansible --start-at-task,  Ansible  -vvv
                        _: |
                            Perform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue:
                            c(continue)を選ぶと、tasks の最後まで実行します
                        指定したタスクを実行した後で停止させる:
                            できません。AI で確認 2024-08-28
                    --tag オプション:  #// 指定したタグが付いたタスクのみ実行します  #keyword: ansible tags, ansible タグ
                        #// Playbook に定義されたタグとコマンドに指定したタグと一致するタスクのみ実行します。他のタスクは実行しません。
                        #// --tag オプションも --tags オプションも指定しない場合、すべてのタグのタスクを実行します。
                        参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_tags.html  #template: __DocumentVersion__
                        コマンドの書式:  #ref: https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html#selecting-or-skipping-tags-when-you-run-a-playbook
                            実行するタスクを表示します:
                                - ansible-playbook  playbook.yml  --list-tasks  --list-hosts  --tag try
                                    #// tasks には実行されるタスクだけ表示されます
                                    #// 表示される TAGS: [ ] の中は、そのタグを指定したときに実行されるタスクであることを表しています
                                    #// --tag オプションを付けなかったときの表示から、タグ名で検索すると実行されるタスクが分かります
                            指定したタグが付いたプレイやタスクを実行します:
                                - ansible-playbook  playbook.yml  --tag try
                                - ansible-playbook  playbook.yml  --tags "try, debug"
                                - ansible-playbook  playbook.yml  --skip-tags "try, debug"
                        プレイやタスクにタグを付けます:
                            サンプル プレイ tags:
                                Playbook.yml:
                                    -   name: Start NFS server
                                        tags: [start-nfs]
                                            #// ここに設定すると、role の中のすべてのタスクに設定したことと同じになります
                                        roles: [nfs-server]
                                        hosts: elasticsearch_main
                            サンプル タスク tags:
                                Playbook.yml:
                                    tasks:
                                        -   debug: msg=”{{ showmevar }}”
                                            tags:
                                                -   try
                                                -   reboot
                                                -   set_up
                                                #// 一時的な場合、[try, reboot] より上記のように並べたほうが切り貼りしやすいです
                                                #// try または reboot または set_up が指定されたときに実行します
                            block の中に tags を書くサンプル:
                                Playbook.yml:
                                    tasks:
                                        -   name: block task
                                            block:
                                                -   name: temporary try
                                                    debug: msg=”{{ showmevar }}”
                                                    tags:
                                                        -   try
                        タグの定義:  #// tags: [__TagName__]
                            Playbook.yml のサンプル:  #// Playbook に書くときは tags、コマンドのオプションは tag または tags
                                role なしの場合:
                                    tasks:
                                        -   name: exec uptime
                                            tags: [uptime]               #// tag. これは YAML のフロースタイルで書かれています
                                            command: /usr/bin/uptime
                                            register: result
                                        -   name: exec uptime debug
                                            tags: [uptime, debug]  #// uptime または debug がコマンドの tag オプションに指定されたら実行されます
                                            debug: var=result
                                        -   name: exec uptime debug 2
                                            debug: msg="debug message"
                                role ありの場合: #focus: uptime_tag,  debug_tag
                                    #// Playbook.yml tags が role の tags にも適用されます
                                    Playbook.yml:
                                        -   name: tags in role
                                            tags: [uptime_tag]
                                            roles: [role1]
                                    roles/role1/tasks/main.yml:
                                        -   name: exec uptime  #// Playbook.yml により tags: [uptime_tag] と同じ動きになります
                                            command: /usr/bin/uptime
                                            register: result
                                        -   name: exec uptime debug
                                            tags: [debug_tag]  #// Playbook.yml により [uptime_tag, debug_tag] と同じ動きになります
                                            debug: var=result
                            既存のタグの一覧:  #see-above: --list-tags
                        定義済みのタグ（特別なタグ）:
                            always:
                            never:  #keyword: Ansible tags never
                                関連） when false との違い  #search: Ansible when false vs tags never
                            参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_tags.html#special-tags  #template: __DocumentVersion__
                        実行例 >> 上記サンプル: |  #// ansible-playbook  ____.yml  --tag __TagName__
                            $ ansible-playbook  playbook.yml --tag uptime   #// --check オプションを付けても動きますが表示内容は変わります
                            
                            PLAY [all] ************************************************************************************************************************************************************
                            （中略）
                            TASK [Gathering Facts] ************************************************************************************************************************************************
                            ok: [ansibletest]
                            （中略）
                            TASK [exec uptime] ****************************************************************************************************************************************************
                            changed: [ansibletest]
                            （中略）
                            TASK [exec uptime debug] **********************************************************************************************************************************************
                            ok: [ansibletest] => {
                            （中略）
                            PLAY RECAP ************************************************************************************************************************************************************
                            ansibletest                : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
                        タグの継承:
                            - hosts と同じインデントの深さに tags を指定すると、同じ深さの tasks にある全てのタスクに
                                タグが適用されます
                            - サンプル:
                                -   hosts: all
                                    tags: [ bar ]
                                    tasks:
                                        ...  #// ここにあるタスクはすべてタグが継承されます（設定されます）
                            - サンプル:
                                roles:
                                -   role: webserver
                                    tags: [ web, foo ]
                            - サンプル:
                                -   import_role:
                                    tags: [ web, foo ]
                            - サンプル:
                                -   import_tasks: foo.yml
                                    tags: [ web, foo ]
                            - https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_tags.html#tag-inheritance  #template: __DocumentVersion__
                    when:  #// 指定した条件によってタスクを実行またはスキップします。条件分岐します  #search: Ansible when
                    指定したロールのみ実行します:
                        同じタスク名があるときに、どちらのタスクから起動するかを指定します:
                            - --role オプションはありません #ref: https://www.google.com/search?q=ansible+playbook+role+execute
                            - 一時的に name を変更し、その name を --start-at-task オプションに指定します。
                        Playbook.yml に import_role するタグ付きタスクを一時的に作ります:
                            -   hosts: __Server1__, __Server2__
                                tasks:
                                    -   name: execute role temporary task
                                        import_role:
                                            name: __RoleName__
                                        tags: [role_execute]
                        実行例:  #// --tag role_execute
                            #bash
                            ansible-playbook  ____.yml  --diff  -v  --tag role_execute
                タスクの開始時刻と処理時間を表示します: #search: profile_tasks
                権限昇格:  #keyword: ansible-playbook become option
                    root ユーザー経由で admin ユーザーにログインする場合:  #// user1 → root → admin
                        -b: 権限昇格します。 become yes を Playbook.yml に指定した場合と同じ動作です
                        -u admin : Playbook.yml を実行するときのユーザー
                        --become-user root : 経由するユーザー
                        --become-method su : become-user にログインするときに、su コマンドを使います
                        --key-file ____.id_rsa :  become-user ユーザーの秘密鍵を指定します
                        -K : 実行中に become-user ユーザーのログイン パスワードを入力できるようにするとき
                    Playbook ファイルに設定する場合: #search: ansible become
                上書きチェック: #keyword: Ansible APPROVED,  Ansible preview  #// Ansible が上書きするファイルの内容を目視で確認させてからデプロイします
                    コード: #keyword: ansible_approved
                        #focus: ansible_approved,  preview
                        group_vars: |  #search: Ansible group_vars YAML  #// 環境変数の値を変数に代入します
                            ansible_approved: "{{ lookup('env', 'APPROVED') | default('0') }}"
                        ヘルプ表示タスク: |  #// 以下のような内容を最初のタスクとして書きます
                            tasks:
                                -   name: __Service__ service deploy guide
                                    assert:
                                        that: ansible_approved == '1'
                                        fail_msg: |
                                            ==========================================
                                            まず以下のコマンドで差分を確認してください:
                                                ansible-playbook  __Parameters__  --diff --tags preview --check
                                            確認後、以下でデプロイを実行してください:
                                                APPROVED=1 ansible-playbook  __Parameters__
                                            ==========================================
                            #// APPROVED 環境変数が 1 などに設定されていなければ（ansible_approved 変数が 1 に設定されていなければ）
                            #// 警告を表示して ansible の実行が終了します
                        ファイルを上書きするタスク:  #// タスクの tags フィールドに preview を追加します
                            -   name: Upload __Service__ config
                                template:
                                    src: app.conf.j2
                                    dest: /etc/app.conf
                                tags: [preview]
                            #// --tags preview オプション を指定すると、上記のように tags の設定があるタスクだけ実行します。
                            #// --tags オプション を指定しなかったときでも、tags の設定があるタスクを実行します。
                            #// --check オプション を指定するとファイルを上書きしません
                            #// --diff オプション を指定すると差分が表示されます
                    コマンド:  #// 通常、以下の順番で実行します
                        （必要なら）ヘルプ表示します:  #// 通常のコマンドを実行するとヘルプ表示だけになります
                            ansible-playbook  __Parameters__  #// --diff の有無は問いません
                        変更内容を確認します:  #// --diff --tags preview --check オプション を指定します
                            ansible-playbook  __Parameters__  --diff --tags preview --check
                        期待した変更内容になるまで ソース ファイル を修正します:
                            vi __FilePath__
                        デプロイします:  #// APPROVED 環境変数を 1 に指定して実行します
                            APPROVED=1 ansible-playbook  __Parameters__  --diff
        ansible-pull コマンド:  #// git から設定手順のリポジトリーをチェックアウトしてプロビジョニングします
            https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_intro.html#ansible-pull  #template: __DocumentVersion__
        ansible-lint コマンド:  #// スタイル チェック
            https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_intro.html#linting-playbooks  #template: __DocumentVersion__
        ansible-doc コマンド:
            コールバックの一覧: ansible-doc -t callback -l
            ansible.builtin.default コールバックのドキュメント: ansible-doc -t callback ansible.builtin.default
    構成:
        ホスト:  #keyword: ansible inventory file  #// インベントリー ファイル,  inventry ではない
            概要: プロビジョニングの対象となるマシーン（ホスト）を control ノード の インベントリー ファイル に書きます。
                ここで定義したホスト名は Playbook ファイル の hosts に指定できます  #search: ansible hosts
            参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/intro_inventory.html  #template: __DocumentVersion__
            インベントリー: #keyword: Ansible inventory
                インベントリー名: #keyword: Ansible inventory name
                    -   インベントリー ファイル の名前で表現されます。グループ名とは違います。
                        #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: inventory name
                    -   ファイル名からインベントリーの種類を判定するのではなく、group_vars に設定します。
                        #search: Ansible group_vars
                定義 >> ベスト プラクティス:
                    - 実際のサーバー名を hosts ファイルに、ホスト グループ のパターン定義を inventory.config ファイルに分けるとよいでしょう
                    - inventory.config ファイルはシンボリックリンクを使い、DEV/STG/PRDで共通の内容にするとよいでしょう
                        #// インベントリー ファイル の中に include のようなものを書くことはできません
                    - インベントリー ファイル には Control ノードの接続先の観点でホストを分類します。
                        設定ファイルに書くグループの観点でホストを分類するときは inventory.config ファイルや、ホスト変数に書きます  #// 未確認
                場所: #keyword: Ansible inventory path  #// hosts ファイル または inventory.config ファイル の場所
                    ansible-playbook コマンドに -i オプションがないとき:
                        ANSIBLE_INVENTORY 環境変数が定義されているとき: その変数の値
                        ANSIBLE_INVENTORY 環境変数が定義されていないとき: /etc/ansible/hosts
                    ansible-playbook コマンドに -i オプションがあるとき: __iOptionValue__/hosts
                    -i オプション（インベントリー ファイル）は複数指定できます:
                    ansible_local を使うとき:  #search: vagrant_ansible_local_inventory
                hosts ファイル: #keyword: Ansible hosts file  #// __Stage__/hosts  #// ファイル名は任意です
                    ansible_local を使うとき: #keyword: vagrant_ansible_local_inventory
                        場所: (@control) /tmp/vagrant-ansible/inventory/vagrant_ansible_local_inventory
                        使い方: #search: Vagrant Ansible SSH
                        内容のサンプル: |  #search: Ansible ini inventory
                            # Generated by Vagrant

                            __HostNameInAnsible__ ansible_connection=local
                    内容の書式:  #search: Ansible ini inventory
                inventory.config ファイル:  #// __Stage__/inventory.config  #// ファイル名は任意です
                    書式:  #search: Ansible YAML inventory
                    #search: Ansible inventory plug in
                フォルダーを -i オプションに指定した場合:
                    指定したフォルダー内の全てのファイル（hosts と ____.config の両方）が有効です。
                    シンボリック リンク を使って共通化することもできます。
                vagrant_ansible_inventory:  #search: Vagrant Ansible inventory file
                    .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory
            書式（基本のみ）: #keyword: Ansible inventory format
                参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/intro_inventory.html#inventoryformat  #template: __DocumentVersion__
                INI形式: #keyword: Ansible ini inventory
                    hosts ファイルのサンプル: |  #// [ ] 内はグループ名、それ以外はホスト名
                        mail.example.com           #keyword: Ansible inventory host   #focus: mail.example.com

                        [webservers]               #keyword: Ansible inventory group  #focus: webservers
                        foo.example.com            #keyword: Ansible inventory host   #focus: foo.example.com
                        bar.example.com

                        [dbservers]
                        one.example.com
                        two.example.com
                        three.example.com http_port=80  #search: Ansible host variable
                    スーパー グループ のサンプル: | #keyword: Ansible super host group  #// ホストグループのグループ
                        ...（上記と同じ内容）

                        [__SuperGroup__:children]
                        webservers
                        dbservers
                    特殊記号一覧:
                        ([ ]): ホスト グループ  #search: ansible host group
                        ([__SuperGroup__:children]): スーパー グループ  #search: Ansible super host group
                        ([__Group__:vars]):  グループ変数  #search: Ansible inventory group_vars
                YAML形式: #keyword: Ansible YAML inventory
                    inventory.config ファイルのサンプル: |  #// children の直下はグループ名、hosts の直下はホスト名
                        all:
                        hosts:
                            mail.example.com:
                        children:
                            webservers:
                                hosts:
                                    foo.example.com:
                                    bar.example.com:
                            dbservers:
                                hosts:
                                    one.example.com:
                                    two.example.com:
                                    three.example.com:
                                        http_port: 80  #search: Ansible host variable
                            east:
                                hosts:
                                    foo.example.com:
                                    one.example.com:
                                    two.example.com:
                            west:
                                hosts:
                                    bar.example.com:
                                    three.example.com:
                            product:
                                hosts:
                                    foo.example.com:
                                    one.example.com:
                                    two.example.com:
                            test:
                                hosts:
                                    bar.example.com:
                                    three.example.com:
                Vagrant が生成する内容:  #search: Vagrant Ansible inventory file
            ホスト単体:  #keyword: ansible inventory host
                ホスト名: #keyword: Ansible host name  #search: ansible hosts
                    インベントリー ファイルに定義を書きます:  #search: ansible inventory file
                    ホストの参照:
                        自ホスト:  #search: inventory_hostname
                        他ホスト:  #search: Ansible host names
                    ホスト名の一部:  #search: Ansible constructed inventory
                ポート番号: #keyword: Ansible port number  #// たとえば localhost:2348
                    INI形式: localhost ansible_port=2348
                    YAML形式: |
                        all:
                            hosts:
                                localhost:
                                    ansible_port: 2348
                エイリアス（インベントリー エイリアス）:  #// IPアドレスに対する別名
                    #// IP アドレスしかないサーバーに対して Ansible 関連ファイルからエイリアスで参照できるようにします
                    書式: __AliasName__  ansible_port=____  ansible_host=___.___.___.___
                    サンプル: jumper ansible_port=5555 ansible_host=192.0.2.50
                ホスト変数: #keyword: Ansible host variable  #// ホストが定義する(?)変数
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/intro_inventory.html#host-variables  #template: __DocumentVersion__
                    インベントリー ファイル 内に書く場合:
                        サンプル: |  #// ホスト名の右に書く __Name__=__Value__ がホスト変数の定義です
                            [atlanta]
                            host1 http_port=80 maxRequestsPerChild=808
                            host2 http_port=303 maxRequestsPerChild=909
                        サンプルの説明:
                            - atlanta はグループ名
                            - http_port=80 は、host1 の http_port 変数の定義と、デフォルト値は 80
                            - maxRequestsPerChild=808 は、http_port=80 と同様
                    ホスト変数ファイル内に書く場合:
                        書式1:
                            /etc/ansible/host_vars/__HostName__ :  #// または
                            __CurrentFolder__/host_vars/__HostName__ : |
                                ---
                                __Name__: __Value__
                                __Name__: __Value__
                        書式1の説明:
                            __HostName__ には hosts ファイルに書かれているホスト名を指定します  #search: ansible inventory file
                        書式2:  #// 値が大きいときに便利です
                            /etc/ansible/host_vars/__HostName__/__VariableName__ :  #// または
                            __CurrentFolder__/host_vars/__HostName__/__VariableName__ : |
                                __Value__
                    ポート番号や接続変数もホスト変数になるらしい(?):
                    関連:  #search: Ansible constructed inventory
                ホストの分類:  #search: Ansible host classification  #// グループ化
            グループ, (ホスト グループ):  #keyword: ansible inventory group,  ansible host group
                グループの定義:
                    ホストを分類します:  #search: Ansible host classification  #// グループ化
                    グループの定義を書きます:  #search: Ansible inventory format
                    所属グループ: #keyword: Ansible multi group  #// それぞれのホストは複数のグループに所属することができます。グループの定義は所属するホスト名から想像できます
                        サンプル: |  #search: Ansible inventory group_vars
                            [webservers]
                            one.example.com

                            [east]
                            one.example.com
                        ホスト名のパターン指定:  #search: Ansible host pattern
                    グループ変数:  #search: Ansible inventory group_vars example  #// グループの定義はグループ変数の値から想像できます
                グループ名: #keyword: Ansible group name  #// all, __GroupName__, ungrouped, ホスト グループ または スーパー ホスト グループ
                    ❗注意: グループ名は、インベントリー ファイル の名前（パス）とは異なる場合があります
                    定義:  #// グループの名前の定義
                        定義済み:  #// プロジェクトに関係なく定義済みのグループ名
                            all: 全てのホスト  #// 定義済み
                            ungrouped: どのグループにも所属していないホスト  #// 定義済み
                        ユーザー定義:  #// Ansible プロジェクトで定義しているグループ名
                            インベントリー ファイル 内:  #// hosts ファイルの [ ] で定義したグループ  #see-above: hosts ファイル
                                #// 下記 [webservers] など
                    ホストが所属するグループ名一覧:  #search: Ansible multi group
                    （サンプル）:
                        役割: webservers, dbservers
                        地域: east, west
                        ステージ: product, test
                ホストの参照: #keyword: Ansible host names  #// グループに所属するホスト、単体、範囲指定、ワイルドカード相当
                    ホスト名:  #search: Ansible host name
                    グループの値:  #// ホスト名の配列
                        groups.__GroupName__: "[u'node1', u'node2', u'node3']"
                        groups.__GroupName__[0]: node1
                        groups.__GroupName__ | join(','): node1,node2,node3
                    ホスト名のパターン指定: #keyword: Ansible host pattern,  Ansible host wildcard  #ref: https://docs.ansible.com/ansible/latest/inventory_guide/intro_patterns.html#common-patterns
                        範囲で指定する場合:  #// プラグインは不要です
                            - www[01:50].example.com  #// www01.example.com ～ www50.example.com
                            - db-[a:f].example.com  #// db-a.example.com ～ db-f.example.com
                        正規表現や接頭辞などで指定する場合:
                            #search: Ansible constructed inventory
                        確認方法: | #keyword: Ansible evaluated host names  #// パターンを展開します。constructed による展開もします
                            ansible -i __InventoryFilePath__ __GroupName__ --list-hosts
                                #// SSH が使えない環境でも実行できます
                グループ変数, 全ホストの変数: #keyword: Ansible group_vars,  Ansible group variables  #// ホストのグループで共通の値を持つ変数
                    参考:  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/intro_inventory.html#group-variables
                    定義:
                        group_vars フォルダー内の YAML に書く場合: #keyword: Ansible group_vars YAML  #// 書式はホスト変数ファイルと同じです  #see-above: ホスト変数ファイル
                            （下記 __GroupName__）: #keyword: Ansible group_vars group name  #// グループ名はデプロイ先のホスト名から決まります
                                #search: Ansible group name
                                #search: Ansible multi group
                                #search: Ansible inventory group_vars example
                                all, __GroupName__, ungrouped, ホスト グループ または スーパー ホスト グループ  #search: Ansible group name
                            YAML の場合:  #// １つのファイルに１つ以上の変数定義をする場合
                                場所:
                                    core version 2.16:  #// 以下のいずれか  #ref: https://docs.ansible.com/ansible/latest/inventory_guide/intro_inventory.html#organizing-host-and-group-variables >> searching paths relative to the inventory file or the playbook file
                                        - __PlaybookFolder__/group_vars/__GroupName__/___.yml  #search: Ansible group_vars group name
                                        - __PlaybookFolder__/group_vars/all/___.yml
                                        - __InventoryFileFolder__/group_vars/__GroupName__/___.yml  #// 未確認  #search: Ansible group_vars group name
                                        - __InventoryFileFolder__/group_vars/all/___.yml  #// 未確認
                                    core version 2.9:  #// 以下のいずれか   #// 違うかも？
                                        - __CurrentFolder__/group_vars/__GroupName__/___.yml   #// 違うかも？
                                        - __CurrentFolder__/group_vars/all/___.yml            #keyword: Ansible group_vars/all.yml  #ref: https://qiita.com/tentom/items/9816a5c07f013b84a6ce
                                        - /etc/ansible/group_vars/__GroupName__/___.yml   #// 違うかも？
                                        - /etc/ansible/group_vars/all/___.yml
                                内容: | #keyword: Ansible group_vars YAML example
                                    __Name__: __Value__
                                    __Name__: __Value__
                            値だけの場合:  #// １つのファイルに１つの変数定義をする場合
                                場所:  #// 以下のいずれか
                                    - __CurrentFolder__/group_vars/__GroupName__/__VariableName__  #search: Ansible group_vars group name
                                    - __CurrentFolder__/group_vars/all/__VariableName__
                                    - /etc/ansible/group_vars/__GroupName__/__VariableName__  #search: Ansible group_vars group name
                                    - /etc/ansible/group_vars/all/__VariableName__
                                内容: |
                                    __Value__
                        インベントリー ファイル 内に書く場合: #keyword: Ansible inventory group_vars
                            サンプル: |  #// :vars はグループ変数の定義であることを示します
                                [atlanta:vars]
                                ntp_server=ntp.atlanta.example.com
                                proxy=proxy.atlanta.example.com
                            サンプルの説明:
                                - atlanta はグループ名です
                                - ntp_server, proxy は変数名です
                            親グループのグループ変数:  #search: Ansible inventory group_vars example
                                サンプル: |  #// :children は子グループであることをと示します。下記「サンプルの説明」を参照
                                    [atlanta]
                                    host1    #// ホスト host1 に対して Ansible が処理するときは、some_server 変数は southeast:vars 「など」に定義されます
                                    host2

                                    [raleigh]
                                    host2
                                    host3

                                    [southeast:children]
                                    atlanta    #// atlanta グループの親は >> southeast グループ になります
                                    raleigh

                                    [southeast:vars]
                                    some_server=foo.southeast.example.com
                                    halon_system_timeout=30
                                    self_destruct_countdown=60
                                    escape_pods=2
                                上記サンプルの説明: #keyword: Ansible inventory group_vars example
                                    ホストから調べる場合:  #focus: host1, atlanta, southeast, vars, some_server
                                        - ホストが異なれば変数の値が異なることがあります
                                        - ホスト host1 に対して Ansible が処理するときの some_server 変数の値は southeast:vars 「など」に定義されている値になります
                                        - southeast は host1 が所属する複数グループのうちの１つです。host1 は atlanta と southeast に所属しています  #search:  Ansible multi group
                                        - グループ変数の定義は YAML に書かれている可能性もあります  #search: Ansible group_vars YAML
                                    グループから調べる場合:  #focus: southeast
                                        - southeast は、atlanta グループと raleigh グループの親グループです
                                        - some_server など southeast:vars で定義した変数は、host1, host2, host3 に適用されます
                                        - 子グループに所属するホストにも適用されます
                                        - グループ変数の定義は YAML に書かれている可能性もあります  #search: Ansible group_vars YAML
                    参照:
                        group_vars フォルダーで定義した変数の値:  #search: Ansible group_vars YAML
                            '{{ __Name__ }}'
                        groups: #keyword: Ansible groups  #// インベントリーのグループの値を参照します
                            groups['__Name__']  #search: Ansible group_vars YAML example
                    優先度: 子が優先ですが、変更もできます https://docs.ansible.com/ansible/2.9_ja/user_guide/intro_inventory.html#how-we-merge
                when: |  #search: Ansible when  #// 特定のグループだけタスクを実行する場合
                    when: "'new_location' in group_names"
                トラブルシューティング(Ansible グループ): #keyword: ansible inventory group trouble
                    undefined グループ変数名:  #keyword: undefined Ansible group_vars
                        対処A:
                            all に定義を移動してみます:
                                __CurrentFolder__/group_vars/all/___.yml 
                        対処B:
                            ansible.cfg の vars_plugins_enabled を設定します:
                                vars_plugins_enabled = host_group_vars,__CustomVers__
                                #search: enable Ansible vars plug in
                        対処C:
                            __GroupName__ が何になるか インベントリー ファイル を確認します:
                                - ホスト名  #search: Ansible playbook.yml hosts
                                - グループ名  #search: Ansible group name
                        対処D:
                            vars（すべて）ではなく 1つだけ参照します
                    グループ変数の値が違う:
                        ホスト名をチェックします:
                            Ansible が処理しているホスト名をメモします
                        グループ名を一覧します:
                            対象ホストが所属しているグループを一覧します  #search: Ansible inventory group_vars example
                                #// インベントリー名とグループ名は異なる可能性があります  #search: Ansible group name
                        変数定義を検索します:
                            変数名とコロンで全文検索して、見つかったファイルの場所や内容から、所属するグループ（複数）にマッチするものを探します
            control ノード: #keyword: ansible control node  #// Ansible を実行するマシーン。SSH クライアント
                control ノードで実行する場合:  #search: ansible delegate_to
            --connection=local オプション:  #keyword: ansible-playbook --connection=local
                SSH 接続を行いません。
                インベントリー ファイル や playbook.yaml の hosts の設定にかかわらず、ローカルを対象ホストとして実行します。
                hosts に localhost が設定してあっても --connection=local オプション を指定しないと SSH 接続を試みます。
            Vagrant が生成する インベントリー ファイル: #keyword: Vagrant Ansible inventory file
                参考: https://www.vagrantup.com/docs/provisioning/ansible_intro
                自動生成 >> ansibl_locale provisioner を使ったときに自動生成される インベントリ ファイル:
                    /tmp/vagrant-ansible/inventory/vagrant_ansible_local_inventory: | #// ゲスト マシーン内に自動的に作られます。 tmp の中なので無くなることがあります
                        # Generated by Vagrant
                        __HostName__ ansible_connection=local
                    __HostName__: config.vm.define の第1引数。指定していなければ default
                自動生成 >> ansible provisioner を使ったときに自動生成される インベントリ ファイル:
                    .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory: | #// ホスト マシーン内に自動的に作られます
                        # Generated by Vagrant
                        default ansible_ssh_host=127.0.0.1 ansible_ssh_port=2200 ansible_ssh_user='vagrant' ansible_ssh_private_key_file='/home/.../.vagrant/machines/default/virtualbox/private_key'
                    #// ファイルには、ホスト マシーン に接続するための SSH に関する情報があります。
                内容:
                    サンプル: 上記
                    書式:  #search: Ansible inventory format
                ホスト変数 >> ホスト変数を使って インベントリ ファイル を生成します:
                    サンプル __Project__/Vagrantfile : |
                        Vagrant.configure("2") do |config|
                        config.vm.provision "ansible" do |ansible|
                            ansible.host_vars = {
                                "host1" => {"http_port" => 80,
                                            "maxRequestsPerChild" => 808},
                                "host2" => {"http_port" => 303,
                                            "maxRequestsPerChild" => 909}
                            }
                    生成される インベントリ ファイル: |
                        # Generated by Vagrant
                        host1 ansible_ssh_host=... http_port=80 maxRequestsPerChild=808
                        host2 ansible_ssh_host=... http_port=303 maxRequestsPerChild=909
                グループ変数 >> グループ変数を使って インベントリ ファイル を生成します:
                    サンプル __Project__/Vagrantfile : |
                        Vagrant.configure("2") do |config|
                        config.vm.provision "ansible" do |ansible|
                            ansible.groups = {
                                "group1" => ["machine1"],
                                "group2" => ["machine2"],
                                "group3" => ["machine[1:2]"],
                                "group4" => ["other_node-[a:d]"], # silly group definition
                                "all_groups:children" => ["group1", "group2"],
                                "group1:vars" => {"variable1" => 9,
                                                "variable2" => "example"}
                            }
                    生成される インベントリ ファイル: |
                        # Generated by Vagrant

                        machine1 ansible_ssh_host=127.0.0.1 ansible_ssh_port=2200 ansible_ssh_user='vagrant' ansible_ssh_private_key_file='/home/.../.vagrant/machines/machine1/virtualbox/private_key'
                        machine2 ansible_ssh_host=127.0.0.1 ansible_ssh_port=2222 ansible_ssh_user='vagrant' ansible_ssh_private_key_file='/home/.../.vagrant/machines/machine2/virtualbox/private_key'

                        [group1]
                        machine1

                        [group2]
                        machine2

                        [group3]
                        machine[1:2]

                        [group4]
                        other_node-[a:d]

                        [all_groups:children]
                        group1
                        group2

                        [group1:vars]
                        variable1=9
                        variable2=example
                    エラーになる設定があるマシーンに関する情報は、インベントリ ファイルに出力されません:
                    ホスト範囲パターン(数値およびアルファベットの範囲)も使えます:
                静的インベントリ >> ユーザーが作った インベントリ ファイル を使う場合:
                    参考: https://www.vagrantup.com/docs/provisioning/ansible_intro#static-inventory
                    サンプル Vagrantfile:
                        node.vm.provision :ansible_local do |ansible|
                            ansible.inventory_path = '/home/vagrant/ansible/inventories/hosts'
            インベントリー プラグイン:  #search: Ansible inventory plug in
        プレイ:  #keyword: Ansible play
            最もシンプルなプレイ:  #search: ansible playbook
                -   hosts: node1
                    tasks:
                        -   name: dummy  #search: ansible tasks, ansible module
                            debug:
                                msg: Ansible ready
            Playbook ファイル(*.yml):  #search: ansible playbook
            実行・非実行を tag で指定でき、変数定義が vars.yml にあり、ローリング実行するプレイ:  #focus: tags, vars_files, serial
                -   name: dummy print    #// --list-tasks で表示されます
                    tags: [dummy]  #// --tag, --tags オプションで実行・非実行を指定できます #search: Ansible tags
                    hosts: node1
                    serial: 1   #// ローリング実行
                    vars_files: vars.yml
                    tasks:
                        -   name: dummy  #search: ansible tasks, ansible module
                            debug:
                                msg: Ansible ready
            ロールを実行するプレイ:  #focus: roles
                -   name: Start NFS server
                    tags: [start-nfs]
                    hosts: node1
                    roles: [nfs-server]  #search: ansible roles
            タスクの開始時刻と処理時間を表示します: #search: profile_tasks
        タスク:  #keyword: Ansible tasks
            フォルダーの場所:  #keyword: Ansible tasks YAML
                #focus: __ModuleName__
                ____.yml#tasks: |   #search: ansible tasks in Playbook.yaml
                    -   hosts: __ServerName__
                        tasks:
                        -   name: ____
                        -   __ModuleName__: ____
                roles/__RoleName__/tasks/main.yml: |  #search: ansible tasks in role folder
                    -   name: ____
                        __ModuleName__: ____
                    -   name: ____
                        __ModuleName__: ____
            関連 >> モジュール: #search: Ansible モジュール
            一覧: #search: Ansible list tasks
            ファイル >> tasks in Playbook.yaml:  #search: ansible tasks in Playbook.yaml
            タスクを階層化します:  #search: ansible block
            必ず実行するタスク: #keyword: Ansible must task  #// どの playbook を実行してもある特定のタスクを実行します
                できません。
                pre_tasks または post_tasks を使っても、それが定義されているタスクやロールをインポートする必要があります。
                #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: must task
            タスクの開始時刻と処理時間を表示します: #search: profile_tasks
        ロール:  #search: Ansible roles
        変数:  #keyword: Ansible vars, Ansible variables
            定義:  #keyword: Ansible vars define  #// 変数を定義します
                基本:
                    ____.yml#vars:                         ⇒ #search: ansible vars in Playbook.yml
                    roles/__RoleName__/vars/main.yml:      ⇒ #search: ansible vars in role folder
                    roles/__RoleName__/defaults/main.yml:
                        参考: ⇒ #serach: ansible default vars in role folder
                        サンプル:
                            __Key1__: __Value___
                            __Key2__: __Value___
                Playbook.yml:  #// Playbook に変数を定義します。ホストごとに値を変える変数を定義します
                    vars:  #search: ansible vars in Playbook.yml
                    tasks.vars:  #search: Ansible tasks.vars
                    vars_files:  #// 変数定義のあるファイルを指定します  #search: Ansible vars_files in Playbook.yml
                    include_vars:  #// 変数定義のあるファイルを指定します  #search: Ansible include_vars in Playbook.yml
                    import_playbook のパラメーター:
                        サンプル:
                            (playbook1.yml):
                                - import_playbook: ./playbook2.yml version=1.2  #// 変数の前に空白文字を２つ入れるとファイル名の末尾に空白が付いてしまいます
                            (playbook2.yml):
                                -   hosts: all
                                    tasks:
                                        - #
                                            name: print message
                                            debug:
                                                msg: "version = {{ version }}"  #// version 変数の値を表示します
                            #// 公式の説明はないが動作確認済み 2021-09
                定義場所:  #// Playbook.yml 以外、vars ファイル、コマンドライン、実行結果
                    ファイル:  #keyword: ansible vars files  #// ファイル（Playbook 以外）で変数を定義します
                        roles/__RoleName__/vars/*.yml: #keyword: ansible vars in role folder  #// ロールのフォルダー内に変数を定義します  #serach: ansible roles
                            ロールで使う全ての変数: #keyword: Ansible all role vars
                                #// ロールで使う変数をすべてここで定義することは、共有するロールで role/__Service__/defaults に一覧するように変数定義するときだけ効果があります
                                #// そうでなければ Playbook.yml で定義するのが基本です。そもそも変数にしないという選択肢もあります。
                            role vars で定義した変数を上書きします:
                                基本ケース:
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/vars/1st/README.yaml
                                同じ変数名で違う role の場合:
                                    vars/main.yml で定義された変数は import_role ごとに vars の内容で上書きされます
                                    defaults/main.yml で定義された変数と動きが異なります
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/vars/2_same_name/README.yaml
                                ネストした変数の場合:
                                    変数に子の変数を定義した場合、親の変数を上書きすると子の変数も置き換わります。マージしません
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/vars/3_nested/README.yaml
                                複数のロールで変数の値を同じにします:  #keyword: Ansible shared vars
                                    複数のロールで共有する変数の値は、group_vars/all.yml で定義した変数を import_role の vars に指定します
                                    role の vars で同じ名前の変数を定義しても、異なる変数として扱われます
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/vars/4_share/README.yaml
                                include_vars でまとめて変更します:
                                    include_vars より上の import_role と下の import_role で使われる変数の値が変わります
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/vars/5_include_vars/README.yaml
                        roles/__RoleName__/defaults/*.yml: #keyword: ansible default vars in role folder  #// ロールのフォルダー内にデフォルトの変数を定義します  #serach: ansible roles
                            role defaults で定義した変数を上書きします:
                                基本ケース:
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/defaults/1st/README.yaml
                                同じ変数名で違う role の場合:
                                    defaults/main.yml で定義された変数は tasks ごとに（中の別の import_role でも）vars の内容で上書きされます
                                    vars/main.yml で定義された変数と動きが異なります
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/defaults/2_same_name/README.yaml
                        group_vars/_____: グループ変数、全ホストの変数  #search: Ansible group_vars YAML
                        ansible.cfg:
                            vars プラグイン:  #// 秘密データのフォルダーなどに使えます  #see-below: vars プラグイン
                        /vars/external_vars.yml: |
                            ---
                            # in the above example, this would be vars/external_vars.yml
                            somevar: somevalue
                            password: magic
                        コマンドラインに指定した外部ファイル(*.yml, *.json):
                            ansible-playbook  __Playbook__.yml --extra-vars "@/vars/external_vars.yml"
                    コマンドライン:  #// コマンドラインで変数を定義します
                        --extra-vars オプション: #keyword: Ansible --extra-vars  #// 短い名前は -e
                            key-value 構文埋め込み（文字列型の値のみ）:
                                複数指定:
                                    ansible-playbook  __Playbook__.yml  --extra-vars "version=1.23.45 other_variable=foo"
                                ネストした変数:  #// ピリオドで区切ります
                                    ansible-playbook  __Playbook__.yml  --extra-vars "my_variable.level1.level2=新しい値"
                            JSON 埋め込み:
                                複数指定:
                                    ansible-playbook  __Playbook__.yml  --extra-vars '{"version":"1.23.45","other_variable":"foo"}'
                                ネストした変数: |
                                    ansible-playbook playbook.yml  --extra-vars '{"my_variable": {"level1": {"level2": "新しい値"}}}'
                            外部ファイル: #see-above: --extra-vars "@/vars/external_vars.yml"
                            値の上書き: vars.yml の定義内容より --extra-vars の定義内容が優先されます
                    実行結果:  #search: ansible register  #// コマンドの実行結果を変数に代入します
                        参考: #ref https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_variables.html#registered-variables  #template: __DocumentVersion__
                        サンプル:
                            tasks:
                                -   shell: __Command__
                                    register: __VariableName__  #// result に統一することを推奨
                                    ignore_errors: __TrueOrFalse__

                                -   shell: __Command__  #// when の条件を満たすときだけ実行します
                                    when: __VariableName__.rc == 5  #search: ansible when
                        stdout を参照できます:
                            登録変数: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_conditionals.html#id7  #template: __DocumentVersion__
                    自動定義:  #search: ansible automatic defined variables
                    定義の優先度:  #search: ansible vars priority
                定義場所を見つけます:
                    変数名で検索する場合:
                        キーワード: " __VariableName__:"  #// 変数名の右にコロンを付け、ワードマッチ検索をします
                        パスの絞り込み:  #search: VSCode search
                            - "*.yml"
                            - "roles/__RoleName__"
                    値で検索する場合:
                        変数の値を表示してから、その値で全文検索します:  #see-below: 変数の値を表示します
                    ロールに設定が必要な変数の仕様:
                        roles/__RoleName__/defaults/main.yml
                自動的に定義される変数: #keyword: ansible automatic defined variables
                    主な定義済み変数:
                        - vars  #// すべて
                        - ansible_facts,  ansible_____  #search: ansible facts
                        - hostvars,  groups,  group_names,  inventory_hostname  #search: ansible magic vars
                        - item  #search: ansible loop,  ansible with_items
                        - その他:
                            #ref: https://docs.ansible.com/ansible/2.9_ja/reference_appendices/special_variables.html  #template: __DocumentVersion__
                            #search: ansible vars define
                    ファクト（Facts）:  #keyword: ansible facts,  service_facts  Gathering Facts
                        参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_variables.html#fact  #template: __DocumentVersion__
                        例:
                            表示される変数名: [ ansible_env, ansible_eth1, ansible_os_family ]
                                #// 定義内容を表示するコマンドを実行したときの変数名は ansible_ から始まります
                            参照するときの変数名: [ ansible_facts.env, ansible_facts.eth1, ansible_facts.os_family ]
                                #// 参照するときの変数名は、ansible_facts のフィールドに、接頭辞 ansible_ を削除して指定します
                        値を表示します:
                            __Playbook__.yml:
                                -   name: Get service_facts (unformatted)
                                    service_facts:
                                    register: result
                                -   name: Show service_facts (formatted)
                                    debug: var=result.ansible_facts
                            コマンド:
                                ansible hostname -m setup
                        サービスのステータス:  #keyword: ansible_facts services
                            サービスが起動中であることをチェックします:  #keyword: Ansible systemctl status
                                tasks/__Playbook__.yml:
                                    -   name: Make sure that a service is running
                                        service_facts:
                                        register: result
                                        failed_when: result.ansible_facts.services['__ServiceName__'].state != 'running'
                                            #// __ServiceName__ の末尾の .service は省略できません
                                            #search: systemctl service name
                        ファクトを使わないときに高速化するとき:
                            __Playbook__.yml:
                                - gather_facts: no
                        ローカルファクト (facts.d):  #// ファクトを追加します
                            #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_variables.html#facts-d  #template: __DocumentVersion__
                        Ansible バージョン:
                        ファクトのキャッシュ:
                    マジック変数:  #keyword: ansible magic vars,  ansible hostvars  group_names
                        参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_variables.html#magic-variables-and-hostvars  #template: __DocumentVersion__
                        一覧: #ref: https://docs.ansible.com/ansible/2.9_ja/reference_appendices/special_variables.html  #template: __DocumentVersion__
                        inventory_hostname: #keyword:
                            - hosts フィールドに書いてあるホスト名  #search: ansible hosts
                            - インベントリー ファイル に書いてあるホスト名  #search: Ansible inventory
                        inventory_hostname_short:
                        hostvars:  #// IP アドレスなど  #keyword: ansible hostvars
                            書式: hostvars['test.example.com'].ansible_facts.____
                            IP アドレス:
                                変数:
                                    - hostvars[inventory_hostname].ansible_all_ipv4_addresses
                                    - hostvars[inventory_hostname].ansible_default_ipv4.address
                                    - hostvars[inventory_hostname].ansible_eth1.ipv4.address
                                    - hostvars[inventory_hostname].ansible_facts.all_ipv4_addresses
                                    #// 注意❗ 環境によっては取れないことがあります
                                    #ref: https://stackoverflow.com/questions/25410656/ansible-ip-address-variable-host-part
                                変数に設定した IP アドレスが正しいかチェックします:
                                    -   hosts: all
                                        tasks:
                                            -   name: Check IP address
                                                debug: var=hostvars[inventory_hostname].ansible_all_ipv4_addresses
                                                failed_when: g_host[inventory_hostname].ipv4.address != hostvars[inventory_hostname].ansible_all_ipv4_addresses[1]
                                        any_errors_fatal: true
                            値を表示します:
                                #// 注意: 応答メッセージは膨大です
                                tasks/__Playbook__.yml:
                                    -   name: Show hostvars
                                        debug: var=hostvars[inventory_hostname]
                                    -   name: Show hostvars
                                        debug: var=hostvars['node1']
                        group_names: |
                            {% if 'webserver' in group_names %}
                                # some part of a configuration file that only applies to webservers
                            {% endif %}
                    接続変数:
                        参考: #ref: https://docs.ansible.com/ansible/2.9_ja/reference_appendices/special_variables.html#connection-variables  #template: __DocumentVersion__
                        ansible_host: ホスト名。IPアドレスなし
                    不明:
                        ansible___NetworkDeviceName__:  #keyword: ansible_eth0.ipv4.address
                            ipv4.address: IP アドレス。ただし最初の IP アドレスのみ。nmcli.ipv4 が "CIDR1, CIDR2" のときは CIDR1 のみ
                                設定例  ansible_eth1.ipv4.address
                コマンドの実行結果:  #search: Ansible register
                ファイルの内容:  #search: Ansible register cat
                条件別: #keyword: Ansible vars condition,  Ansible derived attribute  #// ステージなどの条件によって変数の定義を変えます。派生属性
                    フォルダー:  #// ステージごとに定義するフォルダーを分けます
                        - group_vars/__Stage__/____.yml
                        - group_vars/all/____.yml
                    roles/vars/__Stage__.yml:  #keyword: roles/vars/__Stage__.yml  #// roles/vars に dev.yml などのステージごとのファイルを配置する場合
                        編集前:  #focus: vars
                            playbook.yml: |
                                -   hosts: _____
                                    roles:
                                        __Role__
                            roles/__Role__/vars/main.yml: |
                                var1: ____
                                var2: ____
                        編集後:  #focus: vars, dev
                            playbook.yml: |
                                -   hosts: _____
                                    tasks:
                                        -   name: Merges dev specific role variables
                                            include_vars:
                                                file: "roles/__Role__/vars/{{ inventory_env }}.yml"
                                            when: inventory_env == 'dev'

                                        -   name: Uses the variables in a role
                                            include_role:
                                                name: __Role__
                            roles/__Role__/vars/main.yml: |
                                var1: ____
                                var2: ____
                            roles/__Role__/vars/dev.yml: |
                                var3: ____
                                var4: ____
                    三項演算子:  #focus: environment  #// 条件式や true/false から派生属性を定義します
                        "{{ 'prod-db.example.com' if environment == 'production' else 'dev-db.example.com' }}"
                    辞書: |  #focus: environment  #// 辞書のキーから派生属性を定義します
                        vars:
                            environment: staging
                            max_connections: "{{ connection_limits[environment] }}"
                            connection_limits:
                                production: 100
                                staging: 50
                                development: 20
                    combine: #keyword: Ansible vars combine  #// 辞書をマージする場合。 ステージなどの条件によって辞書変数の定義を変えます
                        編集前:  #focus: example_dictionary
                            playbook.yml: |
                                -   hosts: _____
                                    roles:
                                        __Role__
                                    vars:
                                        example_dictionary:  #// ロール内で参照されます
                                            key1: ____
                                            key2: ____
                        編集後:  #focus: example_dictionary
                            playbook.yml: |
                                -   hosts: _____
                                    tasks:
                                        -   name: Merges dev specific variables
                                            set_fact:
                                                example_dictionary: "{{ example_dictionary | combine(example_dictionary_dev) }}"
                                            when: inventory_env == 'dev'

                                        -   name: Uses the variables in a role
                                            include_role:
                                                name: __Role__
                                    vars:
                                        example_dictionary:  #// ロール内で参照されます
                                            key1: ____
                                            key2: ____
                                        example_dictionary_dev:  #// inventory_env == 'dev' の場合、ロール内で参照されます
                                            key3: ____
                                            key4: ____
                    （関連）:  #search: Ansible conditions
                辞書:  #keyword: define Ansible dictionary variable  #// 辞書やオブジェクトを定義します
                    object.property:  #// object.property 形式でアクセスできるようにする定義の書き方
                        派生属性 >> 別ファイルで定義: #focus: playbook-vars.yml,  current,  property_1,  version_number
                            #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/variable_exapmle/include/playbook.yml＃object - vars_files
                            playbook.yml:
                                hosts: ____
                                vars:
                                    version_number: "{{ g_version }}"
                                vars_files: [playbook-vars.yml]
                                tasks:
                                    -   name: object - with parameter
                                        debug: 'msg="current.property_1: {{ current.property_1 }}"'  #// = Value_5_0
                            playbook-vars.yml:
                                current: "{{ versions[version_number] }}"
                                versions:
                                    v5_0:
                                        property_1: Value_5_0
                                    v4_0:
                                        property_1: Value_4_0
                        派生属性 >> ファイル内で定義:  #focus: current,  property_1,  version_number
                            #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/variable_exapmle/in_one_file/playbook.yml#object - with parameter
                            hosts: ____
                            tasks:
                                -   name: object - with parameter
                                    debug:
                                        msg: "current.property_1: {{ current.property_1 }}"  #// = Value_5_0
                            vars:
                                version_number: v5_0  #// or v4_0
                                current: "{{ versions[version_number] }}"
                                versions:
                                    v5_0:
                                        property_1: Value_5_0
                                    v4_0:
                                        property_1: Value_4_0
                        辞書を使わない場合: #focus: current,  v5_0
                            tasks:
                                -   name: object - simple
                                    debug:
                                        msg: "current.property_1: {{ current.property_1 }}"  #// = Value_5_0
                            vars:
                                current: "{{ v5_0 }}"  #// v4_0 に編集することができます。ただし、外部（グローバルなど）から切り替えることはできません
                                v5_0:
                                    property_1: Value_5_0
                                v4_0:
                                    property_1: Value_4_0
                    dictionary[parameterVariable]:  #// 普通に書くと dictionary[parameterVariable] 形式でしかアクセスできません
                        サンプル プロジェクト: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/variable_exapmle/in_one_file/playbook.yml#dictionary_1[parameter_1]
                        サンプル: #focus: dictionary_1, Value_1_1
                            vars:
                                dictionary_1:
                                    attribute_1: Value_1_1
                                variable_2: "{{ dictionary_1[parameter_1] }}"  #// = Value_1_1
                                parameter_1: attribute_1
                    辞書を渡す場合:  #search: Ansible dictionary environment in server
                グループ変数:  #search: Ansible group_vars
                グローバル変数:  #keyword: Ansible global variable  #// グローバル変数を定義します
                    group_vars/all.yml を使う場合:  #search: Ansible group_vars/all.yml
                        - Playbook ごとのグローバル
                    vars_files: Playbook の hosts ごと  #search: Ansible vars_files
                    ホストのグループに対する変数を定義する場合:  #search: Ansible group_vars
            参照:  #keyword: Ansible vars refer  #// 変数を参照します
                書式:  #// Ansible は内部で Jinja2 のテンプレートエンジンを使っています。ループも使えます  #search: Jinja2 template
                    - "{{ __Name__ }}"  #// 変数が定義されていないとエラーになります
                    - "{{ __Name__ | default('__Value__') }}"  #// 変数が定義されていないときに使う値
                    - "{{ __Object__.__Attribute1__.__Attribute2__ | default('') }}"  #// __Attribute1__ や __Attribute2__ が無くてもエラーになりません
                        #keyword: Ansible no attribute,  Ansible 'dict object' has no attribute property default
                    - sencion: "{{ __Name__ | default(omit) }}"  #// 変数が定義されていないときは section を無くします
                        #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#omitting-undefined-variables  #template: __DocumentVersion__
                    #// ディクショナリーやアレイについては #search: Ansible dictionary, Ansible array
                    #search: Jinja2 template
                    #search: Ansible filter
                表示: #keyword: Ansible vars print  #// 変数の値を表示します
                    Playbook.yml, tasks/___.yml 内: |  #// 推奨  #search: ansible debug
                        -   name: show variable value
                            hosts: localhost
                            tasks:
                                -   name: debug print in _tmp.yml
                                    debug: 'msg="{{ vars }}"'
                    コマンドラインで表示します:  #// 全部は含まれません
                        ansible -i __InventoryFile__  -m debug -a "var=vars" all
                            #// Playbook.yml の指定は不要です
                コードを書く場所:  #// 参照するコードを書く場所
                    Playbook ファイルから参照します:
                        tasks:
                            -   name: create a virtual host file for {{ vhost }}  #// 参照
                                template:
                                src: somefile.j2
                                dest: /etc/httpd/conf.d/{{ vhost }}  #// 参照
                        vars:
                            vhost: host1  #// 定義
                    変数定義に参照を含めます:
                        vars:
                            all: "[{{ main }}, node2, node3]"
                    template ファイルから参照します:
                        template モジュールのテンプレート ファイルから参照できます  #see-below: ansible_template
                    インベントリ ファイル から参照します:
                        groups:
                            groups.__GroupName__  #// ホスト名
                        参考:
                            インストール先のホスト名:  #search: inventory_hostname
                            #ref: https://docs.ansible.com/ansible/latest/user_guide/playbooks_vars_facts.html#information-about-ansible-magic-variables
                            #ref: https://docs.ansible.com/ansible/latest/reference_appendices/special_variables.html
                値: #keyword: Ansible vars value
                    vars:  全部  #search: ansible automatic defined variables
                    定義した値:  #search: Ansible vars define
                    環境変数:  #keyword: Ansible environment variable in host OS  #// ホストOSの環境変数を参照します
                        書式サンプル:
                            line: '{{ lookup("env", "HTTP_PROXY") }}'
                        環境変数を引き継ぎます: |  #focus: env  #// Ansible が root ユーザー になってコマンドを実行するときに、Ansible の CLI の環境変数を引き継ぐ設定のサンプル
                            -   name: yum makecache and check network to repository
                                command: 'sudo yum makecache  --disablerepo="*"  --enablerepo="{{ service_name }}-common"'
                                become: yes
                                become_user: root
                                environment:
                                    no_proxy: '{{ lookup("env", "no_proxy") }}'
                        #// ホストOS が Windows のときは、環境変数名の大文字小文字を区別しません。上記 HTTP_PROXY は http_proxy でも同じ
                    ファイルの内容:
                        control ノード 内:  #search: Ansible lookup plug in type
                        target ノード 内:  #search: ansible register cat
                    コマンドの実行結果:  #search: ansible register
                トラブルシューティング >> undefined:
                    group_vars:  #search: undefined Ansible group_vars
            型: #keyword: Ansible vars type  #// 変数の型
                ディクショナリー（～型変数）:  #keyword: Ansible dictionary
                    定義:
                        vars:
                            __DictionaryName__:
                                __Field1__: __Value1__
                                __Field2__: __Value2__
                    参照:
                        - __DictionaryName__.__Field__  #// Python で予約されているフィールド名は使えません
                        - __DictionaryName__['__Field__']
                        - __DictionaryName__[__VariableName__]
                    ループで使うとき:  #search: ansible loop
                アレイ（～型変数）:  #keyword: Ansible array
                    参照:
                        - __ArrayName__[__Index__]
                    結合:  #keyword: Ansible join, Ansible array join merge
                        基本: "{{ ['a', 'b'] + ['c'] }}"  #// "{{ ['a', 'b', 'c'] }}" と同じ
                        非アレイとアレイの結合:
                            vars:
                                varA: a
                                varB: [b, c]
                            hosts: "{{ [varA] + varB }}"
                        アレイの中で変数参照:
                            vars:
                                main: node1
                            OK: "{{ [main ,'node2', 'node3'] }}"
                            NG: "[ {{ main }}, node2, node3 ]"
                                #// [WARNING]: Could not match supplied host pattern, ignoring: [node1
                                #// [WARNING]: Could not match supplied host pattern, ignoring: node3]
            値:  #search: Ansible vars value
            優先順位:  #keyword: ansible vars priority  #// 同じ変数名の定義が複数あるときの参照先の優先順位
                参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_variables.html#ansible-variable-precedence  #template: __DocumentVersion__
                    #// 上記参照先の一覧のうち下にあるものが優先されます
                概要: 子グループは親グループを上書きし、ホストは常にそのグループを上書きします。
                サンプル（下が優先）:
                    /etc/ansible/group_vars/all :
                        ntp_server: default-time.example.com
                    /etc/ansible/group_vars/boston :
                        ntp_server: boston-time.example.com
                    /etc/ansible/host_vars/xyz.boston.example.com :
                        ntp_server: override.example.com
            関連:
                フィルター:  #search: Ansible filter
        モジュール:  #//🌟 タスクのコマンド  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/__ModuleName___module.html  #keyword: ansible module  #template: __DocumentVersion__
                #keyword: Ansible module
            #// 公式のページの下のほうにある サンプル コード が役に立ちます
            参考:
                - https://docs.ansible.com/ansible/2.9_ja/ >> モジュールの使用 >> Module Index >> All modules  #template: __DocumentVersion__
                - URL にモジュール名を入力: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/__ModuleName___module.html  #template: __DocumentVersion__
                - All modules: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/list_of_all_modules.html  #template: __DocumentVersion__
                    #// Playbook ファイルに書くモジュール名の一覧です
                - Module Index: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/modules_by_category.html  #template: __DocumentVersion__
                    #// ツリーから探します
            書式:
                YAML のキーにパラメーターを指定する場合:
                    サンプル playbook.yml:
                        tasks:
                        -   name: ____
                            __ModuleName__:
                                __ParameterName1__: __Value__
                                __ParameterName2__: __Value__
                            __Others__:  #search: ansible tasks in Playbook.yaml
                値に複数のパラメーターを指定する場合:
                    サンプル playbook.yml:
                        tasks:
                        -   name: ____
                            __ModuleName__: __ParameterName1__=__Value__ __ParameterName2__=__Value__
            カタログ >> 基本的な Ansible モジュール: #// 認証, パッケージ, デーモン, シェル, デバッグ  #keyword: ansible modules catalog,  ansible modules command  #glossary: Ansible module
                カテゴリー順:
                    認証:       #see-below:  authorized_key, rpm_key
                    パッケージ: #see-below:  yum, dnf, pip, yum_repository
                    デーモン:   #see-below:  service, sysvinit  #search: ansible_facts
                    シェル:     #see-below:  shell
                    デバッグ:   #see-below:  debug
                    その他: カタログを参照（親項目）
                authorized_key:  #// サーバー側に SSH 認証キー（公開鍵）を追加または削除します。秘密鍵のアップロードは別途行ってください
                    #serach: authorized_keys
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/authorized_key_module.html  #template: __DocumentVersion__
                command:     #// シェルのコマンドを実行します。冪等性はありません  #keyword: ansible command module
                    #// 通常は shell モジュールを使うのがよいでしょう
                    #// shell 以外の Ansible モジュールを使う場合、shell よりも command のほうが環境が近いです
                    #// 環境変数($HOMEなど)や、 “<”, “>”, “|”, “;” などのパイプやリダイレクトは使えません（←ansible shell との違い）
                    #search: ansible shell
                debug:       #// デバッグ用に変数の値の表示や任意の文字列メッセージの表示をします  #keyword: ansible debug
                    基本サンプル:
                        #search: Ansible tasks YAML
                        -   name: debug print
                            debug: msg="{{ result }}"
                            failed_when: true   #// 流れないようにタスク実行後に終了させます
                        #// environment フィールド（環境変数）は Ansible の変数ではないので、
                        #// debug タスクに environment フィールドをコピーしても見えません。
                        #// {{ result }} で展開されるのは Ansible 変数だけです。
                        #// 辞書を指定すると、すべてのキーと値が表示されます
                    型の表示:
                        -   name: debug print
                            debug: msg="type={{ result | type_debug }}"
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/debug_module.html  #template: __DocumentVersion__
                    サンプル playbook.yml:
                        -   hosts: all
                            tasks:
                                -   name: print message
                                    debug:
                                        msg: "{{ result }}"  #// result 変数の値を表示します（msg パラメーターの機能）

                                -   name: print variable
                                    debug:
                                        var: result  #// result 変数の値を表示します（var パラメーターの機能）

                                -   name: print message
                                    debug:
                                        msg: result  #// result と表示します（msg パラメーターの機能）
                    応用サンプル playbook.yml:  #// 以下にいくつかあります
                        -   hosts: all
                            become: true
                            tasks:
                                -   name: exec uptime
                                    command: /usr/bin/uptime   #// コマンドを実行します
                                    register: result           #// コマンドの実行結果を result 変数に格納します
                                -   name: debug print
                                    debug: var=result          #// result 変数の値を表示します（var パラメーターの機能）
                                -   name: debug print 2
                                    debug: msg="debug message" #// 任意のメッセージを表示します（msg パラメーターの機能）
                                -   debug: var=result
                                -   debug: msg="debug message"
                    上記サンプルの 出力例: |
                        $ ansible-playbook  playbook.yml

                        PLAY [all] ************************************************************************************************************************************************************

                        TASK [Gathering Facts] ************************************************************************************************************************************************
                        ok: [ansibletest]

                        TASK [exec uptime] ****************************************************************************************************************************************************
                        changed: [ansibletest]

                        TASK [debug1] *********************************************************************************************************************************************************
                        ok: [ansibletest] => {
                            "result": {
                                "changed": true, 
                                "cmd": [
                                    "/usr/bin/uptime"
                                ], 
                                "delta": "0:00:00.014018", 
                                "end": "2021-05-28 02:29:07.928580", 
                                "failed": false, 
                                "rc": 0, 
                                "start": "2021-05-28 02:29:07.914562", 
                                "stderr": "", 
                                "stderr_lines": [], 
                                "stdout": " 02:29:07 up  1:48,  0 users,  load average: 0.33, 0.16, 0.09", 
                                "stdout_lines": [
                                    " 02:29:07 up  1:48,  0 users,  load average: 0.33, 0.16, 0.09"
                                ]
                            }
                        }

                        TASK [debug2] *********************************************************************************************************************************************************
                        ok: [ansibletest] => {
                            "msg": "debug message"
                        }

                        PLAY RECAP ************************************************************************************************************************************************************
                        ansibletest                : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
                    環境変数を表示します: |
                        -   name: show env with become
                            ansible.builtin.command: env
                            register: result
                        -   debug:
                                var: result.stdout_lines
                    -vvv オプションを付けて実行します:
                        #search: ansible-playbook -vvv
                    関連:
                        プラグインのデバッグ:  #search: Ansible plug in debug
                        早く動作確認します:  #search: Ansible fast development
                dnf:         #// dnf コマンド。 CentOS7 で RPM（パッケージの形式）をインストールします  #keyword: ansible dnf
                    #ref: https://docs.ansible.com/ansible/2.9_ja/modules/dnf_module.html  #template: __DocumentVersion__
                    CentOS8 の dnf は CentOS7 の yum です:  #search: ansible yum
                    サンプル.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: download epel-release  #template) __Name__
                                become: yes
                                dnf:
                                    name: https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm  #template) name: __URL__
                                    state: present  #search: Ansible yum state
                    #search: ansible yum
                docker_image:  #// Docker のイメージのビルドなど  #keyword: Ansible docker_image module
                    #ref: https://docs.ansible.com/ansible/2.9_ja/modules/docker_image_module.html  #template: __DocumentVersion__
                docker_container:  #// Docker コンテナーを起動します  #keyword: Ansible docker_container module,  docker_container,  Ansible docker run
                    #ref: https://docs.ansible.com/ansible/2.9_ja/modules/docker_container_module.html  #template: __DocumentVersion__
                    #search: docker run
                    起動します:  #// docker run コマンド相当
                        #search: Ansible tasks YAML
                        #// docker run -d  --name __Name__  --restart __Restart__  \
                        #//     -p __HostOSPortNum__:__GuestOSPortNum__  \
                        #//     -v __HostOSPath__:__GuestOSPath__  \
                        #//     -e __EnvironmentVariableName__=__Value__  \
                        #//     __DockerImageName__:__TagOrVersion__
                        name: Start __Name__ docker container
                        docker_container:
                            name: __Name__
                            image: __DockerImageName__:__TagOrVersion__  #search: Docker image name  #// ローカルの場合、タグは必須です  #search: Ansible docker_container module local image
                            state: started
                            restart_policy: __Restart__  #// always, "no"  (no では NG)
                            ports:
                                -   __HostOSPortNum__:__GuestOSPortNum__
                            volumes:
                                -   __HostOSPath__:__GuestOSPath__
                            env:
                                __EnvironmentVariableName__: __Value__
                            command: >  #search: YAML multi lines
                                __Command__  __Parameter1__
                                __Parameter2__
                    プロキシや環境変数を設定します:  #keyword: Ansible docker_container proxy
                        #search: Ansible yum proxy environment variable
                        基本:
                            root ユーザーの場合: |  #// Docker コンテナー内の root
                                -   name: Start docker container
                                    docker_container:
                                        env:
                                            http_proxy: '__ProxyFQDN__'
                                            https_proxy: '__ProxyFQDN__'
                            一般ユーザーの場合: |  #// gitlab-runner ユーザーの場合
                                #// 未確認
                                -   name: Set environment variables in gitlab-runner user in docker container
                                    shell: |
                                        docker exec -i  gitlab-runner-1  su --login  gitlab-runner  --command  \
                                            "echo  'http_proxy={{ lookup('env', 'http_proxy') }}' > /home/gitlab-runner/.bashrc;
                                            echo  'https_proxy={{ lookup('env', 'https_proxy') }}' >> /home/gitlab-runner/.bashrc"
                        IP アドレスを設定する場合:  #// dig を使う場合
                            準備: Ansible の dig ルックアップ プラグイン をインストールしてください
                            プロキシ サーバー の FQDN から IP アドレスを設定する場合:
                                        http_proxy: 'http://{{ lookup("dig", "__ProxyFQDN__") }}:8080/'
                                        https_proxy: 'http://{{ lookup("dig", "__ProxyFQDN__") }}:8080/'
                            プロキシ サーバー の FQDN が入っている環境変数から IP アドレスを設定する場合:
                                        http_proxy: "http://{{ lookup('dig', (lookup('env', 'http_proxy') | urlsplit('hostname'))) }}:8080"
                                        https_proxy: "http://{{ lookup('dig', (lookup('env', 'https_proxy') | urlsplit('hostname'))) }}:8080"
                            VirtualBox の VM 内の Docker コンテナーに設定する場合:
                                playbook:
                                            http_proxy: 'http://172.17.0.1:8080/'
                                            https_proxy: 'http://172.17.0.1:8080/'
                                        #// 172.17.0.1 は Docker コンテナー から見た Docker ホストの IP アドレスです
                                調べ方: |  #// Docker コンテナー から見た Docker ホストの IP アドレス
                                    $ ip addr
                                    ...
                                    4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default 
                                        link/ether 02:42:a4:82:5f:3c brd ff:ff:ff:ff:ff:ff
                                        inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
                                        valid_lft forever preferred_lft forever
                    関連 >> docker exec:
                        状況: Ansible 2.9 には docker exec に相当するモジュールは提供されていません
                        代用: |
                            -   name: docker exec
                                become: true
                                shell: docker exec -i  __ContainerName__  __ComandAnsParameters__
                get_url:     #// wget, curl コマンド。  #keyword: ansible get_url, Ansible wget curl
                    #ref: https://docs.ansible.com/ansible/2.9_ja/modules/get_url_module.html  #template: __DocumentVersion__
                    参考: https://nwengblog.com/ansible-get-url/
                    ダウンロードします:
                        サンプル.yml: |
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: download bind
                                    become: yes  #// sudo が必要な場所にダウンロードする場合は必要
                                    get_url:
                                        url: https://downloads.isc.org/isc/bind9/9.16.2/bind-9.16.2.tar.xz
                                        dest: /usr/local
                        実行ファイルをダウンロードする場合:
                            get_url:
                                mode: 755  #search: chmod
                    tar.gz を展開してインストールするサンプル:  #search: Ansible tar example
                    HTTP GET して特定のステータスになるまで待つ場合:  #search: Ansible uri
                group:       #// ユーザー グループ  #keyword: ansible group
                    #ref: https://docs.ansible.com/ansible/latest/collections/ansible/builtin/group_module.html
                    サンプル playbook.yml:
                        -   name: Add a group
                            become: yes
                            group: name=____ gid=____
                    関連: #search: ansible user
                pause:
                    公式: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/pause_module.html  #template: __DocumentVersion__
                    指定した時間だけ待ちます:
                        playbook.yml:
                            -   hosts: all
                                pause:
                                    seconds: 10  #// seconds または minutes
                rpm_key:     #keyword: ansible rpm_key  #// GPG キーをインストールします  #search: RPM GPG key
                    公式: #ref: https://docs.ansible.com/ansible/latest/collections/ansible/builtin/rpm_key_module.html
                    サンプル.yml:
                        -   tasks:
                            #// rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022
                            -   name: Import a RPM GPG key from a URL
                                become: yes
                                rpm_key:
                                    key: https://repo.mysql.com/RPM-GPG-KEY-mysql-2022
                                    state: present
                script:      #keyword: Ansibile script  #// スクリプトを転送して実行します  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/script_module.html
                service:     #// サービス（デーモン）の起動など  #keyword: ansible systemctl, ansible service
                    注意: 改良版もあります  #search: ansible systemd
                    参考:
                        - #ref: https://docs.ansible.com/ansible/2.9_ja/modules/service_module.html  #template: __DocumentVersion__
                        - #search: systemctl
                    関連:
                        status: #search: ansible_facts services   #// サービスが起動中であることをチェックします
                        daemon-reload: #search: Ansible daemon-reload
                    サンプル.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要

                            -   name: (@__ServerName__) start __ServiceName__  #// 起動していなかったら起動し、再起動時も起動するよう設定します
                                #// (@__ServerName__)$ sudo systemctl restart __ServiceName__
                                #// (@__ServerName__)$ sudo systemctl enable  __ServiceName__
                                become: yes
                                service:
                                    name: __ServiceName__
                                    state: started
                                    enabled: yes    #// 再起動時も起動します

                            -   name: start and enable service short hand  #// （短縮形）起動していなかったら起動します
                                service: name="{{ service_name }}" state=started enabled=yes

                            -   name: stop service httpd, if started  #// 起動してたら終了します
                                become: yes
                                service:
                                    name: httpd
                                    state: stopped

                            -   name: restart service httpd, in all cases  #// 再起動します
                                become: yes
                                service:
                                    name: httpd
                                    state: restarted

                            -   name: reload service httpd, in all cases  #// リロードします
                                become: yes
                                service:
                                    name: httpd
                                    state: reloaded

                            -   name: enable service httpd, and not touch the state  #// systemctl enable 相当
                                become: yes
                                service:
                                    name: httpd
                                    enabled: yes  #// state: enabled ではないので注意

                            -   name: start service foo, based on running process /usr/bin/foo
                                become: yes
                                service:
                                    name: foo
                                    pattern: /usr/bin/foo  #// このプロセスが起動しているのを待ってからサービスを起動します(?)
                                    state: started

                            -   name: restart network service for interface eth0
                                become: yes
                                service:
                                    name: network
                                    state: restarted
                                    args: eth0                  #// 引数
                set_fact:    #// 変数定義
                    基本サンプル.yml:  #focus: content  #// content 変数を定義しています
                        -   name: check file content
                            set_fact:
                                content: "{{ lookup('template', '../templates/table.j2') }}"  #search: Ansible lookup template
                shell:       #// シェルのコマンドを対象ホストで実行します。冪等性はありません  #keyword: ansible shell
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/shell_module.html  #template: __DocumentVersion__
                    #// 環境変数($HOMEなど)や、 “<”, “>”, “|”, “;” などのパイプやリダイレクトは使えます（←ansible command との違い） #search: ansible command module
                    #// shell 以外の Ansible モジュールを使う場合、shell よりも command のほうが環境が近いです
                    基本サンプル.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: ____
                                shell: somecommand parameters
                    コマンドが長いとき, 複数行: | #keyword: Ansible shell long command
                        shell: |
                            docker exec -i  __ContainerName__ \
                            __ComandAnsParameters__
                    デバッグ表示: #🌟  #search: Ansible task stdout
                    実行が長いとき:  #// 処理が完了するまで shell タスクのログは表示されないことへの対処方法
                        対処: リダイレクトします  #// 出力をリダイレクトさせれば、処理途中の様子を確認できます
                        サンプル:
                            tasks/main.yml:
                                -   name: guide of next setup-tasks.sh task
                                    debug:
                                        msg: ⚠️ There is during processing output to the file '/vagrant/working/_setup_error.log' (__Project__/working).

                                -   name: long script
                                    shell: ____/rec-stderr --new --stderr ___/_error.log  --  script.sh
                                #search: rec-stderr
                    root ユーザー chdir:  #// root ユーザーで chdir してから実行するサンプル.yml
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: ____
                                shell:
                                    chdir: /current/folder
                                    cmd: somecommand parameters
                    環境変数: #keyword: Ansible shell env  #// 環境変数を設定してコマンドを実行する場合
                        #search: Ansible environment in server
                    実行環境:  #// PATH, ユーザー  #// コマンドを実行する ターゲット ノード の環境
                        PATH: #keyword: Ansible PATH
                            デフォルト:
                                Ansible 接続時: |  #// /etc/profile などの内容は反映されないようです
                                    /usr/local/bin:/usr/bin
                                VSCode 接続時:
                                    共通: /home/vagrant/.vscode-server/bin/e2816fe719a4026ffa1ee0189dc89bdfdbafb164/bin/remote-cli:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/vagrant/.local/bin:/home/vagrant/bin
                                    CentOS7: /etc/profile の内容 + 共通
                            追加:  #// デプロイ先でコマンドを実行できるように、デプロイ先に PATH を追加します
                                Ansible の中で実行するときの PATH:
                                    方法:
                                        - environment >> PATH に定義します。値に $PATH を指定しても /usr/local/bin:/usr/bin などは定義されません
                                        - tasls >> shell >> environment は仕様にありません
                                    サンプル: |
                                        -   hosts: "{{ hosts }}"
                                            environment:
                                                PATH: /usr/local/bin:/usr/bin:/home/vagrant/.pyenv/bin:/home/vagrant/.pyenv/shims
                                            tasks:

                                                -   name: echo
                                                    shell: echo $PATH

                                                -   name: command test
                                                    shell: pyenv --version
                                    #ref: https://github.com/ansible/ansible/pull/8651
                                Ansible の外で実行するときの PATH:  #// 後で VM 内のシェルから実行できるようにする場合
                                    CentOS7:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/playbooks/add_path_in_centos_controler.yml
                                        サンプル: |
                                            -   hosts: "{{ hosts }}"
                                                tasks:

                                                -   name: 'Add {{ extra_path }} if PATH does not exist for CentOS'  #// 別の行に追加する
                                                    become: true
                                                    lineinfile:
                                                        path: /etc/profile
                                                        line: 'export PATH="$PATH:{{ extra_path }}"'
                                                        insertafter: EOF
                                                    when: lookup('file', '/etc/profile') is not search('^\s*PATH\s*=')

                                                -   name: 'Add {{ extra_path }} to PATH for CentOS'  #// 同じ行に追加する
                                                    become: true
                                                    lineinfile:
                                                        path: /etc/profile
                                                        regexp: 'export PATH=(["])((?!.*?{{ extra_path }}).*?)(["])$'
                                                        line: 'export PATH=\1\2:{{ extra_path }}\3'
                                                        backrefs: yes
                                        #ref: https://stackoverflow.com/questions/56560173/ansible-how-to-add-modify-path-variable-in-centos
                                    Ubuntu:
                                        /etc/environment
                                うまくいかなかった方法:
                                    .bashrc: |
                                            - name: Adding the path in the bashrc files
                                            lineinfile: dest=/root/.bashrc line='export PATH=$PATH:path-to-mysql/bin' insertafter='EOF' regexp='export PATH=\$PATH:path-to-mysql/bin' state=present
                                            #// If set the PATH in .bash_profile, it will be no effect.

                                            - name: Source the bashrc file
                                            shell: source /root/.bashrc

                                            - name: Start the mysql client
                                            shell: mysql -e "show databases";
                                        #ref: https://stackoverflow.com/questions/27733511/how-to-set-linux-environment-variables-with-ansible
                        whoami: vagrant
                        id -u: 1000
                    標準入力へ: #keyword: Ansible shell module stdin
                        入力内容指定:
                            stdin: "y"
                        control ノードのファイルの内容を送ります:
                            JSON の場合: |
                                tasks:
                                    -   name: ____
                                        shell:
                                            cmd: "______"
                                            stdin: "{{ lookup('file', '__FilePathInControlNode__') | from_json | to_nice_json }}"
                                    #// または
                                            stdin: "{{ lookup('template', '__FilePathInControlNode__') | from_json | to_nice_json }}"
                            Jinja2 のタグが付いた JSON の場合: |  #search: Ansible lookup
                                JSON の場合の file を template に置き換えます   （未確認）
                                    stdin: "{{ lookup('template', '__FilePathInControlNode__') | from_json | to_nice_json }}"
                            それ以外の YAML の制御文字がある場合:
                                使えないようです。target ノードにファイルを作り、ファイルから stdin に入力させます
                            from_json | to_nice_json:
                                #// 以下は cat を実行したときに Ansible のログに出力される内容です。加工されているそうです
                                (nothing): |
                                    "{'jwks_url': 'http://localhost:4646/.well-known/jwks.json', 'jwt_supported_algs': ['RS256', 'EdDSA'], 'default_role': 'nomad-workloads'}"
                                from_json: |
                                    "{'jwks_url': 'http://localhost:4646/.well-known/jwks.json', 'jwt_supported_algs': ['RS256', 'EdDSA'], 'default_role': 'nomad-workloads'}"
                                to_nice_json: |
                                    "\"{\\n  \\\"jwks_url\\\": \\\"http://localhost:4646/.well-known/jwks.json\\\",\\n  \\\"jwt_supported_algs\\\": [\\\"RS256\\\", \\\"EdDSA\\\"],\\n  \\\"default_role\\\": \\\"nomad-workloads\\\"\\n}\""
                                from_json | to_nice_json: |
                                    "{\n    \"default_role\": \"nomad-workloads\",\n    \"jwks_url\": \"http://localhost:4646/.well-known/jwks.json\",\n    \"jwt_supported_algs\": [\n        \"RS256\",\n        \"EdDSA\"\n    ]\n}"
                                quote: |
                                    "'{\n  \"jwks_url\": \"http://localhost:4646/.well-known/jwks.json\",\n  \"jwt_supported_algs\": [\"RS256\", \"EdDSA\"],\n  \"default_role\": \"nomad-workloads\"\n}'"
                    応用サンプル.yml:  #// 未確認
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: ____
                                shell: /usr/bin/somecommand  options1
                                    options2
                                args:
                                    chdir: __Directory__
                                ignore_errors: True       #search: ansible ignore_errors
                                register: result  #search: ansible register
                    warn, 警告を抑止します:  #focus: warn
                        -   name: install poetry
                            shell:
                                cmd: curl -sSL https://install.python-poetry.org  | sponge |  POETRY_VERSION={{ poetryVersion }}  python -
                                warn: false
                    tar.gz を展開してインストールするサンプル:  #search: Ansible tar example
                systemd:     #// サービス（デーモン）の起動など。service の改良版  #keyword: ansible systemctl, ansible systemd
                    #// ansible 2.2 以降
                    公式:  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/systemd_module.html  #template: __DocumentVersion__
                    サンプル:
                        #// sudo systemctl daemon-reload    #keyword: Ansible daemon-reload
                        #// sudo systemctl restart emperor.uwsgi.service
                        #// sudo systemctl enable  emperor.uwsgi.service
                        -   name: restart emperor.uwsgi.service
                            become: yes
                            systemd:
                                name: emperor.uwsgi.service  #// 複数指定することはできません。loop を使います  #search: Ansible loop
                                state: restarted
                                daemon_reload: yes
                                enabled: yes

                        #// sudo systemctl stop cron
                        -   name: stop cron, if running
                            systemd:
                                name: cron
                                state: stopped
                    関連:
                        service モジュール:  #search: ansible service
                        systemctl status の Ansible:  #search: Ansible systemctl status
                sysvinit:    #// SysVサービスの起動など  #keyword: ansible sysvinit, ansible init.d
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/sysvinit_module.html  #template: __DocumentVersion__
                    サンプル:
                        __Playbook__.yml:
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                #// sudo /etc/init.d/__ServiceName__ start
                                -   name: make sure __ServiceName__ is started
                                    sysvinit:
                                        name: __ServiceName__
                                        state: started
                                        enabled: yes
                reboot:      #// 再起動  #keyword: ansible reboot
                    #ref: https://docs.ansible.com/ansible/latest/collections/ansible/builtin/reboot_module.html
                    サンプル playbook.yml:
                        #// reboot
                        -   name: Unconditionally reboot the machine with all defaults
                            become: yes
                            reboot:
                uri:  #// HTTP  #keyword: Ansible uri,  Ansible (url),  Ansible https get put post delete
                    公式: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/uri_module.html  #template: __DocumentVersion__
                    HTTP GET して特定のステータスになるまで待つ場合:
                        GET した内容を表示するサンプル.yml: |
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: HTTP GET
                                    uri:
                                        method: GET
                                        url: "http://node1:9200/_snapshot/my_backup/_all?pretty"
                                        timeout: 30  #// 30 second = default
                                        return_content: yes
                                    register: result
                                -   name: print GET response content
                                    debug:
                                        msg: "{{ result.content }}"
                        JSON がレスポンスに来る場合のサンプル.yml: |
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: Wait for status green to load elasticsearch.yml
                                    uri:
                                        method: GET
                                        url: "http://node1:9200/_cluster/health/?level=shards&pretty"
                                        timeout: 30  #// 30 second = default
                                    register: result
                                    until: "result.json.status | default('') == 'green'"  #search: Ansible until
                                    delay: 3
                                    retries: 100  #// リトライ最大回数。これを超えると FAILED になります
                        JSON 以外がレスポンスに来る場合のサンプル.yml: |
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: Wait for starting ElasticSearch service
                                    uri:
                                        method: GET
                                        url: "http://node1:9200/_cat/nodes?v"
                                        timeout: 30  #// 30 second = default
                                        return_content: yes
                                    register: result
                                    until: "'node1' in result.content"  #search: Ansible until
                                    delay: 3
                                    retries: 100  #// リトライ最大回数。これを超えると FAILED になります
                        参考:
                            公式: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/uri_module.html  #template: __DocumentVersion__
                            議論: #ref: https://gist.github.com/mikeifomin/67e233cd461331de16707ef59a07e372
                    HTTP PUT して成功を確認する場合:
                        サンプル.yml: | #keyword: Ansible uri PUT example
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: Set ElasticSearch reposirory and Wait for success
                                    uri:
                                        method: PUT
                                        url: "http://node1:9200/_snapshot/my_backup?pretty"
                                        headers:
                                            "Content-Type": "application/json"
                                        body:  #// body: | でもよい
                                            {
                                                "id": "1",
                                            }
                                        body_format: json
                                    register: result
                                    until: "result.json.acknowledged | default(false) == true"  #search: Ansible until
                                    delay: 3
                                    retries: 100
                    HTTP PUT >> ファイルをアップロードする場合:
                        手順: body の代わりに src を指定します
                        サンプル:
                            #search: Ansible uri PUT example
                            変更前: |
                                body:
                                    {
                                        "id": "1",
                                    }
                            変更後: |
                                src: __PathInPlayingServer__
                    パスワードが必要な場合: #ref: https://stackoverflow.com/questions/63702789/how-to-upload-a-file-to-nexus-using-ansible-modules
                    ダウンロードする場合: #search: ansible get_url
                user:        #// ユーザー  #keyword: ansible user
                    #ref: https://docs.ansible.com/ansible/latest/collections/ansible/builtin/user_module.html
                    ユーザーが所属するグループを追加します:
                        グループを作る場合:  #search: ansible group
                        サンプル playbook.yml:  #// vagrant ユーザーが無ければ作り、docker グループに所属させます。既存の所属グループはそのまま所属します
                            #focus: vagrant, docker
                            #// sudo gpasswd --add  $USER  docker
                            -   name: Make the current user belong to the docker group
                                become: yes
                                user:
                                    name: vagrant
                                    shell: /bin/bash   #// 省略可能
                                    groups: docker
                                    append: yes
                    ユーザーを追加します:
                        サンプル playbook.yml:
                            -   name: Add a user
                                user: name=____ uid=____ group=____ update_password=always password=____
                    ホーム フォルダー を変更します: #keyword: ansible user home
                        新規作成する場合:
                            -   name: Create user1 HOME folder
                                become: yes
                                user:
                                    name: user1
                                    create_home: yes
                                    home: /home/user1
                        #search: Linux HOME folder
                    関連: #search: ansible group  #search: ansible acl
                yum:         #// yum コマンド。 CentOS7 で RPM（パッケージの形式）をインストールします  #keyword: ansible yum
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/yum_module.html  #template: __DocumentVersion__
                    サンプル:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: ____
                                become: true
                                yum:
                                    pkg: ntp        #search: Ansible yum pkg
                                    state: present  #search: Ansible yum state
                                    allow_downgrade: yes
                    複数指定する場合:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: ____
                                yum:
                                    name: [python-devel, python-crypto, libffi-devel]
                                become: true
                                become_user: root
                                environment: "{{ proxy_env }}"
                    pkg キー: #keyword: Ansible yum pkg  #// name キーも同じ意味
                        - __PackageName__
                        - __PackageName__-__Version__  #// allow_downgrade: yes を設定する必要があります
                        - __URL__
                        - [ __PackageName__, __URL__, ... ]  #// 複数指定できます
                    state キー: #keyword: Ansible yum state
                        installed, present:  インストールした状態にします。 OS を再起動したときもサービスは自動的に起動します(systemctl enable 相当)
                        removed, absent:  インストールしていない状態にします。右記リンク先に注意  #search: Ansible uninstall services
                        latest:  最新バージョンがあるかチェックして、あったら再インストールします
                            毎回チェックするため時間がかかります
                        （タスクが無い場合）: インストールの状態はそのままです。absent のタスクを実行しないとアンインストールされません
                    allow_downgrade キー:
                        yes: ダウングレードを許可します
                        no: 古いバージョンをインストールしようとしても無視します
                    disablerepo キー:
                        dnf install --disablerepo オプションと同じ。コンマ区切り
                    Java 8 をインストールする Ansible Playbook:  #keyword: Java 8 Ansible Playbook
                        -   hosts: ____
                            tasks:
                                -   name: install Java 8
                                    become: yes
                                    yum:
                                        pkg: java-1.8.0-openjdk
                                        state: present
                    jq RPM をインストールする Ansible Playbook:  #keyword: ansible jq
                        -   name: install epel-release
                            become: yes
                            yum:
                                name: epel-release
                                state: present
                        -   name: install jq RPM package for _____
                            become: yes
                            yum:
                                pkg: jq
                                state: present
                                enablerepo: epel
                    CentOS7 の yum は CentOS8 の dnf です:  #search: ansible dnf  #keyword: ansible RPM
                    更新されないとき: state="latest" update_cache="yes"
                    トラブルシューティング: #keyword: Ansible yum trouble
                        proxy 環境変数: #keyword: Ansible yum proxy environment variable
                            #search: Ansible proxy  #search: Ansible debug
                        サーバー（repomd.xml）にアクセスできるか確認します:
                            Ansible で確認する場合:
                            問題がある場合の対処法:
                                #search: repodata/repomd.xml trouble
                        yum repos の内容を確認します:  #search: yum repos
                            less  /etc/yum.repos.d/____.repo
                                baseurl
                                proxy
                        repolist に対象バージョンがあるか確認します:
                            問題がある場合の対処法:
                                対処A. RPM を登録します:
                                対処B. リポジトリがミラーの場合、ミラーを作り直します:
                yum_repository:  #// /etc/yum.repos.d/____.repo ファイルを作ります
                    ❗注意: dnf config-manager --add-repo コマンド で .repo ファイルダウンロードすることと同じ処理をする場合、
                        yum_repository モジュールは使いません。shell モジュールを使います
                    参考: #ref: https://docs.ansible.com/ansible/latest/collections/ansible/builtin/yum_repository_module.html
                    サンプル:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: Add __RepositoryName__ repository
                                become: yes
                                ansible.builtin.yum_repository:
                                    baseurl: __URL__
                                    name: __SectionInRepoFile__       #// .repo ファイル のセクション名
                                    description: __NameInRepoFile__   #// .repo ファイル の name キー
                                    enabled: yes
                                    gpgcheck: yes
                yum clean all:  #keyword: Ansible yum clean all
                    サンプル:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: yum clean all in target host
                                become: yes
                                shell:
                                    cmd: yum clean all
                                    warn: no  #// 右の警告を表示しないようにします。[WARNING]: Consider using the yum module rather than running 'yum'.
            カタログ >> プログラミング言語, パッケージ:  #glossary: Ansible programming module
                git: #keyword: Ansible git  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/git_module.html  #// git clone/checkout でデプロイ（ダウンロード）します
                    基本:
                        サンプル.yml:
                            -   name: ____
                                git:
                                    repo: 'https://foosball.example.org/path/to/repo.git'
                                    dest: /srv/checkout
                                    version: release-1.1.x
                        version: ブランチ名、タグ名など。省略時は HEAD（git clone のデフォルトの動きと同じ）
                            ただし、git clone 済みの場合はブランチを切り替えることができないようです。（git 1.8.3.1）
                            手動で git checkout してください。
                    実行が短すぎるとき:
                        TASK [__TaskName__:set_fact] のときは、まだ git clone などを実行していません。
                        TASK [__TaskName__] のときに実行しています。
                    実行が長すぎるとき:
                        git clone|checkout コマンドを使ったほうが早いかもしれません。ただし冪等性を確保するのが難しいかもしれません
                    途中で止まることがあるとき:  #// .git フォルダー が中途半場な状態になって、git タスクが動かなくなるとき
                        トランザクションを作ります:  #search: Ansible transaction file
                    差分表示が長すぎるとき:  #search: disable Ansible diff
                    Git サーバーに接続できないとき:  #keyword: Ansible git URL trouble
                        手順: ansible-playbook コマンドを実行して、git モジュールのタスクで
                        エラー: |  #keyword: unable to access Failed to connect to Network is unreachable
                            fatal: unable to access '__URL__': Failed to connect to __IPAddress__: Network is unreachable"
                        対処A:
                            Ansible を使わずに git clone できることを確認します。プロキシやリポジトリの URL に typo が無いかチェックします
                                echo  $https_proxy
                                git clone https://____.git
                                rm -rf __GitWorkingFolder__
                        対処B: |
                            Ansible で実行するときの https_proxy 環境変数をチェックします。
                                ansible-playbook __Options__  --check  -vvv  --start-at-task "__GitModuleTask__"  --step
                                (N)o/(y)es/(c)ontinue: y
                                ... https_proxy=__ProxyURL__ ...
                        対処C:
                            https しか受け付けないサーバーの場合は、URL は https から始めるようにします
                pip:
                    サンプル: |  #keyword: Ansible install poetry
                        -   name: install poetry
                            pip:
                                name: "poetry"      #// 追加するパッケージ
                                version: "1.4.2"    #// 追加するパッケージのバージョン
                                executable: "/home/user1/.pyenv/versions/3.9.1/bin/pip"   #// パッケージのインストール先の仮想環境の中の pip
                                extra_args: "--no-index  -f /home/user1/.pyenv/pypi"       #// -f オプションは、パッケージ（.wheel ファイル）が置いてある場所 
            カタログ >> ファイルの編集: #keyword: ansible text file  #glossary: Ansible file module
                acl: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/acl_module.html  #// setfacl コマンド
                blockinfile: #keyword: ansible blockinfile module  #// サーバー内の テキスト ファイル を複数行編集します
                    注意: ❗ BEGIN ANSIBLE MANAGED BLOCK などのタグが付きます
                    公式: https://docs.ansible.com/ansible/2.9_ja/modules/blockinfile_module.html  #template: __DocumentVersion__
                    基本:
                        サンプル.yml:
                            -   name: ____
                                blockinfile:
                                    path: /etc/ssh/sshd_config
                                    create: yes  #// 省略すると no
                                    block: |

                                        # comment
                                        PasswordAuthentication no
                        出力のサンプル: |  #// 指定したテキストの前後の行にマーカーが付きます  #keyword: BEGIN ANSIBLE MANAGED BLOCK
                            __ExistingContent__
                            # BEGIN ANSIBLE MANAGED BLOCK

                            # comment
                            PasswordAuthentication no
                            # END ANSIBLE MANAGED BLOCK
                    一部を変数の値に置き換える:
                        サンプル.yml:
                            -   name: ____
                                vars:
                                    __This_IP_Address__: "{{vagrant_network[inventory_hostname].ipv4.address}}"
                                    __DB1_IP_Address__:  "{{vagrant_network.db1.ipv4.address}}"  #search: Ansible dictionary
                                blockinfile:
                                    path: /path/to/file
                                    create: yes  #// 省略すると no
                                    block: |

                                        # comment
                                        IP: {{__DB1_IP_Address__}}
                    marker:  #// 編集する範囲を示すマーカー。デフォルトは "ANSIBLE MANAGED BLOCK"。複数の範囲を編集するときは衝突しないようにマーカーを編集します
                        設定のサンプル:
                            デフォルトと同じ設定にするとき:
                                blockinfile:
                                    marker: ANSIBLE MANAGED BLOCK
                        マーカーのサンプル:  #search: BEGIN ANSIBLE MANAGED BLOCK
                        改行を指定したとき: 改行が空白に置き換わったマーカーになります
                    insertbefore:  #// 編集する範囲のすぐ下を指す検索キーワード
                        設定のサンプル:  #focus: after insert
                            blockinfile:
                                insertbefore: # after insert
                        実行後のファイルの内容:
                            # BEGIN ANSIBLE MANAGED BLOCK
                            ...
                            # END ANSIBLE MANAGED BLOCK
                            # after insert
                copy:        #keyword: ansible copy module         #// ファイルをアップロードします
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/copy_module.html  #template: __DocumentVersion__
                    サンプル プロジェクト:
                        #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/text_file/replace/1st/playbook.yml
                        #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/file_example/text_file/lookup/playbook.yml
                    サンプル1.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: copy to __PathInServer__
                                copy:
                                    src: ./__RelativePathInControler__
                                    dest: __PathInServer__  #// リモートの $HOME からの相対パス
                    末尾の改行を維持します, 秘密鍵のアップロード: #keyword: ansible copy module newline EOF,  Ansible SSH key format
                        #// Ansible の仕様では SSH キー のデプロイで SSH キーの書式（要改行）に合わなくなるため、SSH キーのアップロードそれぞれで対応が必要です
                        エラー, 状況: |
                            invalid format __User__@__Host__  Permission denied (publickey).
                        議論:  #ref: https://github.com/ansible/ansible/issues/30829
                            既存のファイルを改ざんする意味がわかりません。
                        対処:  #// Ansible 2.0 以降
                            line(content) 属性がある場合:
                                タスクを追加します: |  #// mode は "755", "600" など
                                    -   name: Ensure newline at end of file  # https://github.com/ansible/ansible/issues/30829
                                        lineinfile:
                                            path: ____
                                            line: ""
                                            insertafter: EOF
                                            mode: "600"
                            src 属性がある場合:
                                タスクを変更します: |
                                    -   name: Copy file with newline preserved
                                        template:
                                            src: ____
                                            dest: ____
                    dest がフォルダー .yml:  #// dest の末尾に / が無いとフォルダーが存在しないときにエラーになります
                        #前略  #see-above: サンプル1.yml
                        copy: src=index.html  dest=/var/www/html/
                    フォルダーをコピーします:
                        フォルダーの内容をコピーする場合:
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: copy to __PathInServer__
                                    copy:
                                        src: ./_tmp_folder/     #// 末尾にスラッシュ
                                        dest: /path/to/folder   #// ./_tmp_folder/__File__ の内容は /path/to/folder/__File__ にできます
                        フォルダーをコピーする場合:
                                        src: ./_tmp_folder
                                        dest: /path/to/folder   #// /path/to/folder/_tmp_folder ができます
                    ファイルの内容を Ansible から指定します: #keyword: Ansible copy content
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: Make a file in __PathInServer__
                                copy:
                                    dest: /path/to/file
                                    content: "{{ variable }}"
                    ターゲット ホスト 内 のコピー:
                        shell モジュールを使います。copy モジュールは使いません  #search: ansible shell
                    ファイルの属性の詳細.yml:
                        #前略  #see-above: サンプル1.yml
                        copy: src=/etc/ansible/hosts dest=/etc/ansible/hosts
                                owner=root group=root mode='644'
                    ログ表示:  #// コピーしたときに表示される内容
                        ファイルの内容を非表示にします:  #search: Ansible no_log
                        表示される checksum: SHA1  #search: SHA1
                    除外:  #// copy モジュールでは特定のフォルダーなどをコピーから除外することはできませんが方法はあります
                        .gitignore の対象外のみコピーする場合:  #search: Ansible .gitignore
                file:        #keyword: ansible file module         #// ファイルまたはフォルダーまたはリンクを作ります。または削除します
                    公式:  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/file_module.html  #template: __DocumentVersion__
                    フォルダーを作るサンプル.yml:  #keyword: ansible mkdir,  ansible folder
                        基本:  #focus: path
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: create sub_folder  
                                    become: yes  #// sudo が必要なときのみ
                                    file:
                                        state: directory
                                        path: __SubFolder__
                                        recurse: true  #// true = 親の親が無ければ作ります
                        親フォルダーを作ります:
                            path: "{{ __FilePath__ | dirname }}"
                        所有者などを設定します:  #focus: owner, group, mode
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: create sub_folder  
                                    become: yes  #// 作るのに root 権限が必要なときのみ
                                    file:
                                        state: directory
                                        path: __SubFolder__
                                        owner: user
                                        group: group
                                        mode: "644"
                            #search: chown
                    ファイルを作ります:
                        アップロードする場合:  #search: ansible copy  #search: ansible template module
                        空のファイルを作る場合:  #keyword: ansible empty file touch
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: create new file                    #template) __Name__
                                    file:
                                        path: temporary_file
                                        state: touch
                        編集と新規作成の両方に対応する場合:  #search: Ansible lineinfile create
                        ファイルの内容を playbook に書く場合:  #search: Ansible copy content
                    シンボリックリンクを作ります:  #keyword: ansible ln
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: make symbolic link
                                become: yes  #// sudo が必要なときのみ
                                file:
                                    state: link
                                    path: sub_folder_or_file  #// リンク元。作られるリンクのファイル
                                    src:  sub_folder_or_file  #// src だけどリンク先。実体のあるファイル
                        #// ln コマンドと異なり、すでにリンクが存在していてもリンクのファイルは更新されます
                    ファイルやフォルダーを削除するサンプル.yml:  #keyword: ansible rm,  Ansible file delete remove
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: remove sub_folder_or_file  
                                become: yes  #// sudo が必要なときのみ
                                file:
                                    state: absent
                                    path: sub_folder_or_file  #template) path: __Path__
                    パーミッション:  #keyword: Ansible chmod permission
                        file:
                            mode: '755'
                    オーナーの変更:  #keyword: Ansible chown  #// ファイルやフォルダーの所有者やグループを変えます
                        通常: |
                            -   hosts: __Hosts__
                                become: yes
                                tasks:
                                    -   name: Recursively change owner of __FolderPath__
                                        shell: chown -hR  __User__:__Group__  __FolderPath__
                        Ansible にこだわる場合: |  #// おそらくかなり遅いです（未確認）
                            -   hosts: __Hosts__
                                become: yes
                                tasks:
                                    -   name: Find all files and directories
                                        ansible.builtin.find:
                                            paths: __FolderPath__
                                            recurse: yes
                                        register: found_items

                                    -   name: Change owner of found files and directories
                                        ansible.builtin.file:
                                            path: "{{ item.path }}"
                                            owner: __User__
                                            group: __Group__
                                        loop: "{{ found_items.files }}"
                    ファイルやフォルダーを移動するサンプル.yml:  #keyword: ansible mv
                        サンプル:
                            -   name: stat node folder
                                stat: path=/home/vagrant/node
                                register: foo_stat

                            -   name: Move node folder
                                become: yes
                                shell: mv  /home/vagrant/node  /opt/node
                                when: foo_stat.stat.exists
                lineinfile:  #keyword: ansible lineinfile module   #// サーバー内の テキスト ファイル を１行ずつ編集します
                    無ければ行を追加します:  #// insertafter キー
                        注意: 編集対象のファイルが無いとエラーになります。先に touch してください #search: ansible touch
                        １行サンプル.yml:
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: add an line if it does not exist
                                    become: yes  #// sudo する場合
                                    lineinfile:
                                        path: /etc/example.conf
                                        line: 'Listen 8080'
                                        regexp: '^Listen '
                                        insertafter: '^#Listen '  #// ファイルの末尾に追加するときは insertafter: EOF。insertbefore にもできます
                        複数行サンプル.yml:  #// 見つかったら置き換えます。見つからなかったら inserafter の設定に従って追加します
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: Set some kernel parameters
                                    lineinfile:
                                        dest: /etc/sysctl.conf
                                        line:   "{{ item.line }}"
                                        regexp: "{{ item.regexp }}"
                                        insertafter: EOF
                                    with_items:
                                        - { regexp: '\[Service\]',   line: '[Service]' }
                                        - { regexp: '^kernel.shmall =', line: 'kernel.shmall = 2097152' }
                                        - { regexp: '^kernel.shmmax =', line: 'kernel.shmmax = 134217728' }
                                        - { regexp: '^fs.file-max =',   line: 'fs.file-max = 65536' }
                        ファイルが無いときは、ファイルを新規作成します: #keyword: Ansible lineinfile create
                            lineinfile:
                                create: yes
                    PATH を追加します:  #search: Ansible PATH
                    １行を置き換えます:  #// backrefs: yes
                        サンプル.yml:
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: replace line exmaple >> set domain-name-servers  #template) __Name__
                                    lineinfile: 
                                        path: /etc/example.conf
                                        regexp: '^(.*)option domain-name-servers(.*)$'
                                        line: 'option domain-name-servers 10.116.184.1,10.116.144.1,10.116.136.1;'
                                        backrefs: yes  #// 置き換えます
                        サンプル.yml の説明:
                            path: 内容を置き換えるファイルのパス
                            regexp: 置き換える行にマッチする正規表現
                            line: 置き換えた後の内容
                            backrefs:  #keyword: Ansible lineinfile backrefs
                                yes: regexp に一致する行が無かったら何もしません。あったら置き換えます
                                no: regexp に一致する行が無かったら追加します（？未確認）
                        参考: https://stackoverflow.com/questions/40788575/replace-a-line-in-a-config-file-with-ansible
                    １行を削除します:  #// state: absent
                        サンプル.yml:
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: absent line exmaple >> remove domain-name-servers
                                    lineinfile: 
                                        path: /etc/example.conf
                                        regexp: '^(.*)option domain-name-servers(.*)$'
                                        state: absent   #// この行があると、regexp にマッチする行を削除します
                    フォルダーを作ります: #search: ansible mkdir
                    正規表現を使わないで編集します:  #// 編集後の内容の行があれば編集しません。無ければ末尾に追加します
                        -   name: ____
                            lineinfile:
                                path: ____
                                line: __Contents__
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/lineinfile_module.html  #template: __DocumentVersion__
                    関連 >> 複数行:
                        replace:  #search: ansible replace module
                        blockinfile:  #search: ansible blockinfile module
                replace:     #keyword: ansible replace module,  Ansible sed  #// サーバー内の テキスト ファイル を編集します
                    公式: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/replace_module.html  #template: __DocumentVersion__
                    サンプル プロジェクト:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/text_file/replace/1st
                    サンプル:
                        実行前: |
                            [section_B]
                            setting_A = 123
                            setting_B = 456
                            setting_C = 789
                        実行後: |
                            [section_B]
                            setting_A = 123
                            setting_B = 55555
                            setting_C = 789
                        playbook.yml :
                            -   name: replace in the file
                                replace:
                                    path: example.txt
                                    regexp: (\[section_B\](.|\s)*?setting_B =)(.*)
                                    replace: \1 55555
                    フィールド:
                        after:  #// 置き換える対象範囲の１行上の行の内容。正規表現ではありません
                            サンプル: '# HTTP listener'
                        before:  #// 置き換える対象範囲の１行下の行の内容。正規表現ではありません
                            サンプル: '# HTTPS listener'
                    参考: #ref: https://stackoverflow.com/questions/47535197/regex-ansible-lineinfile-subsection
                stat:        #keyword: ansible stat module         #// ファイルやフォルダーの存在など
                    ファイルまたはフォルダーが存在することをチェックします: #keyword: Ansible stat exists
                        同じタスク内の場合:  #// ファイルまたはフォルダーが存在しなければ失敗させるなど
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: Check the ____ exists
                                    stat:
                                        path: "/checking/path"
                                    register: result
                                    failed_when: "result.stat.exists == false"
                        別のタスクの場合:
                            tasks:
                                -   name: Check the __Name__ exists
                                    stat:
                                        path: "__FullPath__"
                                    register: __Name__

                                -   name: __TaskNameWhenExists__
                                    when: __Name__.stat.exists
                                    debug:
                                        msg: "The file or directory exists"

                                -   name: __TaskNameWhenNotExists__
                                    when: not __Name__.stat.exists
                                    debug:
                                        msg: "The file or directory does not exist"
                            #ref: https://phoenixnap.com/kb/ansible-check-if-file-exists
                        トランザクションにする場合: | #keyword: Ansible transaction file  #// トランザクションの中なら一時ファイルが存在するとし、トランザクションの途中で失敗したかどうかを判定します
                            -   name: Check __Path__ creating file exists
                                stat:
                                        path: "__Path___creating"
                                register: creating

                            -   name: Create __Path__ creating file
                                become: yes
                                file:
                                    path: "__Path___creating"
                                    state: touch

                            -   name: Remove __Path__ directory
                                become: yes
                                file:
                                    state: absent
                                    path: "__Path__"
                                when: creating.stat.exists

                            -   name: git clone or pull __Path__
                                git:
                                    repo: 'https://____'
                                    dest: "__Path__"
                                    version: "develop"
                                environment: "{{ proxy_env }}"

                            -   name: Remove __Path__ creating file
                                become: yes
                                file:
                                    state: absent
                                    path: "__Path___creating"
                template:    #keyword: ansible template module     #// ホスト マシーンにあるテンプレート ファイルの一部を置き換えて、ゲスト マシーンにファイルを配置します
                    参考:
                        - https://tekunabe.hatenablog.jp/entry/2019/03/03/ansible_template_intro
                        - https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html
                        - https://docs.ansible.com/ansible/2.9_ja/modules/template_module.html  #template: __DocumentVersion__
                    サンプル プロジェクト: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/file_example/text_file/template/1st/playbook.yml
                    サンプル:  #// template ファイルを元にファイルをアップロードします
                        __Playbook__.yml:
                            -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                                -   name: create the file
                                    template:
                                        src: ./file.conf.template.j2
                                        dest: /etc/file.conf
                        ./file.conf.template.j2: |  #// ホスト マシーンの中の Jinja2 テンプレート ファイル
                            Hello, {{ test_name }}
                        /etc/file.conf: |  #// ゲスト マシーンの中にできるファイル
                            Hello, world
                    手順:
                        変数の値によって テンプレート ファイル を変えます:
                            タスクの src 属性（コピー元）の値を変数参照にします
                            #search: Ansible vars condition
                        タスクに直接プレースホルダーの値を指定します:
                            tasks/main.yml: |  #// vars に指定します
                                -   name: テンプレートを配置
                                    ansible.builtin.template:
                                        src: config.j2
                                        dest: /etc/myapp/config.conf
                                    vars:
                                        app_port: 8080
                                        app_name: "MyApplication"
                                        debug_mode: true
                            config.j2: |
                                port: "{{ app_port }}"
                    #↓ タスクの属性
                    ユーザー, パーミッション:  #search: chown
                        mode='0644' owner="user1" group="group1"
                    #↓ テンプレート ファイル の内容
                    エスケープ:  #// {{ }} をそのまま出力します
                        テンプレート ファイル: |
                            var: "{{ "{{" }} quote {{ "}}" }}"
                        出力: |
                            var: "{{ quote }}"
                    計算式:
                        変数:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/file_example/text_file/template/1st/playbook.yml#vars:
                            vars:
                                string_variable: abc
                                number_variable: 123
                                refer: '{{ string_variable }}'
                                computed_variable: '{{ 3 * 4 }}'  #// 3 * 4 だけは計算されません
                        テンプレート: |  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/file_example/text_file/template/1st/setting.conf.template.j2#compute:
                            {{ string_variable }}
                            {{ number_variable }}
                            compute: {{ variable | int * 2 }}     #// 246
                            repeat:  {{ variable | string * 2 }}  #// 123123
                    Jinja2 テンプレート ファイル:  #keyword: Ansible Jinja2 テンプレート ファイル
                        - https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_templating.html  #template: __DocumentVersion__
                        - https://jinja.palletsprojects.com/en/3.0.x/templates/
                    フィルター:  #keyword: ansible filter in template
                        #// capitalize フィルターは、フィルターに渡される値を大文字にします
                        #// to_yaml フィルターおよび to_json フィルターは変数の値の形式を変更します
                        参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html  #template: __DocumentVersion__
                        書式:
                            {{ __VariableName__ | __Filter__ }}
                        定義場所: plugins/filter/____.py
                    補足:
                        Ansible は、テンプレートで Jinja2 ループと条件を許可しますが、Playbook では使用しません。
                        #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_variables.html#jinja2  #template: __DocumentVersion__
                unarchive:   #keyword: ansible unarchive           #// 圧縮ファイルを展開します
                    公式:  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/unarchive_module.html  #template: __DocumentVersion__
                    サンプル.yml:  #// Ansible 2.0 以降。 下記 stat があるほうが動作は速いです
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: Check Node.js exists
                                stat:
                                    path: "/opt/node-v{{ nodeJsVersion }}-linux-x64"
                                register: node

                            -   name: download and extract Node.js
                                become: true
                                unarchive:
                                    src: https://nodejs.org/dist/v{{ nodeJsVersion }}/node-v{{ nodeJsVersion }}-linux-x64.tar.xz
                                    dest: /opt
                                    remote_src: yes
                                    owner: root
                                    group: root
                                when: not node.stat.exists
                        #// ダウンロードしたファイルは削除されます  /home/vagrant/.ansible/tmp/ansible-tmp-1675834221.59-30906-115860282039913/node-v12.16.1-linux-x64.tarIB1VG9.xz
                    サンプル for Ansible 1.x.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: download Node.js
                                get_url:
                                    url: https://nodejs.org/dist/v__NodeJsVersion__/node-v__NodeJsVersion__-linux-x64.tar.xz
                                    dest: /home/vagrant

                            -   name: extract Node.js
                                become: true
                                unarchive:
                                    src: /home/vagrant/node-v__NodeJsVersion__-linux-x64.tar.xz
                                    dest: /opt
                                    owner: root
                                    group: root

                            -   name: delete Node.js package
                                file:
                                    state: absent
                                    path: /home/vagrant/node-v__NodeJsVersion__-linux-x64.tar.xz
                                when: not node.stat.exists
            カタログ >> データベース, キュー:  #glossary: Ansible database modules
                MySQL:  #keyword: Ansible MySQL,  Ansible MySQL module
                    URL: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/list_of_database_modules.html#mysql  #template: __DocumentVersion__
                    command:  #// MySQL command をそのまま書いて実行します。
                        注意: 冪等性はありません
                        サンプル.yml:
                            vars:
                                mysql_client_username: mysql_user
                                mysql_client_password: ____
                                target_database_name: ____  #// 下記 mysql コマンドで指定しないときは不要
                            tasks:
                                -   name: ____
                                    vars:
                                        mysql_command: >
                                            CREATE USER rpl_user@'%' IDENTIFIED BY 'P@ssword2';
                                    command: >
                                        mysql
                                            --user={{mysql_client_username}}
                                            --password={{mysql_client_password}}
                                            {{target_database_name}}
                                            --host={{inventory_hostname}}
                                            --execute="{{mysql_command}}"
                        2行の mysql_command:
                            mysql_command: >
                                SET SQL_LOG_BIN=0;
                                CREATE USER rpl_user@'%' IDENTIFIED BY 'P@ssword2';
                        変数を参照する mysql_command:
                            mysql_command: >
                                create database {{target_database_name}};
                    mysql_user:  #keyword: Ansible mysql_user module  #// データベースのユーザーを作ります
                        URL:
                            - https://docs.ansible.com/ansible/2.9_ja/ >> モジュールの使用 >> Module Index >> Database modules >> mysql_user  #template: __DocumentVersion__
                            - mysql_user: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/mysql_user_module.html  #template: __DocumentVersion__
                        サンプル >> ユーザーを新しく作ります:  #keyword: Ansible MySQL CREATE USER, Ansible MySQL GRANT
                            #// (@__Server__) mysql> CREATE USER __UserName__@'__Host__' IDENTIFIED BY '__Password__';
                            #// (@__Server__) mysql> GRANT __Privilege__  ON *.* TO __UserName__@'__Host__';
                            -   name: (@__Server__) create MySQL user
                                mysql_user:
                                    name:     "{{ mysql_example_username }}"
                                    password: "{{ mysql_example_password }}"
                                    host: localhost  #// mysql> SELECT user,host FROM mysql.user;
                                    priv: "*.*:ALL"
                                    state: present
                                    login_unix_socket: /var/lib/mysql/mysql.sock
                                    login_host: __MySqlServerName__   #// hosts と違うとき？  #// login_unix_socket と排他らしい
                                    login_user: root
                                    login_password: "{{ mysql_root_password }}"
                        サンプル >> 複数のユーザーを新しく作ります:
                            -   name: create MySQL client user
                                mysql_user:
                                    update_password: on_create
                                    name: "{{ item.user }}"
                                    password: "{{ item.password }}"
                                    host: "{{ item.host }}"
                                    priv: "{{ item.privileges }}"
                                    state: present
                                    login_unix_socket: /var/lib/mysql/mysql.sock
                                    login_user: root
                                    login_password: "{{ mysql_root_password }}"
                                with_items:
                                    -   user: "{{ mysql_client_user_name }}"
                                        password: "{{ mysql_client_password }}"
                                        host: "%"
                                        privileges: "*.*:ALL,GRANT"
                                    -   user: "{{ mysql_client_user_name }}"
                                        password: "{{ mysql_client_password }}"
                                        host: "%"
                                        privileges: "*.*:ALL,GRANT"
                        サンプル >> ユーザーを新しく作ります。暗号化あり:
                            #// CREATE USER 'bob'@'localhost' IDENTIFIED BY '{{ mysql_client_password }}';
                            -   name: create database user using hashed password with all database privileges
                                mysql_user:
                                    name: bob
                                    password: '{{ mysql_client_password }}'
                                    encrypted: yes
                                    priv: '*.*:ALL'   #template) '__DB_Name__.*:__Privileges__'
                                    state: present
                                補足:  #// out of playbook
                                    __Privileges__:
                                        ALL: 全ての権限
                        サンプル >> ユーザーを削除します:
                            #focus: absent
                              #// 未確認
                            -   name: (@__Server__) delete MySQL user
                                mysql_user:
                                    name: "{{ mysql_example_username }}"
                                    host: localhost  #// mysql> SELECT user,host FROM mysql.user;
                                    state: absent
                                    login_unix_socket: /var/lib/mysql/mysql.sock
                                    login_host: __MySqlServerName__  #// hosts と違うとき？  #// login_unix_socket と排他らしい
                                    login_user: root
                                    login_password: "{{ mysql_root_password }}"
                            #search: Ansible MySQL CREATE USER
                        others: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/mysql_user_module.html  #template: __DocumentVersion__
                        priv パラメーター:
                            書式: __DB_Name__.__TableName__:__PrivilegesCSV__
                            __PrivilegesCSV__:
                                サンプル:
                                    - "*.*:ALL PRIVILEGES"
                                    - "mysql.table1:INSERT,UPDATE,DELETE,CREATE"  #// 権限はコンマで区切ります。前後に空白文字を入れないでください
                                    - "db1.table1:INSERT/db1.table2:INSERT"  #// テーブルも含む権限はスラッシュで区切ります
                                権限一覧:  #search: MySQL privileges
                            対応する MySQL コマンド: mysql>  GRANT __PrivilegesCSV__  ON `__DB_Name__`.`__TableName__`  ____
                        Playbook.yml の hosts が MySQL サーバーと異なる場合:  #search: Ansible  mysql_db  login_host
                    mysql_db:  #keyword: Ansible mysql_db module  #// データベースを作ります
                        公式: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/mysql_db_module.html#mysql-db-module  #template: __DocumentVersion__
                        データベースを新しく作ります >> Playbook.yml の hosts が MySQL サーバーと同じ場合:
                            -   name: create _____ database
                                mysql_db:
                                    name: __DatabaseName__
                                    state: present
                                    login_user:     "{{ mysql_client_username }}"
                                    login_password: "{{ mysql_client_password }}"
                        データベースを新しく作ります >> Playbook.yml の hosts が MySQL サーバーと異なる場合:  #keyword: Ansible mysql_db module,  Ansible mysql_db login_host
                            方法1:
                                -   name: create _____ database
                                    mysql_db:
                                        name: __DatabaseName__
                                        state: present
                                        login_host: localhost  #// mysql> SELECT user,host FROM mysql.user;
                                        login_unix_socket: /var/lib/mysql/mysql.sock
                                        login_user:     "{{ mysql_client_username }}"
                                        login_password: "{{ mysql_client_password }}"
                            方法2:
                                -   name: create _____ database
                                    mysql_db:
                                        name: __DatabaseName__
                                        state: present
                                        target: db1  #// host name
                                        login_host:     localhost  #// mysql> SELECT user,host FROM mysql.user;
                                        login_user:     "{{ mysql_client_username }}"
                                        login_password: "{{ mysql_client_password }}"
                        MySQL との対応:  #// 下記のコロンの左は MySQL のキーワードです
                            character set: encoding  #// 未確認
                            collate: collation   #// 未確認
                    mysql_replication:  #keyword: Ansible mysql_replication module
                        公式: https://docs.ansible.com/ansible/latest/collections/community/mysql/mysql_replication_module.html
                        サンプル >> レプリケーションの設定をします:  #keyword: Ansible change master to, mysql_replication changemaster
                            #search: MySQL CHANGE MASTER TO command
                            -   name: Change to primary server
                                #// mysql> CHANGE MASTER TO
                                #// primary == master
                                mysql_replication:
                                    mode: changemaster
                                    master_host: "{{ mysql_replication_master_host_name }}"
                                    master_port: 3306
                                    master_user:     "{{ mysql_replication_username }}"
                                    master_password: "{{ mysql_replication_password }}"
                                    master_auto_position: yes
                                    login_unix_socket: /var/lib/mysql/mysql.sock
                                    login_user: root
                                    login_password: "{{ mysql_root_password }}"
                                when: mysql_primary_secondary == "primary"
                        サンプル >> レプリケーション開始:
                            #// mysql> START SLAVE 相当  #keyword: Ansible start slave
                            -   name: Start mysql replication
                                community.mysql.mysql_replication:
                                    mode: startslave
                RabbitMQ:
                    rabbitmq_vhost:  #ref: https://docs.ansible.com/ansible/2.9/modules/rabbitmq_vhost_module.html
            カタログ >> ネットワーク, マウント:  #glossary: Ansible network modules
                (ipv4.address):  #search: ansible hostvars
                nmcli:  #// ネットワーク アダプター、IP アドレスの設定  #keyword: Ansible nmcli module
                    URL: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/nmcli_module.html  #template: __DocumentVersion__
                    #// nmcli コマンドの Ansible 版。 nmcli の参考 https://www.kd2.jp/memo/centos7/nmcli.php
                    サンプル playbook.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            #// nmcli device show
                            #// nmcli connection show
                            #// sudo nmcli connection modify "System eth1" +ipv4.addresses 192.168.33.111/24
                            #// sudo nmcli connection up "System eth1"
                            -   name: add an ethernet connection with static IP (VIP) configuration
                                become: yes
                                block:
                                    -   name: nmcli connection modify command in the host
                                        nmcli:
                                            conn_name: "System eth1"
                                            type: ethernet
                                            ifname: eth1
                                            ip4: >-
                                                {{ ansible_eth1.ipv4.address }}/{{ sub_net_mask_bit_count }},
                                                {{ mysql_dynamic_primary_ip_address }}/{{ sub_net_mask_bit_count }}
                                            state: present
                                            autoconnect: yes
                                    -   name: nmcli connection up command in the host
                                        shell: sudo nmcli connection up "System eth1"
                uri:  #// HTTP リクエスト  #keyword: Ansible uri module  #keyword: Ansible cURL, Ansible wget
                    参考: https://stackoverflow.com/questions/30509058/post-json-to-api-via-ansible/30509908
                    関連:
                        ダウンロードした内容をファイルに保存します: get_url  #search: ansible get_url
                    サンプル >> GET:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: http request GET method
                                uri:
                                    url: http://example.com/
                                    method: GET
                    サンプル >> GET した内容をチェックします:
                        -   name: Make sure that cluster health is green
                            uri: url=http://{{ inventory_hostname }}:{{ es_http_port }}/_cluster/health method=GET
                            register: result
                            failed_when: "result.json.status != 'green'"
                        #serach: failed_when
                    サンプル >> POST:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: http request POST method
                                uri:
                                    url: http://www.myapi.com/create
                                    method: POST
                                    return_content: yes
                                    HEADER_Content-Type: application/json
                                    body: |
                                        {{ lookup('file','create_body.json') | to_json }}
                wait_for:  #// サービスのポートが開くまで待つなど
                    #ref: https://docs.ansible.com/ansible/2.9_ja/modules/wait_for_module.html  #template: __DocumentVersion__
                    関連: #search: Ansible pause
                mount:  #// Linux mount コマンド  #keyword: Ansible mount
                    注意: 非推奨。Ansible のデータベースに書かれたマウント状態と VM のマウント状態に違いがあると、正しく動作しません。
                    サンプル playbook.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            #// mount -t __Type__  __DeviceName__  __MountPoint__
                            -   name: mount NFS shared folder
                                become: yes
                                shell: mount -t __Type__ "__DeviceName__" "__MountPoint__"
                                # mount:  #// This does not mount if the status in Anaible database and the VM status were different.
                                #     path: __MountPoint__
                                #     src: __DeviceName__
                                #     fstype: __Type__
                                #     state: present
                    参考:  #search: Linux mount
                seboolean:  #// SELinux booleans  #keyword: Ansible seboolean module
                    URL: #ref: https://docs.ansible.com/ansible/latest/collections/ansible/posix/seboolean_module.html
                    参考 >> SELinux boolean: #search: SELinux boolean
                    サンプル playbook.yml:
                        -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                            -   name: Allow httpd SELinux boolean
                                block:
                                    #// sudo setsebool -P __PolicyName__ __OnOrOff__
                                    -   name: httpd_can_network_connect
                                        become: yes
                                        seboolean:
                                            name: httpd_can_network_connect
                                            state: yes
                                            persistent: yes

                                    -   name: __PolicyName__
                                        become: yes
                                        seboolean:
                                            name: __PolicyName__
                                            state: yes
                                            persistent: yes
                selinux:  #// SELinux  #keyword: Ansible selinux module
                    URL: #ref: https://docs.ansible.com/ansible/2.9_ja/modules/selinux_module.html  #template: __DocumentVersion__
                (audit2allow):  #keyword: Ansible audit2allow
                    サンプル playbook.yml:
                        -   name: Allow __Service__ SELinux module
                            block:
                                -   name: Allow __Service__ SELinux module - audit2allow
                                    become: yes
                                    shell: grep __ServiceName__ /var/log/audit/audit.log | sudo audit2allow -M __NewPolicyName__

                                -   name: Allow __Service__ SELinux module - semodule
                                    become: yes
                                    shell: semodule -i __NewPolicyName__.pp

                                -   name: Restart __Service__ server processes
                                    become: yes
                                    systemd:
                                        name: __ServiceName__
                                        state: restarted
                                        enabled: yes

                        -   name: Make sure that __Service__ service is running
                            service_facts:
                            register: result
                            failed_when: result.ansible_facts.services['__ServiceName__.service'].state != 'running'
                    参考:
                        audit2allow: #search:
            カタログ >> その他:
                fail: #keyword: Ansible fail  #// Ansible を実行中にエラーを発生させます
                    実行前に変数値で判定する場合: #keyword: Ansible fail when
                        書式: |
                            -   name: __CheckingTaskName__
                                fail: msg="__ErrorMessage__"
                                when: __Condition__

                            -   name: __NextTaskName__
                        サンプル: |
                            -   name: check migrate version
                                fail: msg="migrate version is too largeer than schema_last_major_version"
                                when: release_version | split('.') | first | int  >  mysql_schema_migration.schema_last_major_version | int
                            -   name: task for new version
                                ...:
                    ログに error が含まれていたらエラーにする場合: |  #keyword: Ansible error log check
                        -   name: error check in the log of install __Operation__
                            shell: grep -i  "error"  "/vagrant/working/__Operation__.log";  test  "$?" != 0
                            register: log_result
                            ignore_errors: true

                        -   name: stop and show the error message
                            when: log_result.rc != 0  #// found error keyword
                            fail: 
                                msg: "See working/__Operation__.log"
                    終了コードで判定する場合: |  #// fatal: [__HostName__]: FAILED! => {"changed": false, "msg": "See working/_error.log"}
                        -   name: command
                            shell: "__CommandLine__"
                            register: result
                            ignore_errors: true

                        -   name: error check of command
                            when: result.rc != 0
                            fail: 
                                msg: "See working/_error.log"
                iptables: #keyword: Ansible iptables module  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/iptables_module.html
                再起動:
                    Ansible でホストを再起動して続きを実行するにはどのように playbook を書けばいいでしょうか。:
                        https://chat.openai.com/c/ca466a9c-4553-40f6-a5bb-3daf89a91730
            関連 >> ローカル実行, 委任: #search: local_action
        フィルター: #keyword: Ansible filter  #// カスタム フィルター  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html  #template: __DocumentVersion__
            #ref: https://docs.ansible.com/ansible/latest/plugins/filter.html#enabling-filter-plugins
            template 内:  #search: ansible filter in template
            定義済みフィルター: #keyword: Ansible built in filter  #glossary: Ansible
                （分類）:
                    未定義時: default, ternary
                    リスト: min, max, flatten, unique, union, intersect, difference, symmetric_difference, zip, subelements
                    辞書: dict2items
                    文字列: regex_search,  regex_replace,  to_json,  to_yaml
                #↓ ABC 順
                default: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#defaulting-undefined-variables
                    {{ __Variable__ | default(5) }}  #// __Variable__ が未定義だったら 5
                    {{ __TrueOrFalse__ | default(__Value__, true) }}
                    __Name__: {{ __Variable__ | default(omit) }}  #// 未定義だったら __Name__ を指定しない
                dict2items: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#dict-filter
                    {{ __Dictionary__ | dict2items }}
                    {{ __Dictionary__ | dict2items(key_name='__KeyName__', value_name='__ValueName__') }}
                        #// { a: b } を {__KeyName__: a, __ValueName__:b } に変換します
                difference: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#list-filters
                    {{ __List1__ | difference(__List2__) }}
                flatten: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#list-filters
                    {{ [__Variable1__, [__Variable21__, __Variable22__]] | flatten }}  #// [__Variable1__, __Variable21__, __Variable22__]
                    {{ __List__ | flatten }}
                    {{ __List__ | flatten(levels=1) }}  #// 深さ 1 まで
                intersect: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#list-filters
                    {{ __List1__ | intersect(__List2__) }}  #// 要素の結合と unique
                items2dict: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#items2dict-filter
                    {{ tags | items2dict }}
                        #// {key:__Key__, value: __Value__} を {__Key__: __Value__} にします
                    {{ tags | items2dict(key_name='__KeyName__', value_name='__ValueName__') }}
                        #// {__KeyName__:__Key__, __ValueName__: __Value__} を {__Key__: __Value__} にします
                min, max: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#list-filters
                    {{ __List__ | min }}
                    {{ [__Variable__, __Variable__] | min }}
                regex_search: #// 正規表現  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#id19  #template: __DocumentVersion__
                    "{{ 'foobar' | regex_search('(foo)') }}" : "foo" #// 未確認
                    #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: Ansible regex_search
                regex_replace:
                subelements:  #// オブジェクトのリスト→属性のリスト  #ref:  https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#id10
                    #focus: users, emails
                    playbook: |  #focus: subelements, example.com, item
                        tasks:
                            -   name:
                                debug:
                                    msg: "User {{ item.0.name }} has email {{ item.1 }}"
                                loop: "{{ users | subelements('emails') }}"
                    出力: |
                        User A has email alice@example.com     #// 実際は次の行との間に他の情報のログがあります
                        User A has email alice@sub.example.com
                        User B has email bob@example.com
                    users 変数の値: |  #// 定義サンプル
                        -   name: A
                            emails:
                                - alice@example.com
                                - alice@sub.example.com
                        -   name: B
                            emails:
                                - bob@example.com
                    subelements を通した後: |  #// loop によって item に入る値。 0 はフィルタリング前、1 はフラットにした属性の値
                        -   item:
                                0:
                                    name: A
                                    emails:
                                        -   alice@example.com
                                        -   alice@sub.example.com
                                1: alice@example.com
                        -   item:
                                0:
                                    name: A
                                    emails:
                                        -   alice@example.com
                                        -   alice@sub.example.com
                                1: alice@sub.example.com
                        -   item:
                                0:
                                    name: B
                                    emails:
                                        -   bob@example.com
                                1: bob@example.com
                symmetric_difference: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#list-filters
                    {{ __List1__ | symmetric_difference(__List2__) }}  #// 対称的な違い
                ternary:  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#id22
                    条件による値: |
                        {{ (name == "John") | ternary('Mr','Ms') }}  #// name が John なら Mr
                to_json: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#filters-for-formatting-data
                    {{ __Variable__ | to_json }}
                    {{ __Variable__ | to_nice_json }}
                    {{ __Variable__ | to_nice_json(indent=__2__) }}
                    {{ __Variable__ | to_nice_json(indent=__8__, width=__4000__) }}
                    {{ __Variable__ | from_json }}
                to_yaml: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#filters-for-formatting-data
                    {{ __Variable__ | to_yaml }}
                    {{ __Variable__ | to_nice_yaml }}
                    {{ __Variable__ | from_yaml }}
                    {{ __Variable__ | from_yaml_all }}  #// 複数ドキュメントの YAML
                union: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#list-filters
                    {{ __List1__ | union(__List2__) }}  #// 要素の結合
                unique: |  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#list-filters
                    {{ __List__ | unique }}
                zip:  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#zip-zip-longest
                    コード: |  #// 2つのリストから、ペアのリストを作ります
                        {{ [1,2,3] | zip(['a','b','c','d','e','f']) | list }}
                    結果: |  #// 要素数は少ないほうと同じになります
                        [(1, 'a'), (2, 'b'), (3, 'c')]
                    応用: |
                        {{ dict(keys_list | zip(values_list)) }}
                zip_longest:  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_filters.html#zip-zip-longest
                    コード: |  #// 2つのリストから、ペアのリストを作ります
                        {{ [1,2,3] | zip_longest(['a','b','c','d','e','f'], [21, 22, 23], fillvalue='X') | list }}
                    結果: |  #// 要素数は多いほうと同じになります
                        [(1, 'a', 21), (2, 'b', 22), (3, 'c', 23), ('X', 'd', 'X'), ('X', 'e', 'X'), ('X', 'f', 'X')]
                Jinja2 で使えるフィルター:  #search: Jinja2 filter
                    Jinja2 のバージョン:  #search: Ansible version
            カスタム フィルター プラグイン: #keyword: Ansible custom filter plug in  #// ユーザー定義のフィルター
                #ref: https://docs.ansible.com/ansible/2.9_ja/dev_guide/developing_plugins.html#filter
                手順:
                    有効化:  #keyword: enable Ansible custom filter plug in  #ref: https://docs.ansible.com/ansible/latest/plugins/filter.html#enabling-filter-plugins
                        ansible.cfg の filter_plugins を設定します  #search: ansible.cfg  filter_plugins
                定義と使用:
                    基本 サンプル:  #// reverse_string を定義するサンプル  #focus: reverse_string  #// 一覧の辞書を返す FilterModule.filters メソッドを書きます
                        playbook.yml: |
                            version | reverse_string
                        __AnsibleProject__/filter_plugins/____.py : |  #// 場所は変更できます  #search: ansible.cfg  filter_plugins
                            def reverse_string(s):
                                return s[::-1]

                            class FilterModule(object):
                                def filters(self):
                                    return {
                                        'reverse_string': reverse_string
                                    }
                    パラメーターあり:  #focus: reverse_string
                        playbook.yml: |
                            version | split('.')
                        __AnsibleProject__/filter_plugins/____.py : |
                            def str_split(s, separator):
                                return s.split(separator)

                            class FilterModule(object):
                                def filters(self):
                                    return {
                                        'split': str_split
                                    }
                ファイル:  #// フィルター プラグイン を置く場所
                    ファイル:
                        探す:  #// 既存の Ansible プロジェクトの中で フィルター プラグイン がある場所をキーワードで探します
                            下記を全文検索します:
                                class FilterModule(object):  #focus: FilterModule
                    フォルダー:  #search: ansible.cfg  filter_plugins
        プラグイン: #keyword: Ansible plug in  #// Jinja2 テンプレート のフィルター、フックなど
            #ref: https://docs.ansible.com/ansible/2.9_ja/plugins/plugins.html  #template: __DocumentVersion__
            #ref: https://docs.ansible.com/ansible/2.9_ja/dev_guide/developing_plugins.html  #template: __DocumentVersion__
            カタログ:  #// コアプラグイン（Core Plugins）, ビルトインプラグイン（Built-in Plugins）, サードパーティ製プラグイン
                vars: #keyword: Ansible vars plug in type  #// 変数を定義するファイルの場所を増やします
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/dev_guide/developing_plugins.html#vars  #template: __DocumentVersion__
                    有効化: #keyword: enable Ansible vars plug in  #// Ansible 2.10 より
                        ansible.cfg: |  #ref: https://docs.ansible.com/ansible/latest/plugins/vars.html#enabling-vars-plugins
                            vars_plugins         = ./plugins/vars         #// 値はプラグインの Python ファイルがあるフォルダーのパス
                            vars_plugins_enabled = host_group_vars,__CustomVers__
                        host_group_vars: デフォルトの vars プラグイン
                        __CustomVers__: カスタム プラグイン の Python ファイル名から .py を除いたもの。vars_plugins に指定したフォルダーにある .py
                        #search: ansible.cfg
                        #search: Ansible plug in debug
                        #// 有効化しないと カスタム Vars プラグイン のオブジェクトは生成されても get_vars メソッドが呼ばれません
                    DEFAULT_VARS_PLUGIN_PATH コンフィグにプラグインを配置する場所を設定します:  #search: ansible.cfg
                ルックアップ: #keyword: Ansible lookup plug in type  #glossary: Ansible lookup
                    env: | #keyword: Ansible env plug in,  Ansible 環境変数  #// 環境変数を参照します
                            {{ lookup("env", "__VariabeName__") }}
                        #search: Ansible vars
                    dig: #keyword: Ansible dig plug in  #// ホスト名を IP アドレスに変換します  #ref: https://docs.ansible.com/ansible/2.7/plugins/lookup/dig.html
                        書式: |
                            {{ lookup("dig", "__HostName__") }}
                        サンプル:
                            Docker コンテナーが使うプロキシの IP アドレス:  #search: Ansible docker_container proxy
                    template:  #// control ノード にある Jinja2 テンプレートから変数の値を埋めたテキスト
                        値のサンプル:
                            "{{ lookup('template', '../templates/table.j2') }}"
                        返り値の型:
                            YAML として意味を持てば dict / list に自動変換されます。
                            JSON でも YAML として意味を持てば dict / list に自動変換されます。
                            それ以外は、テキスト？
                    file:  #// control ノード にあるファイル。AnsibleUnsafeText 型が返ります
                        "{{ lookup('file', '../file/table.csv') }}"
                コールバック: #keyword: Ansible callback plug in type  #// コールバック プラグイン。イベントが発生したときに呼び出されます
                    公式: #ref: https://docs.ansible.com/ansible/2.9_ja/plugins/callback.html  #template: __DocumentVersion__
                        #ref: https://docs.ansible.com/ansible/latest/plugins/callback.html
                    一覧: |  #keyword: list Ansible callback plug in  #ref: https://docs.ansible.com/ansible/latest/collections/index_callback.html
                        $ ansible-doc -t callback -l | sort  #// Ansible 2.9.27 default
                            actionable           shows only items that need attention                                                                                                           
                            aws_resource_actions summarizes all "resource:actions" completed                                                                                                    
                            cgroup_memory_recap  Profiles maximum memory usage of tasks and full execution using cgroups                                                                        
                            cgroup_perf_recap    Profiles system activity of tasks and full execution using cgroups                                                                             
                            context_demo         demo callback that adds play/task context                                                                                                      
                            counter_enabled      adds counters to the output items (tasks and hosts/task)                                                                                       
                            debug                formatted stdout/stderr display                                                                                                                
                            default              default Ansible screen output                                                                                                                  
                            dense                minimal stdout output                                                                                                                          
                            foreman              Sends events to Foreman                                                                                                                        
                            full_skip            suppresses tasks if all hosts skipped                                                                                                          
                            grafana_annotations  send ansible events as annotations on charts to grafana over http api                                                                          
                            hipchat              post task events to hipchat                                                                                                                    
                            jabber               post task events to a jabber server                                                                                                            
                            json                 Ansible screen output as JSON                                                                                                                  
                            junit                write playbook output to a JUnit file                                                                                                          
                            logdna               Sends playbook logs to LogDNA                                                                                                                  
                            logentries           Sends events to Logentries                                                                                                                     
                            log_plays            write playbook output to log file                                                                                                              
                            logstash             Sends events to Logstash                                                                                                                       
                            mail                 Sends failure events via email                                                                                                                 
                            minimal              minimal Ansible screen output                                                                                                                  
                            nrdp                 post task result to a nagios server through nrdp                                                                                               
                            null                 Don't display stuff to screen                                                                                                                  
                            oneline              oneline Ansible screen output                                                                                                                  
                            osx_say              notify using software speech synthesizer                                                                                                       
                            profile_roles        adds timing information to roles                                                                                                               
                            profile_tasks        adds time information to tasks                                                                                                                 
                            say                  notify using software speech synthesizer                                                                                                       
                            selective            only print certain tasks                                                                                                                       
                            skippy               Ansible screen output that ignores skipped status                                                                                              
                            slack                Sends play events to a Slack channel                                                                                                           
                            splunk               Sends task result events to Splunk HTTP Event Collector                                                                                        
                            stderr               Splits output, sending failed tasks to stderr                                                                                                  
                            sumologic            Sends task result events to Sumologic                                                                                                          
                            syslog_json          sends JSON events to syslog                                                                                                                    
                            timer                Adds time to play stats                                                                                                                        
                            tree                 Save host events to files                                                                                                                      
                            unixy                condensed Ansible output                                                                                                                       
                            yaml                 yaml-ized Ansible screen output                                                                                                                
                    ansible.builtin.default: #keyword: Ansible default plug in  #ref: https://docs.ansible.com/ansible/latest/collections/ansible/builtin/default_callback.html
                        概要: stdout に関するコールバックです
                        パラメーター: #glossary: Ansible
                            display_skipped_hosts:  #ref: https://docs.ansible.com/ansible/latest/collections/ansible/builtin/default_callback.html#parameter-display_skipped_hosts
                                #// スキップしたホストを表示しません
                    timer, 基本: #keyword: Ansible timer plug in
                        timer コールバックを有効にします:
                            (@control) /etc/ansible/ansible.cfg に設定する場合:
                                callback_whitelist:  #// 2.15 以降 callback_whitelist は非推奨になり callbacks_enabled に代わりました
                                変更前: |
                                    #callback_whitelist = timer, mail
                                変更後: |
                                    #callback_whitelist = timer, mail
                                    callback_whitelist = timer
                            (@control) 環境変数に設定する場合:
                                ANSIBLE_CALLBACKS_ENABLED=timer
                            公式: #ref: https://docs.ansible.com/ansible/latest/reference_appendices/config.html#callbacks-enabled
                        timer コールバックを試します: |  #focus: seconds  #// 最後に処理時間が表示されます
                            $ ansible-playbook  playbook-0.yml
                                :
                            Playbook run took 0 days, 0 hours, 0 minutes, 1 seconds
                    コールバック関数:
                        v2_on_file_diff: #keyword: Ansible v2_on_file_diff plug in  #// コピー先のファイルの内容が変化したとき
                            概要:  #ref: https://ansible.readthedocs.io/projects/runner/en/latest/ansible_runner.display_callback/#ansible_runner.display_callback.callback.awx_display.CallbackModule.v2_on_file_diff
                                copy タスクを実行するたびに v2_on_file_diff が呼ばれる可能性があり、
                                コピー先のファイルの内容が変化したときに v2_on_file_diff が呼ばれます。
                                通常、引数に渡された内容によってフィルタリングしてから必要な処理をします。
                            _task.args:  #// タスク名（モジュール名？）とパラメーター
                                サンプル: |  #focus: _task.args
                                    class CallbackModule(ansible.plugins.callback.default.CallbackModule):
                                        def v2_on_file_diff(self, result):
                                            print(result._task.args.values())
                        v2_playbook_on_stats: #keyword: Ansible v2_playbook_on_stats plug in  #// playbook の実行の最後のとき
                インベントリー: #keyword: Ansible inventory plug in type  #ref: https://docs.ansible.com/ansible/2.9_ja/plugins/inventory.html  #template: __DocumentVersion__
                    一覧: |  #keyword: list Ansible inventory plug in
                        $ ansible-doc -t inventory -l | sort  #// Ansible 2.9.27 default
                            advanced_host_list  Parses a 'host list' with ranges                                                                                                                
                            auto                Loads and executes an inventory plugin specified in a YAML config                                                                               
                            aws_ec2             EC2 inventory source                                                                                                                            
                            aws_rds             rds instance source                                                                                                                             
                            azure_rm            Azure Resource Manager inventory plugin                                                                                                         
                            cloudscale          cloudscale.ch inventory source                                                                                                                  
                            constructed         Uses Jinja2 to construct vars and groups based on existing inventory                                                                            
                            docker_machine      Docker Machine inventory source                                                                                                                 
                            docker_swarm        Ansible dynamic inventory plugin for Docker swarm nodes                                                                                         
                            foreman             foreman inventory source                                                                                                                        
                            gcp_compute         Google Cloud Compute Engine inventory source                                                                                                    
                            generator           Uses Jinja2 to construct hosts and groups from patterns                                                                                         
                            gitlab_runners      Ansible dynamic inventory plugin for GitLab runners                                                                                             
                            hcloud              Ansible dynamic inventory plugin for the Hetzner Cloud                                                                                          
                            host_list           Parses a 'host list' string                                                                                                                     
                            ini                 Uses an Ansible INI file as inventory source                                                                                                    
                            k8s                 Kubernetes (K8s) inventory source                                                                                                               
                            kubevirt            KubeVirt inventory source                                                                                                                       
                            linode              Ansible dynamic inventory plugin for Linode                                                                                                     
                            netbox              NetBox inventory source                                                                                                                         
                            nmap                Uses nmap to find hosts to target                                                                                                               
                            online              Online inventory source                                                                                                                         
                            openshift           OpenShift inventory source                                                                                                                      
                            openstack           OpenStack inventory source                                                                                                                      
                            scaleway            Scaleway inventory source                                                                                                                       
                            script              Executes an inventory script that returns JSON                                                                                                  
                            toml                Uses a specific TOML file as an inventory source                                                                                                
                            tower               Ansible dynamic inventory plugin for Ansible Tower                                                                                              
                            virtualbox          virtualbox inventory source                                                                                                                     
                            vmware_vm_inventory VMware Guest inventory source                                                                                                                   
                            vultr               Vultr inventory source                                                                                                                          
                            yaml                Uses a specific YAML file as an inventory source                                                                                                
                    constructed: #keyword: Ansible constructed inventory,  constructed  #// Jinja2 を使って、既存のインベントリに基づいて変数とグループを構築します。
                        #ref: https://docs.ansible.com/ansible/2.9_ja/plugins/inventory/constructed.html  #template: __DocumentVersion__
                        関連 >> ホスト名のパターン指定:  #search: Ansible host pattern
                        手順, インストール:
                            インストール:
                                ansible.cfg: |
                                    [inventory]
                                    enable_plugins = __OtherPlugIns__, constructed
                                inventory.config,  ____.config:
                                    ...  #search: constructed.yml
                            ホスト名のパターン:  inventory_hostname.startswith('__Prefix__')  #search: Ansible constructed expression
                            And 条件: "'web' in group_names  and  site == 'tokyo'"  #search: Ansible constructed example compose groups
                            値を確認します:  #search: Ansible constructed hosts
                        ファイル:  #// 変数と ホスト グループ 名 を定義します
                            inventory.config,  ____.config : #keyword: constructed.yml  #// 一般的には constructed.yml という名前が使われるらしい？
                                #↓YAML のフィールド名
                                plugin: constructed  #// 固定
                                compose, 変数: #keyword: Ansible constructed compose  #// 変数を定義します
                                    __VariableName__: __Value__  #search: Ansible constructed expression
                                    #// compose で定義した変数を compose の中で参照することはできません
                                groups, ホスト一覧: #keyword: Ansible constructed groups  #// ホスト グループ をパターンで定義します
                                    定義 >> 書式: |
                                            __GroupName__: __TrueOrFalse__  #search: Ansible constructed expression
                                        #// __TrueOrFalse__ の部分が真に判定される場合のみ inventory_hostname 変数のホスト名が __GroupName__ に所属します
                                        #// __GroupName__ は playbook.yml の hosts などに指定します
                                        #// ❗注意: 最新 Ansible では __GroupName__ の文字にハイフンは使えません  #search: Ansible constructed hyphen
                                    参照:
                                        hosts:  #// Playbook ファイル の hosts
                                            - __GroupName__
                                        Jinja2 タグ: |
                                            - {{ groups['__GroupName__'] }}
                                            - {{ groups['__GroupName__'] }} | first
                                keyed_groups: #keyword: Ansible constructed keyed_groups
                                    サンプル: |
                                        plugin: constructed
                                        keyed_groups:  #// ホスト グループ 名 を定義します
                                            #// 以下は、ホスト グループ 名 が env1___Env2Value__ になります。env2 の値が main なら、env1_main という ホスト グループ が作られます
                                            -   prefix: env1    #// ホスト グループ 名 の接頭辞を指定します。
                                                key: env2       #// ホスト変数の名前を指定します。
                            __Value__ や __TrueOrFalse__ の部分の書式:  #keyword: Ansible constructed expression
                                値のサンプル:
                                    -   inventory_hostname.startswith('__Prefix__')
                                    -   inventory_hostname | regex_search('__RegularExpression__')     #// | の前後に空白置けないかも？
                                    -   "'__Part__' in inventory_hostname  or  '__Part2__' in inventory_hostname"
                                    -   "'web' in group_names  and  'tokyo' in group_names"
                                    -   "'tokyo' if '120' in inventory_hostname else 'osaka'"
                                YAML のサンプル A:
                                    groups:  #// パターンにマッチするホストをホストグループに設定します
                                        db_hosts: inventory_hostname.startswith('db')   #// db_____ にマッチ
                                        main_hosts: inventory_hostname|regex_search('app.*1-.*')     #// app___1__ にマッチ
                                        other_hosts:  inventory_hostname|regex_search('app.*[^1]-.*')  #// app___2__ などにマッチ
                                YAML のサンプル B: #keyword: Ansible constructed example compose groups
                                    #focus: site
                                    compose:
                                        site: "'tokyo' if '120' in inventory_hostname else 'osaka'"
                                    groups:
                                        tokyo: "site == 'tokyo'"
                                        osaka: "site == 'osaka'"
                                        web_tokyo: "'web' in group_names  and  site == 'tokyo'"
                                        dbx_osaka: "'dbx' in group_names  and  site == 'osaka'"
                            確認方法: #keyword: Ansible constructed hosts   #// 正規表現などにマッチしたホスト名を一覧します
                                ansible -i __InventoryFilePath__ __GroupName__ --list-hosts
                                #search: Ansible evaluated host names
                        変数:
                            inventory_hostname:
                            group_names:
                        トラブルシューティング (constructed):
                            - #// skipping: no hosts matched  #keyword: Ansible constructed hyphen
                                手順: ansible-playbook でデプロイ
                                エラー: |
                                    skipping: no hosts matched
                                対処:
                                    最新バージョンの Ansible では constructed の inventory.config の group で定義する名前にハイフンを使うことはできません。
                                    #search: Ansible constructed groupss
                                対応状況:
                                    NG: ansible-playbook 2.9.27
                                    OK: ansible-playbook 2.7.10
                フィルター: #keyword: Ansible filter plug in
                    #search: Ansible filter
                他もあります:
            カスタム プラグイン: #keyword: Ansible custom plug in
                カスタム vars プラグイン:
                    #search: Ansible vars plug in type
                カスタム フィルター プラグイン:  #search: Ansible custom filter plug in
                _display (print 相当):  #keyword: Ansible _display,  Ansible plug in -vvv print  #// -v ～ -vvv オプションに応じた表示
                    概要コード: |  #focus: _display
                        class VarsModule(BaseVarsPlugin):
                            def method(self):
                                self._display.vvv("Found vars dir %s" % d)
                                self._display.error(ex)
            ファイル: #keyword: Ansible plug in files
                場所:  #// プラグインが置いてある場所
                    lookup プラグイン: #search: ansible.cfg  lookup_plugins
                    filter プラグイン:  #search: ansible.cfg  filter_plugins
                見つからないとき:  #search: Ansible no filter named trouble
            コード:
                Ansible 標準:
                    callback プラグイン:
                        - __AnsibleVenv__/lib/python____/site-packages/ansible/plugins/callback/default.py など
                        - /usr/lib/python____/site-packages/ansible/plugins/callback/default.py など
                プラグインのデバッグ:  #keyword: Ansible plug in debug
                    vars プラグイン:
                        _display が使えます: |  #// 未確認
                            class VarsModule(BaseVarsPlugin):
                                def __init__(self):
                                    super(VarsModule, self).__init__()
                                    self._display.error(ex)
                    フィルター プラグイン:
                        debug モジュール からフィルターを呼び出します:  #search: Ansible debug
                            playbook に以下のタスクを追加します: |
                                -   name: filter plug in debug print
                                    debug: 'msg="{{ "example" | my_filter }}"'
                                    failed_when: true
                        できること:
                            - 返り値の表示
                            - 例外が発生したときのコールスタックの表示
                        できないこと:  #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: ansible plug in debug
                            Python コードでの以下:
                                pdb
                                print
                                logger
        Molecule: #keyword: Ansible Molecule  #// Ansible Roleのテストツール
            注意点: molecule は専用のインベントリー使うため、作成した インベントリー ファイル に問題があっても気づけません。
                テストが中途半端であるため、VirtualBox などで作った ターゲット ノード で実際に動作させるほうがよい
            Lint: PlaybookがYAMLの文法に従っているか
            Provision: 2回目の実行で不要な変更が入らないか
            Verify: 別のテストツールを使って作った環境をテスト。別途テストコードを書く必要があります。
            #ref: https://qiita.com/satken2/items/d631ee5820597609a467
        Galaxy:  #// コミュニティーが開発したロールの検索、ダウンロード、共有  #keyword: ansible Galaxy
            https://docs.ansible.com/ansible/2.9_ja/galaxy/user_guide.html  #template: __DocumentVersion__
    ファイル: #keyword: Ansible files  #// playbook.yml
        （構成例）:
            - __Project__/group_vars/
            - __Project__/group_vars/all/____.yml  #search: Ansible group_vars/all.yml
            - __Project__/group_vars/__GroupName__/____.yml
            - __Project__/hosts/              #search: ansible inventory file
            - __Project__/hosts/__GroupName__/
            - __Project__/playbooks/____.yml  #search: ansible playbook
            - __Project__/plugin/             #search: Ansible plug in files
            - __Project__/roles/              #search: Ansible roles folders
            - __Project__/roles/handlers  #// 最後の再起動など
            - __Project__/roles/meta      #// 依存するロールなど
            - __Project__/roles/tasks     #// メイン処理
            - __Project__/roles/template  #// ファイル
            - __Project__/roles/vars      #// 変数
            - __Project__/ansible.cfg         #search: ansible.cfg
        Playbook ファイル(*.yml):  #keyword: ansible playbook, Playbook ファイル, Playbook.yml, Playbook.yaml, __Playbook__.yml
            参考:
                - https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks.html  #template: __DocumentVersion__
                - https://www.vagrantup.com/docs/provisioning/ansible_intro
            特殊記号（Playbook ファイル）:
                "{{ }}": 変数参照。 vars セクションで変数を定義します #search: ansible vars
            実行する: #keyword: Ansible 実行
                プロビジョナー:  #search: Ansible プロビジョナー
                実行順序:  #search: Ansible 実行順序
                依存関係:  #search: Ansible dependencies
                ハンドラー:  #search: Ansible role handlers
            サンプルと説明:
                サンプル プロジェクト:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/
                基本サンプル: | #keyword: Ansible playbook-0.yml  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/playbook-0.yml
                    -   hosts: __ServerName__
                        tasks:
                            -   name: Hello Ansible!
                                debug:
                                    msg: Hello Ansible!
                その他のサンプル: |  #keyword: playbook1.yml  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_intro.html#playbook-basics  #template: __DocumentVersion__
                    ---
                    -   hosts: all                     #search: ansible hosts
                        remote_user: root
                        become: yes                    #search: ansible become
                        tasks:         #// プレイは、タスクと同様に、 Playbook で指定された順序で上から下に実行されます。
                            -   name: ensure ntpd is at the latest version        #search: ansible task name
                                yum: pkg=ntp state=latest                         #search: ansible yum
                    -   import_playbook: __RelativePath__                         #search: ansible import_playbook
            暗号化する（Playbook ファイルなどを）:  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/vault.html  #template: __DocumentVersion__
            hosts: #keyword: ansible hosts  #// プロビジョニング先のサーバー名、またはサーバーグループ名
                参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_intro.html#playbook-hosts-and-users  #template: __DocumentVersion__
                    #see-above: playbook1_yml
                all: インベントリ ファイルにあるすべてのサーバー
                __GroupName__:
                    - インベントリ ファイル に定義があるグループ名  #search: Ansible inventory group
                    - constructed プラグインの .config ファイルに定義があるグループ名  #search: Ansible constructed plug in
                __HostName__:  インベントリ ファイル に定義があるホスト名    #search: Ansible inventory host
                __CSV__: hosts にコンマ区切りで複数のグループ名やホスト名を指定できます
                    inventory_hostname 変数でホスト名を取得できます
                    並列に実行します
                ホストA ⇒ ホストB ⇒ ホストA の順で実行するとき:  #keyword: Ansible host interaction
                    単純なケース:
                        -   hosts: hostA
                            tasks:
                                - debug: msg="hostA 1"

                        -   hosts: hostB
                            tasks:
                                - debug: msg="hostB 1"

                        -   hosts: hostA
                            tasks:
                                - debug: msg="hostA 2"
                    ロールがあるケース:
                        Playbook.yml:

                            -   hosts: hostA
                                vars:
                                    interaction_step: 1
                                tasks:
                                    - debug: msg="hostA 1"
                                    - import_role: name="interaction"

                            -   hosts: hostB
                                tasks:
                                    - debug: msg="hostB 1"

                            -   hosts: hostA
                                vars:
                                    interaction_step: 2
                                tasks:
                                    - debug: msg="hostA 2"
                                    - import_role: name="interaction"

                        roles/interaction/tasks/main.yml:

                            -   import_tasks: ./step1.yml
                                when: interaction_step == 1

                            # do the task in related hosts

                            -   import_tasks: ./step2.yml
                                when: interaction_step == 2

                        roles/interaction/tasks/step1.yml:
                            -   name: task step 1
                                debug: msg="task step 1"

                        roles/interaction/tasks/step2.yml:
                            -   name: task step 2
                                debug: msg="task step 2"
                ホスト名を参照します:  #// ターゲット ノード
                    "{{ inventory_hostname }}"  #search: inventory_hostname
                ローカル実行, 委任 >> local_action: #keyword: local_action
                    #ref: https://stackoverflow.com/questions/56048959/ansible-local-action-example-how-does-it-work
                    #ref: https://docs.ansible.com/ansible/latest/user_guide/playbooks_delegation.html
                関連:
                    ホスト:  #search: ansible inventory host
                    インベントリ ファイル:  #search: Ansible inventory file
                    --connection=local オプション:  #search: ansible-playbook --connection=local
            become 関連:  #// 権限昇格。プレイ全体ではなく特定のタスクで使用することもできます。  #keyword: ansible become,  Ansible sudo
                サンプル1.yml:
                    -   tasks:  #// roles/__RoleName__/tasks/____.yml では tasks の行は不要
                        -   name: install MySQL RPM package for CentOS7
                            become: yes
                            yum:
                                pkg: https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
                                state: present
                become:  #// 権限昇格。ゲスト マシーン の中で権限昇格します
                    参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/become.html  #template: __DocumentVersion__
                        #see-above: playbook1_yml
                    yes: 権限昇格またはユーザーを指定して実行をアクティブにします
                become_user:  #// 権限昇格時のゲスト マシーンのユーザ－名
                    これを省略すると root を指定したときと同じ処理をします。
                    Ansible を実行するユーザーにするときは、"{{ lookup('env','USER') }}"
                    権限昇格するときは、become も yes にする必要がありますと書いてありますが、
                    become_user も指定すると指定したユーザーで実行するだけで昇格するわけではありません。
                    代わりにフォルダーやリンクのパーミッションを 755 や 777 に設定してください。
                コマンドラインに指定する場合: #search: ansible-playbook become option
            tasks:  #// ゲスト マシーンで実行するコマンドや、ゲスト マシーンに期待する状態  #keyword: ansible tasks in Playbook.yaml
                #// プロビジョニングしたログからタスクの内容（ここ）を検索するときは、name: __TaskName__ で grep します
                サンプル: |  #see-below: 値に複数のパラメーターを指定する場合
                    -   tasks:
                        -   name: template configuration file
                            template:
                                src: template.j2
                                dest: /etc/foo.conf
                name トピック:  #// タスク名  #search: ansible task name
                    概要:
                        - name セクションの値はログに出力されます。少し自然言語風に書きます
                        - name セクションの値は、イベント通知をするときに nofity セクションの値に指定します。 #search: Ansible notify
                __ModuleName__:  #// 上記の template  #ref: https://docs.ansible.com/ansible/2.9_ja/modules/__ModuleName___module.html  #see-below: ansible_module  #template: __DocumentVersion__
                    #// tasks の直下に __ModuleName__ を書けることを Action Shorthand と呼びます  https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_intro.html#action-shorthand  #template: __DocumentVersion__
                    基本的なコマンド:  copy, shell, template, yum など  #search: ansible modules catalog
                environment セクション:  #keyword: Ansible environment in server,  ansible environment  #// このタスクに限りホスト内の環境変数を設定します
                    #search: Ansible shell env
                    参考:
                        - https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_environment.html  #template: __DocumentVersion__
                        - https://stackoverflow.com/questions/27733511/how-to-set-linux-environment-variables-with-ansible
                    サンプル:
                        -   hosts: all
                            remote_user: root
                            tasks:
                                -   name: Install cobbler
                                    package:
                                        name: cobbler
                                        state: present
                                    environment:                                         #// ここ
                                        http_proxy: http://proxy.example.com:8080
                    ❗注意: CLI から実行する場合と、Ansible で実行する場合では環境変数は異なる可能性があります。
                        debug モジュール で環境変数の値を確認してください  #search: Ansible debug
                    no_proxy などの設定: #keyword: Ansible proxy,  Ansible http_proxy,  https_proxy,  no_proxy
                        1か所に書く場合:  #// たとえば、プロキシの設定を 1か所にまとめて書く場合
                            #focus: proxy_env
                            tasks/main.yml: |
                                -   name: debug print              #// デバッグする場合のみ書きます
                                    debug: msg="{{ proxy_env }}"   #// デバッグする場合のみ書きます

                                -   name: install minio
                                    yum: name="minio"
                                    become: yes
                                    become_user: root
                                    environment: "{{ proxy_env }}"
                            group_vars/____/____.yml: |
                                proxy_env:
                                    http_proxy:  "http://{{ proxy_host }}:{{ proxy_port }}/"
                                    https_proxy: "http://{{ proxy_host }}:{{ proxy_port }}/"
                                    no_proxy: "____"
                        単純な実装の場合: |
                            -   name: コマンド実行
                                shell: your_command
                                environment:
                                    no_proxy: "localhost,127.0.0.1,.example.com"
                                    http_proxy: "{{ http_proxy }}"
                                    https_proxy: "{{ https_proxy }}"
                    辞書を指定した場合:  #keyword: Ansible dictionary environment in server  #// 辞書を指定すると、辞書の内容が展開されます
                        コード: |  #focus: second_vars,  variable1
                            vars:
                                first_variables:
                                    variable1: value1
                                    variable2: value2
                                second_vars: "{{ first_variables }}"
                            environment: "{{ second_vars }}"
                        同じ動作をするコード: |
                            environment:
                                variable1: value1
                                variable2: value2
                    VM 内に環境変数を設定し続ける場合:  #search: Ansible lineinfile module
                        lineinfile モジュールを使って /etc/profile (CentOS7) などを編集します
                    import_tasks にまとめて定義する場合: |  #keyword: Ansible import_tasks environment  #search: ansible environment in server
                        -   name: ____
                            import_tasks: ____.yml
                            environment:
                                __Name__: __Value__
                    block で定義する場合: |  #focus: LD_LIBRARY_PATH   #// block 必要ないかも
                        -   name: environment variabe example
                            block:
                                -   name: shell in environment variabe example
                                    become: yes
                                    become_user: root
                                    shell:
                                        cmd: "echo ${LD_LIBRARY_PATH}"
                            environment:
                                LD_LIBRARY_PATH: "/etc/lib"
                    コマンドに埋め込む場合:
                        playbook.yml: |
                            -   name: ____
                                shell: __Name__="__Value__"  __Command__
                        参考 >> コマンドが長いとき, 複数行:  #search: Ansible shell long command
                    env フィールド は未サポート:
                        playbook.yml: |
                            -   name: ____
                                shell:
                                    cmd: __Command__
                                    env:
                                        __Name__: __Value__
                        エラー: |
                            Unsupported parameters for (command) module: env Supported parameters
                vars:  #// １つのタスクの中からだけ参照できる変数を定義します  #keyword: Ansible tasks.vars
                    サンプル __Playbook__.yml:
                        tasks:
                            -   vars:
                                    __Name1__: __Value1__
                                    __Name2__: __Value2__
                                include_vars: "__FilePath__.yml"
                                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/role_example/vars/5_include_vars/playbook.yml#include_vars
                ignore_errors セクション:  #// タスクが失敗したとしても無視してプロビジョニングを成功させます  #keyword: ansible ignore_errors
                    yes: エラーになっても無視します
                    エラーかエラーでないかで分岐:  #search: Ansible when ignore_errors
                failed_when: #keyword: Ansible failed_when  #// 条件によってはタスクを失敗させます
                    引数: 失敗する条件
                    （関連）実行結果ではなく変数値で判定する場合: #search: Ansible fail when
                    サンプル: |
                        -   name: get root password
                            shell: grep "password" /var/log/mysqld.log | awk '{print $(NF)}'
                            register: result
                            failed_when: result.rc == 2  or  result.rc == 4  #// .rc = 終了コード
                    プレイを中止する場合: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_error_handling.html#id7  #template: __DocumentVersion__
                        #// 以下のいずれか、または両方
                        failed_when を true に設定します: |
                            #// 実行した後でエラーになります
                            -   name: temporary exit
                                debug: msg="temporary exit"
                                failed_when: true
                        any_errors_fatal を true に設定します: |  #focus: any_errors_fatal
                            -   hosts: all
                                tasks:
                                    -   name: Check IP address
                                        debug: var=hostvars[inventory_hostname].ansible_all_ipv4_addresses
                                        failed_when: g_host[inventory_hostname].ipv4.address != hostvars[inventory_hostname].ansible_all_ipv4_addresses[1]
                                any_errors_fatal: true
                    デバッグ:
                        サンプル: |  #// failed_when に指定する条件式を debug msg の {{ }} の中にコピペしてチェックします。更に構成する変数の値をチェックします
                            -   name: debug print 1
                                debug: msg="{{ result.rc == 2  or  result.rc == 4 }}"
                            -   name: debug print 2
                                debug: msg="{{ result.rc }}"
                                failed_when: true
                    バリエーション:  #// 終了コードの変更や複合条件
                        終了コード: |  #focus: result
                            register: result  #search: Ansible register  #// 同じタスク内でできるか未確認
                            failed_when: result.rc == 2
                        ログに error が含まれていたらエラーにする場合:  #search: Ansible error log check
                        stdout, stderr に含まれているかどうか:
                            含まれているとき: |  #focus: in
                                failed_when: "'FAILED' in __Register__.stdout"
                            含まれていないとき: |  #focus: not in
                                failed_when: "'FAILED' not in __Register__.stdout"
                        演算子:
                            ==, !=
                        and 条件:
                            failed_when:
                                - __Condition1__
                                - __Condition2__
                        or 条件:
                            1行に書くとき:
                                failed_when: __Condition1__  or  __Condition2__
                            複数行に書くとき:
                                failed_when: >  #// ( ) いる？
                                    (__Condition1__)  or
                                    (__Condition2__)
                    バリデーション:  #// 変数の値をバリデーションします:  #search: Ansible variable varidation
                    エラー メッセージ をカスタマイズする場合:  #search: Ansible fail
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_error_handling.html#controlling-what-defines-failure  #template: __DocumentVersion__
                    関連:  #search: Ansible when
                register セクション: #keyword: Ansible register  #// コマンドの実行結果に関する情報を変数に代入します
                    サンプル:  #focus: result,  result.stdout
                        -   name: get root password
                            shell: grep "password" /var/log/mysqld.log | awk '{print $(NF)}'
                            register: result          #keyword: ansible result
                        -   name: print root password
                            debug: var=result.stdout  #// 標準出力の内容
                    プロパティ:  #// register に指定した変数のプロパティ
                        changed: #keyword: register Ansible changed  #// 変更の有無
                            内容: タスクによって対象ホストに変化があったかどうか  #search: Ansible 冪等性
                            サンプル playbook.yml: |  #focus: register,  yum_result,  when,  changed
                                tasks:
                                    -   name: httpd パッケージをインストールします
                                        yum:
                                            name: httpd
                                            state: present
                                        register: yum_result

                                    -   name: 結果を表示します
                                        debug:
                                            msg: "httpd をインストールしました。～をしてください。"
                                        when: yum_result.changed
                            複数条件のサンプル playbook.yml: |  #focus: and,  restarted
                                tasks:
                                    -   name: httpd パッケージをインストールします
                                        yum:
                                            name: httpd
                                            state: present
                                        register: yum_result

                                    -   name: /etc/httpd/conf/httpd.conf に設定を追加します
                                        lineinfile:
                                            path: /etc/httpd/conf/httpd.conf
                                            line: 'ServerTokens Prod'
                                            state: present
                                        register: file_edit_result

                                    -   name: restarted.changed のデフォルトを設定します
                                        set_fact:
                                            restarted: {changed: false}

                                    -   name: サービスを再起動します
                                        become: true
                                        systemd:
                                            name: docker
                                            state: restarted
                                            daemon_reload: yes
                                            enabled: yes
                                        register: restarted
                                        when: yum_result.changed  and  file_edit_result.changed

                                    -   name: 結果を表示します
                                        debug:
                                            msg: "httpd サービスの状態が変わりました。～をしてください。"
                                        when: restarted.changed
                            再起動するタスクの ベスト プラクティス:  #search: Ansible restart task
                        json: #keyword: register Ansible json  #// HTTP レスポンスの JSON
                            内容: ansible uri のレスポンスの JSON。
                            サンプル playbook.yml: |
                                -   name: Wait for status green
                                    uri:
                                        url: "http://node1:9200/_cluster/health/?level=shards&pretty"
                                        method: GET
                                    register: result
                                    until: "result.json.indices['logs-my_app-default'].status == 'green'"
                                    delay: 3
                                    retries: 100
                        content: #keyword: register Ansible content  #// HTTP レスポンス全体 (?)
                            内容: ansible uri のレスポンス全体の文字列(?)。
                                ただし、return_content が yes でないと content は存在しません。
                                content から JSON の中のプロパティにアクセスできません。
                                register に指定した変数が result の場合、
                            サンプル playbook.yml: |
                                -   name: Wait for status green
                                    uri:
                                        url: "http://node1:9200/_cluster/health/?level=shards&pretty"
                                        method: GET
                                        return_content: yes
                                    register: result
                                    until: "'green' in result.content"
                    コマンドの出力を調べる: |  #focus: pyenv_versions  #keyword: Ansible grep
                        -   name: check if Python is installed for {{ user }}
                            become: true
                            become_user: "{{ user }}"
                            shell: pyenv versions | grep '{{ pythonVersion }}'  ||  true  #// true が無いと見つからなかったときにエラーになります
                            register: pyenv_versions

                        -   name: install Python for {{ user }}
                            become: true
                            become_user: "{{ user }}"
                            shell: pyenv install -v {{ pythonVersion }}
                            when: pyenv_versions.stdout == ""
                    ファイルの内容で変数定義する: #keyword: Ansible register cat
                        サンプル: |  #focus: result,  result.stdout
                            -   name: get unseal key 1
                                shell: cat  /home/user1/.secrets/vault_initial.log  |  grep  "Unseal Key 1:"  |  awk  '{print $NF}'
                                register: result
                            -   name: debug print
                                debug: msg="{{ result.stdout }}"
                        control ノード 内 のファイルの場合:  #search: Ansible lookup plug in type
                    実行結果によっては失敗させる場合: #search: ansible failed_when
                    実行結果が期待値になるまで待つ: #search: ansible until
                until:  #// コマンドの実行結果が期待値になるまで繰り返します  #keyword: Ansible until
                    書式:
                        __Module__:
                            register: result
                            until: "'green' in result.content"
                            retries: 100
                    サンプル:
                        #search: ansible uri
                    バリエーション:  #// 下記の条件が真になるまで繰り返します
                        概要: Jinja2 の式です
                        レスポンスの JSON の特定の値が等しい:
                            - "result.json.status == 'green'"  #// json や status が無いと FAILED になります
                            - "'json' in result  and  'status' in result.json  and  result.json.status == 'green'"  #// 長い…
                            - "result.json.status | default('') == 'green'"  #// json や status が無くても FAILED になりません  #search: Ansible no attribute
                            - "result.json.exitCode | default(99) == 0"  #// 0 == '0' は偽と判定されます
                            - "result.json.indices['logs-my_app-default'].status == 'green'"  #// JavaScript のプロパティ名に使えない文字がある場合
                        レスポンスの content のどこかの値に含む: "'green' in result.content"  #focus: in
                        レスポンスの content のどこかの値に含まない: "'green' not in result.content"  #focus: not in
                    result の内容を表示します:
                        -v オプションを付けて実行すると、レスポンスの値が表示されます。
                notify セクション:  #// ターゲット ノード に変化があったときに通知するイベント  #search: Ansible notify
                    参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_intro.html#handlers  #template: __DocumentVersion__
                    動作基本:
                        - ターゲット ノード に変化があったときに handlers（のタスク）を実行します
                        #search: Ansible role handlers
                    動作詳細:  #keyword: Ansible notify behavior
                        - 変更（インストール等）が行われたときだけ handlers を実行します。
                            たとえば yum モジュールに指定したモジュールがすでにインストールされていたら handlers は実行されません。
                            #search(ChatGPT3.5): Ansible の role を使わないで playbook に書かれた notify による通知を受ける handlers はどこに書けばよいでしょうか
                        - プレイ内のすべてのタスクが実行された後でハンドラーのタスクが実行されます
                        - notify セクションの順番ではなく、handlers セクションの定義の順でタスクを実行します
                        - イベント名のスコープはグローバルです
                        - 複数のイベントが発生してもタスクを実行するのは１回だけです
                        - | #// 同じ listen が設定されているとき
                            すべてのハンドラー roles/__FirstRole__/handlers/main.yml（など？）が実行されます。
                        - | #// 同じ name が定義されているとき
                            先に実行するロールのハンドラー roles/__FirstRole__/handlers/main.yml だけ有効です。
                                #// playbook.yml
                                roles:
                                    - __FirstRole__
                                    - __SecondRole__
                        - ホストA ⇒ ホストB ⇒ ホストA の順で実行するとき  #search: Ansible host interaction
                        #search: Ansible 設計
                    ハンドラー:  #keyword: Ansible handlers
                        別のファイルに書く場合:  #search: Ansible role handlers
                        同じファイルに書く場合:  #search: Ansible notify to handlers.name
                    handlers.name が定義したタスクを nofity から起動する場合: #keyword: Ansible notify to handlers.name
                        #focus: restart memcached
                        -   tasks:
                            -   name: template configuration file
                                template:
                                    src: template.j2
                                    dest: /etc/foo.conf
                                notify:
                                    - restart memcached
                                    - restart apache
                        -   handlers:
                            -   name: restart memcached
                                __ModuleName__: ____
                            -   name: restart apache
                                __ModuleName__: ____
                    notify が定義したイベントを、handlers.listen が応答する場合: #keyword: Ansible notify to handlers.listen
                        #focus: template configuration file updated
                        -   tasks:
                            -   name: template configuration file
                                template:
                                    src: template.j2
                                    dest: /etc/foo.conf
                                notify:
                                    - template configuration file updated  #// 0個以上のイベント ハンドラーが起動します
                        -   handlers:
                            -   name: ____
                                listen: template configuration file updated
                                __ModuleName__: ____
                tags セクション:  #search: Ansible tags
                when: #keyword: Ansible when,  Ansible conditions
                    概要: タスクを実行する条件を指定します
                    公式: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_conditionals.html  #template: __DocumentVersion__
                    基本:
                        サンプル コード playbook.yml:
                            tasks:
                                -   name: ____
                                    shell: __Command__  #// when の条件を満たすときだけ shell モジュールを実行します
                                    when: __VariableName__ == __Value__  #// when は shell の上でも下でも動きは変わりません
                                        #search: Ansible conditions
                    起動時に分岐先を指定する場合: #keyword: Ansible when --extra-vars  #// ansible-playbook コマンド起動時に指定した変数の値によって分岐します
                        #focus: target
                        サンプル コード playbook.yml:
                            tasks:
                                -   name: Check target variable specified by ansible-playbook command    #keyword: Ansible variable varidation
                                    debug: var=target
                                    failed_when: target != 'local'  and  target != 'server'

                                -   name: ____
                                    shell: __Command__
                                    when: target == 'local'  #// target が定義されていないと __Command__ 実行前にエラーになります
                        コマンド:
                            - ansible-playbook  __PlayBook__.yml  -i __InventoryFile__  --extra-vars 'target=local'  --check  #// dry run
                        アンインストールする場合: #keyword: Ansible uninstall services
                            ❗注意: 間違えてアンインストールしないように、特殊な環境変数を設定していないと実行できないようにします
                            playbook.yml:
                                when: confirm == 'remove-__Service__'
                            ansible-playbook のオプション:
                                --extra-vars 'confirm=remove-__Service__'
                    コマンドの実行結果による分岐: #keyword: Ansible when ignore_errors
                        サンプル コード playbook.yml:
                            tasks:
                                -   command: git --version
                                    register: install_check
                                    ignore_errors: True

                                -   when: install_check is failed
                                    command: /bin/something

                                -   when: install_check is succeeded
                                    command: /bin/something_else

                                -   when: install_check is skipped
                                    command: /bin/still/something_else
                    ファイルまたはフォルダーの有無による分岐:  #search: Ansible stat exists
                    ループの中の条件: #keyword: Ansible loop conditions
                        条件のサンプル:
                            - ==, !=, <, >, <=, >=, and, or, in, not in  #// Python (?)
                            - inventory_hostname != 'db1'
                            - ansible_facts['os_family'] == "Debian"
                            - ansible_facts['lsb']['major_release']|int >= 6
                            - true or "yes"|bool
                            - not __VariableName__
                            - __VariableName__ is defined
                            - __VariableName__ is undefined
                            - ( ansible_facts[‘distribution’] == "CentOS"  and
                                ansible_facts[‘distribution_major_version’] == "6" ) or (____)
                        列挙する（配列を指定する）と and 条件になります:
                        条件を満たす item のみ実行します:
                            tasks:
                                -   name: ____
                                    loop: [ 0, 2, 4, 6, 8, 10 ]
                                    when: item > 5  #// 6, 8, 10 のときだけ実行します
                                    command: echo {{ item }}
                        １つでも満たさないときは実行しません:
                            基本:
                                tasks:
                                    -   name: ____
                                        loop: "{{ mylist|default([]) }}"
                                        when: item > 5
                                        command: echo {{ item }}
                            item が辞書のとき:
                                tasks:
                                    -   name: ____
                                        loop: "{{ query('dict', mydict|default({})) }}"
                                        when: item.value > 5
                                        command: echo {{ item }}
                    インクルードに when を指定したとき:
                        #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_conditionals.html#applying-when-to-roles-imports-and-includes  #template: __DocumentVersion__
                        -   when: "'reticulating splines' in output"
                            import_tasks: tasks/sometasks.yml
                    無条件にスキップします: #keyword: Ansible skip
                        サンプル コード:
                            when: false  #// name と同じインデントの深さに書きます
                        "tags: never との違い":  #keyword: Ansible when false vs tags never
                            - when: false はスキップ。ログ表示あり  #// ステップ実行オプションを指定したとき、一時停止あり
                            - tags: never もスキップ。ログ表示無し  #// ステップ実行オプションを指定したとき、一時停止なし
                                #search: Ansible tags never
                    スキップの警告表示を無くします: #keyword: Ansible disable warning,  don't show hide
                        ANSIBLE_DISPLAY_SKIPPED_HOSTS=False  ansible-playbook  ____
                        #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/run-playbook.sh#ANSIBLE_DISPLAY_SKIPPED_HOSTS
                        #ref: https://stackoverflow.com/questions/39189549/how-can-i-hide-skipped-tasks-output-in-ansible
                    ロールのメソッドごとの分岐: #search: ansible roles design
                    関連:
                        条件によってエラーにする場合:  #search: Ansible failed_when
                        変数によって値を変える場合:  #search: Ansible vars condition
                loop:  #// for 文のようにタスクを繰り返し定義します  #keyword: ansible loop, ansible item
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_loops.html  #template: __DocumentVersion__
                    delegate_to >> __Playbook__.yml のサンプル: |
                        ---
                        -   hosts: all
                            become: yes
                            gather_facts: False

                            tasks:
                                -   name: Copy file
                                    copy:
                                        src: /etc/ansible/qiita.txt
                                        dest: /tmp/dir
                                    delegate_to: "{{ item }}"
                                    loop: "{{ ['group1', 'group2'] }}"
                    __Playbook__.yml のサンプルの説明:
                        #// group2 はグループ名です  #search: ansible groups
                        #// item は loop に指定した配列の要素です
                        #// 以上から、上記 Copy file タスクは group2 に所属するサーバーの中でコピーを実行します
                    オブジェクトをループします: #keyword: Ansible object loop
                        tasks:
                            -   name: ...
                                pip:
                                    name: "{{ item.name }}"
                                    version: "{{ item.version }}"
                                loop:
                                    - {name: 'dnspython', version: '1.16.0'}
                                    - {name: 'PyMySQL',   version: '0.10.1'}
                    キーでループします: #keyword: Ansible key loop  #focus: item,  with_items
                        vars:
                            __DictionaryName__:
                                __Field1__: __Value1__
                                __Field2__: __Value2__
                        tasks:
                            -   name: ____
                                debug:
                                    msg: "{{ item }}: {{ __DictionaryName__[item] }}"  #// key: value 形式で表示されます
                                with_items: "{{ __DictionaryName__.keys() }}"
                    変数ではない配列をループします:
                        -   name: loop example
                            debug: var={{ item.user }}
                            loop:
                                - { user: "sample1", password: "{{ test_password }}" }
                                - { user: "sample2", password: "{{ test_password }}" }
                    with_items と include_tasks の組み合わせ:  #search: Ansible with_items include_tasks
                    block 全体をループします:
                        できません。別の playbook をループすることはできます: #keyword: Ansible block include
                            サンプル プロジェクト: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/variable_exapmle/include/playbook.yml#include: block.yml arguments=
                            __Playbook__.yml のサンプル: |  #focus: arguments
                                tasks:
                                    -   name: include_tasks loop
                                        include: block.yml arguments={{ item }}  #// block.yml の右を空白２つにするとエラーになります
                                        loop:
                                            -   property_1: Value_1_1
                                                property_2: Value_1_2

                                            -   property_1: Value_2_1
                                                property_2: Value_2_2
                            block.yml のサンプル: |
                                #// This file is included from playbook.yml

                                -   name: property_1
                                    debug:
                                        msg: "arguments.property_1: {{ arguments.property_1 }}"

                                -   name: property_2
                                    debug:
                                        msg: "arguments.property_2: {{ arguments.property_2 }}"
                        参考:
                            Ansible block単位でLoopしたい！でも、出来ない ので: #ref: https://qiita.com/tbuchi888/items/c03e7cbce8608b1c55f1
                loop_control:  #keyword: ansible loop_control  #// ループに関する設定
                    loop_var:  #// ループ変数の名前を変更します。デフォルトは item です
                    #search: with_items
                with_items:  #keyword: ansible with_items  #// vars と同様に変数を定義しますが、ループ変数が使えます
                    #// loop とほぼ同じです。 ネストした配列が指定されたときは、フラットに展開してループします
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_loops.html#loop-with  #template: __DocumentVersion__
                    基本:
                        #search: Ansible key loop
                        #snip:
                            サンプル:  #focus: item,  with_items
                                -   name: ____
                                    debug:
                                        msg: "{{ item }}: {{ __DictionaryName__[item] }}"  #// key: value 形式で表示されます
                                    with_items: "{{ __DictionaryName__.keys() }}"
                    with_items と include_tasks の組み合わせの場合:  #keyword: Ansible with_items include_tasks
                        -   name: ____
                            include_tasks: sub_task.yml  #// 変数に入っている配列の要素数によるため import_tasks は使えません
                            with_items: "{{ item_list }}"  #// ループ変数に入る値の配列
                            loop_control:  #// ループに関する設定
                                loop_var: loop_item  #// sub_task.yml の中で参照できるループ変数。 with_items の要素
                block:  #// タスクをまとめます  #keyword: ansible block
                    参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_blocks.html  #template: __DocumentVersion__
                    __Playbook__.yml サンプル: |
                        -   tasks:
                            -   name: install, configure, and start Apache
                                block:
                                    -   name: install httpd and memcached          #// タスク
                                        yum:
                                            name:
                                                - httpd
                                                - memcached
                                            state: present
                                    -   name: apply the foo config template        #// タスク
                                        template:
                                            src: templates/src.j2
                                            dest: /etc/foo.conf
                                    -   name: start service bar and enable it      #// タスク
                                        service:
                                            name: bar
                                            state: started
                                            enabled: True
                                    -   name: i force a failure                    #// タスク
                                        command: /bin/false                        #// 必ず失敗する
                                    -   debug:                                     #// 失敗したら次のタスクは実行されません
                                        msg: 'I never execute, due to the above task failing, :-('
                                rescue:
                                    -   debug:
                                        msg: 'I caught an error, can do stuff here to fix it, :-)'
                                always:
                                    -   debug:
                                        msg: "This always executes, :-)"
                                when: ansible_facts['distribution'] == 'CentOS'    #// 以下の設定は上記全てのタスクに適用されます
                                become: true
                                become_user: root
                                ignore_errors: yes
                    __Playbook__.yml サンプルの説明:
                        rescue:  #// block の中で失敗したときに実行するタスク。オプション  #keyword: ansible rescue
                            ansible_failed_task 変数, ansible_failed_result 変数を参照できます:
                        always:  #// block の中で成功・失敗に関わらず実行するタスク。オプション  #keyword: ansible always
                include*: #// 動的に他のファイルをインポートします。評価される動的タスクのみインポートします。(?) #keyword: ansible include
                    参考: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_reuse.html  #template: __DocumentVersion__
                    #// ループ内に書けます。注意点は、 https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_reuse.html#id3  #template: __DocumentVersion__
                    include_tasks: #keyword: Ansible include_tasks  #// 関連: import_tasks  #// dynamic include
                        パラメーターを渡します:
                            playbooks/main_playbook.yml: |
                                tasks:
                                    -   name: add pyenv shims to PATH
                                        include_tasks: ../sub_tasks/add_path.yml
                                        vars:
                                            extra_path: /home/vagrant/.pyenv/shims
                            sub_tasks/add_path.yml: |  #// tasks: の行は不要
                                    -   name: 'Add {{ extra_path }} if PATH does not exist for CentOS'  #// 別の行に追加する
                                        become: true
                                        lineinfile:
                                            path: /etc/profile
                                            line: 'export PATH="{{ extra_path }}:$PATH"'
                                            insertafter: EOF
                                        when: lookup('file', '/etc/profile') is not search('^\s*PATH\s*=')
                        ループしてパラメーターを渡します:  #search: Ansible with_items include_tasks
                            playbooks/main_playbook.yml: |
                                tasks:
                                    -   name: add pyenv shims to PATH
                                        include_tasks: ../sub_tasks/add_path.yml
                                        with_items:
                                            - /home/vagrant/.pyenv/bin
                                            - /home/vagrant/.pyenv/shims
                                        loop_control:
                                            loop_var: extra_path  #// インクルードする YAML ファイルの中で参照できる変数。 with_items の要素
                            sub_tasks/add_path.yml:  #// 上記
                    include_role: #keyword: Ansible include_role   #// 関連: import_roles
                    include: #// 2.16 から deprecated になりました。tasks の中が書かれたファイルをインポートします。
                        サンプル: #search: Ansible block include
                import*: #glossary: Ansible  #// 静的に他のファイルをインポートします。Playbook 解析時にすべてインポートします。
                    import:  #keyword: ansible import
                    import_playbook:  #keyword: ansible import_playbook
                        注意 >> パッケージのバージョンが異なる場合:
                            まとめた playbook を作らないこと: #keyword: Ansible import only playbook problem
                                まとめた playbook のサンプル:
                                    release3.11.yml:
                                        - import_playbook: playbook-A.yml
                                        - import_playbook: playbook-B.yml
                                    #// 切り戻しのまとめた playbook も作らない
                                対処:
                                    -   playbook を1つずつ実行する手順にする。
                                    -   ただし、フロントエンドとバックエンドのようにセットのものは一度に実行する？（一度にできれば）
                                    -   失敗した playbook のみ切り戻しする手順にする（できる）。（1つずつ切り戻すコマンドにする）
                                不採用理由:
                                    -   一部の playbook だけ version を変える（統一しない）ことができないため。--extra-vars 'release_version=3.11.0'
                                            ansible-playbook コマンドに指定するバージョン番号は 1種類であるため
                                    -   Ansible では import_playbook した一部の playbook の成功を確認できないため（ログに表示される結果はホストごとになってしまう）
                                    -   ファイルの編集はリリース手順の中では行わない（というルールが多い）ため
                        基本サンプル:
                            ./parent.yaml: |
                                -   import_playbook: ./child.yml
                            ./child.yml: |
                                -   hosts: centos7_51
                                    tasks:
                                        -   name: create target database
                                            mysql_db:
                                                login_user: user1
                        グローバル変数を参照するサンプル:  #focus: vars
                            ./parent.yaml: |
                                -   import_playbook: ./child.yml
                            ./child.yml: |
                                -   hosts: "{{ my_hosts }}"
                                    vars_files: [../vars.yml]
                                    vars:
                                        databaseVersion: 3.1.1
                                        user: user1
                                    tasks:
                                        -   name: create target database {{ databaseVersion }}
                                            mysql_db:
                                                login_user: "{{ user }}"
                            ./vars.yml: |
                                my_hosts: centos7_51
                        パラメーター付きサンプル:  #focus: user
                            ./parent.yaml: |
                                -   import_playbook: database/playbook.yml
                                    vars:
                                        user: user1
                            ./database/playbook.yml: |
                                -   hosts: centos7_51
                                    vars:
                                        databaseVersion: 3.1.1
                                        # user: user1
                                    tasks:
                                        -   name: create target database {{ databaseVersion }}
                                            mysql_db:
                                                login_user: "{{ user }}"
                        注意: バージョン番号などの変数定義は playbook の中に書くほうが分かりやすく、実行しやすいです。
                            どうしても可変にしなければならないなら、playbook の中に {{ ____ }} を書きます。
                        旧）パラメーター付きサンプル:
                            ./parent.yaml:
                                - #
                                    import_playbook: playbooks/__Sub__/playbook.yml
                                    vars:
                                        __Sub___hosts: user1
                                        __Sub___username: "{{ common_password }}"
                                        __Sub___vars_files: ../../group_vars/all.yml
                                #// __Sub___vars_files は parent.yaml があるフォルダーから参照できる変数
                                #// （上記の common_password ）を参照して渡すときに必要です。
                                #// なぜなら、参照した変数の値を渡すのではなく、変数参照を渡しているため、
                                #// __Sub__ フォルダーから変数を参照できないからです。
                            ./playbooks/__Sub__/playbook.yml:
                                - #
                                    hosts: "{{ __Sub___hosts }}"
                                    vars_files: ["{{ __Sub___vars_files }}"]
                                    tasks:
                                        - #
                                            name: create target database
                                            mysql_db:
                                                login_user: "{{ __Sub___username }}"
                    import_tasks:  #// static include
                        基本サンプル: |
                            -   name: ____
                                import_tasks: ____.yml
                        環境変数: #search: Ansible import_tasks environment
                    import_roles:  #search: ansible roles
                    グラフ表示: #keyword: ansible-playbook-grapher,  Ansible tree  #// import include の様子をグラフで表示します
                        #ref: https://github.com/haidaraM/ansible-playbook-grapher
                        pip install ansible-playbook-grapher
                        sudo yum install -y  graphviz
                        ansible-playbook-grapher  __PlaybookFilePath__
                        （___.svg が作られます）
                        #search: Ansible system debug
                delegate_to:  #keyword: ansible delegate_to  #// 実行するマシーンを変更します。localhost を指定すると SSH クライアントを使いません
                    参考:
                        - https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_delegation.html  #template: __DocumentVersion__
                        - https://qiita.com/fumiya-konno/items/d2d6b67296e5ee94340b
                    .gitignore の対象外のみコピーする場合:  #keyword: Ansible .gitignore
                        playbook.yml: |
                            tasks:
                                -   name: make playwright_example folder that does not have .gitignore releated files
                                    shell:
                                        chdir: /vagrant/service_example/playwright_example
                                        cmd: git checkout-index -fau --prefix="/vagrant/working/"
                                    delegate_to: localhost

                                -   name: install Playwright project example
                                    copy:
                                        src: /vagrant/working/service_example/playwright_example/
                                        dest: "/home/vagrant/playwright_example/"
                                        mode: '755'

                                -   name: delete playwright_example folder that does not have .gitignore releated files
                                    file:
                                        state: absent
                                        path: /vagrant/working/service_example/playwright_example
                                    delegate_to: localhost
                        補足:
                            localhost: control ノードです
                            git checkout-index: .gitignore の対象外のみコピーします
                    古いサンプル:
                        __Playbook__.yml のサンプル: |
                            ---
                            -   name: test play
                                hosts: webservers
                                serial: 2

                                tasks:
                                    name: take out of load balancer pool
                                    command: /usr/bin/take_out_of_pool {{ inventory_hostname }}
                                    delegate_to: 127.0.0.1
                        __Playbook__.yml のサンプルの説明:
                            #// delegate_to: 127.0.0.1 によって、Ansible を実行しているマシーンでタスクを実行します
                            #// 対象のホストの名前は inventory_hostname 変数の値です
            handlers:  #// イベント ハンドラー
                name トピック:  #search: Ansible notify to handlers.name
                listen トピック:  #search: Ansible notify to handlers.listen
            vars:  #// 変数定義。__Playbook__.yml の hosts キーごと  #keyword: ansible vars in Playbook.yml
                参照: ⇒ #search: ansible vars
                注意: role を使う場合、ここ（__Playbook__.yml）に変数の定義を書くと、依存する role の処理で変数を参照できなくなります  #search: ansible vars in role folder
                サンプル:
                    __Playbook__.yml:
                        vars:  #// hosts と同じインデントの深さ
                            __Name1__: __Value1__  #// 変数名に使える文字は、文字（アルファベット？）、数字、アンダースコア
                            __Name2__: __Value2__
                        include_vars: "__FilePath__.yml"
                        vars_files:                        #see-below: ansible_vars_files
                            - /vars/external_vars.yml
            vars_files:  #// 変数定義ファイルの参照  #keyword: Ansible vars_files in Playbook.yml
                サンプル Playbook.yml:
                    -   hosts: ____
                        vars_files: [vars.yml]
                        tasks:
                            ____
                    #search: define Ansible dictionary variable
                サンプル(2) Playbook.yml:
                    - #
                        hosts: ____
                        vars_files:
                            - /vars/external_vars.yml
                            - ../../group_vars/all.yml
                        tasks:
                            ____
                vars.yml:
                    __Name1__: __Value1__  #// 変数名に使える文字は、文字（アルファベット？）、数字、アンダースコア
                    __Name2__: __Value2__
            include_vars:  #// 変数定義のあるファイルを指定します  #keyword: Ansible include_vars in Playbook.yml
                関連 >> vars_files:  #// hosts と同じ深さで定義する変数をインポートします
                    #search: Ansible vars_files in Playbook.yml
                pre_tasks で include_vars するサンプル Playbook.yml:
                    - name: mysql schema migration
                      vars:
                        mysql_schema_migration:
                          schema_list: "{{ mysql_schema_list.schema_list }}"
                      pre_tasks:
                        - name: load schema list
                          include_vars:
                            file: mysql-schema-list.yml
                            name: mysql_schema_list  #// mysql_schema_list.__VariableName__ で参照するような設定です
            import_playbook:  #search: ansible import_playbook
            roles:  #// ロール #keyword: ansible roles
                設計: #keyword: ansible roles design  #// 使うソフトウェアごとに作ります
                    使うソフトウェアごとに作ります:
                    メソッドごとに作ります。たとえば、インストールとアンインストールは別にします:
                        ロールに複数のメソッドを配置することは非推奨。
                        動作はできるが、状況の表示が複雑になるため。
                        ansible-playbook コマンドに --step オプションを指定すると、when が false でもステップ（一時停止）してしまうため。
                        #ref: https://stackoverflow.com/questions/28945082/how-to-do-best-organization-of-install-and-delete-in-the-same-ansible-playbook
                    ホストはロールを使う側が設定します:
                参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_reuse_roles.html  #template: __DocumentVersion__
                # 特定の vars_files、タスク、およびハンドラーを自動的に読み込む方法
                サンプル roles フォルダー:
                    #focus: __RoleName__, shell, shared_folder, my_shared_folder
                    group_vars/:
                        all.yml:
                            my_shared_folder: ____
                    roles/:
                        __RoleName__/:
                            defaults/:  #// または vars
                                main.yml:
                                    role:
                                        shared_folder: "{{ my_shared_folder }}"
                            tasks/:
                                main.yml:
                                    # sudo umount  "${share_}"
                                    -   name: Unmount shared folder
                                        become: yes
                                        become_user: root
                                        shell: umount  "{{ role.shared_folder }}"
                    playbook.yml:
                        -   name: Unmount shared folder
                            hosts: ____
                            roles: [__RoleName__]
                Playbook.yml へロールをインポートします:  #keyword: ansible roles in Playbook.yaml, ansible import_role, ansible include_role
                    サンプル プロジェクト:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/
                    新しい書き方）import_role セクションで静的インポート:  #// 動的インクルードのときは include_role
                        playbook.yml:
                            -   hosts: __Host__
                                tasks:
                                    -   name: import __RoleName__
                                        import_role:
                                            name: __RoleName__
                        roles/__RoleName__/tasks/main.yml: |
                            -   import_role: name=example
                    古い書き方）roles セクションで静的インポート: |
                            ---
                            -   hosts: __Host__
                                roles:
                                    - common
                                    - webservers
                                    - role: '___/roles/__RoleName__'
                        #// rules の子要素に同じ名前のロールがあっても実行するのは１回です
                        #// 2回実行する場合は、ロールの複製および実行 https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_reuse_roles.html#id5  #template: __DocumentVersion__
                        #//    異なるパラメーター または allow_duplicates: true
                    role による依存解決（古い書き方）: |  #focus: __ChildRole1__, __ChildRole11__
                        __Playbook__.yml:
                            -   roles:
                                -   __ChildRole1__
                                -   __ChildRole2__
                        roles/__ChildRole1__/meta/main.yml:  #// ルートの Playbook の role に書くほうが分散しないので、デバッグ時に途中から実行しやすくなります
                            dependencies:
                                -   { role: __ChildRole11__ }
                                -   { role: __ChildRole12__ }
                        roles/__ChildRole1__/tasks/main.yml
                            -   name: install python
                                yum: name="python"
                                become: yes
                                become_user: root
                                environment: "{{ proxy_env }}"
                        roles/__ChildRole11__/meta/main.yml:   #// 上記と同様
                        roles/__ChildRole11__/tasks/main.yml:  #// 上記と同様
                        roles/__ChildRole12__/meta/main.yml:   #// 上記と同様
                        roles/__ChildRole12__/tasks/main.yml:  #// 上記と同様
                        roles/__ChildRole2__/meta/main.yml:    #// 上記と同様
                        roles/__ChildRole2__/tasks/main.yml:   #// 上記と同様
                フォルダー構成: #keyword: Ansible roles folders  #🌟  #// ロール別の設定は下記のフォルダーに配置します
                    roles フォルダーの位置:
                        - __FolderHavingPlaybook__/roles/
                        #または
                        - /etc/ansible/roles/
                        #または
                        - 追加の roles_path
                    roles/__RoleName__/tasks/main.yml :  #keyword: Ansible tasks in role folder  #// 処理内容（メイン）
                        tasks フォルダーに複数のファイルを配置する場合のサンプル: |
                            -   include: install.yml
                                become: yes
                            -   include: configure.yml
                                become: yes
                        #// when セクションで場合分けすることもよくあります  #search: ansible when
                    roles/__RoleName__/handlers/main.yml :  #keyword: Ansible role handlers  #// ファイルに変更があったら、reload web server イベントをトリガーします
                        サンプル:
                            tasks/main.yml: |  #// ファイルに変更があったら、reload web server イベントをトリガーします（変更がなかったときの動作は未確認）
                                -   name: copy nginx conf
                                    template:
                                        src: "nginx.conf.j2"
                                        dest: "/etc/nginx/conf.d/example.conf"
                                    notify:
                                        -   reload web server    #// handlers/main.yml の name または listen
                            handlers/main.yml: |  #// reload web server イベントがトリガーされたときに実行するタスク（ハンドラー）reload nginx
                                -   name: reload nginx
                                    service:
                                        name: nginx
                                        state: reloaded
                                    become: yes
                                    listen: "reload web server"    #// name でもトリガーできるので、listen は必須ではありません
                        name, listen:  #// イベント名
                            - notify ステートメント に listen ステートメントの値を設定します  #search: Ansible notify
                            - listen が存在しないときは、name の値を notify ステートメント に設定します
                        使うケース:
                            handlers は変更したら呼ばれるものというよりかは、
                            設定ファイルやインストール状態を変更して、
                            最後に再起動するパターンで使うという認識でいると適切に使えます。
                        動作詳細:  #search: Ansible notify behavior
                    roles/__RoleName__/defaults/main.yml :  #search: ansible default vars in role folder  #// デフォルト変数
                    roles/__RoleName__/vars/main.yml :      #search: ansible vars in role folder
                    roles/__RoleName__/templates/main.yml :
                    roles/__RoleName__/meta/main.yml :  #search: Ansible dependencies
                    roles/__RoleName__/__Others__/main.yml :
                実行順序: #keyword: Ansible 実行順序
                    実行順序:
                        #// 参考: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_reuse_roles.html#id4  #template: __DocumentVersion__
                        - pre_tasks
                        - roles
                            #// 依存先（子ロールの tasks/*.yml）を先に実行します  #search: Ansible dependencies
                            #// 複数の roles フィールドに同じ依存先が指定されるときは 1度だけ実行します
                            #// tasks/main.yml を実行後、通知を受けたハンドラー handlers/main.yml が動作します  #search: Ansible role handlers
                        - tasks
                        - post_tasks
                    実行順序を確認します:
                        #search: Ansible --list-tasks
                    #search: Ansible 設計
                依存関係: #keyword: Ansible dependencies
                    playbook => roles:  #search: ansible roles in Playbook.yaml
                    roles => roles:
                        場所: roles/__RoleName__/meta/main.yml
                        内容のサンプル:  #// bike は wheel に依存しています
                            roles/bike/meta/main.yml: |
                                ---
                                dependencies:
                                - role: wheel
                                    vars:
                                    n: 1
                                - role: wheel
                                    vars:
                                    n: 2
                    条件付き依存:  #// 未確認  #focus: when
                        playbook.yml : |
                            roles:
                                -   role: base_rpms
                                -   role: python
                                    when: python_is_used
                    関連 >> ハンドラー:  #search: Ansible role handlers
                複数ノードに対するロール:
                    - ロールではなく import する Playbook に書きます  #search: ansible import_playbook
                    - https://serverfault.com/questions/970405/ansible-multiple-hosts-in-one-role
            serial:  #// 並列実行の最大数  #keyword: Ansible serial
                省略した場合: 最大数の制限を付けず、すべて並列動作します
                1: #// サーバー1つずつ実行します。シンプルな ローリング アップデート の場合はこれ
                    サンプル playbook.yml:
                        -   hosts: [node1, node2, node3]
                            serial: 1  #// node1 name 1 => node1 name 2 => node2 name 1 => node2 name 2 => node3 name 1 => node3 name 2
                            tasks:

                            -   name: 1) Install the service
                                become: yes
                                yum:
                                    pkg: ["/home/vagrant/Downloads/service-1.0.0.rpm"]
                                    state: present

                            -   name: 2) Start and reload the service
                                become: yes
                                systemd:
                                    name: __ServiceName__
                                    state: restarted
                                    daemon_reload: yes
                                    enabled: yes
                注意: |
                    [WARNING]: Could not match supplied host pattern, ignoring: [node1
                    のようにホスト名に [ が表示されたら、配列（アレイ）の指定方法を正しくしてください  #search: Ansible join
                参考:
                    Delegation, Rolling Updates, and Local Actions: #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_delegation.html  #template: __DocumentVersion__
                __Playbook__.yml: |
                    ---
                    -   name: test play
                        hosts: webservers
                        serial: 2  #// 2= 2台ずつ。 30%=全体の30%の台数ずつ
                        gather_facts: False

                        tasks:
            pre_tasks:
                _: ロールを含む他のすべてのタスクの前にそれらのタスクが実行されます
                参考:
                    Set the order of task execution in Ansible with these two keywords: #ref: https://www.redhat.com/sysadmin/ansible-pretasks-posttasks
            post_tasks:
                参考:
                    Set the order of task execution in Ansible with these two keywords: #ref: https://www.redhat.com/sysadmin/ansible-pretasks-posttasks
        roles/:  #search: Ansible roles folders  #search: ansible roles
        group_vars/:  #search: Ansible group_vars/all.yml
        インベントリー ファイル:  #search: ansible inventory file
        ansible.cfg ファイル, コンフィギュレーション: #keyword: ansible.cfg, ansible configurations  #// Configuration file
            概要:
                説明:
                    - https://docs.ansible.com/ansible/2.9_ja/installation_guide/intro_configuration.html  #template: __DocumentVersion__
                    - https://www.vagrantup.com/docs/provisioning/ansible_intro#the-ansible-configuration-file
                リファレンスの見方: #keyword: ansible.cfg reference
                    公式コードから:
                        手順: https://github.com/ansible/ansible  >>  repo:ansible/ansible  __Keyword__
                        サンプル: https://github.com/ansible/ansible  >>  repo:ansible/ansible  ssh_args
                    プロジェクトのコードから:
                        grep してください。プロジェクト独自の ansible.cfg のフィールドを追加することができます。
                    ドキュメントから:  #// 情報が不足しています
                        リファレンス:
                            #ref: https://docs.ansible.com/ansible/latest/reference_appendices/config.html
                            #ref: https://docs.ansible.com/ansible/2.9_ja/reference_appendices/config.html#common-options  #template: __DocumentVersion__
                        サンプル:
                            ACTION_WARNINGS:
                                Description: （説明）
                                Default:     True
                                Ini Section: defaults
                                Ini Key:     action_warnings
                                Environment: ANSIBLE_ACTION_WARNINGS
                        サンプルの説明:
                            - ACTION_WARNINGS は設定名です。ansible-config コマンドに指定します: |
                                $ ansible-config dump | grep ACTION_WARNINGS
                                ACTION_WARNINGS(default) = True
                            - Ini Section と Ini Key は、ansible.cfg ファイルに書く Ini 形式のセクションとキーです:
                                ansible.cfg : |
                                    [defaults]
                                    action_warnings = False
                            - Environment は環境変数に設定するときの環境変数名です:
                                ANSIBLE_ACTION_WARNINGS=False  ansible-config dump
            手順:  #// 設定方法
                ansible.cfg に設定する場合:
                    サンプル:
                        lookup_plugins = __LookUpPlugInPath__
                        filter_plugins = __CustomFilterPlugInPath__
                環境変数に設定する場合:
                    DEFAULT_LOOKUP_PLUGIN_PATH=__LookUpPlugInPath__
                    DEFAULT_FILTER_PLUGIN_PATH=__CustomFilterPlugInPath__
            場所:
                使われているファイルの場所: |
                    $ ansible --version
                    ...
                        config file = /home/user1/project/ansible.cfg
                候補:  #// 下記は上が優先。下記のファイルの複数のファイルに同じ設定項目が書かれているとき、上にあるファイルの設定ほど優先されます。
                    -   __CurrentFolder__/ansible.cfg
                    -   ~/.ansible.cfg
                    -   /etc/ansible/ansible.cfg
            内容:  #// ansible.cfg ファイル の内容   #glossary: ansible.cfg  #search: ansible.cfg reference
                lookup_plugins:  #keyword: ansible.cfg  lookup_plugins
                    ansible.cfg : |  #search: ansible.cfg
                        [defaults]
                        lookup_plugins = __LookUpPlugInPath__
                    #search: Ansible lookup plug in
                filter_plugins:  #keyword: ansible.cfg  filter_plugins  #ref: https://docs.ansible.com/ansible/latest/reference_appendices/config.html#default-filter-plugin-path
                    ansible.cfg : |  #search: Ansible plug in files
                        [defaults]
                        filter_plugins = __CustomFilterPlugInPath__
                    省略時: __AnsibleProject__/filter_plugins/____.py
                    #search: Ansible custom filter plug in
                profile_tasks: #keyword:  #// タスクの開始時刻と処理時間を表示します
                    表示例:
                        各タスク実行開始時:
                            TASK [__TaskName__] ******************************************************************************************************************
                            Wednesday 02 February 2022  02:22:22 +0000 (0:00:01.754)       0:00:05.206 **** 
                                #// 日時    プレイ開始からの経過時間
                        プレイの最後:  #// 時間がかかったタスクの順位
                            Wednesday 02 February 2022  04:56:00 +0000 (0:00:32.747)       0:10:34.700 **** 
                            =============================================================================== 
                            Wait for starting ElasticSearch node --------------------------------------------------------------------------------------- 118.81s
                            Restart ElasticSearch to load elasticsearch.yml ----------------------------------------------------------------------------- 51.25s
                            Restore all ElasticSearch index --------------------------------------------------------------------------------------------- 32.75s
                    /etc/ansible/ansible.cfg:  #// 場所はコマンド ansible --version で表示されます
                        編集前: |
                            #callback_whitelist = timer, mail
                        編集後: |
                            #callback_whitelist = timer, mail
                            callback_whitelist = profile_tasks
                        以上で Ansible を実行すると表示されます:
            コマンド:
                表示:
                    - ansible --version  #// ansible.cfg ファイルの場所などを表示します  #see-above: ansible --version
                    - ansible-config dump  #// すべてのコンフィギュレーションを表示します
                    - ansible-config dump --only-changed  #see-above: ansible-config dump --only-changed
                    - ansible-config dump | grep __ConfigurationName__  #see-below: ansible-config dump | grep
        サーバーに置く任意のファイル:  #search: ansible file module
        プラグイン:  #search: Ansible plug in files
    設定: #settings:
        __DocumentVersion__: 2.9_ja
    トラブルシューティング（Ansible）:  #keyword: Ansible trouble shooting
        - ステップ実行する:  #search: Ansible step
        - スキップしてしまう: #keyword: Ansible skip
            ログ: |
                TASK [__Role__ : __Task__] **********************************************************************
                skipping: [__FQDN__]
            リモートのファイルの状態が変わった場合:
                ansible-playbook コマンドに --flush-cache オプションを付けて実行します。
                Gathering Facts が実行されます。
            タスクに条件がある場合:
                when, changed_when, creates などの条件を満たすか確認します
        - エラーを発生させるなど: #keyword: Ansible error  #ref: https://docs.ansible.com/ansible/2.9_ja/user_guide/playbooks_error_handling.html  #template: __DocumentVersion__
            エラーを発生させます:
                #search: Ansible  failed_when
                #search: Ansible  fail
            エラーを無視します:  #search: Ansible ignore_errors
        - 文法エラーが正しくない: #search: VSCode Ansible syntax error
        - 内部で使っている Python: #search: Ansible version
        - バージョンアップしたときのエラー:  #keyword: Ansible system debug,  Ansible version up playbook.yml
            対処:
                リセットします:
                    - ansible.cfg や インベントリー ファイル を空にしてから、少しずつ復元させます
                変数参照 playbook (_var_test.yml) で試します: #keyword: Ansible _var_test.yml
                    - debug モジュールしか使わない最もシンプルな playbook を使います  #search: Ansible debug
                    - 参照する変数によって結果が変わります。たとえば、プラグインを参照しない変数なら、プラグインが登録していなくても参照できます
                    - デプロイ先のホストによってグループ変数が変わります  #search: Ansible group_vars YAML
                実行する playbook の最初のタスクで変数参照します:
                    - role をコメントアウトして変数参照します。role が先に実行されるため
                    - role の中で変数参照します
        - プラグインのデバッグ:  #search: Ansible plug in debug
        #// エラーメッセージ
        - #// No package ____ available. Failed to install some of the specified packages
            手順: ansible-playbook >> dnf モジュール
            ログ: |
                fatal: [__Host__]: FAILED! => {"changed": false, "failures": ["No package ____ available."], "msg": "Failed to install some of the specified packages", "rc": 1, "results": []}
            対処:
                #search: createrepo
                #search: /etc/yum.repos.d/____.repo
        - #// not supported between instances of 'str' and 'int'
            手順: ansible-playbook コマンドで yum モジュールのタスクを実行
            エラー: |
                TASK [__Role__ : __Task__] ***************************************************************
                fatal: [__Host__]: FAILED! => {"msg": "Unexpected templating type error occurred on ({{ __Expression__ }}): '>' not supported between instances of 'str' and 'int'. '>' not supported between instances of 'str' and 'int'"}
            対処: |
                {{ __Expression__ | int }}
        - #// fatal: [__FQDN__]: UNREACHABLE!  #keyword: Ansible fatal UNREACHABLE!
            手順: ansible-playbook コマンド
            エラー: |
                TASK [Gathering Facts] *********************************************************
                fatal: [__FQDN__]: UNREACHABLE! 
            対処:
                接続してよいかの確認がされないようにします  #search: SSH fingerprint
        - #// ModuleNotFoundError: No module named 'pyexpat'
            手順: Python のソースをビルド
            エラー: |
                File "/home/user1/_________/python37/build/python-source/Python-3.7.2/Lib/xml/parsers/expat.py", line 4, in <module>
                    from pyexpat import *
                ModuleNotFoundError: No module named 'pyexpat'
            対処:
                sudo dnf install -y  expat-devel
        - #// skipping: [__HostName__]
            手順: ansible-playbook コマンド
            ログ: |
                TASK [____] **************
                skipping: [__HostName__]
            対処A:
                一度ログアウトします
            対処B:
                ansible-playbook コマンドに --check オプションを付けて実行し、--check オプションを付けないコマンドに戻して実行します
        - #// Error pulling image __Image__:latest - 404 Client Error for http+docker:_____ Not Found (\"pull access denied
            手順: docker_container のタスク
            エラー: |
                fatal: [localhost.example.com]: FAILED! => {"changed": false, "msg": "
                    Error pulling image group/python-github-runner:latest - 404 Client Error for
                    http+docker://localhost/v1.44/images/create?tag=latest&fromImage=group%2Fpython-github-runner: 
                    Not Found (\"pull access denied for group/python-github-runner,
                        repository does not exist or may require 'docker login': denied:
                        requested access to the resource is denied\")"}
            対処A:
                docker images コマンドで対象のイメージが存在することを確認します
            対処B:
                Dockerfile の image フィールドを修正します: #keyword: Ansible docker_container module local image
                    修正前: |
                        image: group/python-github-runner
                    修正後: |
                        image: group/python-github-runner:latest
            補足:
                docker images で表示されるイメージを使うときは、イメージ名のタグ部分（latest など）まで書く必要があります
                    $ docker images
                    REPOSITORY                  TAG       IMAGE ID       CREATED       SIZE
                    my/python-github-runner     latest    fdfa84af82e7   1 days ago    1.01GB
                #ref: https://stackoverflow.com/questions/38169244/how-do-i-tag-a-local-docker-image-with-ansible-docker-image-module
        - #// Unknown Error occurred: Transaction test error: package __RpmFileName__ does not verify: no digest
            手順: ansible-playbook コマンド >> yum モジュール
            エラー: |
                Unknown Error occurred: Transaction test error: package __RpmFileName__ does not verify: no digest
            対処:
                CentOS8 にインストールする RPM ファイルは、CentOS8 で作るべき  #search: cross RPM CentOS7 CentOS8
        - #// ERROR! [DEPRECATED]: ansible.builtin.include has been removed. Use include_tasks or import_tasks instead.
            手順: ansible-playbook コマンド
            エラー: |
                ERROR! [DEPRECATED]: ansible.builtin.include has been removed. Use include_tasks or import_tasks instead. This feature was removed from ansible-core in a release after 2023-05-16. Please update your playbooks.
            対処:
                エラーが発生しているタスク以外も include を include_tasks などに置き換えます
                #ref: https://docs.ansible.com/ansible-core/2.12/user_guide/playbooks_reuse.html#re-using-files-and-roles
        - #// fatal: [__Host__]: FAILED! => {"msg": "The task includes an option with an undefined variable.
            手順: ansible-playbook コマンド
            エラー: |
                fatal: [__Host__]: FAILED! => {"msg": "The task includes an option with an undefined variable.
                The error was: __Expression__: '__Symbol__' is undefined. '__Symbol__' is undefined. __Expression__:
            対処:
                ansible.cfg に vars_plugins を設定します
        - #// [WARNING]:  * Failed to parse __InventoryIniFilePath__ with ini plugin: Invalid host pattern 'plugin:' supplied, ending
            手順: ansible-playbook コマンド
            エラー: |
                [WARNING]:  * Failed to parse __InventoryIniFilePath__ with ini plugin: Invalid host pattern 'plugin:' supplied, ending
                in ':' is not allowed, this character is reserved to provide a port.
                [WARNING]: Unable to parse __InventoryIniFilePath__ as an inventory source
            対処A:
                ansible.cfg ファイルの enable_plugins に constructed を追加します: |
                    [inventory]
                    enable_plugins = ini, constructed
            対処B:  #search: Ansible system debug
            原因:
                下記の plugin がホスト名として解釈されてしまっています:
                    YAML の インベントリー ファイル: |
                        plugin: constructed
            参考:
                インベントリー プラグイン:  #search: Ansible inventory plug in
        - #// Unsupported parameters for (command) module: env Supported parameters
            手順: 環境変数を指定した shell モジュールを使ったタスクの実行
            エラー: |
                fatal: [__FQDN__]: FAILED! => {"changed": false, "msg": "Unsupported parameters for (command) module: env Supported parameters include: _raw_params, _uses_shell, argv, chdir, creates, executable, removes, stdin, warn"}
            対処:
                #search: Ansible shell env
        - #// template error while templating string: no filter named
            手順: ansible-playbook ...
            エラー: |
                template error while templating string: no filter named '__FunctionName__'. String: {{ __Expression__ | __FunctionName__ }}"}  #keyword: Ansible no filter named trouble
            対処A:
                エラーが発生していないか確認します: |  #// 起動時に警告が表示されますが、そのまま実行されてしまいます
                    $ ansible-playbook ...
                    [WARNING]: Skipping plugin (/____/plugins/filter/__Filters__.py) as it seems to be
                    invalid: invalid syntax (__Filters__.py, line __LineNum__)
            対処B:
                filter プラグイン が入っているフォルダーの場所を確認します:
                    ansible-config dump | grep FILTER
                そのフォルダーの中の Python ファイルでフィルターが正しく定義されているか確認します:
                    #search: Ansible custom plug in
        - #// Could not load "__Symbol__"
            手順: ansible-playbook コマンド
            エラー: |
                [WARNING]:  * Failed to parse __InventoryIniFilePath__ with __PlugInName__ plugin:
                failed to parse __InventoryIniFilePath__: Could not set host_type for host __HostName__: template error while templating string: Could not
                load "__Symbol__": '__Symbol__'. String: {{ ...__Symbol__ ... )}}. Could not load "__Symbol__": '__Symbol__' . Could not set
                host_type for host __HostName__: template error while templating string: Could not load "__Symbol__": '__Symbol__'. String:
                {{ ...__Symbol__ ... }}. Could not load "__Symbol__": '__Symbol__'
            対処A:
                カスタム フィルター プラグイン を使えるようにします:  #search: ansible.cfg  filter_plugins
            対処B:  #search: Ansible no filter named trouble
            対処C:  #search: Ansible system debug
            原因:
                ユーザー定義のプラグインの関数 __Symbol__ が見つかりません。
        - #// VALUE_SPECIFIED_IN_NO_LOG_PARAMETER
            手順: ansible-playbook ... -vvv
            メッセージ: |
                ... "user": "admin", "login_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER", ...
            対処A:
                Playbook ファイル:
                    no_log: False
            対処B:  #ref: https://serverfault.com/questions/1048538/how-to-expose-passwords-secrets-in-ansible-playbook
                ansible.cfg ファイル:
                    no_log = False
                非対応の場合:  #// 上記の方法は Ansible 2.9 では使えないようです
                    password フィールドに設定してある値を debug モジュールにコピーしてください  #search: Ansible debug
        - #// Invalid host pattern 'plugin:' supplied, ending in ':' is not allowed, this character is reserved to provide a port.
            手順: ansible-playbook
            エラー: |  #focus: __DefineSymbol__, __ReferredSymbol__
                [WARNING]:  * Failed to parse ____/inventory.config with ini plugin:
                Invalid host pattern 'plugin:' supplied, ending in ':' is not allowed, this character is reserved to provide a port.
                [WARNING]:  * Failed to parse ____/inventory.config with constructed
                plugin: failed to parse ____/inventory.config: Could not set __DefineSymbol__ for host
                __TargetHost__: '__ReferredSymbol__' is undefined
            対処:
                compose で定義した変数を compose の中で参照することはできません。
                変数の定義内容に展開してください。
        - #// [WARNING]: Failure using method (__Method__) in callback plugin (<ansible.plugins.callback.custom.CallbackModule object at ____>): '__Parameter__'
            手順: ansible-playbook コマンド
            エラー: |
                [WARNING]: Failure using method (v2_playbook_on_task_start) in callback plugin (<ansible.plugins.callback.custom.CallbackModule object at 0x7ff5a29c7cd0>): 'display_skipped_hosts'
            対処A:  #// ansible.cfg ファイルを最小限にします  #keyword: minimum ansible.cfg
                ansible.cfg ファイル のバックアップを取ります:
                ansible.cfg ファイル に最小限の設定を書きます: |  #// 他の設定はすべて削除します
                    [defaults]
                    display_skipped_hosts = false
            対処B:  #// ansible.cfg ファイルに設定を追加します
                ansible.cfg ファイル の場所を調べます:
                    ansible --version  #search: ansible.cfg
                ansible.cfg ファイル に設定を書きます: |
                    [defaults]
                    display_skipped_hosts = false
            原因:
                概要: Ansible の内部の v2_playbook_on_task_start メソッドの中で例外が発生しています。
                    デフォルト値がある基本的な設定で警告される場合は、ansible.cfg ファイルに問題があって読めてない可能性があります。
                解析方法:
                    -vvv を付けて ansible-playbook コマンドを実行して、Python の例外が発生したときの コール スタック を確認します: |
                        Callback Exception: 
                            File "__Home__/bin/ansible-venv/lib/python3.11/site-packages/ansible/executor/task_queue_manager.py", line 465, in send_callback
                                method(*new_args, **kwargs)
                            File "__Home__/bin/ansible-venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py", line 143, in v2_playbook_on_task_start
                                self._task_start(task, prefix='TASK')
                            File "__Home__/bin/ansible-venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py", line 162, in _task_start
                                if self.get_option('display_skipped_hosts') and self.get_option('display_ok_hosts'):
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                            File "__Home__/bin/ansible-venv/lib/python3.11/site-packages/ansible/plugins/callback/__init__.py", line 175, in get_option
                                return self._plugin_options[k]
                    pdb を使って、変数の値を確認します。たとえば下記の場合、必須の _plugin_options "display_skipped_hosts" が不足しています: |
                        def get_option(self, k):
                            import pdb
                            pdb.set_trace()
                            return self._plugin_options[k]
                        (Pdb) p k
                        'display_skipped_hosts'
                    #search: display_skipped_hosts
        - #// __PlugInName__ declined parsing __FilePath__ as it did not pass its verify_file() method
            手順: ansible-playbook コマンド
            エラー: |
                host_list declined parsing ____/hosts as it did not pass its verify_file() method
            対処A: #// __FilePath__ ファイルを最小限にします
                __FilePath__ ファイル のバックアップを取ります:
                __FilePath__ ファイル に最小限の設定を書きます:
            対処B:
                ansible.cfg ファイルを最小限にします  #search: minimum ansible.cfg
        - #// [WARNING]: Skipping plugin (__PythonFilePath__) __ErrorMessage__  #keyword: [WARNING]: Skipping plugin
            手順: ansible-playbook
            エラー: |
                [WARNING]: Skipping plugin (__PythonFilePath__) __ErrorMessage__
            対処:
                __PythonFilePath__ のファイルに print をバラばいて原因を特定します
            原因:
                プラグインの Python コード (__PythonFilePath__) の import 中（実行中）に例外が発生したため
        - #// [WARNING]: Skipping plugin (.../plugins/filter/__Filters__.py) as it seems to be invalid: No module named packaging.specifiers
            手順: ansible-playbook
            エラー: |
                [WARNING]: Skipping plugin (.../plugins/filter/__Filters__.py) as it seems to be invalid: No module named packaging.specifiers
            対処:
                #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: ansible python
                Ansible が使っている Python の場所を特定します:  #keyword: Ansible Python path,  ansible_python_interpreter
                    ./_show_python_interpreter.yml : |  #// 下記は localhost の Python を調べる場合。plugins はおそらく localhost でありターゲット（SSH サーバー）ではない
                        -   hosts: localhost
                            tasks:
                                -   name: Show Python interpreter
                                    debug:
                                        msg: "{{ ansible_python_interpreter }}"
                    コマンド:
                        ansible-playbook  ./_show_python_interpreter.yml  --check
                        rm  ./_show_python_interpreter.yml
                    出力例: |
                        ...
                        ok: [localhost] => {
                            "msg": "/usr/bin/python2"
                        ...
            原因:
                packaging の Python パッケージが見つかりません
        - #// [WARNING]: Skipping plugin (____/plugins/__Filters__.py) as it seems to be invalid: No module named __Package__.__SubName__
            手順: ansible-playbook
            エラー: |
                [WARNING]: Skipping plugin (____/plugins/__Filters__.py) as it seems to be invalid: No module named __Package__.__SubName__
            対処:
                Ansible control ノード で Ansbile が使う Python に対して pip install など Python パッケージ __Package__ をインストールします
        - #// Not replacing invalid character(s) "set([u'-'])" in group name (host-bak)
            手順: ansible-playbook --check
            エラー: |
                [WARNING]: Invalid characters were found in group names and automatically replaced, use -vvvv to see details
                Not replacing invalid character(s) "set([u'-'])" in group name (host-bak)
                    または
                [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details
            対処:
                グループ名に英数字とアンダースコア(_)のみ使うようにします
        - #// Could not match supplied host pattern, ignoring: centos7_52
            手順: ansible-playbook コマンド
            エラー: |
                [WARNING]: Unable to parse /tmp/vagrant-ansible/inventory/vagrant_ansible_local_inventory as an inventory source
                [WARNING]: No inventory was parsed, only implicit localhost is available
                [WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'
                [WARNING]: Could not match supplied host pattern, ignoring: centos7_52
            対処:
                /tmp/vagrant-ansible/inventory/vagrant_ansible_local_inventory に centos7_52 を登録してください
        - #// Failed to set permissions on the temporary files Ansible needs to create when becoming an unprivileged user
            手順: ansible-playbook コマンド
            エラー: |
                fatal: [__Host__]: FAILED! => {"msg": "Failed to set permissions on the temporary files Ansible needs to create when becoming an unprivileged user (rc: 1, err: chown: invalid user: ‘go’\n}).
                For information on working around this, see https://docs.ansible.com/ansible/become.html#becoming-an-unprivileged-user"}
            対処:
                become_user の設定が無い？
        - #// curl: (23) Failed writing body  #keyword: Ansible curl failed writing body
            手順: Ansible の shell モジュールで curl ____  |  ____  
            エラー: |
                SyntaxError: invalid syntax
                curl: (23) Failed writing body (3948 != 5935)
                stderr_lines": ["  File \"<stdin>\", line 137"
                    return f\"{STYLES[style]}{text}\\033[0m\"
            対処:
                curl ____  |  ____  を curl ____  |  sponge  |  ____  に変更します
                #ref: https://stackoverflow.com/questions/16703647/why-does-curl-return-error-23-failed-writing-body
            参考:
                sponge:  #keyword: sponge
                    インストール:
                        CentOS7: sudo yum install -y  moreutils
                    tee との違い: #ref: https://stackoverflow.com/questions/33638511/differences-between-sponge-and-tee
        - #// yum モジュールで HTTP Error 403: Forbidden
            手順: yum モジュールで yum install 相当
            エラー: |
                TASK [____] **************************************************************************************************************************
                    fatal: [centos7_56]: FAILED! => {"changed": false, "msg": "Failure downloading https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm,
                    HTTP Error 403: Forbidden"}
            対処:
                HTTP ヘッダーを確認します:
                    下記 Ansible タスクを実行します: |
                        -   name: check HTTP header
                            become: true
                            shell: curl --head https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
                出力（レスポンス ヘッダー）を確認します: |
                    HTTP/1.1 200 Connection established
                    HTTP/1.1 302 Moved Temporarily
                    Content-Type: text/html; charset=UTF-8
                    ....
                    Location: https://repo.mysql.com//mysql80-community-release-el7-3.noarch.rpm
                    ....
                302 エラーの場合（上記の場合）:
                    Location に書かれた URL に修正します
                #ref: https://qiita.com/kiyokiyopip56/items/6540f1a90574176fb3b6
        - #// skipping: [__VM__] => {"changed": false, "skip_reason": "Conditional result was False"}
            手順: ansible-playbook  playbook.yml
            エラー: |
                skipping: [__VM__] => {"changed": false, "skip_reason": "Conditional result was False"}
            状況:
                タスクの実行条件を満たしていないのでスキップしました。予想通りなら無視できます  #search: Ansible when
        - #// ERROR! A worker was found in a dead state  Connection to localhost closed.
            手順: ansible-playbook  playbook.yml
            エラー: |
                TASK [Gathering Facts] ********************
                ERROR! A worker was found in a dead state
                Connection to localhost closed.
            対処:
                SSH で (@control)（ansible_local がインストールされた VM）から他の VM に接続できるようにします:
                    upload_SSH_keys.sh  #keyword:
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible/README.yaml:csv#~/.ssh/known_hosts, ./upload_SSH_keys.sh
        - #// expected name or number
            手順: ansible-playbook  playbook.yml
            エラー: |
                fatal: [__ServerName__]: FAILED! => {"msg":
                "template error while templating string: expected name or number. String:
                {{result.ansible_facts.services.['__ServiceName__']}}"}
            対処:
                以下のいずれかに正します:
                    - __Object__.__PropertyName__
                    - __Object__['__PropertyName__']
                    - __Object__["__PropertyName__"]
                    - __Object__[__VariableName__]
                注意: |
                    [] の前にピリオドを書かないでください
        - #// need string or buffer, int found
            手順: ansible-playbook  playbook.yml
            エラー: |
                fatal: [__Host__]: FAILED! => {"msg": "The conditional check '__Condition__' failed.
                The error was: Unexpected templating type error occurred on 
                ({% if __Condition__  in  result.content %} True {% else %} False {% endif %}):
                coercing to Unicode: need string or buffer, int found"}
            対処:
                文字列型に変換します:
                    (__Expression__ | string)
        - #// ERROR! A malformed role declaration was encountered.
            手順: ansible-playbook  playbook.yml
            エラー: |
                ERROR! A malformed role declaration was encountered.
            対処:
                roles を配列にしてください（未確認）
                サーバーのファイルとローカルのファイルがあるとき、サーバーの内容をチェックします
        - #// UNREACHABLE!
            手順: ansible-playbook  playbook.yml
            エラー: |
                fatal: [db1]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: Could not resolve hostname db1: Name or 
                service not known", "unreachable": true}
            対処:
                Ansible を実行しているサーバーの /etc/hosts に db1 を設定します。
        - #// yum モジュールを実行して rc == -9 だったとき
            手順: ansible-playbook  playbook.yml
            エラー: |
                fatal: [control]: FAILED! => {"changed": false, "changes": {___, "rc": -9, "results": [___]}
            対処:  #// 以下のいずれか
                もう一度 Ansible タスク を動かす:
                RPM のデータベースを修復する:
                    #search: cannot open Packages index using db5
        - #// No package matching '____' found available
            手順: ansible-playbook  playbook.yml yum module
            エラー: |
                FAILED! => {"changed": false, "msg": "No package matching '____' found available,
                installed or updated", "rc": 126, "results": ["No package matching '____' found available, installed or updated"]}
            対処:
                前の手順でインストールした RPM リポジトリの URL が間違っていた可能性があります
        - #// A worker was found in a dead state
            手順: ansible-playbook  playbook.yml
            エラー: |
                ERROR! A worker was found in a dead state
            対処:
                もう一度実行します。
            原因:
                しばらく実行していないと発生するようです。
        - #// Failure downloading Request failed CERTIFICATE_VERIFY_FAILED certificate verify failed
            手順:
                ansible-playbook  playbook.yml  yum モジュール
            エラー: |
                fatal: [zabbix1]: FAILED! => {"changed": false, "msg": "Failure downloading
                https://repo.zabbix.com/zabbix/6.0/rhel/7/x86_64/zabbix-release-6.0-1.el7.noarch.rpm,
                Request failed: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)>"}
            対処A:
                HTTPS クライアントを、自己署名証明書の HTTPS サーバーでも許可するようにします
                    #search: accept self signed certificate
            対処B:
                https を http に変更します
        - #// unable to find /root/.my.cnf. Exception message: (2005, \"Unknown MySQL server host '__LoginHost__'
            手順: ansible-playbook  playbook.yml  mysql_db モジュール
            エラー: |
                FAILED! => {"changed": false, "msg": "unable to find /root/.my.cnf. Exception message: (2005, \"Unknown MySQL server host '__LoginHost__' (2)\")"}
            対処:
                mysql_db モジュールの target, login_host, login_user を正しく指定してください
                    #search: Ansible mysql_db module
        - #// conditional statements should not include jinja2 templating delimiters such as {{ }} or {% %}
            手順: ansible-playbook  playbook.yml
            エラー: |
                [WARNING]: conditional statements should not include jinja2 templating delimiters such as {{ }} or {% %}. Found:
                version_found.json.version.number != "{{ _____ }}"
            対処: |
                条件を指定するときは、{{ }} で囲まないようにします。 文字列と結合するときは + を使います。
                （条件以外を指定するときは "{{ }}" で囲みます）
            修正前の例:
                when: "'multi_instance_directories = /etc/{{ instance }}' not in check_result.stdout"
            修正後の例:
                when: ('multi_instance_directories = /etc/' + instance) not in check_result.stdout
        - #// The PyMySQL (Python 2.7 and Python 3.X) or MySQL-python (Python 2.X) module is required.
            手順: mysql_user モジュールや mysql_db モジュールのタスクを実行したとき
            エラー: The PyMySQL (Python 2.7 and Python 3.X) or MySQL-python (Python 2.X) module is required.
            対処:
                mysql のクライアント側になるホストに MySQL-python をインストールするタスクを実行します:
                    Playbook.yml:  #keyword: MySQL-python, python3-PyMySQL
                        -   name: install MySQL-python  #// for "mysql_user" ansible module
                            become: yes
                            yum:
                                name: MySQL-python  #// CentOS8 からは python3-PyMySQL
                                state: present
        - #// file depending on the exact syntax problem
            手順: ansible-playbook  playbook.yml  --list-tasks
            エラー: |
                The error appears to be in '/vagrant/playbook.yml': line 21, column 13, but may
                be elsewhere in the file depending on the exact syntax problem.
                The offending line appears to be:
                                name: mysql-server
                        -   name: install flyway
                            ^ here
            対処: name 以外のキーを指定できる位置を正しくしてください
            原因: name 以外のキーが正しくないか、そこに指定できない
        - #// No matching task "__TaskName__" found
            手順: ansible-playbook  ____.yml  ____  --start-at-task "__TaskName__"
            エラー: |
                [ERROR]: No matching task "__TaskName__" found. Note: --start-at-task can only follow static includes.
            対処A:  #// import_tasks, import_role だけしているタスクの場合
                サンプル task: |  #focus: import_tasks
                    -   name: create databases
                        import_tasks: _migrate.yml
                対処:
                    直前にダミーのタスク（debugなど）を入れて、そのタスクの name を --start-at-task に指定します。
                        #// import_tasks, import_role だけしているタスクの name を --start-at-task に指定できません
                    #search: Ansible debug
            対処B:  #// block の name の場合
                サンプル task: |  #focus: block
                    - name: run flyway
                    block:
                        - name: migrate
                対処:
                    import_tasks の場合と同じ
            対処C:  #// typo している場合
                name キーの値をコピペします
            対処D:
                - --tag オプションや --limit オプションを指定しているときは、
                    その指定によって実行されるタスクを --start-at-task に指定してください
        - #// Could not match supplied host pattern
            手順: ansible-playbook  ____.yml  ____  --limit "__ServerName__"
            エラー: |
                [WARNING]: Could not match supplied host pattern, ignoring: __ServerName__
                ERROR! Specified hosts and/or --limit does not match any hosts
            対処: |
                インベントリー ファイルに __ServerName__ を追加します  #search: ansible inventory file
        - #// プロビジョニングが失敗するとき:
            ベースとなる VM をプロビジョニングしてから、まずはシェルで実行できることを確認してください
        - #// No matching task
            手順: ansible-playbook コマンド
            エラー: |
                [ERROR]: No matching task "__TaskName__" found. Note: --start-at-task can only follow static includes.
            対処:
                インベントリー ファイルの場所を正しく指定してください:  #search: Ansible inventory path
        - #// unable to find /home/__User__/.my.cnf
            手順: mysql_replication モジュール
            エラー: |
                "msg": "unable to find /home/vagrant/.my.cnf. Exception message: (1045, \"Access denied for user 'vagrant'@'localhost' (using password: NO)\")"
            対処:
                以下のパラメーターをタスクに追加してください:
                    login_unix_socket: /var/lib/mysql/mysql.sock
                    login_user: root
                    login_password: "{{ mysql_root_password }}"
        - その他:
            タスクが失敗したマシーンのタスクは、Playbook 全体のローテーションから除外されます。
            Playbook ファイルを修正し、再実行してください。
Terraform, HCL 言語: #keyword:
    Terraform:
        チュートリアル: #ref: https://developer.hashicorp.com/terraform/tutorials
            #ref: https://developer.hashicorp.com/terraform/downloads
        プロバイダー: #keyword: Terraform provider  #ref: https://registry.terraform.io/browse/providers
            管理するリソース。AWS, Azure, GCP, Kubernetes, Helm, GitHub, Splunk, DataDog, ...
        State と Backends:
            State: 現在のデプロイ状況が書かれたファイル
            Backends: State のリポジトリ。Terraform Cloud や GCP Cloud Storage
    HCL: #// Hashicorp Configuration Language  #ref: https://github.com/hashicorp/hcl
        特徴:
            JSON 互換の意味:
                文法に互換性はありません。
                JSON, YAML を出力したり、配列と辞書からなるデータ構造にAPIでアクセスできることを互換性があると言っています。
            IaC: #search:
        手順:
            VSCode 拡張機能:  #search: VSCode extension
                HashiCorp HCL
            HCL をパースして Go 言語のデータにします:
                try_HCL:  #ref: ${GitHub}/Trials/try_HCL/example/1_first_HCL/parser.go
            HCL で GoCD のパイプラインを作る場合: #keyword: HCL GoCD
                HCL Go 言語: #ref: https://pkg.go.dev/github.com/hashicorp/hcl/v2
        ファイル:
            サンプル: |  #ref: https://github.com/hashicorp/hcl#hcl
                package main

                import (
                    "log"

                    "github.com/hashicorp/hcl/v2/hclsimple"
                )

                type Config struct {
                    IOMode  string        `hcl:"io_mode"`
                    Service ServiceConfig `hcl:"service,block"`
                }

                type ServiceConfig struct {
                    Protocol   string          `hcl:"protocol,label"`
                    Type       string          `hcl:"type,label"`
                    ListenAddr string          `hcl:"listen_addr"`
                    Processes  []ProcessConfig `hcl:"process,block"`
                }

                type ProcessConfig struct {
                    Type    string   `hcl:"type,label"`
                    Command []string `hcl:"command"`
                }

                func main() {
                    var config Config
                    err := hclsimple.DecodeFile("config.hcl", nil, &config)
                    if err != nil {
                        log.Fatalf("Failed to load configuration: %s", err)
                    }
                    log.Printf("Configuration is %#v", config)
                }
            (${____}) 構文, 文字列補間:  #keyword: HCL ${},  HCL string interpolation
        参考:
            nomad HCL:  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/hcl2
            HCL を Parse する:  #ref: https://qiita.com/TsuyoshiUshio@github/items/ba4a2101be4784253cc5
            HCL をパースして、構造を組み替えて再出力する:  #ref: https://chroju.dev/blog/hcl_parse_and_output
            Build your own DSL with Go & HCL:  #ref: https://blog.devgenius.io/build-your-own-dsl-with-go-hcl-602c92ce24c0
Nomad: #keyword: HashiCorp Nomad,  Nomad  #// オーケストレーション ツール,  オートスケーリング ツール
    概要:
        サービスの配置:  #search: Nomad placement
        Nomad と Docker の違い:
            起動:
                Docker
                    ssh server-1
                    docker run django-app
                nomad
                    nomad job run django-app.nomad.hcl   1回の宣言で3台に自動配置
            nomad に設定する内容:
                Docker Hub プライベートリポジトリ 認証情報
            nomad ができないこと:  #// GitHub Actions などで実行。ローカルでは act コマンドで .github/workflows/.yml を実行できます
                - Docker イメージのビルド
                - Docker イメージをレジストリへ登録
            同じ:
                コンテナ化されたアプリケーションのデプロイ
        RPM Ansible と Docker イメージ nomad:
            _: テスト環境でDockerイメージ内にRPMをインストールしてテストするのはベストプラクティスですが、
                コンテナネイティブのほうがかなりビルドが速いです
            Ansible と Docker Nomad: |
                Ansible によるテンプレートと Nomad 変数によるテンプレートをそれぞれ用意したほうがシンプル
                いずれは、Dockerfile だけに段階的に移行すべき
                    今すぐ: 新しいDockerテスト環境を既存Ansibleと並行構築
                    3ヶ月以内: 1-2個の簡単なサービスでDocker移行テスト
                    6ヶ月以内: 移行成功サービスの本番展開
                    1年以内: 新規サービスは全てDocker、既存は選択的移行
                    2年以内: レガシーシステムを除いて大部分をDocker化
        GitHub Actions でも使えます:
            セルフホステッドランナー（実行環境）に Nomad CLI もしくは Nomad への到達手段（HTTP API）があれば、
            GitHub Actions のジョブから nomad job run / nomad job dispatch / nomad job promote などでデプロイできます。
        #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: nomad
    手順:
        インストールと起動: #keyword: install Nomad
            Nomad をインストールします: |  #// WSL2 Rocky Linux 8
                sudo dnf config-manager --add-repo  https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
                sudo dnf -y install nomad
                nomad version

                #// Nomad depends on these packages.
                sudo dnf install -y  iproute  #// ip command

                #// ...
                sleep  3s
                sudo systemctl start nomad
                sudo systemctl enable nomad
            nomad.hcl ファイルを編集して再起動します: |  #search: nomad.hcl minimum Docker
                sudo tee /etc/nomad.d/nomad.hcl > /dev/null
                    内容を貼り付けます。ただし、__ProxyURL__ の部分は置き換えてください  #search: nomad.hcl minimum Docker
                sudo systemctl restart nomad
                nomad node status -self -verbose
            ~/django.nomad ファイルを作ります: #keyword: Docker Django Nomad example,  django.nomad
                同等のコマンド:  #search: docker run Django
                内容: |  #// python コンテナ―内でのプログラムのインストールは apt-get です
                    job "django-app" {
                        group "web" {
                            task "django" {
                                driver = "docker"
                                config {
                                    image = "python:3.11"
                                    network_mode = "host"
                                    extra_hosts = ["host.docker.internal:host-gateway"]
                                    work_dir = "/app"
                                    command = "sh"
                                    args = [
                                        "-c",
                                        join(" && ", [

                                            "echo 'task: install Django...'",
                                            "pip install django",
                                            "django-admin startproject myproject .",
                                            "sed -i -E 's/ALLOWED_HOSTS = \\[\\]/ALLOWED_HOSTS = [\"*\"]/'  myproject/settings.py",
                                            "python manage.py migrate",
                                            "python manage.py runserver 0.0.0.0:8000",

                                            "echo 'task: sleep infinity...'",
                                            "trap 'exit 0' TERM;  sleep infinity  &  wait"
                                        ])
                                    ]
                                }
                                env {
                                    http_proxy  = "${meta.http_proxy}"  # "meta" is defined in client block in nomad.hcl file.
                                    https_proxy = "${meta.https_proxy}"
                                    HTTP_PROXY  = "${meta.http_proxy}"
                                    HTTPS_PROXY = "${meta.https_proxy}"
                                    no_proxy    = "${meta.no_proxy}"
                                    NO_PROXY    = "${meta.no_proxy}"
                                }
                                resources {
                                    cpu = 800
                                    memory = 512
                                }
                            }
                        }
                    }
                （応用）:
                    無限 sleep:  #// コンテナ―にログインするために何もしない  #search: docker container run -d sleep
                    ブリッジ ネットワーク に変える: |
                        job "django-app" {
                            group "web" {
                                network {
                                    port "http" {
                                        static = 8000
                                        to     = 8000
                                    }
                                }
                                task "django" {
                                    driver = "docker"
                                    config {
                                        image = "python:3.11"
                                        ports = ["http"]
                                        # network_mode = "host"
                                        # extra_hosts = ["host.docker.internal:host-gateway"]
                    軽量化:
                        python の代わりに python-slim を指定します
                    OS 変更:
                        #search: Docker Rocky
            起動終了コマンド: | #keyword: nomad job run example
                nomad job run  django.nomad
                    #// 初回は約30秒、2回目以降は約10秒
                #// http://172.18.136.196:8000/  のような IP アドレスでアクセスできます
                nomad job status  django-app
                nomad job stop  django-app
                nomad system gc
            デバッグ用コマンド: #keyword: Nomad debug  #search: Nomad trouble
                WebUI: #keyword: Nomad debug WebUI  #// 詳細なエラーメッセージを表示します
                    URL の書式:   http://__NomadHost__:4646/ui/jobs/__JobName__
                    URL サンプル: http://172.18.136.196:4646/ui/jobs/django-app
                    Not Authorized になる場合:  #ref: https://developer.hashicorp.com/nomad/commands/ui
                        nomad ui -authenticate -address=http://__NomadHost__:4646
                    主な項目:
                        Deployment History: #keyword: Noame Deployment History
                            Received:
                                Task received by client: コマンドを受信したとき？
                            Downloading Artifacts:
                            Template:
                            Terminated: タスク実行時のエラー  .nomad >> task >> args
                        Allocation History:
                        View Logs:
                client, systemd:
                    基本:
                        sudo journalctl -u nomad  --no-pager  |  less
                    表示し続ける場合:
                        sudo journalctl -u nomad  --follow
                docker: |  #// コンテナーにログインします
                    ContainerName="$( docker ps --format "{{.Names}}"  |  grep "^django-" )"  &&  echo "${ContainerName}"
                    docker exec -it  ${ContainerName}  bash
                nomad: |  #focus: django-app
                    nomad status  django-app
                        Allocations
                        ID        Node ID   Task Group  Version  Desired  Status   Created    Modified
                        3da868f5  7deb987c  web         0        run      running  3m28s ago  3m ago
                    AllocationID=3da868f5
                    nomad alloc status ${AllocationID}   #// -job オプション は使えません
                    nomad alloc logs -job django-app    #search: nomad alloc logs
                    nomad alloc logs  ${AllocationID}   #search: nomad alloc logs
                    nomad alloc exec  ${AllocationID}  /bin/bash
                artifact:  #serach: Nomad artifact trouble
            docker コマンドを使えるようにします:  #search: nomad docker command
        Vault と接続します: #keyword: install Nomad Vault
            Nomad をインストールします:
                #search: install Nomad
            Vault をインストールします:
                #search: install HashiCorp Vault
            workload ID チュートリアル を実施します:  #ref: https://developer.hashicorp.com/nomad/docs/secure/workload-identity/vault
                Nomad と Vault を接続できるようにします:
                    nomad.hcl に acl ブロック と vault ブロック を追加して再起動します: |
                        sudo vi /etc/nomad.d/nomad.hcl  #search: nomad.hcl with Vault
                        sudo systemctl restart nomad
                        #// nomad node status -self -verbose  #// "nomad.hcl" ファイルの acl が enabled の場合、nomad コマンドを実行するには bootstrap トークン（下記）が必要なので、まだ実行できません。
                    Nomad の ACL システム を初期化します: | #keyword: nomad acl bootstrap
                        export VAULT_ADDR="http://localhost:8200"
                        nomad acl bootstrap
                            表示された内容（特に以下のキー）を安全な場所 ~/.secrets/nomad_acl_bootstrap.log に保存します。
                                Accessor ID  = __NomadAccessorID__
                                Secret ID    = __BootstrapToken__
                            すでに実行済みならエラーになります。再初期化されません
                            エラー Unexpected response code: 400 (ACL support disabled) が発生するときは sudo systemctl restart nomad
                        export VAULT_ADDR="http://localhost:8200"
                        export NOMAD_TOKEN=__BootstrapToken__
                        nomad node status -self -verbose
                    Vault ACL auth method を作ります: |
                        export VAULT_ADDR="http://localhost:8200"  #search: VAULT_ADDR
                        vault auth enable -path "jwt-nomad" "jwt"
                    Vault に各種設定を保存します:  #// workload ID を使った認証方法に関する設定です
                        #focus: nomad-workloads
                        auth/jwt-nomad/config: |  #keyword: auth/jwt-nomad
                            vault write "auth/jwt-nomad/config" - << HERE_DOCUMENT
                            {
                                "jwks_url": "http://localhost:4646/.well-known/jwks.json",
                                "jwt_supported_algs": ["RS256", "EdDSA"],
                                "default_role": "nomad-workloads"
                            }
                            HERE_DOCUMENT
                        auth/jwt-nomad/role/nomad-workloads: |
                            vault write "auth/jwt-nomad/role/nomad-workloads" - << HERE_DOCUMENT
                            {
                                "role_type": "jwt",
                                "bound_audiences": ["vault.io"],
                                "user_claim": "/nomad_job_id",
                                "user_claim_json_pointer": true,
                                "claim_mappings": {
                                    "nomad_namespace": "nomad_namespace",
                                    "nomad_job_id": "nomad_job_id",
                                    "nomad_task": "nomad_task"
                                },
                                "token_type": "service",
                                "token_policies": ["nomad-workloads"],
                                "token_period": "30m",
                                "token_explicit_max_ttl": 0
                            }
                            HERE_DOCUMENT
                        #↓ 補足
                        vault-role-nomad-workloads.json:
                            token_policies: #keyword: token_policies Nomad Vault
                                auth/jwt-nomad の デフォルト ロール がデフォルトで使うポリシー
                                Nomad の Job ファイルの vault ブロックが空のときに使われるポリシー
                    ポリシーを登録します:
                        #focus: nomad-workloads
                        auth method accessor の値（auth_jwt_）を確認します: #keyword: auth_jwt_ HashiCorp Vault
                            export VAULT_ADDR="http://127.0.0.1:8200"
                            vault auth list -detailed
                                jwt-nomad/    jwt       auth_jwt_8a6f7cd1  ...
                                ...
                        ポリシーを登録します: #keyword: vault policy write example  #search: policy HashiCorp Vault
                            サンプル: |  #// nomad-workloads ポリシーを登録します。 下記の注意点をチェックしてから実行してください
                                vault policy write  "nomad-workloads" - << HERE_DOCUMENT
                                path "secret/data/{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_namespace}}/{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_job_id}}/*" {
                                    capabilities = ["read"]
                                }

                                path "secret/data/{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_namespace}}/{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_job_id}}" {
                                    capabilities = ["read"]
                                }

                                path "secret/metadata/{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_namespace}}/*" {
                                    capabilities = ["list"]
                                }

                                path "secret/metadata/*" {
                                    capabilities = ["list"]
                                }
                                HERE_DOCUMENT
                            #↓ 注意点
                            auth_jwt_:  #focus: auth_jwt_
                                auth_jwt_00000000 を auth method accessor の値に置き換えてください  #search: auth_jwt_ HashiCorp Vault
                            path "secret/:  #focus: secret
                                path の secret/ は、マウント名に置き換えてください  #search: mount HashiCorp Vault
                            nomad_namespace: #keyword: nomad_namespace  #focus: nomad_namespace
                                .../{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_namespace}}/...
                                    の部分は、実行時には、通常、
                                .../default/...
                                    に置き換わります  #search: default namespace HashiCorp Vault
                            nomad_job_id: #keyword: nomad_job_id  #// Nomad の Job 名
                                .../{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_job_id}}/...
                                    の部分は、実行時には、Nomad のジョブ名に置き換わります
                                #search: Nomad job name
                Nomad の Web UI を開きます:  #// Job の実行結果を確認します
                    export NOMAD_TOKEN=__BootstrapToken__
                    nomad ui -authenticate -address=http://localhost:4646
                Nomad の Job が使うシークレットを登録します:
                    環境変数を設定します:
                        export VAULT_ADDR="http://localhost:8200"
                    key value v2 を使う設定になっていることを確認します:  #search: HashiCorp Vault key value engine version 2
                        vault secrets list -detailed  |  grep version
                            ...  version:2
                    シークレットを Vault に登録します: |
                        vault kv put  "secret/default/mongo/config"  root_password=secret-password  #// "secret/data/default/mongo/config" ではありません
                        vault kv get  "secret/default/mongo/config"
                Job を実行します:
                    mongo.nomad.hcl ファイルを作ります: |  #// 下記内容のインデントは除いてください
                        job "mongo" {
                            namespace = "default"

                            group "db" {
                                network {
                                    port "db" {
                                        static = 27017
                                    }
                                }

                                service {
                                    provider = "nomad"
                                    name     = "mongo"
                                    port     = "db"
                                }

                                task "mongo" {
                                    driver = "docker"

                                    config {
                                        image = "mongo:7"
                                        ports = ["db"]
                                    }

                                    vault {}

                                    template {
                                        data        = <<EOF
                        MONGO_INITDB_ROOT_USERNAME=root
                        MONGO_INITDB_ROOT_PASSWORD={{with secret "secret/data/default/mongo/config"}}{{.Data.data.root_password}}{{end}}
                        EOF
                                        destination = "secrets/env"
                                        env         = true
                                    }
                                }
                            }
                        }
                    Job を実行します:
                        bootstrap token を使う場合: |
                            export NOMAD_TOKEN=__BootstrapToken__
                            nomad job run  "mongo.nomad.hcl"
                        参考）bootstrap token を間接的に使う場合:  #// 新しいトークンを生成する権限を持つポリシーを別途作るなどしないと、あまり安全にはなりません
                            （初回のみ）: |
                                export NOMAD_TOKEN=__BootstrapToken__
                                nomad acl policy apply "job-operator-policy"  -  #// 末尾の - が必要です。下記テキストを貼り付けて、Ctrl + D を押します
                                    namespace "default" {
                                        policy       = "write"
                                        capabilities = ["submit-job", "dispatch-job", "read-logs", "alloc-exec", "read-job"]
                                    }

                                    namespace "*" {
                                        policy       = "read"
                                    }

                                    node {
                                        policy = "read"
                                    }

                                    agent {
                                        policy = "read"
                                    }

                                    operator {
                                        policy = "read"
                                    }
                            _:
                                export NOMAD_TOKEN=__BootstrapToken__
                                nomad acl token create  -name="job-operator-token"  -policy="job-operator-policy"  -ttl="24h"
                                    Secret ID    = __JobOperatorToken__
                                export NOMAD_TOKEN=__JobOperatorToken__
                                nomad job run  "mongo.nomad.hcl"
                シークレットが埋め込まれたことを確認します:
                    ContainerName="$( docker ps --format "{{.Names}}"  |  grep "^mongo-" )"  &&  echo "${ContainerName}"
                    docker exec -it  ${ContainerName}  cat /secrets/env
                        MONGO_INITDB_ROOT_USERNAME=root
                        MONGO_INITDB_ROOT_PASSWORD=secret-password
                デバッグ: |  #keyword: Nomad Vault debug
                    http://localhost:8200/  #// Vault
                    export NOMAD_TOKEN=__BootstrapToken__
                    nomad ui -authenticate -address=http://localhost:4646
                        Allocation History
                        View Logs
                    nomad job status  mongo
                    nomad alloc logs -job mongo
                    ContainerName="$( docker ps --format "{{.Names}}"  |  grep "^mongo-" )"  &&  echo "${ContainerName}"
                    docker exec -it  ${ContainerName}  bash
                終了: |
                    nomad job stop  mongo
                    nomad system gc
                    nomad status  mongo
            （参考）:
                workload ID: #keyword: Nomad workload ID,  Nomad workload Identity
                    1. Nomadタスク → Workload ID (JWT) を生成。 Nomad サーバーの秘密鍵で署名されている JWT
                    2. Workload ID → Vaultで認証 → 短期間・最小権限のVaultトークンを発行
                    3. Vaultトークン → Vault → シークレット取得
                    4. Workload Identity はタスクのライフサイクルに連動して自動的に破棄されます
                動的シークレット: #keyword: Nomad Vault dynamic secrets,  Nomad Vault 動的シークレット
                    上記チュートリアルでは Mongo DB のシークレットを指します
        初期化します: #keyword: initialize Nomad
            シークレットの最新バックアップがあることを確認します:
            サービスを止めします:
                sudo systemctl stop  nomad
            データがある場所を調べます:
                cat  /etc/nomad.d/nomad.hcl  |  grep  data_dir
            データを削除します:
                sudo ls -la  "/opt/nomad/data"
                sudo rm -rf  "/opt/nomad/data"
                sudo ls -la  "/opt/nomad/data"
            再初期化します:  #// 未確認。 Ansible でのみ確認済みだが内容は未知
                #search: install Nomad
        手順のテスト: #keyword: NomadTutorial, NomadVaultTutorial  #ref: ${GitHub}/MyPrivateCode/Nomad/Nomad_Django_REST_API/nomad_test.sh
        スケール アウト:  #// グループ単位
            nomad job scale example optional 1
                #template__: nomad job scale __Job__ __Group__ __Count__
        公式 CLI クイック スタート:
            参考:
                - https://learn.hashicorp.com/tutorials/nomad/get-started-install
                - https://learn.hashicorp.com/tutorials/nomad/get-started-intro
            #// 最後まで動作確認済みなのは、Linux で実行、ホストOS=Windows という環境のみ
            nomad コマンドをインストールします:
                Linux で実行する場合:  #// ホストOS=Windows
                    Linux の仮想マシンを作ります:  #search: Vagrant Windows
                        #// Visual Studio Code で Linux の仮想マシンと SSH 接続します
                    Linux に Docker をインストールします:  #search: Docker for CentOS
                    ダウンロードします:  https://nomadproject.io/downloads/ >> (Linux タブ) >> (OSの種類) >>
                        （表示されたコマンドを実行します）
                    起動できることを確認します:
                        シェル:
                            nomad -version
                Windows で実行する場合:
                    ダウンロードします:  https://nomadproject.io/downloads/ >> (Windows タブ) >> 64-bit
                        （例：nomad_1.1.0_windows_amd64.zip）
                    zip の中の exe を PATH の通った場所にコピーします:
                        例： C:\Users\__User__\AppData\Local\Microsoft\WindowsApps\nomad.exe
                    起動できることを確認します:
                        シェル:  #// PowerShell, Git bash
                            nomad -version
            #// 以下は Linux で実行、ホストOS=Windows という環境でのみ確認済み
            エージェントをサーバモードとクライアントモードの両方で起動します:
                #nomad をインストールしたマシーンの新しいシェル
                sudo nomad agent -dev -bind 127.0.0.1 -log-level INFO
                #// client: node registration complete が２行表示されるまで待ちます
                #// Ctrl + C キーを押すなどしてエージェントを終了できます
                #// -dev は実験環境で起動するという意味です
                #// -bind はサーバーの IP アドレスが使える範囲になります。省略すると 127.0.0.1 になります
                #//    サンプルでは -bind 0.0.0.0 ですが、これではプロキシがある LAN ではプロキシ サーバーがエラーを返してしまいます
            ローカル モードのエージェントのステータスを表示します:
                #新しいシェル
                nomad node status
            サーバー モードのエージェントのステータスを表示します:  #// ゴシップ プロトコルで接続されたサーバー
                nomad server members
                #ref: https://ja.wikipedia.org/wiki/ゴシッププロトコル
            新しいジョブを作って実行します:  #// プログラムをインストールして起動します
                nomad ファイル (example.nomad) を作ります:
                    - mkdir -p  ~/nomad_example
                    - cd        ~/nomad_example
                    - nomad job init  #// nomad ファイルのテンプレートを作ります
                        #// サンプルとして redis をインストールするタスクが作られます
                        #// -short オプションを付けるとコンパクトになりますが、チュートリアルの一部ができなくなります
                    - code  example.nomad  #// 新しく作られたファイルの内容を確認します
                ジョブを実行します:  #// プロビジョニングします(?)
                    nomad job run  example.nomad  #template) nomad job run  __NomadFilePath__
                        #// allocation（割り当て）が作られ、run と表示されれば起動済みです
                ジョブのステータスを表示して、allocation の ID などを表示します:
                    bash:
                        nomad job status  example  #template) nomad job status  __JobName__
                            #// __JobName__ は nomad ファイルに書かれています。
                            #// 下のほうに Allocations の ID などが表示されます。 Node ID ではありません
                    もし、下記のメッセージが表示されたら、Docker をインストールしてエージェントの再起動からやり直してください: |
                        Task Group "cache" (failed to place 1 allocation):
                        * Constraint "missing drivers": 1 nodes excluded by filter
                ジョブ名、タスク名、allocation の ID を一時的な環境変数に設定します:  #// 環境変数に設定しなくても nomad は使えます
                    bash: |
                        job="example"  #template) __JobName__
                        task="redis"   #template) __TaskName__
                        alloc="__AllocationID__"
                            #// __AllocationID__ は nomad job status __JobName__ で表示できます。
                allocation の状態を表示します:
                    nomad alloc status  $alloc
                ジョブの標準出力と標準エラー出力を表示します:
                    nomad alloc logs  $alloc  $task
            ジョブの内容を更新します:  #// プログラムを更新したサーバーを起動して、そのサーバーに切り替えます
                example.nomad ファイルの一部を変更します:
                    変更前: image = "redis:3.2"
                    変更後: image = "redis:4.0"
                ジョブの更新内容を表示します:
                    bash:
                        nomad job plan  example.nomad  #template) nomad job plan  __NomadFilePath__
                    Dry run に成功したことを確認します: |
                        Scheduler dry-run:
                        - All tasks successfully allocated.
                    ジョブを実行するときのコマンドも表示されます:
                        表示例: |
                            :
                            Job Modify Index: 10
                            To submit the job with version verification run:

                            nomad job run -check-index 10 example.nomad
                        表示例の説明:
                            - nomad job run -check-index 10 example.nomad を入力するとジョブを実行します
                            - Job Modify Index (10) は、排他制御に使われます（他の人がジョブを実行していたらエラーになる？）
                内容に問題がなければ、ジョブを実行します:
                    #// nomad job plan コマンドの出力からコピペしてください
                    nomad job run -check-index 10 example.nomad
                ジョブの進捗状況を表示します:
                    nomad job status example
                        #// 今までの allocation は stop になり、新しい allocation が run になります
            ブラウザーで管理画面(nomad web interface)を開きます:
                URL: http://__NomadAgnet__:4646/  #// ゲストOS なので下記の手順で表示します
                Visual Studio Code で Linux の仮想マシンと SSH 接続している場合:
                    ポート フォワーディングを設定します:
                        VSCode >> シェルの PORTS タブ >> Add Port ボタン >> 4646
                    ホストOSのブラウザーから nomad web interface を開きます:
                        VSCode >> シェルの PORTS タブ >> （Local Address の）Open in Browser ボタン
                サーバーの情報とモニターを表示します:  #// モニターはアプリケーションの標準出力などを表示します(?)
                    nomad web >> Servers（左下）>>（サーバー名）>> Monitor
                ログインします:
                    nomad web >> Jobs（左上）>>（ジョブ名）>> Exec ボタン（右上）>>
                        （タスク グループ名）（左上）>>（タスク名）>>（右半分をクリック）>> Enter キー >>
                    使わなくなったらウィンドウを閉じます
            ジョブを停止します:  #// サーバーをシャットダウンします
                nomad web の場合:
                    nomad web >> Jobs（左上）>>（ジョブ名）>> Stop ボタン（右上）>> Yes, Stop ボタン
            エージェントを終了します:
                （sudo nomad agent を実行していたシェル）>> Ctrl + C キー
            環境を削除します:
                Linux で実行していた場合:  #// ホストOS=Windows
                    Linux の仮想マシンを削除します:  #search: Vagrant Windows
    機能:
        デプロイ:
            コンテナ化されたアプリケーションのデプロイと管理
        イベント:  #// Nomad が状態の変化を検出して、ユーザーが定義した処理を実行できますが、その状態の変化
            Job の起動:  #search: nomad job run
            Job の終了:  #search: nomad job stop
            設定値の変更:  #// .nomad >> task >> template >> change_mode
    Web UI:  #ref: https://learn.hashicorp.com/collections/nomad/web-ui
        Deployment History:  #search: Nomad debug WebUI
    コマンド:  #glossary: Nomad
        環境変数: #keyword: nomad CLI environment  #glossary:
            サンプル:
                Nomad + Vault 環境:
                    export NOMAD_ADDR="https://localhost:4646"
                    export NOMAD_CACERT="/etc/nomad.d/tls/tls.crt"
                    export NOMAD_TOKEN="$( cat  ~/.secrets/nomad_acl_bootstrap.log  |  grep  "Secret ID"  |  awk  '{print $NF}'  |  tail -1 )"
                    nomad status
                    nomad node status
            NOMAD_ADDR:
                未設定の場合: http://127.0.0.1:4646  #// http と https の違いに注意
            NOMAD_CACERT: |
                export NOMAD_CACERT="/etc/nomad.d/tls/tls.crt"
                設定しないと以下のようなエラーになります。
                    tls: failed to verify certificate: x509: certificate signed by unknown authority
            NOMAD_TOKEN:
                export NOMAD_TOKEN="$( cat  ~/.secrets/nomad_acl_bootstrap.log  |  grep  "Secret ID"  |  awk  '{print $NF}'  |  tail -1 )"
                #search: nomad acl bootstrap
        nomad job run:  #// ジョブを実行します
            #search: nomad job run example
        nomad job inspect: |
            nomad job inspect  __JobName__
                {
                    "Job": {
                        "ID": "__JobName__",
                        "Namespace": "default",
        nomad alloc logs:  #// タスクのログを表示します
            プロキシ サーバー のエラー応答が表示される場合:
                原因調査:
                    #// 以下のコマンドでうまくいったら、プロキシを使わない設定をしてください
                    export no_proxy="localhost, 127.0.0.1, .local, 172.17.0.1, 172.18.0.1, 172.19.0.1, 172.20.0.1, host.docker.internal, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16"
                    export NO_PROXY="${no_proxy}"
                    nomad job status  __JobName__
        docker: #keyword: nomad docker command  #// タスク内で docker コマンドを使う場合
            DooD 環境の構築: #keyword: Nomad DooD  #// Docker ホスト（＝ Nomad クライアント、Nomad ノード）の Docker システムを使います
                #search: Docker outside of Docker
                基本的なタスクが動くようにします:
                    #search: install Nomad
                docker コマンドをインストールします:
                    .nomad ファイル: |
                        task "____" {
                            driver = "docker"
                            config {
                                args = [
                                    "-c",
                                    join(" && ", [

                                        "echo 'task: install docker CLI...'",
                                        "yum install -y yum-utils",
                                        "yum-config-manager  --add-repo https://download.docker.com/linux/centos/docker-ce.repo",
                                        "yum install -y  docker-ce-cli",
                /var/run/docker.sock をボリュームに設定します: #keyword: Nomad volume /var/run/docker.sock
                    #// Nomad クライアント の /var/run/docker.sock を host_volume に設定します
                    nomad.hcl ファイル: |  #focus: docker-sock
                        client {
                            host_volume "docker-sock" {
                                path      = "/var/run/docker.sock"
                                read_only = false
                            }
                    .nomad ファイル: |
                        task "django" {
                            group "web" {
                                task "____" {
                                    volume_mount {
                                        volume      = "docker-sock"
                                        destination = "/var/run/docker.sock"
                                    }
                                }
                                volume "docker-sock" {
                                    type      = "host"
                                    source    = "docker-sock"
                                    read_only = false
                                }
                タスク内（コンテナー内）で docker コマンドが使えます:
                    docker ps など
                    Docker デーモンは、Nomad クライアント にあります
        nomad namespace list:
            基本, default: #keyword: default namespace HashiCorp Vault
                以下のように実行される場合、ネームスペースは default 固定です。
                $ nomad namespace list
                No namespaces found
        （接続できないとき）:  #search: nomad CLI environment
    構成:
        #↓ 概要
        サービスの配置: #keyword: Nomad placement
            サービスは、1つのサーバーではなく、複数のサーバーに分散配置
            Nomad が Consul にサービスを自動登録し、Consul がサービス発見・ヘルスチェックを提供
        ロード バランサー:
            nginx の場合:  #// nginx はリクエストを分散させます
                upstream django_backend {
                    server 10.0.1.10:8080;
                    server 10.0.1.11:8081;
                    server 10.0.1.12:8082;
        配置の例:
            基本: |  #// ローカルで Nomad クラスター起動
                ┌─ あなたのWSL2 Rocky Linux ─────────┐
                │                                              │
                │ ┌─ Consul (Service Discovery) ────┐   │
                │ │ http://localhost:8500                │   │
                │ └───────────────────┘   │
                │                                              │
                │ ┌─ Nomad Server + Client -──────┐   │
                │ │ http://localhost:4646                │   │
                │ │                                      │   │
                │ │ ┌─ Django Container task -──┐   │   │
                │ │ │ http://localhost:8000        │   │   │
                │ │ └───────────────┘   │   │
                │ │                                      │   │
                │ │ ┌─ PostgreSQL Container task -┐   │   │
                │ │ │ port: 5432                   │   │   │
                │ │ └───────────────┘   │   │
                │ │                                      │   │
                │ │ ┌─ Redis Container task ───┐   │   │
                │ │ │ port: 6379                   │   │   │
                │ │ └───────────────┘   │   │
                │ └───────────────────┘   │
                └───────────────────────┘
            2つのインスタンス: | #// ローカルで１種類のサービスを 2つのインスタンス（ポート）に配置
                ┌────────────────────┐
                │ Nomad Agent (Server + Client)          │
                │ http://localhost:4646                   │
                │                                         │
                │ ┌─ Django Container #1 ───────┐  │
                │ │ Port: 8000 → 32001 (dynamic)      │  │
                │ │ CPU: 250m, RAM: 256MB              │  │
                │ │ PID: 12345                         │  │
                │ └──────────────────┘  │
                │                                         │
                │ ┌─ Django Container #2 ───────┐  │
                │ │ Port: 8000 → 32002 (dynamic)      │  │
                │ │ CPU: 250m, RAM: 256MB              │  │
                │ │ PID: 12346                         │  │
                │ └──────────────────┘  │
                │                                         │
                │ ┌─ PostgreSQL (shared) ──────┐  │
                │ │ Port: 5432                         │  │
                │ └──────────────────┘  │
                │                                         │
                │ ┌─ Redis (shared) ──────────┐  │
                │ │ Port: 6379                         │  │
                │ └──────────────────┘  │
                └─────────────────────┘
                # 方法1: ロードバランサー経由
                    curl http://localhost:8080/api/
                # 方法2: 各インスタンスに直接アクセス
                    curl http://localhost:32001/api/  # Django Container #1
                    curl http://localhost:32002/api/  # Django Container #2
            2つのバージョンの併存: |
                ┌- サーバー (8GB RAM, 4 CPU) -------------------------┐
                │                                                      │
                │ ┌- Nginx Load Balancer -------------------------┐   │
                │ │ Port: 8080                                    │   │
                │ │ /v1/* → django-app-v1                        │   │
                │ │ /v2/* → django-app-v2                        │   │
                │ │ /*    → django-app-v2 (default)              │   │
                │ └----------------------------------------------┘   │
                │                                                      │
                │ ┌- Django V1 (2 instances) --------------------┐   │
                │ │ Container 1: Port 32001, CPU: 250m, RAM:256M │   │
                │ │ Container 2: Port 32002, CPU: 250m, RAM:256M │   │
                │ └----------------------------------------------┘   │
                │                                                      │
                │ ┌- Django V2 (2 instances) --------------------┐   │
                │ │ Container 3: Port 32003, CPU: 250m, RAM:256M │   │
                │ │ Container 4: Port 32004, CPU: 250m, RAM:256M │   │
                │ └----------------------------------------------┘   │
                │                                                      │
                │ ┌- Shared Services -----------------------------┐   │
                │ │ PostgreSQL: Port 5432                         │   │
                │ │ ├- Database: myapp_v1                         │   │
                │ │ └- Database: myapp_v2                         │   │
                │ │                                               │   │
                │ │ Redis: Port 6379                              │   │
                │ │ ├- DB 1 (V1用)                                │   │
                │ │ └- DB 2 (V2用)                                │   │
                │ └----------------------------------------------┘   │
                │                                                      │
                │ ┌- Nomad + Consul -----------------------------┐   │
                │ │ Nomad: Port 4646                              │   │
                │ │ Consul: Port 8500                             │   │
                │ └----------------------------------------------┘   │
                └------------------------------------------------------┘
        #↓ 構成要素
        （構造）:
            Nomad:
                Job:
                    Group:
                        Task: #🌟  #// Docker のコンテナー、Kubernetes の Pods、実行ファイル
                Cluster:
                    server:
                    client, node:  #// 物理/仮想マシン
            Consul:
        ノマド クラスター:  #// サーバーとエージェント
            エージェント(agent): 
            dev agent:  #// 開発と実験をするときのエージェント
            サーバー（サーバー モードのエージェント）: #keyword: Nomad server  #// リージョンごとにサーバーのクラスターがあります
                リーダー:  #// サーバーのリーダー
                フォロワー:  #// リーダー以外のサーバー
            クライアント（クライアント モードのエージェント）: #keyword: Nomad client  #// クライアント モードで実行されている Nomad エージェント、Docker ホスト
                #// クラスタ内の他のすべてのエージェントは、クライアント モード
                設定: nomad.hcl >> client
            ノード: #keyword: nomad node
                クライアントと同じ
        ノマド オブジェクト:  #// ジョブとタスク
            ジョブ:  #// 1つ以上のタスクを含む 1つ以上のタスク・グループ
                jobspec（ジョブ仕様）:  #// ジョブのスキーマ。種類、実行に必要なタスクとリソース、スプレッド、自動スケーラー ポリシー、Consul サービス情報など
                    ジョブの定義を表示します: Nomad Web UI >> Jobs（左上）>> 行（右半分）>> Definition（タブ）>> command（を検索）
            タスク グループ:  #// 一緒に実行する必要があるタスクのセット。スケール アウト の単位
            タスク:  #// Docker コンテナー など
                タスク ドライバー:  #// タスクのコマンド？
            allocation（割り当て）:  #// タスク グループとクライアント ノード間のマッピング。タスク グループのインスタンス
            evaluation（評価）:  #// スケジューリングの決定を行うメカニズム。変更があったら、新しい評価を作成して、アクションの必要性を判断します
        スケジューリング:
            bin packing（binパッキング）:  #// バイナリの名前。不規則なバイナリ サイズに対応するアルゴリズム
            スプレッド スケジューリング:  #// 負荷分散アルゴリズム
    ファイル:
        .nomad ファイル, Job ファイル: #keyword: .nomad job file  #ref: __Project__/__Application__.nomad  #glossary: Nomad
            #ref: https://developer.hashicorp.com/nomad/docs/job-specification
            #↓ サンプル
            Docker + Django サンプル:  #search: Docker Django Nomad example
            Dockerfile を使うサンプル:  #// 未確認。 インストールなどをするコマンドは、Dockerfile に書き、Job ファイル には書きません。
                .nomad: |
                    job "django-app" {
                        datacenters = ["local"]  #// nomad.hcl ファイルの datacenter で定義した名前
                        type = "service"
                        group "web" {
                            count = 1
                            network {
                                port "http" {
                                    static = 8000
                                }
                            }
                            task "django" {
                                driver = "docker"
                                config {
                                    image = "my-django-app:latest"
                                    ports = ["http"]  #// network.port で定義した名前
                                }
                                env {
                                    DEBUG = "true"
                                    ALLOWED_HOSTS = "*"
                                }
                            }
                        }
                    }
                最小限の Django Dockerfile: |
                    FROM python:3.11-slim

                    WORKDIR /app
                    COPY requirements.txt .
                    RUN pip install -r requirements.txt

                    COPY . .

                    EXPOSE 8000
                    CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]
                最小限の requirements.txt: |
                    Django>=4.2.0,<5.0
                    psycopg2-binary>=2.9.0
                    gunicorn>=20.1.0
                    python-decouple>=3.6
                    whitenoise>=6.0.0
            #↓ 設定項目
            （構成）:
                job:  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/job
                    group:
                        network:
                            port:
                        task:
                            driver:
                            config:
                                work_dir:
                                command:
                            template:
                            artifact:  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/artifact
                                source:
                            env:
                            vault:
                            volume_mount:  #search: Nomad volume_mount
                            volume:
                            resources:  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/resources
                                memory:
                    vault:
                locals:
            job:  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/job
                ジョブ名: #keyword: Nomad job name
                    job "django-app" {
                    と書かれていたら、ジョブ名は django-app です  #search: Docker Django Nomad example
            group:
            network:
            task:
                タスク名, コンテナ―名:
                    __GroueName__-__AllocationID__-__Hash__
                    特定の名前は指定できません。 task フィールドに name フィールドはありません。
                driver:
                    docker など
            config:
                #↓ driver = "docker" の場合
                image:  #search: Docker Django Nomad example
                ports:
                work_dir:
                command: #keyword: Nomad task command
                args:
                volumes:  #search: Nomad Docker volume
            env: #keyword: .nomad env  #// task >> env  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/env
                サンプル: |  #focus: env, region
                    job "django-app" {
                        group "web" {
                            task "django" {
                                env {
                                    my_key = "my-value"
                                    opas_password = "${local.region}"
                    locals {
                        region = "tokyo"
            artifact:  #// task >> artifact  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/artifact
                （サンプル）: |
                    task "____" {
                        artifact {
                            source = "http://172.17.0.1:8089/your-app.rpm"
                            destination = "local/your-app.rpm"
                            mode = "file"
                        }
                source:  #// ダウンロード URL
                    .zip ファイルを指定する場合: #keyword: Nomad .zip artifact
                        サンプル設定:
                            source = "https://github.com/hashicorp/nomad-guides/archive/refs/heads/master.zip"
                        出力:
                            展開されます
                    Git リポジトリ:
                        アーカイブ(.zip)を指定する場合:
                            サンプル設定:
                                source = "https://github.com/hashicorp/nomad-guides/archive/refs/heads/master.zip"
                            出力:
                                destination に指定したフォルダーのパスの直下に __Repository__-__Branch__ フォルダーができ、
                                その中に .zip の内容が展開されます
                        リポジトリを指定する場合:
                            source = "git::https://github.com/hashicorp/nomad-guides"
                    (${ }), 文字列補間:  #search: Nomad string interpolation
                        サンプル: |
                            task "____" {
                                artifact {
                                    source = "http://${ meta.nomad_host }:8089/your-app.rpm"
                                    destination = "local/your-app.rpm"
                                    mode = "file"
                                }
                        ${ } が展開されない場合:
                            メタデータの名前が間違ってないか、登録されているかチェックしてください。
                            #search: Nomad meta
                        代替手段 >> 実行するコマンドに curl を書きます: | #keyword: Nomad curl without artifact
                            task "____" {
                                config {
                                    args = [
                                        "-c",
                                        join(" && ", [
                                            "curl -OL  http://${ meta.nomad_host }:8089/your-app.rpm",
                    ローカル file について:  #// ローカル ファイル を指定できません
                        公式:
                            コンテナの分離を強制するため、 ローカル ファイル はサポートしていません。
                            #ref: https://github.com/hashicorp/nomad/issues/1897
                        代替手段 >> HTTP サーバー を立てます: #keyword: Nomad artifact http server
                            cd  __PublicHTML__
                            python3 -m http.server 8089
                destination:  #// 出力先
                    デフォルト:
                        local
                    ファイル名指定: |  #// mode = "file" も指定します
                        destination = "local/your-app.rpm"
                        mode = "file"
                トラブルシューティング (Nomad artifact): #keyword: Nomad artifact trouble
                    - #// 代わり:  #search: Nomad curl without artifact  #search: Nomad artifact http server
                        #// 制限が多いため、HTTP サーバーを立てて、curl を実行したほうが確実ですが、template などが使えなくなります
                    - #// failed to download artifact
                        手順: nomad job run  ____.nomad
                        ログ: |
                            nomad status  __JobName__
                            nomad alloc status __AllocationID__
                                Recent Events:
                                Time                       Type                      Description
                                2025-09-05T18:17:19+09:00  Restarting                Task restarting in 18.667241879s
                                2025-09-05T18:17:19+09:00  Failed Artifact Download  failed to download artifact "https://github.com/hashicorp/nomad-guides/archive/refs/heads/master.zip": getter subprocess failed: exit status 1: failed to download artifact: Get "https://github.com/hashicorp/nomad-guides/archive/refs/heads/master.zip": dial tcp 20.27.177.113:443: connect: network is unreachable
                        対処: #keyword: Nomad set_environment_variables
                            /etc/nomad.d/nomad.env:
                                http_proxy=http://____:____
                                https_proxy=http://____:____
                                no_proxy=____,localhost,127.0.0.1,.local,172.17.0.1,172.18.0.1,172.19.0.1,172.20.0.1,host.docker.internal,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16
                            nomad.hcl: |
                                client {
                                    artifact {
                                        set_environment_variables = "HTTP_PROXY,HTTPS_PROXY,http_proxy,https_proxy,NO_PROXY,no_proxy"
            template: #keyword: .nomad template  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/template
                #↓ フィールド
                data:  #search: Nomad template contents
                source:  #search: Nomad template contentss
                destination:  #// テンプレートを使って生成するファイルの場所
                    local:  #// 値が "local/_tmp.conf" の場合
                        #↓ タスクの種類
                        Docker コンテナーの中の場合:
                            /local/_tmp.conf
                    ルート(/)以下のフルパス:  #// 値が "/etc/yum.repos.d/_tmp.repo__" の場合
                        動作: ファイルは作られません。エラーにもなりません。
                        #↓ 代替手段  #focus: _tmp.repo__
                        Docker ボリューム を使う場合: | #keyword: Nomad Docker volume
                            config {
                                image = "centos:7"
                                volumes = [
                                    "local/root/etc/yum.repos.d/_tmp.repo__:/etc/yum.repos.d/_tmp.repo__"
                                ]
                            }                            
                            template {
                                data = "..."
                                destination = "local/root/etc/yum.repos.d/_tmp.repo__"
                            }
                        カスタム Docker イメージ を使う場合:
                            Job が使う Docker イメージに、
                            あらかじめ /etc/yum.repos.d/_tmp.repo__ ファイルを作っておきます
                #↓ 構成
                テンプレート: #keyword: Nomad template contents
                    data, 埋め込み(.nomad):  #// .nomad >> task >> template >> data
                        template {
                            data = <<EOH
                        Line 1
                        Line 2
                        EOH
                    source, 外部ファイル(.tpl):  #// .nomad >> task >> template >> source
                        注意: artifact が必要です  #search: Nomad artifact
                        サンプル: |
                            artifact {
                                source = "https://github.com/hashicorp/nomad-guides/archive/refs/heads/master.zip"
                                #// extract to local/nomad-guides-master
                            }
                            template {
                                source = "local/nomad-guides-master/templates/example.conf.tpl"
                                destination = "local/example.conf"
                            }
                置き換える部分, Template Action: #keyword: Nomad go template action,  Nomad placeholder
                    #↓ 定義場所
                    環境変数 (env stanza): |
                        {{ env "APP_NAME" }}
                    Consul Key-Value ストア: |
                        {{ key "myapp/database/host" }}
                    Vault シークレット: |
                        {{ with secret "secret/myapp/db" }}
                            {{ .Data.username }}
                        {{ end }}
                    Nomad変数 (Variables): |
                        {{ with nomadVar "nomad/jobs/myapp" }}
                            {{ .database_url }}
                        {{ end }}
                    サービス ディスカバリー: |
                        {{ range service "web-backend" }}
                            - {{ .Address }}:{{ .Port }}
                        {{ end }}
                    #↓ 演算
                    デフォルト値: |
                        {{ env "PORT" | default "8080" }}
                生成タイミング: |  #focus: テンプレート生成
                    nomad job run: ジョブ定義をNomadクラスターに送信
                    スケジューリング: Nomadサーバーが適切なクライアントノードを選択
                    アロケーション: 選択されたクライアントノードにタスクが配置
                    テンプレート生成: クライアントノード上で、タスク開始前にテンプレートファイルが作成される
                    タスク実行: 生成されたファイルを使ってタスクが開始
                    change_mode = "restart"
                        テンプレートが変更されるとタスクを再起動
            volume_mount: #keyword: Nomad volume  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/volume_mount
                #// Nomad の ホスト OS の中の特定のフォルダーを、タスク（コンテナー）の中のフォルダーにマウントします
                （構成）:
                    task -- volume_mount -- volume -- host_volume
                /var/run/docker.sock:  #search: Nomad volume /var/run/docker.sock
                /repository:
                    ❗注意: #// WSL2(?)では成功していません。
                        /home/users を作ります:
                            cd /home
                            sudo mkdir users
                            sudo chmod a+w users
                        nomad.hcl に設定します: |
                            sudo vi /etc/nomad.d/nomad.hcl
                            sudo systemctl restart nomad
                            nomad node status -self -verbose
                                ...
                                Host Volumes
                                Name        ReadOnly  Source
                                repository  true      /home/user1
                                ...
                        Job ファイルを編集して起動します: |
                            code  django.nomad
                            nomad job run  django.nomad
                            nomad job status django-app
                                ...
                                Placement Failure
                                Task Group "web":
                                    * Constraint "missing compatible host volumes": 1 nodes excluded by filte
                                ...
                    volume_mount: #keyword: Nomad volume_mount  #// .nomad >> task >> volume_mount  #// Nomad の ホスト OS の中の特定のフォルダーを、タスク（コンテナー）の中のフォルダーにマウントします
                        サンプル: |
                            volume_mount {
                                destination = "/repository"
                                volume      = "repository1"
                                read_only   = true
                            }
                    volume:  #// .nomad >> group >> volume  #// タスクからアクセスできるボリュームを宣言します
                        サンプル: |
                            volume "repository1" {
                                source = "repository"  #// host_volume で定義した名前
                                type   = "host"
                            }
                    host_volume:  #// nomad.hcl >> client >> host_volume  #// Nomad の ホスト OS の中の特定のフォルダーを、タスク（コンテナー）からアクセスできる、ホスト ボリューム を定義します
                        #ref: https://developer.hashicorp.com/nomad/docs/configuration/client#host_volume-block
                        サンプル: |
                            host_volume "repository" {
                                path      = "/home/users"
                                read_only = true
                            }
            resources:  #ref: https://developer.hashicorp.com/nomad/docs/job-specification/resources
                cpu:
                    デフォルト 100(MHz)
                memory:
                    デフォルト 300(MB)
            locals: #keyword: .nomad locals  #// ローカル変数  #ref: https://developer.hashicorp.com/nomad/docs/reference/hcl2/locals
                サンプル: |  #focus: locals, local  #search: .nomad env
                    job "django-app" {
                        group "web" {
                            task "django" {
                                env {
                                    my_key = "my-value"
                                    opas_password = "${local.region}"
                    locals {
                        region = "tokyo"
            vault: #keyword: .nomad vault  #// job >> vault,  task >> vault
                vault {}: #keyword: .nomad empty vault
                    デフォルトのポリシーを使います  #search: token_policies Nomad Vault
            #↓ 設定内容（項目共通）
            Nomad が自動的に設定する環境変数:  #keyword: Nomad 自動定義 環境変数  #glossary: Nomad
                #ref: https://developer.hashicorp.com/nomad/docs/reference/runtime-environment-settings
                #↓ ネットワーク
                #ref: https://developer.hashicorp.com/nomad/docs/job-specification/network
                NOMAD_PORT_http: ポート番号
                NOMAD_IP_http: バインドIPアドレス
                NOMAD_ADDR_http: IP:ポートの組み合わせ
                NOMAD_HOST_PORT_http: ホスト側のポート（NATの場合）
        nomad.hcl:  #ref: /etc/nomad.d/nomad.hcl  #// Nomad サービスの設定  #glossary: Nomad
            手順 >> 設定: #keyword: nomad.hcl  #snippet-depth: 1
                systemctl status  nomad
                sudo tee /etc/nomad.d/nomad.hcl > /dev/null
                    内容を貼り付けます
                sudo systemctl restart nomad
                sudo journalctl -u nomad --no-pager  |  less
                nomad node status -self -verbose
            #↓ サンプル
            最低限の設定: | #keyword: nomad.hcl minimum Docker  #focus: __ProxyURL__
                datacenter = "local"
                data_dir = "/opt/nomad/data"

                server {
                    enabled = true
                    bootstrap_expect = 1  # node count
                }

                client {
                    enabled = true
                    meta {

                        #// Proxy:
                        http_proxy = "__ProxyURL__"
                        https_proxy = "__ProxyURL__"
                        no_proxy = "localhost, 127.0.0.1, .local, 172.17.0.1, 172.18.0.1, 172.19.0.1, 172.20.0.1, host.docker.internal, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16"

                        #// Server:
                        nomad_host = "172.17.0.1"
                    }
                    host_volume "docker-sock" {
                        path      = "/var/run/docker.sock"
                        read_only = false
                    }
                    options {
                        "docker.bridge.ip" = "0.0.0.0"
                    }
                }

                plugin "docker" {
                    config {
                        allow_privileged = false
                    }
                }
            Vault を使う設定: | #keyword: nomad.hcl with Vault
                datacenter = "local"
                data_dir = "/opt/nomad/data"

                server {
                    enabled = true
                    bootstrap_expect = 1  # node count
                }

                client {
                    enabled = true
                    meta {

                        #// Proxy:
                        http_proxy = "__ProxyURL__"
                        https_proxy = "__ProxyURL__"
                        no_proxy = "localhost, 127.0.0.1, .local, 172.17.0.1, 172.18.0.1, 172.19.0.1, 172.20.0.1, host.docker.internal, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16"

                        #// Server:
                        nomad_host = "172.17.0.1"
                    }
                    host_volume "docker-sock" {
                        path      = "/var/run/docker.sock"
                        read_only = false
                    }
                    options {
                        "docker.bridge.ip" = "0.0.0.0"
                    }
                }

                plugin "docker" {
                    config {
                        allow_privileged = false
                    }
                }

                acl {
                    enabled = true
                }

                vault {
                    enabled = true
                    address = "http://127.0.0.1:8200"

                    default_identity {
                        aud = ["vault.io"]
                        ttl = "1h"
                    }
                }
            #↓ 設定項目
            （構成）:
                datacenter:
                data_dir:
                server:
                client:
                    meta:
                    artifact:  #ref: https://developer.hashicorp.com/nomad/docs/configuration/client#artifact-parameters
                    host_volume:  #ref: https://developer.hashicorp.com/nomad/docs/configuration/client#host_volume-block
                plugin:
            （設定の確認）:
                nomad node status -self -verbose
            #↓   基本的なクラスター設定
            datacenter:
                サンプル:
                    -   datacenter = "local"
                    -   datacenter = "stg"
                    -   datacenter = "aws-ap-northeast-1"
                ホストとの関係:
                    同じデータセンター内の全ホストに、同じデータセンター名を設定します。
                適する名前:
                    物理サーバーの場所:
                適さない名前:
                    環境名: dev, staging, prod  #// 同じ場所にある場合は Nomad namespace で分離すべき
                    アプリケーション名: web-servers, database-servers  #// node class や constraint で制御すべき
            namespace:  #// Enterprise 版の nomad のみ
                サンプル:
                    namespace = "production"
                    namespace = "staging"  
                    namespace = "development"
                    namespace = "team-frontend"
                    namespace = "team-backend"
            data_dir:  #// Nomad のデータディレクトリ
            bind_addr:  #// どのネットワークインターフェースで待機するか
            log_level:
                INFO など
            #↓   サーバーモード設定（スケジューラー機能）
            server: |
                server {
                    enabled = true
                    bootstrap_expect = 1  # 単一ノードの場合は1、クラスターなら3以上
                    raft_protocol = 3  # リーダー選出設定
                    default_scheduler_config {
                        scheduler_algorithm = "binpack"
                    }
                }
            #↓   クライアントモード設定（ワーカー機能）コンテナを実際に実行するサーバー、リソースの監視と報告。nomad コマンドを実行するホストではありません
            client:
                クライアント モード の役割:
                    1. 開発者がJobを投入
                        nomad job run django-app.nomad
                    ↓
                    2. サーバーがスケジューリング
                        「django-appをworker1で起動しよう」
                    ↓
                    3. クライアント（worker1）が実行
                        docker run python:3.11-slim ...
                    ↓
                    4. クライアントが状態報告
                        「コンテナ起動完了、CPU 10%使用中」
                設定: |
                    client {
                        enabled = true
                        node_class = "compute"
                        meta {
                            http_proxy = "__ProxyURL__"
                            https_proxy = "__ProxyURL__"
                            no_proxy = "localhost, 127.0.0.1, .local, 172.17.0.1, 172.18.0.1, 172.19.0.1, 172.20.0.1, host.docker.internal, 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16"
                            nomad_host = "172.17.0.1"
                        }
                        reserved {
                            cpu = 800
                            memory = 512
                        }
                    }
                artifact:  #ref: https://developer.hashicorp.com/nomad/docs/configuration/client#artifact-parameters
                    decompression_file_count_limit:
            meta: #keyword: Nomad client metadata
                サンプル: |  #// nomad.hcl >> client >> meta
                    meta {
                        http_proxy  = "http://proxy.company.com:8080"
                        environment = "production"
                    }
                参照できる場所:
                    task >> env
                    task >> config >> args
                参照できない場所:
                    task >> artifact
            host_volume:  #// nomad.hcl >> client >> host_volume  #search: Nomad volume
            #↓   プラグイン設定
            plugin: |
                plugin "docker" {
                    config {
                        allow_privileged = false
                        volumes {
                            enabled = true
                        }
                        gc {  # イメージの自動削除
                            image       = true
                            image_delay = "3m"
                        }
                    }
                }
                plugin "raw_exec" {  # execドライバーの無効化（セキュリティ上の理由）
                    config {
                        enabled = false
                    }
                }
            #↓   ネットワーク設定
            ports: |
                ports {
                    http = 4646
                    rpc  = 4647
                    serf = 4648
                }
            advertise: | #// 他ノードに通知するアドレス
                advertise {
                    http = "192.168.1.100:4646"
                    rpc  = "192.168.1.100:4647"
                    serf = "192.168.1.100:4648"
                }
            #↓   セキュリティ設定
            acl: | #// ACL
                acl {
                    enabled = true
                    token_ttl = "30s"
                    policy_ttl = "60s"
                }
            tls: | #// TLS
                tls {
                    http = true
                    rpc  = true

                    ca_file   = "/etc/nomad.d/certs/ca.pem"
                    cert_file = "/etc/nomad.d/certs/nomad.pem"
                    key_file  = "/etc/nomad.d/certs/nomad-key.pem"
                }
        テンプレート:
            (${ }), 文字列補間: #keyword: Nomad string interpolation,  Nomad ${ },  Nomad variables
                仕様:  #search: HCL string interpolation
                中に指定できるもの:  #// ❗注意: ${  } の内側に空白を入れることはできません。 ${ meta.data } は置き換えられません。 ${meta.data} は置き換えられます
                    -   __EnvironmentVariableName__  #search: Nomad 自動定義 環境変数
                    -   meta.__ClientMetadataName__  #search: Nomad client metadata
                    -   var.__VariableName__
                    -   node.____
                    -   attr.____
            ({{ }}), gomplate, template stanza: #keyword: Nomad gomplate,  Nomad template stanza,  Nomad {{ }}  #ref: https://docs.gomplate.ca/
                Job ファイルの設定:  #search: .nomad template
                テンプレートの内容:  #search: Nomad go template action
            Levant: #keyword:
                サードパーティツール - HashiCorp製ではない。
                Levantは、複雑な環境での Nomad デプロイメントを簡素化する強力なツールですが、シンプルな用途では純粋なNomadで十分な場合もあります。
            Nomad 変数:  #// ファイルはコンテナ起動前に生成されます
                variables.nomad.hcl: |
                    variable "service_a_port" {
                        description = "Service A のポート番号"
                        type        = number
                        default     = 8080
                    }
                service-a.nomad.hcl: |
                    hcljob "service-a" {
                        datacenters = ["dc1"]

                        group "app" {
                            network {
                                port "http" {
                                    static = var.service_a_port  # 変数を参照
                                }
                            }
                service-b.nomad.hcl: |
                    hcljob "service-b" {
                        datacenters = ["dc1"]

                        group "app" {
                            task "app" {
                                driver = "docker"

                                config {
                                    image = "service-b:latest"
                                }

                                # 設定ファイルをテンプレートで生成
                                template {
                                    data = <<EOF
                    # Service B Configuration
                    upstream:
                        service_a:
                            host: "${var.service_a_host}"
                            port: ${var.service_a_port}

                    database:
                        host: "postgres.service.consul"
                        port: 5432
                    EOF
                                    destination = "local/config.yaml"
                                    change_mode = "restart"
                                }

                                env {
                                    CONFIG_FILE = "/local/config.yaml"
                                }
                            }
                        }
                    }
            クライアントの設定ファイルの全変更:
                Chat: あるサービスAのクライアントとなるサービス B,Cがあり、B,Cそれぞれ設定ファイルにAのポート番号が書いてある場合、
                    nomad 環境でポート番号の設定を一元化するには
                    Nomad 変数
        Dockerfile:
            開発環境とテスト環境の Docker イメージ: |  #// マルチステージDockerfile
                # ========================================
                # 共通ベース：アプリケーション実行環境
                # ========================================
                FROM python:3.11-slim as app-base

                # アプリケーション実行に必要な最小限
                RUN apt-get update && apt-get install -y \
                    libpq5 \
                    curl \
                    && rm -rf /var/lib/apt/lists/*

                WORKDIR /app
                COPY requirements.txt .
                RUN pip install --no-cache-dir -r requirements.txt

                COPY src/ .
                RUN useradd -m -u 1000 appuser
                USER appuser

                # ========================================
                # 開発環境：開発ツール追加
                # ========================================
                FROM app-base as development

                USER root
                # 開発専用ツール
                RUN pip install \
                    pytest \
                    black \
                    flake8 \
                    debugpy \
                    ipython \
                    jupyter

                # ホットリロード、デバッグポート
                EXPOSE 8000 5678
                USER appuser
                CMD ["python", "-m", "debugpy", "--listen", "0.0.0.0:5678", "--wait-for-client", "app.py"]

                # ========================================
                # テスト環境：テストツールのみ追加
                # ========================================
                FROM app-base as test

                USER root
                # テスト実行に必要なツールのみ
                RUN pip install \
                    pytest \
                    pytest-cov \
                    pytest-mock \
                    requests-mock

                USER appuser
                # テスト実行用
                CMD ["pytest", "-v", "--cov=src"]

                # ========================================
                # 本番環境：最小構成
                # ========================================
                FROM app-base as production

                # 本番用設定のみ
                EXPOSE 8000
                CMD ["python", "app.py"]
    トラブルシューティング: #keyword: Nomad trouble
        デバッグ用コマンド:  #search: Nomad debug
        artifact 関連:  #search: Nomad artifact trouble
        変数が展開されない:  #search: Nomad ${ }
        #↓ エラー メッセージ
        Unexpected response code 403,  Unexpected response code 400:
            手順:
                nomad コマンド
            ログ: |
                $ nomad node status
                Error querying node status: Unexpected response code: 403 (Permission denied)
                    または
                Error querying jobs: Unexpected response code: 400 (Client sent an HTTP request to an HTTPS server.)
            対処:
                #search: nomad CLI environment
        400 (Client sent an HTTP request to an HTTPS server.):  #keyword: NOMAD_ADDR
            手順: nomad コマンド
            ログ: |
                Error submitting job: Unexpected response code: 400 (Client sent an HTTP request to an HTTPS server.).
                Additionally, an error occurred while constructing this error (read tcp 127.0.0.1:55462->127.0.0.1:4646:
                read: connection reset by peer); the body might be truncated or missing.
            対処:  #// NOMAD_ADDR に https ～ を設定します
                export NOMAD_ADDR="https://localhost:4646"
                export NOMAD_CACERT="/etc/nomad.d/tls/tls.crt"
                nomad job run -address="https://localhost:4646"  "django.nomad"
        https://registry-1.docker.io/v2/ context deadline exceeded:
            手順: nomad job run
            ログ: |  #// Nomad Web UI
                Driver Failure: Failed to pull `__DockerImage__`: Error response from daemon: Get "https://registry-1.docker.io/v2/": context deadline exceeded
            対処:
                nomad コマンドを実行する環境とユーザーで、docker コマンドが使えることを確認してください
        missing compatible host volumes:
            手順: nomad job run
            ログ: |  #// Nomad Web UI
                Constraint missing compatible host volumes filtered 1 node
            対処:  #// nomad.hcl の host_volume を追加修正します
                ボリューム名をメモします: |  #focus: docker-sock  #// .nomad >> ... >> volume_mount
                    volume_mount {
                        volume      = "docker-sock"
                        destination = "/var/run/docker.sock"
                    }
                nomad.hcl に以下を追加します: |
                    host_volume "docker-sock" {
                        path      = "/var/run/docker.sock"
                        read_only = false
                    }
        No default interface found:
            手順: nomad job run  example.nomad
            ログ: |
                [ERROR] agent: error starting agent: error="client setup failed: fingerprinting failed: Error while detecting network interface  during fingerprinting: No default interface found"
            対処:
                network_interface を正しく設定します:
                    sudo vi  /etc/nomad.d/nomad.hcl
                        client {
                            network_interface = "eth1"
        zip archive contains too many files:
            手順: nomad job run
            ログ: |
                Failed Artifact Download: failed to download artifact "__URL__": getter subprocess failed: exit status 1: failed to download artifact: zip archive contains too many files: __Count__ > 4096
            対処: |  #search: Nomad client
                client {
                    artifact {
                        decompression_file_count_limit = 10000
        Template Missing vault.read(secret/data/mongo/config):
            ログ: |  #// Nomad Web UI
                Template: Missing: vault.read(secret/data/mongo/config)
            状況:  #focus: secret/data/mongo/config,  settings.yml.tpl
                .nomad ファイル: |
                    template {
                        source = "local/settings.yml.tpl"
                settings.yml.tpl ファイル: |
                    {{- with secret "secret/data/mongo/config" }}
                    {{- end }}
            対処A: | #// nomad のログから URL を確認します
                sudo journalctl  -u nomad  --follow
                    Sep 11 15:11:34 host nomad[197324]: URL: GET http://127.0.0.1:8200/v1/secret/data/mongo/config
                    Sep 11 15:11:34 host nomad[197324]: Code: 403. Errors:
                    Sep 11 15:11:34 host nomad[197324]: * permission denied (retry attempt 9 after "1m0s")
                197324 は Nomad クライアントの PID です。
                （エラー時しか出ないかも）
                URL を確認したら、他の対処法も参照してください
            対処B:  #// Vault にシークレットが登録されているかチェックします  #search: vault kv get
                vault kv get "secret/default/mongo/config"  #// "secret/data/default/mongo/config" ではありません
            対処C:  #// Vault にシークレットを登録します  #search: vault kv put
                vault kv put "secret/default/mongo/config"  "root_password=secret-password"
            対処D:  #// テンプレートが参照するパスをチェックします
                settings.yml.tpl ファイル: |  #// "secret/default/mongo/config" ではありません
                    {{- with secret "secret/data/default/mongo/config" }}
                        {{.Data.data.root_password}}
                    {{- end }}
            対処E:  #// ポリシーとパスを確認します
                workload ID を使う場合:  #search: install Nomad Vault  #search: Nomad workload ID
                    - シークレットのパスを、workload ID に対応したポリシーのパスの形式に合わせます
                        #search: vault policy write example
                        #search: install Nomad Vault
                    - auth_jwt_ の後の値が合っているか確認します
                        #search: auth_jwt_ HashiCorp Vault
                workload ID を使わない場合:
                    Nomad クライアント が使うポリシー:
                        nomad.hcl
                            vault {
                                token   = "your-vault-token"
            対処F:  #// Job ファイル に vault ブロックがあることを確認します
                job "____" {
                    vault {}
                #search: .nomad empty vault
            対処G:  #// ポリシーを一時的に緩くします  ❗動作確認できたら戻してください
                path "secret/data/*" {
                    capabilities = ["read"]
Vault, OpenBao: #keyword: HashiCorp Vault,  Vault,  OpenBao  #// シークレット管理サーバー
    #ref: https://www.ctc-g.co.jp/solutions/vault/
    #ref: https://zenn.dev/nameless_gyoza/articles/hashicorp-vault-hands-on
    手順:
        Vault と OpenBao の違い:  #ref: https://www.publickey1.jp/blog/23/hashicorp_vaultopenbaolinux_foundation.html
            サービス名: valut, openbao  #// systemctl など
            コマンド名: vault, bao
            ファイル名: /etc/vault.d/vault.hcl,  /etc/vault.d/openbao.hcl
        インストール: #keyword: install HashiCorp Vault
            #// 以下は HTTP の場合（HTTPS ではない場合）
            プログラムをインストールします:
                sudo dnf config-manager --add-repo  https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
                sudo dnf install -y  vault
            HTTPS アクセスを不要にします:  #// 開発環境のみ
                #// バージョンによっては、以下のファイル名が /etc/vault.d/openbao.hcl になります  #ref: https://openbao.org/
                /etc/vault.d/vault.hcl: | #keyword:  #// HTTP listener を有効に、HTTPS listener を無効にします
                    # HTTP listener
                    listener "tcp" {
                        address = "127.0.0.1:8200"
                        tls_disable = 1
                    }

                    # HTTPS listener
                    # listener "tcp" {
                    #   address       = "0.0.0.0:8200"
                    #   tls_cert_file = "/opt/vault/tls/tls.crt"
                    #   tls_key_file  = "/opt/vault/tls/tls.key"
                    # }
            サービスを起動します:
                sudo systemctl start  vault
                sudo systemctl enable  vault
            初期化します: |  #keyword: create HashiCorp Vault root token,  vault operator init,  Initial Root Token HashiCorp Vault
                export VAULT_ADDR="http://localhost:8200"
                vault status
                vault operator init
                    表示された内容（特に以下のキー）を安全な場所 ~/.secrets/vault_initial.log に保存します。
                        Unseal Key 1: AbCdEf...   #// __UnsealKey1__
                        Unseal Key 2: GhIjKl...   #// __UnsealKey2__
                        Unseal Key 3: MnOpQr...   #// __UnsealKey3__
                        Unseal Key 4: StUvWx...
                        Unseal Key 5: YzAbCd...
                        Initial Root Token: s.EfGhIj...   #// __InitialRootToken__
            アンシールします:  #keyword: vault operator unseal  #// サービス（再）起動時はシールした状態になっていて、アクセスできません
                教科書的なコマンド: |  #// ログに残るため非推奨
                    vault operator unseal  __UnsealKey1__  #// アンシールキーは複数の信頼できる人に分散して保管
                    vault operator unseal  __UnsealKey2__
                    vault operator unseal  __UnsealKey3__
                実践的なコマンド: |
                    less  __UnsealKeyMemoFile__  #// アンシールキーは複数の信頼できる人に分散して保管
                    read -s -p "Enter one of unseal key: "  UnsealKey;  vault operator unseal "${UnsealKey}"
            Web UI を開いてみます: |  #ref: https://developer.hashicorp.com/vault/tutorials/get-started/learn-ui
                http://localhost:8200/ui/
                    Sign in to Vault
                    Token: __InitialRootToken__
            現在の Linux ユーザー が、Vault にアクセスできるようにします:
                vault login  __InitialRootToken__  #// ~/.vault-token に保存されます
            key value v2 を使うようにします:
                vault secrets enable  -path="secret"  kv-v2
                vault secrets list -detailed  |  grep version
                    ...  version:2
            key value を登録してみます: |
                vault kv put  "secret/path"  key1=value1  key2=value2
                vault kv get  "secret/path"
                    == Secret Path ==
                    secret/data/path

                    ======= Metadata =======
                    Key                Value
                    ---                -----
                    created_time       2025-09-09T09:19:00.846534342Z
                    custom_metadata    <nil>
                    deletion_time      n/a
                    destroyed          false
                    version            1

                    ==== Data ====
                    Key     Value
                    ---     -----
                    key1    value1
                    key2    value2
                http://localhost:8200/ui/vault/secrets/secret/kv/path/details
                    {
                        "key1": "value1",
                        "key2": "value2"
                    }
                vault kv delete  "secret/path"  #// アンデリートができる削除です。代わりに kv destroy を実行すると完全に削除します
            YAML に基づいて key value を登録します: #keyword: HashiCorp Vault YAML
                サンプル YAML を作ります: |
                    tee ~/_example_vault.yaml > /dev/null  << HERE_DOCUMENT
                    key1: value1
                    key2:
                        key21: value21
                        key22: value22
                    HERE_DOCUMENT
                （初回のみ）yq をインストールします:  #search: yq
                    sudo curl -L  -o /usr/local/bin/yq  https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
                    sudo chmod +x  /usr/local/bin/yq
                登録してみます: |  #search: vault kv put
                    yq eval -o=json ~/_example_vault.yaml  |  vault kv put  "secret/config/app"  -  #// 末尾にハイフンが必要です
                    vault kv get  "secret/config/app"
                        Key     Value
                        ---     -----
                        key1    value1
                        key2    map[key21:value21 key22:value22]
                    http://localhost:8200/ui/vault/secrets/secret/kv/config%2Fapp/details
                        {
                            "key1": "value1",
                            "key2": {
                                "key21": "value21",
                                "key22": "value22"
                            }
                        }
        初期化します: #keyword: initialize OpenBao
            シークレットの最新バックアップがあることを確認します:
            サービスを止めします:
                sudo systemctl stop  openbao
            データがある場所を調べます:
                sudo systemctl cat  openbao
                    ExecStart=/usr/bin/bao server -config=/etc/openbao.d/openbao.hcl
                cat /etc/openbao.d/openbao.hcl
                    storage "file" {
                        path = "/var/lib/openbao/data"
            データを削除します:
                sudo ls -la  "/var/lib/openbao/data"
                sudo rm -rf  "/var/lib/openbao/data"
                sudo ls -la  "/var/lib/openbao/data"
            Nomad と連携している場合:
                #search: initialize Nomad
            再初期化します:
                #// Ansible を使う環境では、以下ではなく、Ansible を使います
                sudo systemctl start openbao
                VAULT_ADDR=http://localhost:8200 vault operator init
        CLI でログインします: #keyword: Vault log in
            トークンを変数に代入する場合:
                #search: vault write auth/__AuthenticationMethod__/login
            トークンを保存する場合:
                vault login コマンド: #keyword: vault login
                    設定: vault login  __Token__  #// Initial Root Token など
                ~/.vault-token:
                    内容: トークン（生のテキスト）  #search: policy token HashiCorp Vault
        WebUI でログインします: #keyword: Vault web UI
            URL: https://localhost:8200
            Method: Token
            Token:
                local の場合:  #search: Initial Root Token HashiCorp Vault
                    less  ~/.secrets/vault_initial.log
    コマンド:  #glossary:
        #// OpenBao では valut → bao （そのシンボリックリンクを作ってもよい）
        環境変数: #keyword: vault CLI environment  #glossary:
            サンプル: |
                export VAULT_CACERT="/etc/vault.d/tls/tls.crt"
                    または
                export VAULT_CACERT="/etc/openbao.d/tls/tls.crt"
                vault status
            VAULT_ADDR: |
                export VAULT_ADDR=http://localhost:8200   #// コンテナ―内なら http://172.17.0.1:8200
                vault ____
                #// 関連: less  ~/.vault-token  #// コマンドが処理できる権限を持ったトークン。開発環境では root token  #search: ~/.vault-token
            VAULT_CACERT:
                サンプル: |
                    export VAULT_CACERT="/etc/vault.d/tls/tls.crt"
                        または
                    export VAULT_CACERT="/etc/openbao.d/tls/tls.crt"
                    vault status  #// VAULT_CACERT が有効になっているか動作確認します
                説明: |
                    Vault CLI（Vault クライアント）が Vault サーバーの証明書を検証するための CA 証明書 の場所
                    設定しないと以下のようなエラーになります。
                        Get "https://127.0.0.1:8200/v1/sys/seal-status": tls: failed to verify certificate: x509: certificate signed by unknown authority
                HTTPS 関連の設定をする前の場合:  #search: VAULT_SKIP_VERIFY
            VAULT_SKIP_VERIFY:  #// Vault サーバーの証明書を検証する内部手順をスキップします
                export VAULT_SKIP_VERIFY=1
                #// 通常、VAULT_CACERT を設定するように変えます
        vault login:  #search: Vault log in
        vault status:
        vault policy write:
            #search: vault policy write example
            #search: policy HashiCorp Vault
        vault policy read:
            vault policy read  "nomad-workloads"
            #search: vault policy write example
        vault token create: |  #search: create policy HashiCorp Vault
            vault token create  -policy=__PolicyName__
                token                __Token__
                token_accessor       __TokenAccessor__               #search: HashiCorp Vault token accessor
                policies             ["default" "__PolicyName__"]
                token_policies       ["default" "__PolicyName__"]
                identity_policies    []
                token_duration       768h
                token_renewable      true
            #// 生成したら token と token_accessor を安全な場所にメモします
            #search: lookup token accessor HashiCorp Vault
        vault token capabilities: #keyword:  #// 権限があるか確認します  #search: vault token capabilities example
        vault kv put:
            基本:
                export VAULT_ADDR="http://localhost:8200"
                vault kv put  "secret/mongo/config"  "root_password=secret-password"
                #template__: vault kv put  "__Path__"  "__Key__=__Value__"
                #// 上記は、
            パスの書き方, __Path__:  #search: path HashiCorp Vault
            複数のキー:
                vault kv put  "__Path__"  "__Key1__=__Value1__"  "__Key2__=__Value2__"
            ファイル:
                vault kv put "secret/myapp"  @__Path__
            標準入力:
                vault kv put "secret/myapp"  -
                #// 通常、ヒアドキュメントと共に使われます  #search: HashiCorp Vault JSON
            JSON: | #keyword: HashiCorp Vault JSON  #// 構造を持って格納されます  #search: HERE_DOCUMENT
                vault kv put "secret/myapp" - << HERE_DOCUMENT
                {
                    "database": {
                        "host": "localhost",
                        "port": 5432,
                        "username": "admin",
                        "password": "secret123"
                    },
                    "api_key": "abc-def-123",
                    "debug": true
                }
                HERE_DOCUMENT
            YAML:
                JSON に変換しないと、構造を持って格納されません  #search: HashiCorp Vault YAML
            -mount オプション: #keyword: -mount HashiCorp Vault
                シークレット エンジン（のマウント名）を指定します  #search: secret engine HashiCorp Vault
        vault kv get:
            基本:
                export VAULT_ADDR="http://localhost:8200"
                vault kv get  "secret/mongo/config"
                vault kv get -field=password  "secret/mongo/config"  #// -field オプション はパスの左に書いてください
                #template-at__(-2): vault kv get  "__Path__"
            パスの書き方, __Path__:  #search: path HashiCorp Vault
            -mount オプション:  #search: -mount HashiCorp Vault
        vault write, bao write:  #// HTTP POST に相当。 kv 以外の シークレット エンジン に対しても使えます
            vault kv put との比較:  #// 以下の 2つのコマンドは同じ処理です。主にパスが違います
                vault kv put  "secret/mongo/config"              "root_password=secret-password"
                vault write   "secret/data/mongo/config"  data='{"root_password":"secret-password"}'
            ログインに使います:  #search: Vault log in
        vault read, bao read:  #// HTTP GET に相当。 #// kv 以外の シークレット エンジン に対しても使えます
            vault kv get との比較:  #// 以下の 2つのコマンドは同じ処理です。主にパスが違います
                vault kv get  "secret/mongo/config"
                vault read    "secret/data/mongo/config"
        vault delete, bao delete:  #// HTTP DELETE に相当
        vault list, bao list:  #// HTTP LIST に相当
    構成:
        構成例:
            Vault + GitLab PAT + CI + Container: #keyword:  #ref: ${typrm_files}/ref/VMWare/Vulat_PAT.mmd.html
                PAT との比較:
                    PAT を CI のシークレットに置くより、Vault ROLE_ID + SECRET_ID を置いたほうが、
                    Vault 側で IP 制限、CIDR 制限、namespace / role 制限、mTLSなどをかけられます。
                    Vault の監査ログに login（PAT取得）の痕跡が残ります。
                Vault Token との比較:
                    Vault ROLE_ID + SECRET_ID を使って Vault login すると、TTL が短い Vault Token が得られますが、
                    IP 制限などができないため、権限が強い CI が Vault Token を持たないほうが良いです。
                シークレットの渡し方:
                    環境変数で渡すのは手軽ですが、プロセス一覧やデバッグログに残る可能性があるので、より堅くするなら STDIN 渡しに寄せる（後述）と良いです。
                git credential approve, credential-cache メモリー:
                    一定時間保持  credential-cache は 同一ユーザーの同一コンテナ内で一定時間使えます。
                    PAT を approve で渡す瞬間、そのシェルのメモリには乗ります
                    #search: GitLab PAT
                GIT_ASKPASS か git credential か:  #keyword: GIT_ASKPASS
                    プロセス環境に token が乗るなど別の注意点が出ます
        パス:  #keyword: path HashiCorp Vault
            シークレットとディレクトリ:  #// ファイルとフォルダーに相当
                シークレット: secret/config/app    #keyword: secret HashiCorp Vaule  #// ファイルに相当
                ディレクトリ: secret/config/app/   #keyword: directory HashiCorp Vaule  #// フォルダーに相当
            マウント名の省略:  #// valut kv コマンドの場合
                最初の / の左が、マウント名の場合:  #search: mount HashiCorp Vault
                    CLI: secret/config/app
                    フル パス: secret/data/config/app
                最初の / の左が、マウント名ではない場合:  #// マウント名 secret が暗黙的に指定されます
                    CLI: default/config/app
                    フル パス: secret/data/default/config/app
                フルパスの確認方法:
                    vault kv put コマンドを実行すると表示されます
            ジョブ名:  #// パスの中のジョブ名の部分
                workload ID を使う場合、ポリシーのパスの中に
                    /{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_job_id}}/
                のような nomad_job_id があるときは、
                その部分が Nomad で実行する Job 名になります。
                なので、シークレットのパスにジョブ名を含める必要があります。
                #search: vault policy write example
            ネームスペース, default:  #// パスの中のネームスペース部分
                workload ID を使う場合、ポリシーのパスの中に
                    /{{identity.entity.aliases.auth_jwt_00000000.metadata.nomad_namespace}}/
                のような nomad_namespace があるときは、
                その部分が通常 default に固定されます。
                なので、シークレットのパスに default を含める必要があります。
                #search: vault policy write example
                #search: default namespace HashiCorp Vault
            KV Version 2:  #// secret に kv-v2 がマウントされている場合
                #focus: config  #// config/app の部分はサンプルです
                vault kv get コマンドの引数:             secret/config/app
                vault token capabilities コマンドの引数: secret/data/config/app
                __PolicyName__.hcl ファイルの中の {{ }}: secret/data/config/app
                Web UI の URL:
                    ____:8200/ui/vault/secrets/secret/show/config/app
                    ____:8200/ui/vault/secrets/secret/kv/config%2Fapp
                Web UI のパンくずリスト:
                    < secrets < secret < config < app
                        または
                    Secrets / secret / config / app
                （kv と secret の違い）:
                    kv: vault secrets enable -path=kv kv-v2 で KVv2 としてマウントした場合のマウント
                    secret: デフォルトのマウント
            KV Version 1:
                # CLIパス: secret/config/app
                # APIパス: secret/config/app
                # ポリシーパス: secret/config/app
        シークレット:  #// ターゲットのシークレット。Vault が保護するパスワードなど。アプリケーションなどのパスワード
        ポリシー: #keyword: policy HashiCorp Vault  #// シークレットを入れる場所と同じパスに対してポリシーを割り当てます
            手順:
                設定して、トークンを生成します: #keyword: create policy HashiCorp Vault
                    #↓ 手順
                    コマンドにポリシーを書く場合:
                        #search: vault policy write example
                    ファイルにポリシーを書く場合:
                        ポリシーの定義を書きます: #keyword: __PolicyName__.hcl
                            ____/__PolicyName__.hcl ファイル: |
                                path "secret/data/config/app" {
                                    capabilities = ["read"]
                                }
                            path について:  #search: path HashiCorp Vault
                        vault policy write: |  #// ポリシーを登録します
                            ...     #search: vault CLI environment
                            vault policy write  "__PolicyName__"  ____/__PolicyName__.hcl
                                #// または
                            cat  ____/__PolicyName__.hcl  |  vault policy write  "__PolicyName__"  -  #// 末尾の - は必要です
                        権限を確認します:
                            vault policy read  "__PolicyName__"
                            など
                            #search: vault token capabilities example
                権限を確認します: #keyword: vault token capabilities example
                    #↓ 手順
                    環境変数を設定します:  #search: vault CLI environment
                    KV のバージョンを確認します: | #keyword: HashiCorp Vault KV version
                        vault secrets list -detailed | grep version:
                            version:2
                    vault policy read:  #// ポリシーの内容を表示します
                        （ポリシーを定義する場合）:  #search: create policy HashiCorp Vault
                        コマンド: |
                            vault policy read  "myapp-policy"
                                path "secret/data/config/app" {
                                    capabilities = ["read"]
                                }
                        path について:  #search: path HashiCorp Vault
                            シークレットなら: secret/data/config/app
                            フォルダーなら:   secret/data/config/app/
                    vault token create:  #// 指定したポリシーの権限を持つトークンを生成します
                        vault token create -policy="myapp-policy"
                            token  __PolicyToken__
                        export POLICY_TOKEN=__PolicyToken__
                    vault token capabilities:  #// トークンの権限を確認します
                        コマンド:
                            vault token capabilities  ${POLICY_TOKEN}  secret/data/config/app
                                read
                        path について:  #search: path HashiCorp Vault
                            シークレットなら: secret/data/config/app
                            フォルダーなら:   secret/data/config/app/a
                        他の出力:  #// 指定したパス（secret/data/config/app/）に関する権限を表示します
                            deny: 何も権限はありません
                            read: read 権限があります
                            root: root 権限があります
                    vault kv get:  #// シークレットを取得します
                        コマンド:
                            VAULT_TOKEN=${POLICY_TOKEN}  vault kv get  secret/config/app
                        path について:  #search: path HashiCorp Vault
                            ポリシーの path: secret/data/config/app
                            KV の path:      secret/config/app       #// KV version 2 の場合
                        （必要なら）ダミーのトークンで拒否されることを確認します: |
                            VAULT_TOKEN=bad_token  vault kv get  secret/config/app
                                ...
                                * invalid token
                    vault token revoke:  #// トークンを削除します
                        vault token revoke  ${POLICY_TOKEN}
                参照:  #// ポリシーの内容を表示します
                    CLI:  #search: vault token capabilities
                    Web UI: http://____:8200/ui/vault/policies/acl
            ファイル, 構成:
                書式: |
                    path "kv/data/__Path__" {
                        capabilities = ["__Capability1__", "__Capability2__"]
                    }
                サンプル: |
                    path "kv/data/dev-ci/gitlab-pat" {
                        capabilities = ["read"]
                    }
                パス:  #search: path HashiCorp Vault
                サンプル2:
                    nomad-server-policy: #keyword: nomad-server-policy HashiCorp Vault
                        内容: |  #// ____/nomad-server-policy.hcl
                            path "auth/token/create/nomad-cluster" {
                                capabilities = ["create", "update"]
                            }

                            path "auth/token/roles/nomad-cluster" {
                                capabilities = ["read"]
                            }

                            path "auth/token/lookup-self" {
                                capabilities = ["read"]
                            }

                            path "auth/token/lookup" {
                                capabilities = ["update"]
                            }

                            path "auth/token/revoke-accessor" {
                                capabilities = ["update"]
                            }

                            path "sys/capabilities-self" {
                                capabilities = ["update"]
                            }

                            path "auth/token/renew-self" {
                                capabilities = ["update"]
                            }
                        登録します: |
                            ...     #search: vault CLI environment
                            vault policy write  "nomad-server-policy"  ____/nomad-server-policy.hcl
            duration 形式: #keyword: Vault duration format  #ref: https://developer.hashicorp.com/vault/docs/concepts/duration-format
                サンプル:
                    - 60h   #// 60時間
                    - 1.5h  #// 1.5時間
                    - 50d   #// 50日
                    - 100ms #// 100ミリ秒
                    - 50ns  #// 50ナノ秒
                単位:
                    ns: Nanoseconds
                    us: Microseconds
                    ms: Milliseconds
                    s: Seconds
                    m: Minutes
                    h: Hours
                    d: Days
        ポリシー ロール: #keyword: policy role HashiCorp Vault  #// ポリシーにトークンの TTL などが追加設定されたもの
            vault write auth/token/roles/myapp-policy-role  name="myapp-policy-role"  allowed_policies="myapp-policy" \
                explicit_max_ttl=3600  orphan=true  period=3600  renewable=true
            vault read auth/token/roles/myapp-policy-role
            vault token create -role="myapp-policy-role"
                token  __PolicyToken__
            export POLICY_TOKEN=__PolicyToken__
            vault token revoke  ${POLICY_TOKEN}
        トークン: #keyword: policy token HashiCorp Vault  #// ポリシーに定義した権限を持つトークン
            通常のトークン:
                生成:  #search: create policy HashiCorp Vault
                削除:
                    vault token revoke  __Token__
                        または
                    vault token revoke -accessor  __TokenAccessor__
            Initial Root Token: #keyword:  #ref: https://developer.hashicorp.com/vault/docs/concepts/tokens#root-tokens
                作成:  #search: create HashiCorp Vault root token
                削除:
                    トークンを指定する場合:
                        トークンを削除します:
                            vault token revoke __RootToken__
                        削除されたことを確認します:
                            vault token lookup __RootToken__
                    現在のトークンを指定する場合:
                        vault token revoke -self
                再作成:
                    #// 未確認
                    vault operator generate-root
                        unseal key が必要です
                #↓ 運用, 初期化後
                基本方針:
                    - Initial Root Token は初期セットアップ後に revoke します
                    - 以降の運用は OIDC/LDAP 等の管理者認証により実施します
                人のアカウント:
                    Vault 使い捨て運用: #keyword:  #// 再インストールします
                        - 再インストールすることができるユーザーが権限を持つことになります
                        - 再インストールすると保存しているシークレットは削除されるので、再設定が必要です（小規模なら問題なし）
                        - 実行は手動ではなく、スクリプトを使うほうが確実です
                        - /var/lib/vault を直接見に行ける を許す限り、Vault は暗号化ファイルと同様な暗号強度ですが、
                            鍵管理と攻撃面の設計により、条件次第で「暗号ファイルより破りにくい状態」を作れる。
                            ただし OS 権限侵害を許す脅威モデルでは両者は実質同等となる。
                    userpass:  #// ユーザーとパスワード
                    OIDC/LDAP:  #// 認証サーバーを使う場合
                    （方針の比較）:
                        初期は Vault 使い捨て運用でも十分であるし、最も安全です（穴が少ない）。
                        userpass は手軽ですが、次が弱点です。
                            パスワード管理が増える（ローテ/失効・漏えい対応）
                            MFA が絡めにくい（別の仕組みが必要）
                            監査はできるが、IdP 連携より運用が重い
                        なので、方針としては
                            まず userpass でスタート
                            余裕ができたら **OIDC/JWT（特にGitLab CI）**へ寄せる
                        が現実的です。
                機械アカウント:
        アクセサー, token accessor: #keyword: token accessor HashiCorp Vault  #// トークンを識別する値。 トークンを使った処理をするための権限はありません
            概要:
                - トークンに 1対1 に対応した識別子です
                - 生成したときにメモしたメモから token を特定します
            表示: | #keyword: lookup token accessor HashiCorp Vault
                vault token lookup -accessor  __TokenAccessor__
                    policies            [default __PolicyName__]
                    issue_time          2025-09-10T19:50:02.726703737+09:00
                    expire_time         2025-10-12T19:50:02.726698937+09:00
                    ...
                vault token lookup  __Token__
                    accessor            __TokenAccessor__
                    policies            [default __PolicyName__]
                    ...
        JSON フィールド, -field オプション: #keyword: -field HashiCorp Vault
            #// vault read コマンド などの出力 JSON の中の特定のフィールドを指定します
            サンプル:
                -field オプション が無いとき: |
                    {
                        "request_id": "...",
                        "data": {
                            "secret_id": "c4c5e3b2-....",
                            "secret_id_accessor": "b0a3..."
                        }
                    }
                -field=secret_id オプション があるとき:
                    c4c5e3b2-....
        シークレット エンジン: #keyword: secret engine HashiCorp Vault
            #↓ 手順
            選択します:  #search: -mount HashiCorp Vault
            #↓ 種類
            secret, kv, kv-v2:  #// デフォルトのマウント名は secret。Key-Value (KV) 。静的なキー・バリューペアを保存
                version:2: #keyword: key value version 2 HashiCorp Vault  #// Key-Value (KV) version 2。静的なキー・バリューペアを保存、バージョン管理機能付き
                    key value v2 を使う設定になっていることを確認します:
                        vault secrets list -detailed  |  grep version
                            ...  version:2
                    マウント名: #keyword: mount HashiCorp Vault
                        secret が多い。 vault kv put など各種コマンドのデフォルト
                    マウントします:  #// 有効化します
                        -   vault secrets enable  -path="secret"  kv-v2  #// kv-v2 シークレット エンジン を secret（各種コマンドのデフォルト）にマウントします
                        -   vault secrets enable  -path="__MountName__"  kv-v2
                        -   vault secrets enable  "kv-v2"           #// kv-v2 シークレット エンジン を kv-v2 にマウントします
                        -   vault secrets enable  -version 2  "kv"  #// kv-v2 シークレット エンジン を kv にマウントします
                    アンマウントします:  #// 無効化します
                        -   vault secrets disable  "__MountName__"
                    サンプル:
                        #search: install HashiCorp Vault
                        #search: install Nomad Vault
                version:1:  #// Key-Value (KV) version 1。静的なキー・バリューペアを保存
                    マウント名: secret
                サンプル:  #search: -mount HashiCorp Vault
            その他:
                Database - データベースの動的な認証情報を生成
                AWS - AWS IAMの一時的な認証情報を生成
                Azure - Azureの動的な認証情報を生成
                PKI - X.509証明書の発行・管理
                SSH - SSH鍵の動的生成
                Transit - 暗号化・復号化サービス
                LDAP - LDAP認証
                Kubernetes - Kubernetesサービスアカウントトークン生成
                Consul - Consulトークン生成
    ファイル:  #glossary:
        /etc/vault.d/vault.hcl, /etc/openbao.d/openbao.hcl:
            #search: /etc/vault.d/vault.hcl
        ~/.vault-token:  #search: Vault log in
    トラブルシューティング: #keyword: HashiCorp Vault trouble
        権限があるか確認します:  #search: vault token capabilities example
        エラー, x509 certificate signed by unknown authority:
            手順:
                sudo vault operator init
                    または
                sudo bao operator init
            エラー: |
                Get "https://127.0.0.1:8200/v1/sys/seal-status": tls: failed to verify certificate: x509: certificate signed by unknown authority
            対処A:
                export VAULT_CACERT="/etc/openbao.d/tls/tls.crt"
                #search: VAULT_CACERT
            対処B:
                開発環境なら
                sudo BAO_SKIP_VERIFY=1  vault operator init
        エラー, no handler for route "auth/jwt-nomad/config". route entry not found.:
            手順: vault write "auth/jwt-nomad/config"  @__FilePath__
            ログ: |
                Error writing data to auth/jwt-nomad/config: Error making API request.
                    URL: PUT http://127.0.0.1:8200/v1/auth/jwt-nomad/config
                    Code: 404. Errors:
                * no handler for route "auth/jwt-nomad/config". route entry not found.
            対処:
                vault auth enable -path=jwt-nomad jwt
        エラー, VAULT_ADDR WARNING: #keyword: VAULT_ADDR
            手順: vault コマンド
            ログ: |
                WARNING! VAULT_ADDR and -address unset. Defaulting to https://127.0.0.1:8200.
            対処:
                export VAULT_ADDR="http://127.0.0.1:8200"
        エラー, Error checking seal status:
            手順: vault status
            ログ: |
                Error checking seal status: Get "http://127.0.0.1:8200/v1/sys/seal-status": dial tcp 127.0.0.1:8200: connect: connection refused
                Error checking seal status: Get "http://localhost:8200/v1/sys/seal-status": dial tcp 127.0.0.1:8200: connect: connection refused
            対処:
                vault サービスを起動します:
                    sudo systemctl start  vault
            #// ログにある unseal は関係ありません。最初にアクセスする API のようです  #search: Vault unseal
        エラー, Error unsealing:
            手順: vault operator unseal  ____
            ログ: |
                Error unsealing: Put "http://127.0.0.1:8200/v1/sys/unseal": dial tcp 127.0.0.1:8200: connect: connection refused
            対処:
                vault サービスを起動します:
                    sudo systemctl start  vault
        エラー, Vault is sealed: #keyword:
            手順: |
                vault secrets list -detailed | grep version:
            ログ: |
                Error listing secrets engines: Error making API request.
                    URL: GET http://172.17.0.1:8200/v1/sys/mounts
                    Code: 503. Errors:
                * Vault is sealed
            対処:
                #search: vault operator unseal
Envoy: #keyword:
    機能:
        通信制御: 通信を制御し、サービス間の通信の暗号化、認証、認可、トラフィックのルーティング、負荷分散、レート制限など
        監視: メトリクス、ログ、トレースを生成し、システムの動作状況を可視化
        移植性: Kubernetes、Nomad、Consul など、様々なプラットフォームと統合できます
Consul: #keyword:  #// サーバ上でサービスが正常に動作していことを管理します
    読み:
        コンスルと聞こえます（公式動画より）
            https://learn.hashicorp.com/tutorials/consul/get-started-install?in=consul/getting-started
        コンサルと読みます（LAC社より）
            https://www.lac.co.jp/solution_product/consul.html
    公式:
        https://www.consul.io/
        https://github.com/hashicorp/docker-consul
        https://hub.docker.com/_/consul
        https://learn.hashicorp.com/consul
        https://www.hashicorp.com/products/consul
    概要:
        概要: サーバ上でサービス（アプリケーション）が正常に動作していことを管理します。
            どの Nomad Client にコンテナアプリケーションが配置されたかという情報。
            現在の状態しか保持しません。状況変化時に人間を介さず機械的に処理を行えます。
        RPC 機能:
            図: データセンター, サーバー, クライアント, エージェント  #ref: ${my_images}/2021/consul-arch.png
            データセンター: 別のデータセンターに通信するときは、インターネットを経由します
            サーバー: たとえば 3～5台。サーバーはすべて、1 つの Raft ピア セットの一部です。単一のリーダーを選出
            クライアント: キャッシュを持っています。サーバーが一時的に使用できなくなったりしても、
                サービス検出やキャッシュからの接続認証などの一部のクエリに応答できます
            エージェント: ゴシップ プロトコル でやり取りしています。
                サーバーのアドレスを使用してクライアントを構成する必要はありません。
                検出や障害検出は自動的に行われます。
            公式: https://www.consul.io/docs/architecture
        サービス ディスカバリ 機能: IP アドレスを検出します
        ヘルスチェック: ヘルスチェックの結果も表示します
    手順, サンプル:  #keyword: install Consul
        はじめての HashiCorp Consul - classmethod:  #ref: https://dev.classmethod.jp/articles/hashicorp-consul-getting-started-001/
            Docker for Linux の VM を作ります:  #search: Docker for Linux
            Consul の Docker イメージをダウンロードします:
                (@node1) docker pull consul
            Consul のコンテナーが動くことを確認します:
                コンテナーを起動してログインします:
                    (@node1) docker run --rm -it consul  sh  #// bash は使えません
                Consul のバージョンを表示します:
                    (@consul) consul version
                コンテナーからログアウトします:
                    (@consul) exit
            Consul エージェントを起動します >> 共有フォルダーなし:  #keyword: start Consul agent dev example
                新しい bash:
                    (@node1) docker run --rm  --name consul_1  consul agent -node=consul_1 -dev
                        #// -node は Consul サーバーに付けるノード名
                        #// -dev は開発モード
                起動するまで少し待ちます:
                    #// 数行上に [INFO]  agent: Synced node info と表示されるまで待ちます。すぐ表示されます。
                後でエージェントを終了するとき:
                    Ctrl + C キー
            ノードを一覧します:  #keyword: list Consul nodes example
                Consul のコンテナー(@consul_1)にログインします:  #keyword: Consul docker log in
                    新しい bash:
                        - (@node1) docker exec -it consul_1  sh  #// これで起動するシェルを (@consul_1) とします
                            #// エージェントが起動されていないときは、 #search: start Consul agent
                        - (@consul_1)  PS1='\n[\u@\h(consul_1) \W]\$ '  #// プロンプトを見やすくします
                    後でログアウトするとき:
                        (@consul_1) exit
                HTTP API でノードを一覧する場合:  #// 強整合性
                    コマンド: (@consul_1) curl localhost:8500/v1/catalog/nodes
                    出力例: |
                        [
                            {
                                "ID": "06c3a455-89f3-fe42-569b-8784803deb25",
                                "Node": "a62d35d1a61f",
                                "Address": "127.0.0.1",
                                "Datacenter": "dc1",
                                "TaggedAddresses": {
                                    "lan": "127.0.0.1",
                                    "lan_ipv4": "127.0.0.1",
                                    "wan": "127.0.0.1",
                                    "wan_ipv4": "127.0.0.1"
                                },
                                "Meta": {
                                    "consul-network-segment": ""
                                },
                                "CreateIndex": 11,
                                "ModifyIndex": 13
                            }
                        ]
                ゴシップ プロトコル でノードを一覧する場合:  #// 結果整合性  #search: ゴシップ プロトコル
                    コマンド: (@consul_1) consul members
                    出力例: |
                        Node          Address         Status  Type    Build   Protocol  DC   Segment
                        a62d35d1a61f  127.0.0.1:8301  alive   server  1.10.1  2         dc1  <all>
            ノードの IP アドレスを確認します:  #keyword: Consul DNS example
                Consul のコンテナー(@consul_1)にログインします:  #search: Consul docker log in
                dig と jq をインストールします:  #keyword: install BIND in Consul
                    Docker ホストOSが プロキシが無い LAN にいる場合:
                        (@consul_1) apk add  bind-tools  jq
                    Docker ホストOSが プロキシが有る LAN にいる場合:
                        (@consul_1) HTTPS_PROXY=http://___.___.___.___:____  apk add  bind-tools  jq
                最初のノードの ID を NODE 環境変数に代入します:
                    (@consul_1) NODE=$(curl -s localhost:8500/v1/catalog/nodes | jq -r '.[].Node')
                DNS に IP アドレスを問い合わせます:
                    コマンド: (@consul_1) dig +short @127.0.0.1 -p 8600  ${NODE}.node.consul
                    出力例: 127.0.0.1
            Consul エージェントを起動します >> サービス情報あり:  #keyword: start Consul example
                ゲストOSと共有するフォルダーをホストOSに作ります:
                    (@node1) mkdir -p ~/consul_config
                web.json >> サービスの情報が書かれた設定ファイルを作ります:  #// ファイル名はおそらく *.json なら何でもよい
                    (@node1) ~/consul_config/web.json : |
                        {
                            "service": {
                                "name": "web",
                                "tags": ["rails"],
                                "port": 80 }}
                    補足:
                        作られるサービスの FQDN:port: __TagName__.__ServiceName__.service.consul:__PortNum__
                        name: サービス名。 サービスの FQDN の一部になります（上記）
                        tag: タグ名。サービスの FQDN の一部になります（上記）
                Consul コンテナーが起動していたら終了します:  #search: docker rm
                Consul を起動します >> 共有フォルダーあり:  #keyword: start Consul server
                    新しい bash:
                        (@node1) docker run --rm --name consul_1 -v ~/consul_config/:/consul/config  consul -node=consul_1 -dev
                            #// -node は Consul サーバーに付けるノード名
                            #// -dev は開発モード
                            #// (@consul_1) /consul/config/web.json をリードします
                    後でエージェントを終了するとき:
                        Ctrl + C キー
            サービスの情報を表示します:  #keyword: show Consul service example
                Consul のコンテナー(@consul_1)にログインします:  #search: Consul docker log in
                HTTP API で問い合わせる場合:
                    ヘルスチェックに失敗したサーバーも含む場合:
                        公式:  #// List Nodes for Service  https://www.consul.io/api/catalog#list-nodes-for-service
                        書式:     (@consul_1) curl http://localhost:8500/v1/catalog/service/__ServiceName__
                        サンプル: (@consul_1) curl http://localhost:8500/v1/catalog/service/web
                        出力例: |
                            [
                                {
                                    "ID": "0954a6e4-c9e1-22f7-3e02-d4f4556d0574",
                                    "Node": "ce3cbf7a181c",
                                    "Address": "127.0.0.1",
                                    "Datacenter": "dc1",
                                    "TaggedAddresses": {
                                        "lan": "127.0.0.1",
                                        "lan_ipv4": "127.0.0.1",
                                        "wan": "127.0.0.1",
                                        "wan_ipv4": "127.0.0.1"
                                    },
                                    "NodeMeta": {
                                        "consul-network-segment": ""
                                    },
                                    "ServiceKind": "",
                                    "ServiceID": "web",
                                    "ServiceName": "web",
                                    "ServiceTags": [
                                        "rails"
                                    ],
                                    "ServiceAddress": "",
                                    "ServiceWeights": {
                                        "Passing": 1,
                                        "Warning": 1
                                    },
                                    "ServiceMeta": {},
                                    "ServicePort": 80,
                                    "ServiceSocketPath": "",
                                    "ServiceEnableTagOverride": false,
                                    "ServiceProxy": {
                                        "Mode": "",
                                        "MeshGateway": {},
                                        "Expose": {}
                                    },
                                    "ServiceConnect": {},
                                    "CreateIndex": 14,
                                    "ModifyIndex": 14
                                }
                            ]
                    ヘルスチェックに失敗したサーバーを含まない場合:
                        公式:  #// List Service Instances for Service  https://www.consul.io/api/health#list-nodes-for-service
                        書式:     (@consul_1) curl http://localhost:8500/v1/health/service/__ServiceName__?passing
                        サンプル: (@consul_1) curl http://localhost:8500/v1/health/service/web?passing
                DNS に問い合わせる場合:
                    dig と jq をインストールします:  #search: install BIND in Consul
                    DNS の SRV レコードを問い合わせます:
                        コマンド: (@consul_1) dig +short @127.0.0.1 -p 8600  web.service.consul SRV
                        出力例: 1 1 80 ce3cbf7a181c.node.dc1.consul.
            サービスの情報を更新します:  #keyword: update Consul service example
                demo タグがないことを確認します:
                    (@consul_1) curl -s http://localhost:8500/v1/catalog/service/web | grep demo  #// 何も出力されません
                設定ファイルを編集します:
                    demo タグを追加します:
                        ~/consul_config/web.json : |
                            {
                                "service": {
                                    "name": "web",
                                    "tags": ["rails","demo"],
                                    "port": 80 }}
                Consul エージェントを再起動します:  #keyword: restart Consul example
                    (@consul_1) kill -HUP $(pgrep -f "consul agent")
                        #search: Linux kill SIGHUP
                demo タグがあることを確認します:
                    (@consul_1) curl -s http://localhost:8500/v1/catalog/service/web | grep demo  #// "demo" が出力されます
        KV Store >> 公式 CLI Quick Start >> Store Data in Consul KV: #keyword: Consul KV example  #ref: https://learn.hashicorp.com/tutorials/consul/get-started-key-value-store
            Docker for Linux の VM を作ります:  #search: Docker for Linux
            Consul の Docker イメージをダウンロードします:
                (@node1) docker pull consul
            Consul エージェントを起動します >> 共有フォルダーなし:  #search: start Consul agent dev example
            KV CLI を使う場合:  #keyword: Consul CLI KV
                Consul のコンテナー(@consul_1)にログインします:  #search: Consul docker log in
                基本, PUT, GET, 別のキー:
                    PUT minconns: (@consul_1) consul kv put  redis/config/minconns 1
                    GET minconns: (@consul_1) consul kv get  redis/config/minconns  #// 1 と表示されます
                    PUT maxconns: (@consul_1) consul kv put  redis/config/maxconns 20
                    GET maxconns: (@consul_1) consul kv get  redis/config/maxconns  #// 20 と表示されます
                上書きと ModifyIndex:
                    前提条件を設定します:
                        PUT: (@consul_1) consul kv put  redis/config/maxconns 22  #// 上書きできます
                        GET: (@consul_1) consul kv get  redis/config/maxconns  #// 22 と表示されます
                    上書きします:
                        PUT: (@consul_1) consul kv put  redis/config/maxconns 25  #// 上書きできます
                        GET: (@consul_1) consul kv get  redis/config/maxconns  #// 25 と表示されます
                    Check-And-Set (CAS) で上書きします:  #// CAS は楽観的並行性制御に使います  #search: 楽観的並行性制御
                        前提条件を設定して確認します:
                            PUT: (@consul_1) consul kv put  redis/config/maxconns 25
                            GET -detailed オプション (0): (@consul_1) consul kv get -detailed  redis/config/maxconns
                            出力: |
                                CreateIndex      40
                                Flags            0  🌟
                                Key              redis/config/maxconns
                                LockIndex        0
                                ModifyIndex      121
                                Session          -
                                Value            25
                        PUT >> 小さい ModifyIndex: (@consul_1) consul kv put -cas -modify-index=120  redis/config/maxconns 29
                            #// Error! Did not write to redis/config/maxconns: CAS failed と表示され、上書きしません
                        GET: (@consul_1) consul kv get  redis/config/maxconns  #// 25 と表示されます
                        リトライ PUT >> 同じ ModifyIndex: (@consul_1) consul kv put -cas -modify-index=121  redis/config/maxconns 29
                            #// 上書きに成功します
                        GET (2): (@consul_1) consul kv get  redis/config/maxconns  #// 29 と表示されます
                    同じ値で上書きします:
                        前提条件を設定して確認します:
                            PUT: (@consul_1) consul kv put  redis/config/maxconns 29
                            GET -detailed オプション: (@consul_1) consul kv get -detailed  redis/config/maxconns  |  grep ModifyIndex
                                #// ModifyIndex  121  と表示されたとします
                        PUT: (@consul_1) consul kv put  redis/config/maxconns 29  #// 上書きできます
                        GET -detailed オプション: (@consul_1) consul kv get -detailed  redis/config/maxconns  |  grep ModifyIndex
                            #// ModifyIndex  121  と表示されます。同じ値を設定したときは増えません
                一覧:
                    コマンド: consul kv get -recurse
                    出力: |
                        redis/config/maxconns:25
                        redis/config/minconns:1
                        redis/config/users/admin:abcd1234
                削除:
                    DELETE: (@consul_1) consul kv delete redis/config/minconns  #// key-value を削除します
                    DELETE -recurse オプション: (@consul_1) consul kv delete -recurse  redis/config/
                        #// 前方一致するすべてのキーを削除します
                        #// コマンドに指定するキー: redis/config/
                        #//     対象:   redis/config/minconns
                        #//     対象:   redis/config/maxconns
                        #//     対象外: redis/config/users/admin
                        #// コマンドに指定するキー: redis/config/max
                        #//     対象外: redis/config/minconns
                        #//     対象:   redis/config/maxconns
                        #//     対象外: redis/config/users/admin
                --flags オプション:  #// 64ビット整数
                    PUT: consul kv put -flags=42  redis/config/users/admin abcd1234
                    GET: consul kv get  redis/config/users/admin  #// abcd1234 と表示されます
                    GET -detailed オプション:  #// -flags に指定した値などを表示します
                        コマンド: consul kv get -detailed  redis/config/users/admin
                        出力: |
                            CreateIndex      40
                            Flags            42  🌟
                            Key              redis/config/users/admin
                            LockIndex        0
                            ModifyIndex      40
                            Session          -
                            Value            abcd1234
            HTTP API を使う場合:  #keyword: Consul KV API
                公式: https://www.consul.io/api/kv
                PUT: (@consul_1) curl -X PUT http://localhost:8500/v1/kv/redis/config/minconns  -d 1  #// true と表示されます
                GET: (@consul_1) curl -X GET http://localhost:8500/v1/kv/redis/config/minconns?raw  #// 1 と表示されます
                一覧:
                    - (@consul_1) curl "http://localhost:8500/v1/kv/?recurse&pretty"
                    - (@consul_1) curl "http://localhost:8500/v1/kv/____?recurse&pretty"
                DELETE:
                    キー:       (@consul_1) curl -X DELETE http://localhost:8500/v1/kv/redis/config/minconns  #// true と表示されます
                    フォルダー: (@consul_1) curl -X DELETE http://localhost:8500/v1/kv/redis?recurse  #// recurse を指定します
                Check-And-Set (CAS) で上書きします:  #// ?cas パラメーター  #// CAS は楽観的並行性制御に使います  #search: 楽観的並行性制御
                    前提条件を設定して確認します:
                        PUT: (@consul_1) curl -X PUT http://localhost:8500/v1/kv/redis/config/maxconns  -d 25
                        GET 詳細: (@consul_1) curl -X GET http://localhost:8500/v1/kv/redis/config/maxconns
                        出力: |
                            [
                                {
                                    "LockIndex": 0,
                                    "Key": "redis/config/maxconns",
                                    "Flags": 0,
                                    "Value": "MjU=",
                                    "CreateIndex": 40,
                                    "ModifyIndex": 121
                                }
                            ]
                    PUT >> 小さい ModifyIndex:
                         (@consul_1) curl -X PUT http://localhost:8500/v1/kv/redis/config/maxconns?cas=120  -d 29
                        #// false と表示され、上書きしません
                    GET: (@consul_1) curl -X GET http://localhost:8500/v1/kv/redis/config/maxconns?raw  &&  echo ""
                        #// 25 と表示されます
                    リトライ PUT >> 同じ ModifyIndex: (@consul_1) curl -X PUT http://localhost:8500/v1/kv/redis/config/maxconns?cas=121  -d 29
                        #// true と表示され、上書きに成功します
                    GET (2): (@consul_1) curl -X GET http://localhost:8500/v1/kv/redis/config/maxconns?raw  &&  echo ""  #// 29 と表示されます
                参考: https://www.consul.io/api/kv#create-update-key
            Web UI を使う場合:  #// 未調査
        セッションの CRUD: #keyword: Consul session example  #ref: https://www.consul.io/api-docs/session
            Docker for Linux の VM を作ります:  #search: Docker for Linux
            Consul の Docker イメージをダウンロードします:
                (@node1) docker pull consul
            Consul エージェントを起動します >> 共有フォルダーなし:  #search: start Consul agent dev example
            Consul のコンテナー(@consul_1)にログインします:  #search: Consul docker log in
            セッションを新規作成します: #// そのままでも動きますが、必要に応じて JSON 部分を編集してください
                コマンド: |
                    curl -X PUT http://localhost:8500/v1/session/create  -H "Content-Type:application/json" -d '{
                        "LockDelay": "15s",
                        "Name": "session_1",
                        "Node": "consul_1",
                        "Behavior": "release",
                        "TTL": "60s"
                    }'
                出力例: |
                    {
                        "ID": "6a99821e-58a5-edec-35ca-e83b10483970"
                    }
                説明:
                    TTL: デフォルトは ""。自動的に破棄されません
                #// 簡易設定: #search: Consul simple create session
            セッションを一覧します:
                curl -X GET http://localhost:8500/v1/session/list
            セッションの情報を表示します:
                書式:     curl -X GET http://localhost:8500/v1/session/node/__ConsulNodeName__
                サンプル: curl -X GET http://localhost:8500/v1/session/node/consul_1
            セッションを更新します:  #// TTL の有効期限が延長されます
                curl -X PUT http://localhost:8500/v1/session/renew/__SessionID__
                    #// __SessionID__ にセッション名は指定できません
            セッションを削除します:
                curl -X PUT http://localhost:8500/v1/session/destroy/__SessionID__
                #// 成功したら true と表示されます。すでに存在しないときも true と表示されます
        dashboard:  #search: Consul dashboard
    機能:
        ヘルスチェック:
            #ref: https://stackoverflow.com/questions/58274182/how-to-set-consul-alias-service
        KV, Key-Value Store:  #// Key-Value ストア
            概要: 単純な KV ストアであり、フル機能のデータストア (DynamoDB など) を意図したものではありません
            サンプル:  #search: Consul CLI KV
            参考:
                公式: https://www.consul.io/docs/dynamic-app-config/kv
                CLI: https://www.consul.io/commands/kv
                HTTP:
                    https://www.consul.io/api/kv
                    https://www.consul.io/api-docs/kv
        ロック:  #keyword: Consul lock
            相互排除またはリーダー選挙のみが必要な場合: https://learn.hashicorp.com/tutorials/consul/application-leader-elections
            API: #search: Consul lock API example
            コマンド:  #ref: https://www.consul.io/commands/lock
                サンプル:
                    キーを一覧します:
                        curl -X GET "http://localhost:8500/v1/kv/?recurse&pretty"
                    キーを表示します:
                        curl -X GET "http://localhost:8500/v1/kv/example.lock?pretty"
                    セッションを生成します: |
                        curl -X PUT "http://localhost:8500/v1/session/create" -d '{"Name":"client_1_session"}'
                    出力された __SessionID_1__ をメモします:
                        751903af-f949-79ff-fd17-455dc0a2ebaf
                    ロックします:
                        curl -X PUT "http://localhost:8500/v1/kv/example.lock?acquire=751903af-f949-79ff-fd17-455dc0a2ebaf" -d client_1_session
                    ロック解除します:
                        curl -X PUT "http://localhost:8500/v1/kv/example.lock?release=751903af-f949-79ff-fd17-455dc0a2ebaf"
                    ロックを削除します:
                        curl -X DELETE http://localhost:8500/v1/kv/example.lock
                    セッションを削除します:
                        curl -X PUT "http://localhost:8500/v1/session/destroy/751903af-f949-79ff-fd17-455dc0a2ebaf"
                詳細サンプル:
                    #search: Consul lock example
                詳細:
                    ロックホルダーの数が複数の場合は、性能が悪いセマフォが使用されます。
                    ロック中は子プロセスが存在します  https://www.consul.io/commands/lock
        ロック, 分散セマフォー:  #keyword: Consul lock example
            HTTP API を使う場合:  #keyword: Consul lock API example
                注意: 片方のクライアントで consul lock コマンドを使った共存をすることはできません
                    client_1 から再度ロックします(2) で Existing key does not match lock use エラーになります
                設定: #settings:
                    __Prefix__: service/foo/lock
                    __SessionID_1__: 6a905190-83f4-ff9f-b1a0-5653d64b089d  #// 下記手順の中で決まります
                    __SessionID_2__: 735f9df9-d46e-fab0-25aa-372b5b1ea928  #// 下記手順の中で決まります
                Docker for Linux の VM を作ります:  #search: Docker for Linux
                Consul サーバーを起動します:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker run -it --rm  --name consul_server  -p 8500:8500  \
                            consul agent  -server  -bootstrap  -data-dir /tmp  -client=0.0.0.0  -ui  -node=server
                            #// -node オプションにノードに付けたい名前を指定します
                            #// -bootstrap オプションは修復も行います
                    出力例: |
                        ==> Starting Consul agent...
                                 Version: '1.10.1'
                                 Node ID: 'e96d504f-3323-5b6c-d4e7-321e4e44aed2'
                               Node name: 'be16a29b261c'
                              Datacenter: 'dc1' (Segment: '<all>')
                                  Server: true (Bootstrap: false)
                             Client Addr: [0.0.0.0] (HTTP: 8500, HTTPS: -1, gRPC: -1, DNS: 8600)
                            Cluster Addr: 172.17.0.2 (LAN: 8301, WAN: 8302)
                                 Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false
                        （中略）
                        [INFO]  agent: Synced node info
                Consul クライアントを起動します:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker run -it --rm  --name consul_client_1  \
                            consul agent  -join 172.17.0.2  -data-dir /tmp  -node=client_1
                            #// -join には Consul サーバー(@consul_server) の IP アドレスを指定します
                    出力例: |
                        ==> Starting Consul agent...
                                   Version: '1.10.1'
                                   Node ID: '110c7662-3f1e-99c9-3ae9-e314bb47d779'
                                 Node name: '4845dff60762'
                                Datacenter: 'dc1' (Segment: '')
                                    Server: false (Bootstrap: false)
                               Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: -1, DNS: 8600)
                              Cluster Addr: 172.17.0.3 (LAN: 8301, WAN: 8302)
                                   Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false
                        （中略）
                        [INFO]  agent: Synced node info
                クラスターのメンバーを確認します:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker exec -it  consul_server  sh
                        - (@consul_server)  PS1='\n[\u@\h(consul_server) \W]\$ '  #// プロンプトを見やすくします
                        - (@consul_server)  consul members
                    出力例: |
                        Node          Address          Status  Type    Build   Protocol  DC   Segment
                        be16a29b261c  172.17.0.2:8301  alive   server  1.10.1  2         dc1  <all>
                        4845dff60762  172.17.0.3:8301  alive   client  1.10.1  2         dc1  <default>
                Consul Web UI を開きます:
                    VM のホスト（通常 Windows）のブラウザーで VM のポート 8500 を開きます:
                        http://192.168.33.51:8500
                    開けないとき:
                        Consul エージェントの client オプションが正しいことと、-ui オプションがあること:
                            consul agent ____ -client=0.0.0.0  -ui
                        Docker のポートフォワーディングのオプションがあること:
                            -p 8500:8500
                        参考:  #search: network trouble shooting
                排他制御を試します:
                    client_1 で使うセッションを生成します:
                        client_1 にログインします: |
                            #// 新しいシェル
                            - (@node1)  docker exec -it  consul_client_1  sh
                            - (@consul_client_1)  PS1='\n[\u@\h(consul_client_1) \W]\$ '  #// プロンプトを見やすくします
                        セッションを生成します: |
                            - (@consul_client_1)  curl -X PUT http://localhost:8500/v1/session/create -d '{"Name":"client_1_session"}'
                        出力された __SessionID_1__ をメモします:
                            6a905190-83f4-ff9f-b1a0-5653d64b089d  #template: __SessionID_1__
                    client_1 からロックします:
                        コマンド:
                            - (@consul_client_1)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?acquire=6a905190-83f4-ff9f-b1a0-5653d64b089d -d client_1_session
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?acquire=__SessionID_1__ -d client_1_session
                        出力: true
                        説明:
                            -d オプション(body): 例： ノード名。・ロックするノードに対するロール名 など
                                この内容によってConsul の動作が変わることはありません。
                        作成したロックの内容を表示します:
                            Web UI の場合:
                                メニュー: http://192.168.33.51:8500 >> Key/Value >> service >> foo >> lock >> .lock
                                Node: client_1
                            CLI の場合:
                                コマンド:
                                    (@consul_1)  curl -X GET http://localhost:8500/v1/kv/service/foo/lock/.lock?pretty
                                        #template: curl -X GET http://localhost:8500/v1/kv/__Prefix__/.lock?pretty
                                出力例: |
                                    [
                                        {
                                            "LockIndex": 1,
                                            "Key": "service/foo/lock/.lock",
                                            "Flags": 0,
                                            "Value": "",
                                            "Session": "6a905190-83f4-ff9f-b1a0-5653d64b089d",
                                            "CreateIndex": 666,
                                            "ModifyIndex": 666
                                        }
                                    ]

                                        #template-at(-6): "Session": "__SessionID_1__"
                                説明:
                                    Session は、ロック状態のときに存在します。値はセッションIDです
                    client_2 で使うセッションを生成します:
                        client_2 の Consul クライアントを起動します:
                            #// 新しいシェル
                            - (@node1)  docker run -it --rm  --name consul_client_2  \
                                consul agent  -join 172.17.0.2  -data-dir /tmp  -node=client_2
                                #// -join には Consul サーバー(@consul_server) の IP アドレスを指定します
                        client_2 にログインします: |
                            #// 新しいシェル
                            - (@node1)  docker exec -it  consul_client_2  sh
                            - (@consul_client_2)  PS1='\n[\u@\h(consul_client_2) \W]\$ '  #// プロンプトを見やすくします
                        セッションを生成します: |
                            - (@consul_client_2)  curl -X PUT http://localhost:8500/v1/session/create -d '{"Name":"client_2_session"}'
                        出力された __SessionID_2__ をメモします:
                            735f9df9-d46e-fab0-25aa-372b5b1ea928  #template: __SessionID_2__
                    client_2 からロックします:
                        コマンド:
                            - (@consul_client_2)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?acquire=735f9df9-d46e-fab0-25aa-372b5b1ea928 -d client_2_session
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?acquire=__SessionID_2__ -d client_2_session
                        出力: false  #// すでにロックされているため
                    client_1 からロック解除します:
                        コマンド:
                            - (@consul_client_1)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?release=6a905190-83f4-ff9f-b1a0-5653d64b089d
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?release=__SessionID_1__
                        出力: true
                    client_2 から再度ロックします:
                        コマンド:
                            - (@consul_client_2)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?acquire=735f9df9-d46e-fab0-25aa-372b5b1ea928 -d client_2_session
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?acquire=__SessionID_2__ -d client_2_session
                        出力: true
                    client_1 から再度ロックします:
                        コマンド:
                            - (@consul_client_1)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?acquire=6a905190-83f4-ff9f-b1a0-5653d64b089d -d client_1_session
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?acquire=__SessionID_1__ -d client_1_session
                        出力: false  #// すでにロックされているため
                    client_2 からロック解除します:
                        コマンド:
                            - (@consul_client_2)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?release=735f9df9-d46e-fab0-25aa-372b5b1ea928
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?release=__SessionID_2__
                        出力: true
                    client_1 から再度ロックします(2):
                        コマンド:
                            - (@consul_client_1)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?acquire=6a905190-83f4-ff9f-b1a0-5653d64b089d -d client_1_session
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?acquire=__SessionID_1__ -d client_1_session
                        出力: true
                    client_1 からロック解除します(2):
                        コマンド:
                            - (@consul_client_1)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?release=6a905190-83f4-ff9f-b1a0-5653d64b089d
                                #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?release=__SessionID_1__
                        出力: true
                セッションが無効になったときの動作を確認します:
                    セッションが無効になったときに削除するセッションを生成します:
                        client_1 にログインします: |
                            #// 新しいシェル
                            - (@node1)  docker exec -it  consul_client_1  sh
                            - (@consul_client_1)  PS1='\n[\u@\h(consul_client_1) \W]\$ '  #// プロンプトを見やすくします
                        セッションを生成します: |
                            - (@consul_client_1)  curl -X PUT http://localhost:8500/v1/session/create -d '{"Name":"client_1_session", "Behavior":"delete"}'
                        出力された __SessionID_1__ をメモします:
                            6a905190-83f4-ff9f-b1a0-5653d64b089d  #template: __SessionID_1__
                    client_1 からロックします:
                        (@consul_client_1)  curl -X PUT http://localhost:8500/v1/kv/service/foo/lock/.lock?acquire=6a905190-83f4-ff9f-b1a0-5653d64b089d -d client_1_session
                            #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/.lock?acquire=__SessionID_1__ -d client_1_session
                    ロックを一覧します:
                        KV store を一覧します:
                            (@consul_client_1)  curl http://localhost:8500/v1/kv/service/foo/lock?recurse\&pretty
                    セッションを削除します:
                        (@consul_client_1)  curl -X PUT http://localhost:8500/v1/session/destroy/6a905190-83f4-ff9f-b1a0-5653d64b089d
                            #template: curl -X PUT http://localhost:8500/v1/session/destroy/__SessionID_1__
                    ロックを一覧します(2):
                        (@consul_client_1)  curl http://localhost:8500/v1/kv/service/foo/lock?recurse\&pretty
                            #// 削除されていることを確認します
                クリーン:
                    client_1 で使ったセッションを削除します:
                        curl -X PUT http://localhost:8500/v1/session/destroy/6a905190-83f4-ff9f-b1a0-5653d64b089d
                            #template: curl -X PUT http://localhost:8500/v1/session/destroy/__SessionID_1__
                    client_2 で使ったセッションを削除します:
                        curl -X PUT http://localhost:8500/v1/session/destroy/735f9df9-d46e-fab0-25aa-372b5b1ea928
                            #template: curl -X PUT http://localhost:8500/v1/session/destroy/__SessionID_2__
                    ロックを削除します:
                        curl -X DELETE http://localhost:8500/v1/kv/service/foo/lock/.lock
                            #template: curl -X DELETE http://localhost:8500/v1/kv/__Prefix__/.lock
            Consul lock コマンドを使う場合:  #// log.fstn  https://fstn.hateblo.jp/entry/2015/02/21/024400  #keyword: Consul lock CLI example
                Docker for Linux の VM を作ります:  #search: Docker for Linux
                Consul サーバーを起動します:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker run -it --rm  --name consul_server  consul  sh
                        - (@consul_server)  PS1='\n[\u@\h(consul_server) \W]\$ '  #// プロンプトを見やすくします
                        - (@consul_server)  consul agent  -server  -bootstrap  -data-dir /tmp
                    出力例: |
                        ==> Starting Consul agent...
                                 Version: '1.10.1'
                                 Node ID: 'e96d504f-3323-5b6c-d4e7-321e4e44aed2'
                               Node name: 'be16a29b261c'
                              Datacenter: 'dc1' (Segment: '<all>')
                                  Server: true (Bootstrap: false)
                             Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: -1, DNS: 8600)
                            Cluster Addr: 172.17.0.2 (LAN: 8301, WAN: 8302)
                                 Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false
                Consul クライアントを起動します:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker run -it --rm  --name consul_client_1  consul  sh
                        - (@consul_client_1)  PS1='\n[\u@\h(consul_client_1) \W]\$ '  #// プロンプトを見やすくします
                        - (@consul_client_1)  consul agent  -join 172.17.0.2  -data-dir /tmp
                    出力例: |
                        ==> Starting Consul agent...
                                   Version: '1.10.1'
                                   Node ID: '110c7662-3f1e-99c9-3ae9-e314bb47d779'
                                 Node name: '4845dff60762'
                                Datacenter: 'dc1' (Segment: '')
                                    Server: false (Bootstrap: false)
                               Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: -1, DNS: 8600)
                              Cluster Addr: 172.17.0.3 (LAN: 8301, WAN: 8302)
                                   Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false, Auto-Encrypt-TLS: false
                クラスターのメンバーを確認します:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker exec -it  consul_server  sh
                        - (@consul_server)  PS1='\n[\u@\h(consul_server) \W]\$ '  #// プロンプトを見やすくします
                        - (@consul_server)  consul members
                    出力例: |
                        Node          Address          Status  Type    Build   Protocol  DC   Segment
                        be16a29b261c  172.17.0.2:8301  alive   server  1.10.1  2         dc1  <all>
                        4845dff60762  172.17.0.3:8301  alive   client  1.10.1  2         dc1  <default>
                ロックします:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker exec -it  consul_client_1  sh
                        - (@consul_client_1)  PS1='\n[\u@\h(consul_client_1) \W]\$ '  #// プロンプトを見やすくします
                        - (@consul_client_1)  consul lock -verbose service/foo/lock "while true; do date; sleep 2; done"
                    出力例: |
                        Setting up lock at path: service/foo/lock/.lock
                        Attempting lock acquisition
                        Starting handler
                        Mon Aug 16 06:49:07 UTC 2021
                        Mon Aug 16 06:49:08 UTC 2021
                        Mon Aug 16 06:49:09 UTC 2021
                        #// 以下繰り返します
                別のクライアントからロックします:
                    コマンド:
                        #// 新しいシェル
                        - (@node1)  docker run -it --rm  --name consul_client_2  consul  sh
                        - (@consul_client_2)  PS1='\n[\u@\h(consul_client_2) \W]\$ '  #// プロンプトを見やすくします
                        - (@consul_client_2)  consul agent  -join 172.17.0.2  -data-dir /tmp
                        #// 新しいシェル
                        - (@node1)  docker exec -it  consul_client_2  sh
                        - (@consul_client_2)  PS1='\n[\u@\h(consul_client_2) \W]\$ '  #// プロンプトを見やすくします
                        - (@consul_client_2)  consul lock -verbose service/foo/lock "while true; do date; sleep 2; done"
                    出力例: |
                        Setting up lock at path: service/foo/lock/.lock
                        Attempting lock acquisition
                            #// ロックが解除されるまで待っています                
                元のクライアントの子プロセスを停止します:
                    (@consul_client_1)  Ctrl + C キー
                    #// @consul_client_2 で Mon Aug 16 06:49:07 UTC 2021 が表示し始めます
                終了します:
                    (@consul_client_2)  Ctrl + C キー
                    (@consul_client_2)  exit
                    (@consul_client_1)  exit
                    (@consul_server)  exit
            プログラミング言語を使う場合: HTTP クライアントから HTTP API を呼び出します
            公式:  #ref: https://learn.hashicorp.com/tutorials/consul/distributed-semaphore
                設定: #settings:
                    __SessionName__: db-semaphore
                    __Prefix__: prefix_1
                    __LockKey__: prefix_1/.lock  #// 通常 __Prefix__/.lock
                    __SessionID__: 632c4563-4454-d7d0-27cb-73b742e34904  #// 下記手順の中で決まります
                    __LockModifyIndex__: 161  #// 下記手順の中で決まります
                準備:
                    Docker for Linux の VM を作ります:  #search: Docker for Linux
                    Consul の Docker イメージをダウンロードします:
                        (@node1) docker pull consul
                    Consul エージェントを起動します >> 共有フォルダーなし:  #search: start Consul agent dev example
                    Consul のコンテナー(@consul_1)にログインします:  #search: Consul docker log in
                session/create >> セッションを新規作成します: #// 必要に応じて Name の値を編集してください  #keyword: Consul simple create session
                    コマンド: |
                        (@consul_1)  curl -X PUT http://localhost:8500/v1/session/create -d '{"Name":"db-semaphore"}'
                            #template: "Name":"__SessionName__"
                    出力例: |
                        {
                            "ID": "6a99821e-58a5-edec-35ca-e83b10483970"
                        }
                    出力された __SessionID__ をメモします:
                        632c4563-4454-d7d0-27cb-73b742e34904  #template: __SessionID__
                    セッションがまだ生きていることを確認します:
                        (@consul_1)  curl -X GET http://localhost:8500/v1/session/list
                kv/__Prefix__/__SessionID__?acquire >> ロック候補エントリーを新規作成します:
                    コマンド:
                        (@consul_1)  curl -X PUT http://localhost:8500/v1/kv/prefix_1/632c4563-4454-d7d0-27cb-73b742e34904?acquire=632c4563-4454-d7d0-27cb-73b742e34904 -d node_1
                            #template: curl -X PUT http://localhost:8500/v1/kv/__Prefix__/__SessionID__?acquire=__SessionID__ -d node_1
                    出力例: true
                    説明:
                        -d オプション(body): 例： ノード名。・ロックするノードに対するロール名 など
                            この内容によってConsul の動作が変わることはありません。
                    作成したロック候補エントリーの内容を表示します:
                        コマンド:
                            (@consul_1)  curl -X GET http://localhost:8500/v1/kv/prefix_1/632c4563-4454-d7d0-27cb-73b742e34904?acquire=a2ef6fbd-b640-1f68-2843-a5e8b2f26651
                                #template: curl -X GET http://localhost:8500/v1/kv/__Prefix__/__SessionID__
                        出力例: |
                            [
                                {
                                    "LockIndex": 1,
                                    "Key": "prefix_1/a2ef6fbd-b640-1f68-2843-a5e8b2f26651",
                                    "Flags": 0,
                                    "Value": "bm9kZV8x",
                                    "Session": "a2ef6fbd-b640-1f68-2843-a5e8b2f26651",
                                    "CreateIndex": 666,
                                    "ModifyIndex": 666
                                }
                            ]
                kv/__Prefix__/.lock >> シングル キーを新規作成します:
                    コマンド:
                        (@consul_1)  curl -X PUT http://localhost:8500/v1/kv/prefix_1/.lock?cas=0 -d '{"Limit":2, "Holders":["632c4563-4454-d7d0-27cb-73b742e34904"]}'
                            #template: curl -X PUT http://localhost:8500/v1/kv/__LockKey__?cas=0 -d '{"Limit":2, "Holders":["__SessionID__"]}
                    説明:
                        Limit: スロット数の最大(?)
                        cas: #// 新規作成時の排他制御に使います  #search: Check-And-Set
                        __SessionID__: 保有者
                kv/__Prefix__ >> セマフォ－の現在の状態を表示します:  #keyword: Consul list semaphore example
                    コマンド:
                        (@consul_1)  curl http://localhost:8500/v1/kv/prefix_1?recurse
                            #template: curl http://localhost:8500/v1/kv/__Prefix__?recurse
                    出力例: |
                        [
                            {
                                "LockIndex": 0,
                                "Key": "prefix_1/.lock",
                                "Flags": 0,
                                "Value": "ewogICAgIkxpbWl0IjogMiwKICAgICJIb2xkZXJzIjogWyI2MzJjNDU2My00NDU0LWQ3ZDAtMjdjYi03M2I3NDJlMzQ5MDQiXQp9",
                                "CreateIndex": 161,
                                "ModifyIndex": 161
                            },
                            {
                                "LockIndex": 1,
                                "Key": "prefix_1/632c4563-4454-d7d0-27cb-73b742e34904",
                                "Flags": 0,
                                "Value": "bm9kZV8x",
                                "Session": "632c4563-4454-d7d0-27cb-73b742e34904",
                                "CreateIndex": 620,
                                "ModifyIndex": 620
                            }
                        ]
                    説明:
                        ２つのキーが表示されます:
                            #template-at(-18): "Key": "__LockKey__"
                            #template-at(-11):  "Key": "__Prefix__/__SessionID__"
                            #template-at(-9):  "Session": "__SessionID__"
                        LockIndex: prefix_1/__SessionID__ キーの LockIndex が +1 されます
                        Value:
                            ロック候補エントリーや シングル キー を新規作成したときの -d オプションの値を
                            base64 でエンコードした値  #search: base64
                kv/__Prefix__/.lock >> ロックします（？）:
                    prefix_1/.lock の ModifyIndex をメモします:  #template: __LockKey__ の ModifyIndex
                        セマフォ－の現在の状態を表示します:  #search: Consul list semaphore example
                            "ModifyIndex": 161  #template-at(-24): "ModifyIndex": __LockModifyIndex__
                    コマンド: |
                        (@consul_1)  curl -X PUT http://localhost:8500/v1/kv/prefix_1/.lock?cas=161 -d __UpdatedLockBody__
                            #template: curl -X PUT http://localhost:8500/v1/kv/__LockKey__?cas=__LockModifyIndex__ -d __UpdatedLockBody__
                    出力例: true  #// false と表示された場合、スロットを獲得することに失敗しました
                    説明:
                        __UpdatedLockBody__:
                            成功した場合: prefix_1/.lock の Value が __UpdatedLockBody__ に変わります
                            prefix_1/.lock の Value を表示します:  #search: Consul list semaphore example
    構成:
        dashboard:  #keyword: Consul dashboard
            ノード:  #// サーバー
                ノード一覧:  Consul (Web) >> Nodes（左上）
                IP アドレス:  Consul (Web) >> Nodes（左上）>> Unhealthy Nodes または Healthy Nodes
            サービス:
                サービス一覧:  Consul (Web) >> Services（左上）
                ポート番号:  Consul (Web) >> Nodes（左上）>>（ノード名）>> Service Instances（タブ）
            特定のノードのサービス:
                サービスから探す:  Consul (Web) >> Services（左上）>>（サービス名の行）>>（ノードの行のサービス名）
                ノードから探す:  Consul (Web) >> Nodes（左上）>>（ノード名）>> Service Instances（タブ）>>（サービス名の行）>>（ノードの行のサービス名）
            公式: https://www.consul.io/docs/connect/observability/ui-visualization#configuring-dashboard-urls
        Consul サーバー:
            ログイン:
                Docker:  #// Consul Docker コンテナーにログインします  #search: Consul docker log in
            HTTP インターフェース: デフォルトのポート番号は 8500
            DNS  インターフェース: デフォルトのポート番号は 8600
        エージェント:  #// Consul サーバーのプロセス  #// すべてのホストはエージェントです。ホストはエージェント兼サーバーになれます
            起動:  #search: start Consul agent example
                -dev オプション: #// 通常不要  #search: start Consul agent dev example
                -bind オプション: #// Cluster Addr を指定します
                    #ref: https://www.consul.io/docs/agent/options#_bind
                    #ref: https://gihyo.jp/admin/feature/01/serf-consul/0005
                -client オプション: #// HTTPサーバーやDNSサーバーなどにバインドするアドレス  #keyword: Consul agent client option
                    #// デフォルトは 127.0.0.1 ＝ localhost からのリクエストのみ許可します
                    #// 0.0.0.0 ＝ インターネットを含むすべてのリクエストを許可します
                    #ref: https://www.consul.io/docs/agent/options#_client
                    #ref: https://stackoverflow.com/questions/43115152/starting-consul-in-docker-does-not-expose-http-ports
                    #// 参考: プライベート サブネットに DB サーバーを配置する  #ref: ${programming}/ネットワーク・セキュリティ/Cloud/Cloud.svg#private_subnet
            再起動:  #search: restart Consul example
            参考:
                公式の get started: https://learn.hashicorp.com/tutorials/consul/get-started-agent
                起動コマンド:
                    https://www.consul.io/commands/agent
                    https://www.consul.io/docs/agent
                    https://www.consul.io/docs/agent/options#command-line-options
        サーバー, ノード:  #// 監視対象のサーバー  #// ホストはエージェント兼サーバーになれます
            トポロジー: クライアントモードのエージェントは「スター型」のトポロジー。エージェント同士が直接通信を行いません。
                サービスディスカバリーやKV操作などはすべてサーバーを経由らしい
                クライアント間で直接ゴシッププロトコルを使った通信は行われないらしい
            一覧:  #search: list Consul nodes example
            IP アドレス:  #// ノードの IP アドレスを表示します  #search: Consul DNS example
        サービス:  #// サービスの情報
            表示:  #keyword: show Consul service example
            更新:  #keyword: update Consul service example
        セッション:  #keyword: Consul session
            参考: #ref: https://www.consul.io/docs/dynamic-app-config/sessions
            リファレンス: #ref: https://www.consul.io/api/session
            CRUD:
                （手順）:  #search: Consul session example
                生成:
                    基本:
                        curl -X PUT http://localhost:8500/v1/session/create -d '{"Name":"__client_N_session__"}'
                    詳細設定: |
                        curl -X PUT http://localhost:8500/v1/session/create -d '{
                                "Name": "client_1_session",
                                "Behavior":"delete"
                            }'
                    参考: https://www.consul.io/api/session#create-session
                一覧:
                    curl -X GET http://localhost:8500/v1/session/list?pretty
                詳細:
                    書式: curl -X GET http://localhost:8500/v1/session/node/__ConsulNodeName__?pretty
                    __ConsulNodeName__:
                        - consul agent -node consul_1 で起動した場合、consul_1
                        - consul agent に -node オプションを指定しなかった場合、
                            セッションを一覧すると "Node" キーに表示されます
                削除:
                    書式: curl -X PUT http://localhost:8500/v1/session/destroy/__SessionID__
                    出力:
                        成功したら true と表示されます。すでに存在しないときも true と表示されます
                セッションを更新します:  #// TTL の有効期限が延長されます
                    書式: curl -X PUT http://localhost:8500/v1/session/renew/__SessionID__
                    __SessionID__:
                        __SessionID__ にセッション名は指定できません
            Lock:  #search: Consul lock API example
            セッションが無効になったとき:
                セッションが無効になる条件:
                    - セッションを明示的に削除した
                    - ノード（サーバー）の登録から外れた
                    - ヘルスチェックの登録から外れた
                    - ヘルスチェックがクリティカル状態になった
                    - TTL の有効期限が切れた
                    - 参考: https://www.consul.io/docs/dynamic-app-config/sessions >> the session will be invalidated
                セッションが無効になったときの動作:
                    #// 以下のいずれか。設定による
                    削除:
                        削除されると、保持されているロックのいずれかに対応するキーが削除されます。
                        Session HTTP Endpoint の Behavior オプション ＝ delete
                    リリース: #// デフォルト
                        リリースされると、ModifyIndex が増えます
                        Session HTTP Endpoint の Behavior オプション ＝ release
                    サンプル: #search: Consul lock API example
                    参考: https://www.consul.io/api/session#behavior
                メモ:
                    - ヘルスチェックを使用しないセッションを作成できます。
                    - TTL は、デフォルトでは15秒。0 から 60 秒
            排他制御:  #// 悲観的排他制御におけるロックのオーナー
                通常のキーの更新がありますが、LockIndexの増分もあります。
                取得中に特定のセッションによってロックがすでに保持されている場合、
                LockIndexはインクリメントされませんが、キーの内容は更新されます。 
                これにより、現在のロック所有者は、ロックを放棄して再取得することなく、
                キーの内容を更新できます。
            ゴシップ障害検出機能:
                概要:
                    - デフォルトでオン
                    - ノードが異常になったらセッションは保持されません
                出典:
                    デフォルトでは、セッションはゴシップ障害検出機能のみを使用します。
                    つまり、デフォルトの Serf ヘルスチェックでノードが異常を宣言していない限り、
                    セッションはノードによって保持されていると見なされます。
                    https://learn.hashicorp.com/tutorials/consul/distributed-semaphore?in=consul/developer-configuration
        イベント: #keyword: Consul event
            有効無効:
                Consul Agent が動作していれば常に有効
            API:
                POST /v1/event/fire/:name	イベントを発火（送信）する
                GET /v1/event/list	イベントの一覧を取得する
                GET /v1/event/list?name=foo	特定のイベント名にフィルタして取得
            サンプル: |
                # イベントを発火
                    curl --request PUT \
                        --data 'Hello Consul' \
                        http://localhost:8500/v1/event/fire/test
                # イベントを取得
                    curl http://localhost:8500/v1/event/list?name=test
        KV Store, Key-Value: #keyword: Consul KV Store 
            #search: Consul KV example
    コマンド:  #ref: https://www.consul.io/commands
        サンプル: #search: install Consul
    API:  #ref: https://www.consul.io/api
    ファイル:
        consul.hcl: #keyword:  #// Agents Configuration File  #ref: https://developer.hashicorp.com/consul/docs/agent/config/config-files
            サーバー用設定？:
                server: サーバーになるかどうか。デフォルトは false でエージェントでのみ動作します
                bootstrap_expect: クラスターに期待するサーバーの数
                    bootstrap_expectで指定した数のサーバーが参加した時点でリーダー選出が開始されます。
                    追加のサーバーも問題なくクラスタに参加できます
                    クォーラム（合意形成に必要な最小数）も増加します
            WebUI 用設定:
                ui: WebUI を有効にするかどうか
                ui_content_path:
                    カスタムUIコンテンツの配置場所を指定するために使用されます
                    デフォルトでは、Consulは組み込みのUIアセットを使用します
            エージェント用設定:
            共通設定？:
                datacenter: データーセンター名
                advertise_addr:  #ref: https://developer.hashicorp.com/consul/docs/agent/config/cli-flags#advertise-address-options
                    この consul.hcl ファイルを使う Consul サービスに、Consul エージェント（クライアント）が通信相手として指定する IPアドレス。
                    ホスト自身のIPアドレスとは限りません。
                advertise_addr_wan:  #ref: https://developer.hashicorp.com/consul/docs/agent/config/cli-flags#advertise-address-options
                    WANゴシッププロトコルで使用されるIPアドレス。マルチデータセンター構成で使用されます。
                client_addr:
                    - リッスン アドレス。 #search: ListenAddress
                    - HTTPインターフェース、DNSインターフェース、gRPCインターフェースなど、クライアント向けサービスのリッスンアドレス
                retry_join:
                    通信相手のホストの IP アドレスの配列。サーバーとしてはクラスターを構成するホストを探すため、エージェントとしてはサーバーを探すため。
                retry_join_wan:
                    WAN 用の retry_join
                disable_update_check:
                    Consul の新バージョンを確認する通信を行うかどうか
    トラブルシューティング:
        - #// 脆弱性情報  #ref: https://discuss.hashicorp.com/c/security/52
        - #// No cluster leader
            手順: consul agent
            エラー: |
                agent: Coordinate update error: error="No cluster leader"
            対処:
                consul agent に -bootstrap オプションを追加します
                https://learn.hashicorp.com/tutorials/consul/recovery-outage
                https://christina04.hatenablog.com/entry/consul-upgrade-problem
        - #// No cluster leader
            手順: consul agent
            エラー:
                Cluster Addr が 172.17.0.___ にならない: |
                    Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)
            対処:
                consul agent から -dev オプションを外します
TICスタック:
    Telegraf: #keyword:  #// メトリクスやデータを収集するためのエージェント
    InfluxDB: #keyword:  #// 時系列データベース
    Chronograf: #keyword:  #// 収集したデータを可視化するためのWebベースのインターフェース
Zabbix: #keyword:
    公式:
        公式:
            英語: #ref: https://www.zabbix.com/
            日本語: #ref: https://www.zabbix.com/jp/
        日本Zabbixユーザー会: #ref: http://www.zabbix.jp/
    手順: #// インストールなど  #keyword: install Zabbix
        バージョン番号の確認:  #// インストール済みが対象
            Zabbix フロントエンドの最も下
        Docker: |
            services:
                zabbix-postgres:
                    image: postgres:16.3-alpine
                    environment:
                        -   "POSTGRES_USER=zabbix"
                        -   "POSTGRES_PASSWORD=zabbix"
                    volumes:
                        -   "zabbix-postgres-data:/var/lib/postgresql/data"

                zabbix-server:
                    image: zabbix/zabbix-server-pgsql:alpine-6.3.10
                    environment:
                        -   "DB_SERVER_HOST=zabbix-postgres"
                        -   "DB_SERVER_DBNAME=zabbix"
                        -   "POSTGRES_USER=zabbix"
                        -   "POSTGRES_PASSWORD=zabbix"
                    depends_on:
                        -   zabbix-postgres

                zabbix-web:
                    image: zabbix/zabbix-web-nginx-pgsql:alpine-6.3.10
                    environment:
                        -   "DB_SERVER_HOST=zabbix-postgres"
                        -   "DB_SERVER_DBNAME=zabbix"
                        -   "POSTGRES_USER=zabbix"
                        -   "POSTGRES_PASSWORD=zabbix"
                    ports:
                        -   "18082:8080"  #// Zabbix6: 8080, Zabbix4: 80
                    depends_on:
                        -   zabbix-server

                zabbix-agent:
                    image: zabbix/zabbix-agent:alpine-6.3.10
                    environment:
                        -   "ZBX_SERVER_HOST=zabbix"
                    depends_on:
                        -   zabbix-server

            volumes:
                zabbix-postgres-data: {}
        Zabbix 4.0 on CentOS 7:  #keyword: install Zabbix4 CentOS7  #// Ansible 使用
            参考: #ref: https://www.zabbix.com/jp/download?zabbix=4.0&os_distribution=centos&os_version=7&db=mysql&ws=apache
            エージェントとフロントエンドをインストールします:  #keyword: install Zabbix4 agent CentOS7
                Ansible を使う場合:
                    プロジェクトをコピーしてインストールします:
                        #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible
                    #// README.yaml を参照
            Zabbix の初期設定と動作確認をします:
                #search: initialize Zabbix
        Zabbix 5.0 on CentOS 7:  #keyword: install Zabbix5 CentOS7  #// Ansible 使用
            参考: #ref: https://www.zabbix.com/jp/download?zabbix=5.0&os_distribution=centos&os_version=7&db=mysql&ws=apache
            エージェントとフロントエンドをインストールします:  #keyword: install Zabbix5 agent CentOS7
                Ansible を使う場合:
                    #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ansible
                    #// 以下に続きます
                手動の場合: |
                    sudo rpm -Uvh https://repo.zabbix.com/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm
                    sudo yum clean all
                    sudo yum install zabbix-server-mysql zabbix-agent -y
                    sudo yum install centos-release-scl -y
                    sudo vi /etc/yum.repos.d/zabbix.repo
                        [zabbix-frontend]
                            enabled=0
                            enabled=1

                    sudo yum install zabbix-web-mysql-scl zabbix-apache-conf-scl -y
                    mysql -uroot -p
                        Pass55##
                    mysql>
                        create database zabbix character set utf8 collate utf8_bin;
                        create user zabbix@localhost identified by 'Zabbix55##';
                        grant all privileges on zabbix.* to zabbix@localhost;
                        quit;
                    sudo zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix
                        Zabbix55##
                    sudo vi /etc/zabbix/zabbix_server.conf
                        #DBPassword=
                        DBPassword=Zabbix55##
                    sudo vi /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf
                        ; php_value[date.timezone] = Europe/Riga
                        php_value[date.timezone] = Asia/Tokyo
                    sudo systemctl restart zabbix-server zabbix-agent httpd rh-php72-php-fpm
                    sudo systemctl enable zabbix-server zabbix-agent httpd rh-php72-php-fpm

                    #keyword: Zabbix SELinux
                    sudo setsebool -P httpd_can_connect_zabbix on
                    sudo setsebool -P zabbix_can_network on
                    sudo setsebool -P zabbix_run_sudo on

                    sudo grep zabbix_server /var/log/audit/audit.log | sudo audit2allow -M zabbix-policy
                    sudo semodule -i zabbix-policy.pp
                    sudo systemctl restart zabbix-server
                    systemctl status zabbix-server

                    sudo grep zabbix_server /var/log/audit/audit.log | sudo audit2allow -M zabbix-agent-policy
                    sudo semodule -i zabbix-agent-policy.pp
                    sudo systemctl restart zabbix-server
                    systemctl status zabbix-server

                    http://192.168.33.61/zabbix
                #// 以下に続きます
            Zabbix の初期設定と動作確認をします:
                #search: initialize Zabbix
        Zabbix 5.0 on CentOS 8:  #// Ansible なし
            参考:
                #ref: https://www.zabbix.com/jp/download
                #ref: https://qiita.com/atanaka7/items/282a3499e135e00edcdc
            設定: #settings:
                __ZabbixServerName__: 192.168.56.101
                __MySQL_RootPass__: Pass55!!
                __MySQL_ZabbixPass__: Pass55!!
            上記「CentOS 8 を VirtualBox にインストールします」:
            Visual Studio Code をインストールします:  #// SSH クライアントとして使います
                #search: Windows に Visual Studio Code をインストールして CentOS + VirtualBox に SSH で接続します
            MySQLをインストールします: #search: CentOS に MySQL をインストールします
            RHEL 8 用 yum リポジトリを登録します:  #// Zabbix LLC 社製
                注意: データベースが１つもないときはインストールできないようです。古いバージョンなどを探してください
                URL: https://www.zabbix.com/jp/download  #// 内容を見るだけでなのでどの OS で見ても OK
                ZABBIXバージョン: 5.0 LTS
                OSディストリビューション: CentOS
                OSバージョン: 8
                データベース: MySQL
                WEB SERVER: Apache
            インストールします:  #// 上記 Zabbix のホームページからコピーしたものです
                a. Zabbix のリポジトリをインストールします:
                    コマンド:
                        - sudo rpm -Uvh https://repo.zabbix.com/zabbix/5.0/rhel/8/x86_64/zabbix-release-5.0-1.el8.noarch.rpm
                        - dnf clean all
                    他の URL: #ref: https://www.zabbix.com/jp/download?zabbix=6.0&os_distribution=centos&os_version=7&db=&ws=
                b. Zabbix のサーバー・フロントエンド・エージェントをインストールします:
                    sudo dnf install -y zabbix-server-mysql zabbix-web-mysql zabbix-apache-conf zabbix-agent
                c. データベースを初期化します:
                    - sudo mysql -u root -p  #// __MySQL_RootPass__
                    - mysql> create database zabbix character set utf8 collate utf8_bin;
                    - mysql> create user zabbix@localhost identified by 'Pass55!!';  #template: __MySQL_ZabbixPass__
                    - mysql> grant all privileges on zabbix.* to zabbix@localhost;
                    - mysql> quit;
                    - zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -u zabbix -p zabbix
                        #// パスワードは __MySQL_ZabbixPass__
                    - MySQL 8 の場合、MySQL ユーザーの認証方法を SHA2 から MySQL ネイティブに変更します:
                        - mysql -u root -p mysql
                            #// パスワードは Pass55!!  #template: __MySQL_RootPass__
                        - mysql> select user, host, plugin from user;  #// zabbix ユーザーは caching_sha2_password
                        - mysql> alter user 'zabbix'@'localhost' identified with mysql_native_password by 'Pass55!!';
                            #template: by '__MySQL_ZabbixPass__'
                        - mysql> select user, host, plugin from user;  #// zabbix ユーザーは mysql_native_password
                        - mysql> quit;
                d. Zabbix サーバーの設定にデータベースの設定を追加します:
                    - sudo nano /etc/zabbix/zabbix_server.conf : |  #// DBPassword でファイル内を検索して
                        DBPassword=Pass55!!
                            #template: __MySQL_ZabbixPass__
                e. Zabbix フロントエンドの設定にPHPの設定をします:
                    - sudo nano /etc/php-fpm.d/zabbix.conf : |  #// date.timezone でファイル内を検索して
                        php_value[date.timezone] = Asia/Tokyo
                            #// 行頭の ; は削除します
                f. Zabbix サーバー・エージェントを起動し、OS再起動時にも起動するように設定します:
                    sudo systemctl restart zabbix-server zabbix-agent httpd php-fpm
                    sudo systemctl enable  zabbix-server zabbix-agent httpd php-fpm
                g. Zabbix フロントエンドの設定をします:
                    参考: https://www.zabbix.com/documentation/5.0/manual/installation/frontend
                    ポートを開きます:
                        - sudo firewall-cmd --set-default-zone=trusted  #// デフォルトゾーンを変更します。trusted は全てオープン。firewalld 再起動不要
                    ブラウザーで Zabbix フロントエンドを開きます:
                        URL: http://192.168.56.101/zabbix  #template: __ZabbixServerName__
                        Welcome:
                            Next step ボタン（右下）:
                        Check of pre-requisites:
                            Next step ボタン（右下）:
                        Configure DB connection:
                            Database host: localhost  #// ホストOSのブラウザーでゲストOSの Zabbix を使う場合でも localhost
                            Password: Pass55!!  #template: __MySQL_ZabbixPass__
                            トラブルシューティング:
                                エラー: The server requested authentication method unknown to the client
                                対処法: 上記「MySQL ユーザーの認証方法を SHA2 から MySQL ネイティブに変更します」
                            Next step ボタン（右下）:
                        Zabbix server details:
                            Next step ボタン（右下）:
                        Pre-installation summary:
                            Next step ボタン（右下）:
                        Install:
                            Finish ボタン（右下）:
                Zabbix フロントエンドの初期設定:
                    URL: http://192.168.56.101/zabbix  #template: __ZabbixServerName__
                    初期の管理者アカウント:
                        Username: Admin
                        Passowrd: zabbix
                    Zabbix フロントエンドを日本語にします:
                        UserSettings（左下）:
                            Language: Japanese
                            Update ボタン:
                    httpd から zabbix_server にアクセスできるようにします:
                        bash:
                            - getsebool -a | grep zabbix  #// SELinuxの設定のうち Zabbix に関する設定を表示します
                            - sudo setsebool -P httpd_can_connect_zabbix on
                            - sudo setsebool -P zabbix_can_network on
                            - sudo setsebool -P zabbix_run_sudo on
                            - getsebool -a | grep zabbix

                            - sudo grep zabbix_server /var/log/audit/audit.log | audit2allow
                            - sudo grep zabbix_server /var/log/audit/audit.log | audit2allow -M zabbix-policy
                            - sudo semodule -i zabbix-policy.pp
                            - sudo grep zabbix_server /var/log/audit/audit.log | audit2allow -M zabbix-agent-policy
                            - sudo semodule -i zabbix-agent-policy.pp

                            - sudo systemctl restart zabbix-server
                    Zabbix サーバーの起動を確認します:
                        URL: http://192.168.56.101/zabbix >> 監視データ（左上）>> ダッシュボード
                            #template: __ZabbixServerName__
        Zabbix エージェント:  #keyword: install Zabbix agent
            インストール:
                Zabbix サーバーのインストールのサンプルでもインストールしているのでそちらを参照
                #search: install Zabbix5 agent CentOS7
            Zabbix エージェント:  #search: Zabbix agent
        初期化:  #keyword: zabbix reset  #// Zabbix のデータを初期化して、再起動します
            Docker の場合:
                #search: docker volume rm
            Zabbix の初期設定と動作確認をします:  #keyword: initialize Zabbix
                設定: #settings:
                    __ZabbixServerName__: 192.168.33.61
                    __MySQL_ZabbixPass__: Zabbix55##
                ブラウザーで Zabbix の初期設定を行います:
                    ブラウザーで Zabbix フロントエンドを開きます:
                        URL: http://192.168.33.61/zabbix  #template: __ZabbixServerName__
                    Welcome:
                        Next step ボタン（右下）:
                    Check of pre-requisites:
                        Next step ボタン（右下）:
                    Configure DB connection:
                        User: zabbix
                        Password: Zabbix55##  #template: __MySQL_ZabbixPass__
                        Next step ボタン（右下）:
                    Zabbix server details:
                        Next step ボタン（右下）:
                    Pre-installation summary:
                        Next step ボタン（右下）:
                    Install:
                        Finish ボタン（右下）:
                Zabbix フロントエンドの初期設定:
                    URL: http://192.168.33.61/zabbix  #template: __ZabbixServerName__
                    初期の管理者アカウント:
                        Username: Admin
                        Passowrd: zabbix
                    Zabbix フロントエンドを日本語にします:
                        UserSettings（左下）:
                            Language: Japanese
                            Update ボタン:
                Zabbix servers を表示します:
                    Zabbix >> 設定（左上）>> ホスト
                Zabbix servers の最新データを表示します:
                    Zabbix >> 監視データ（左上）>> 最新データ >> （ホストの）選択 >> Zabbix server >> 選択 >> 適用 >>
                    ▲（すべて折りたたみます：表の左上）>>
                    CPU（2列目の最も上）>> CPU idle time（4行目）>> グラフ（最も右）>> 表示形式＝値（右上）
                その他の基本手順:
                    #search: Zabbix basic
        パフォーマンス チューニング: #🌟
            StartPollers の設定: #keyword: Zabbix StartPollers
                監視するプロセスの数。実際の負荷状況を見ながら、調整することになります。
                増やすと、メモリーの消費量は増え、CPU の稼働率は上がります。
                #search: Zabbix poller
                #ref: https://unam.hatenadiary.jp/entry/2018/02/20/215659
                #ref: https://www.zabbix.com/documentation/2.2/jp/manual/appendix/performance_tuning?hl=StartPollers
            Timeout の設定: #keyword: Zabbix Timeout
                デフォルト: 3秒
                    /etc/zabbix/zabbix_server.conf
                注意: 通常、デフォルトで構いません。増やすと負荷が高まります
        その他の基本手順: #keyword: Zabbix basic
            ホストやアイテムを追加します: #search: create Zabbix host
            グラフ: #search: Zabbix graph
            負荷を与えます: #search: Zabbix stress test
            トリガー: #search: create Zabbix trigger
            メール通知: #search: Zabbix mail
            スクリプト実行: #search: Zabbix alert script
            その他: #search: Zabbix concept
    概念: #keyword: Zabbix concept
        ホスト:  #// 監視対象  #search: Zabbix host configuration  #search: Zabbix host monitoring data
            表示:
                Zabbix 6:  #search: Zabbix6 host menu
                Zabbix 4:  #search: Zabbix host menu
            追加: #keyword: create Zabbix host
                Zabbix のフロントエンドで操作する場合: #keyword: create Zabbix host example
                    ホスト:
                        メニュー: Zabbix >> 設定 >> ホスト >> ホストの作成（右上）
                        ホスト名: control （任意）
                        グループ: Virtual machines （省略不可）
                        エージェントのインターフェース:
                            IPアドレス: 192.168.33.59 (例)
                        追加 ボタン:
                        灰色: エージェント未使用 または 監視項目なし
                    アイテム: #keyword: create Zabbix item example  #search: Zabbix item
                        メニュー: 設定 >> ホスト >> アイテム（表の3列目）>> アイテムの作成（右上）
                        名前: CPU load （任意）
                        キー: system.cpu.load
                        データ型: 数値（浮動小数）
                        Zabbix 5.0 の場合:
                            テスト ボタン（下）:
                            値の取得とテスト ボタン（右下）:
                        追加 ボタン:
                    エージェントの動作を確認します:
                        監視データをリクエストします:
                            メニュー: Zabbix >> 監視データ >> 最新データ
                            ホスト: control
                            適用 ボタン:
                        エージェントの状態を表示します:
                            メニュー: Zabbix >> 設定 >> ホスト
                            ブラウザーをリロードします:
                            エージェントの状態: #// 緑色＝正常, 赤色＝異常  #// 1分ぐらい後で表示されるようです
                            グラフ: #search: Zabbix graph
            監視データ: #search: Zabbix host monitoring  #// 取得したメトリクスのデータ
            テンプレート: #search: Zabbix template  #// アイテムやトリガーをまとめたもの
            アイテム:  #search: Zabbix item  #// 監視項目, 取得する監視データ ,メトリクス
            トリガー:  #search: Zabbix trigger  #// 警告など, 障害の発生条件の設定
        ホストグループ: #keyword: Zabbix host group  #// ホストおよびテンプレートのグループ
            概要: ホストは必ずどこかのホストグループに所属します。
                同じホストグループにホストとテンプレートが所属していても、
                そのホストはそのテンプレートを使うわけではありません。
                ブラウズする際に親フォルダーに相当するホストグループから辿れるようになるだけです。
                所属する全てのホストが正常か障害かを一覧表の中の色で判断できます。
            表示: #search: Zabbix host group menu
            追加: #// 既存のホストを既存の ホスト グループ に追加します
                Zabbix >> Configuration（タブ）>> Hosts（タブ）>>（ホスト名）>>
                Group（に一部でも入力） または（Group：上から3つ目 の）Select ボタン >>
                Update ボタン（左下）
                #ref: https://www.zabbix.com/documentation/current/en/manual/config/hosts/host
            ネストされた ホスト グループ:
                __ParentGroup__/__ChildGroup__  #// グループ名の先頭に、親グループ名とスラッシュを含めます
                #ref: https://www.zabbix.com/documentation/current/en/manual/config/hosts/host >> nested host group
        サーバー:  #// 監視データを集めるサービス
            #search: install Zabbix
        エージェント: #keyword: agent of Zabbix  #// ホストで動作する監視データを集めるサービス
            Zabbix エージェント: #keyword: Zabbix agent
                主なアイテム: #search: Zabbix agent items
                インストール: #search: install Zabbix agent
                設定ファイル: #search: zabbix_agentd.conf
            zabbix_sender: #keyword: zabbix_sender  #// Zabbixサーバーに監視データを送るコマンドラインユーティリティ
                #ref: https://www.zabbix.com/documentation/current/en/manual/concepts/sender
            SNMP エージェント:  #keyword: Zabbix SNMP agent  #// ポーリングで監視データを集めます
                SNMP trap が来たとき:
                    モジュール構成:
                        (@agent) snmptrap → (@manager) snmptrapd → snmptrap receiver → snmp trapper file → snmp trapper → DB
                        #ref: http://cyberfortress.jp/2020/04/17/blog-zabbix-setup-snmptrap/
                        #search: SNMP trap
                    Zabbix 構成:
                        ログファイルに保存:
                        アイテムが監視データに変換:
                        トリガーで通知:
                接続先のホスト:
                    アイテムから探す場合:
                        メニュー: Zabbix >> 設定 >> ホスト（または）テンプレート >>（対象の行の）アイテム
                        ホストインターフェース: 接続先のホスト
                    ホストから探す場合:
                        メニュー: Zabbix >> 設定 >> ホスト（または）テンプレート >>（ホスト名）
                        SNMP インターフェース: （IP アドレス, ポート）
                監視データの内容: #search: Zabbix SNMP items
                    Zabbix をインストールすると SNMP を使ったアイテムがテンプレートにすでに入っています
                    Template Module Interfaces Simple SNMPv2 など多数
                参考:
                    MIB:  #search: MIB
                    Zabbix SNMP trap:
                        https://www.zabbix.com/documentation/current/en/manual/config/items/itemtypes/snmptrap
                    【入門編】ZabbixでSNMPトラップ監視を始めるには？:
                        https://www.ashisuto.co.jp/enishi/system_management/zabbix_snmp.html
            SSH エージェント:  #keyword: Zabbix SSH check,  Zabbix SSH  #// SSH 経由で任意のコマンドを実行して監視データを取得します
                公式: #ref: https://www.zabbix.com/documentation/2.2/jp/manual/config/items/itemtypes/ssh_checks
                注意: Zabbix 4.0.39 では動作できないようです
                監視データの内容: #search: Zabbix SSH items
                追加: #keyword: create Zabbix SSH check
                    アイテムを作ります:
                        メニュー: Zabbix >> 設定 >> ホスト（または）テンプレート >>（対象の行の）アイテム >> アイテムの作成（右上）
                        名前: file count  #// 任意
                        タイプ: SSH エージェント
                        キー: ssh.run[file_count]    ssh.run[file_count2,control]
                        認証方式: 公開鍵
                        ユーザー名: root
                        公開鍵ファイル: id_rsa.pub
                        秘密鍵ファイル: id_rsa
                        実行するスクリプト:
                            ls -l $HOME | wc --lines
                        追加 ボタン:
                    監視データを取得します:
                        メニュー: Zabbix >> 監視データ >> 最新データ
            外部チェック: #keyword: Zabbix external check  #// Zabbix サーバーで任意のコマンドを実行して監視データを取得します
                公式: #ref: https://www.zabbix.com/documentation/2.2/jp/manual/config/items/itemtypes/external
                監視データの内容:
                    スクリプトの置き場所: #search: Zabbix ExternalScripts
                    ファイル名: #search: Zabbix external check items 
                追加: #keyword: create Zabbix external check
                    スクリプトを作ります:
                        bash (@zabbix1): |
                            edit=/usr/lib/zabbix/externalscripts/get.sh  #search: Zabbix ExternalScripts
                            sudo mkdir -p ${edit}
                            sudo rmdir    ${edit}
                            sudo tee ${edit} > /dev/null
                                #!/bin/bash
                                echo "$1"
                            sudo chown zabbix:zabbix ${edit}
                            sudo chmod +x ${edit}
                            ls -l ${edit}
                        #// Python3 の場合:  #search: Zabbix Python3
                    アイテムを作ります:
                        メニュー: Zabbix >> 設定 >> ホスト（または）テンプレート >>（対象の行の）アイテム >> アイテムの作成（右上）
                        名前: get  #// 任意
                        タイプ: 外部チェック
                        キー: get.sh[10]  #search: Zabbix external check key
                        追加 ボタン:
                    （作ったアイテム）:
                        監視データ取得 ボタン:  #// 不要かも？
                    データを確認します:
                        #search: Zabbix graph
                キー: #keyword: Zabbix external check key
                    サンプル:
                        動作確認サンプル:
                            #search: create Zabbix external check
                        キーに指定する値のサンプル:
                            - get.sh[10]
                            - address.sh[www.example.com]
                            - with-macro.sh[{$FQDN}]
                    キー全体: #// 以下のいずれか
                        - __ScriptFileName__
                        - __ScriptFileName__[]
                        - __ScriptFileName__[__Argument_1__]
                        - __ScriptFileName__[__Argument_1__,__Argument_2__,...]
                    キーに指定するマクロ:  #keyword: Zabbix macro in external check
                        サンプル:
                            ホスト:  #// ホスト直下にマクロを定義、テンプレートでマクロを参照
                                マクロ:  #search: Zabbix macro
                                    FQDN: example.com  #// 定義
                                テンプレート >> アイテム >>（外部チェックの）キー:  #search: Zabbix external check key
                                    with-macro.sh[{$FQDN}]  #// 参照
            その他のエージェント:
                関連 >> 主なアイテム: #search: Zabbix main items
            JavaScript のプリプロセッシング: #// Zabbix 5.4以降  #ref: https://www.zabbix.com/documentation/current/jp/manual/config/items/preprocessing/javascript
            poller プロセス: #keyword: Zabbix poller  #// zabbix agent、SNMP、外部チェックを処理するプロセス
                Zabbix の負荷率を監視する場合:  #search: Zabbix インターナル
                #ref: https://unam.hatenadiary.jp/entry/2018/01/27/193310
                #search: Zabbix StartPollers
        監視データ:  #search: Zabbix monitoring  #// 取得したメトリクスのデータ
            ホストの状態: #keyword: Zabbix host monitoring
                監視データ:
                    グラフ: #keyword: Zabbix graph
                        Zabbix 6.0:
                            表示: Zabbix >> 監視データ >> ホスト >>（対象ホストの行の）最新データ（グラフではない：中央）>> 名前（の列の対象行）>> グラフ（または）値
                        Zabbix 5.0:
                            表示: Zabbix >> 監視データ >> ホスト >>（対象ホストの行の）最新データ（グラフではない：中央）>>（対象アイテムの行の）グラフ（右端）
                            一覧: Zabbix >> 監視データ >> ホスト >>（対象ホストの行の）グラフ  #// ただし、グラフの設定が無いと選べません
                        Zabbix 4.0:
                            表示: Zabbix >> 監視データ >> 最新データ >> リセット >> （ホストの）選択 >>（ホスト名）>> 選択 >> 適用 >> グラフ（右端）>>
                                表示形式（右上）＝値
                        関連 >> 負荷を与えます: #search: Zabbix stress test
                トリガー, 障害（ホスト）: #keyword: Zabbix host problems  #// 特定のホストのトリガーされた障害
                    設定 メニューの場合: #// Zabbix 4.0～5.0 の場合
                        メニュー: Zabbix >> 設定 >> ホスト >> トリガー（表の4列目）
                        リロードします:  #// ブラウザーのリロード
                        値: 障害（赤字）, 正常（緑字）
                    監視データ メニューの場合: #// Zabbix 5.0 の場合
                        現在:
                            Zabbix >> 監視データ >> ホスト >> 障害（2列あるうちのクリックできる列：右側）
                        ヒストリ:  #// 現在とすべての過去の障害
                            Zabbix >> 監視データ >> ホスト >> 障害（2列あるうちのクリックできる列：右側）>> 表示（左上）＝ヒストリ >> 適用
            障害一覧: #keyword: Zabbix problems  #// 全ホストのトリガーされた障害
                ヒストリ:  #// 現在とすべての過去の障害 #// Zabbix 4.0～5.0 の場合
                    Zabbix >> 監視データ >> 障害 >> リセット（中央）>> 表示（左上）＝ヒストリ >> 適用
                現在:  #// 現在発生中の障害 #// Zabbix 4.0～5.0 の場合
                    Zabbix >> 監視データ >> ダッシュボード >> 障害（下半分）
                現在（最近の解決済を含む）:  #// 現在発生中の障害 および 最近解決した障害（過去10分？）
                    Zabbix >> 監視データ >> 障害 >> リセット（中央）
                特定のホスト: #search: Zabbix host problems
        アイテム:  #keyword: Zabbix item  #// 監視項目, 取得する監視データ ,メトリクス, SSH エージェント, 外部チェック
            関連 >> テンプレート: #search: Zabbix template  #// アイテムやトリガーをまとめたもの
            表示: #search: Zabbix6 host menu  #search: Zabbix item menu
            主なアイテム: #keyword: Zabbix main items
                設定手順: #search: create Zabbix item
                エージェントごとのアイテム:  #// エージェントのインストールは #search: agent of Zabbix
                    Zabbix エージェント のアイテム: #keyword: Zabbix agent items  #// ホストにインストールされた Zabbix エージェントと通信して監視データを取得します
                        system.cpu.load:  #// ロード アベレージ
                            サンプル:
                                名前: CPU load average
                                キー: system.cpu.load
                                データ型: 数値（浮動小数）
                        system.cpu.util:  #// CPU 使用率
                            サンプル:
                                名前: CPU load (1min)
                                キー: system.cpu.util[all, user, avg1]
                                データ型: 数値（浮動小数）
                    SNMP エージェント: #keyword: Zabbix SNMP items
                        設定:
                            メニュー: Zabbix >> 設定 >> ホスト（または）テンプレート >>（対象の行の）アイテム
                            ホストインターフェース: 接続先のホスト
                            キー:
                            SNMP OID: #search: MIB OID
                            SNMPコミュニティ:
                        #search: Zabbix SNMP agent
                    SSH エージェント: #keyword: Zabbix SSH items  #search: Zabbix SSH check  #// SSH 経由で任意のコマンドを実行して監視データを取得します
                        #// 取得内容は、スクリプトの内容によります
                        メニュー: Zabbix >> 設定 >> ホスト（または）テンプレート >>（対象の行の）アイテム >> アイテムの作成（右上）
                        実行するスクリプト:
                            ls -l $HOME | wc --lines
                    外部チェック: #keyword: Zabbix external check items  #search: Zabbix external check  #// Zabbix サーバーで任意のコマンドを実行して監視データを取得します
                        実行するホスト: Zabbix サーバー
                        スクリプトの置き場所, 内容: #search: Zabbix ExternalScripts
                    Zabbix インターナル:
                        Zabbix 自体の稼働状況を監視します。負荷率
                        #ref: https://unam.hatenadiary.jp/entry/2018/01/27/193310
                        #search: Zabbix poller
            設定手順: #keyword: create Zabbix item
                設定値のサンプル: #search: Zabbix main items
                （対象のホストをまだ登録していない場合）: #search: create Zabbix host
                名前: 任意
                キー:  #// 以下のいずれか
                    公式ページから探してキーボードから入力するかコピペします: #keyword: Zabbix item help
                        英語 5.0:  #ref: https://www.zabbix.com/documentation/5.0/en/manual/config/items/itemtypes/zabbix_agent
                        日本語 2.2: 文章が崩れています  #ref: https://www.zabbix.com/documentation/2.2/jp/manual/config/items/itemtypes/zabbix_agent
                    選択 ボタンを押して、ブラウザーの検索機能でアイテムのキーを検索します:
                データ型: 公式ページを参照  #search: Zabbix item help
                監視間隔: デフォルトを推奨。長く設定しても テスト ボタン（下記）ですぐに値を確認できます
                テスト ボタン（下）:
                値の取得とテスト ボタン（右下）:
                追加 ボタン:
            現在の値: #keyword: read Zabbix item
                Zabbix 5.0:
                    メニュー: Zabbix >> 設定 >> ホスト >>（対象のホストの行の）アイテム >>（アイテム名：2列目）>> テスト ボタン（最も下）
                    負荷をかけます: #search: Linux stress
                Zabbix 4.0:
                    グラフ: #search: Zabbix graph
                        Zabbix >> 監視データ >> 最新データ >> リセット >> （ホストの）選択 >>（ホスト名）>> 選択 >> 適用 >> グラフ（右端）>>
                            表示形式（右上）＝値
            過去の値: #// 監視データ  #search: Zabbix host monitoring data
        トリガー:  #keyword: Zabbix trigger  #// 警告など, 障害の発生条件の設定
            表示: #search: Zabbix trigger menu
            追加: #keyword: create Zabbix trigger
                Zabbix のフロントエンドで操作する場合:
                    基本:
                        メニュー: Zabbix >> 設定 >> ホスト >> トリガー >> トリガーの作成（右上）
                        名前: CPU load (1min)  #// 任意
                        深刻度: 警告
                        条件式:
                            追加 ボタン:
                            アイテム: 選択 >> CPU load (1min)
                            結果: [">", 0.5]
                            挿入 ボタン:
                            #// 条件式に MIB の OID を指定できるらしい
                        追加 ボタン:
                    応用:
                        復旧条件式:  #// 障害状態から正常状態に戻すための条件。条件式とは別に設定できる
                        タグ: #keyword: Zabbix trigger tag
                            トリガーするタグ。 複数種類の障害に対して、1種類のアクションを実行する場合に使います。
                            その場合、アクションの条件に「タグを含む」を設定します。
            テスト: #keyword: Zabbix stress test  #// 障害を発生させてみます
                CPU の負荷を高めます:
                    （監視対象のホスト）:
                        stress  --cpu 2  --timeout 60  #// 2つのスレッドを 60秒間だけ動かし続けます
                        #// stress のインストール  #search: Linux stress
                確認します:
                    #search: Zabbix trigger status
                関連:
                    障害発生時にメールを送るように設定します: #search: Zabbix mail
            障害の表示: #keyword: Zabbix trigger status  #// トリガーの状態を確認します
                メニュー: Zabbix >> 設定 >> ホスト >> トリガー
            ステータス: #// 有効か無効かを設定できます。リード オンリー ではありません
        アクション:  #// 障害発生時の処理
            条件 >> タグを含む:  #search: Zabbix trigger tag
            メール通知: #keyword: Zabbix mail  #// 障害発生時にメールを送るように設定します
                公式: #ref: https://www.zabbix.com/documentation/2.2/jp/manual/config/notifications/media/email
                メディアタイプを設定します:  #// 送信元の メール サーバー に関する設定
                    メニュー: Zabbix >> 管理 >> メディアタイプ >> Email
                    名前: Email
                    タイプ: メール
                    SMTPサーバー: localhost
                    SMTP helo: localhost
                    送信元メールアドレス: zabbix@zabbix1
                    更新 ボタン:
                ユーザーのメディアを設定します:  #// 送信元のユーザーと送信先に関する設定
                    メニュー: Zabbix >> 管理 >> ユーザー >> Admin >> メディア（タブ）>> 追加
                    タイプ: Email
                    送信先: vagrant@localhost.localdomain  #// サンプル
                        #// 送信先の近くにある 追加 をクリックすると複数の送信先を登録できます
                    追加 ボタン（右下）:
                    更新 ボタン（左下）: 押し忘れないこと
                障害発生時にメールを送る機能を有効にします:
                    メニュー: Zabbix >> 設定 >> アクション >>
                        （Report problems to Zabbix administrators の行のステータス列）無効
                        （をクリックして有効にします）
                テストします: #keyword: Zabbix mail test
                    受信前の受信メール一覧を確認します:
                        #search: Linux mail command example
                    障害を発生させます:
                        stress  --cpu 2  --timeout 60  #search: Zabbix stress test
                    アクションの結果を確認します:
                        レポート メニューの場合:
                            メニュー: Zabbix >> レポート >> アクションログ
                            ステータス: 送信済み, 失敗, 実行中
                            情報: （スクリプトの標準出力の内容）
                                #// 成功した場合、情報は表示されません。zabbix_server.log にも記録されません
                        監視データ メニューの場合:
                            Zabbix >> 監視データ >> 障害 >>（下半分にある表の）アクション（列）>>
                            ステータス（列）
                            #// 送信済（緑）と表示されていること
                    メール送信のログを確認します:
                        (vagrant@zabbix1):
                            sudo less /var/log/maillog  #search: /var/log/maillog
                    受信したメールの内容を確認します:
                        #search: Linux mail
            スクリプト実行: #keyword: Zabbix alert script,  Zabbix AlertScripts
                注意: 未確認
                公式: #ref: https://www.zabbix.com/documentation/current/en/manual/config/notifications/media/script
                スクリプトの置き場所: #search: Zabbix AlertScriptsPath
                追加: #keyword: create Zabbix alert script
                    スクリプトを作ります:
                        bash スクリプトの場合:
                            bash (@zabbix1): |
                                edit=/usr/lib/zabbix/alertscripts/mail.sh  #search: Zabbix AlertScriptsPath
                                sudo mkdir -p ${edit}
                                sudo rmdir    ${edit}
                                sudo tee ${edit} > /dev/null
                                    #!/bin/bash
                                    to=$1
                                    subject=$2
                                    body=$3
                                    echo '$to'
                                    echo "$to"
                                    echo '$subject'
                                    echo "$subject"
                                    echo '$body'
                                    echo "$body"

                                    cat <<- HERE_DOCUMENT | mail -s "$subject" "$to"
                                    $body
                                    HERE_DOCUMENT
                                sudo chown zabbix:zabbix ${edit}
                                sudo chmod +x ${edit}
                                ls -l ${edit}
                        Python3 の場合:  #keyword: Zabbix Python3
                            Python3 を @zabbix1 サーバーにインストールします:
                                #search: install CentOS7 Python3
                            bash (@zabbix1): |
                                edit=/usr/lib/zabbix/alertscripts/mail.py  #search: Zabbix AlertScriptsPath
                                sudo mkdir -p ${edit}
                                sudo rmdir    ${edit}
                                sudo tee ${edit} > /dev/null
                                    #!/usr/bin/python3
                                    import sys, smtplib, textwrap
                                    to = sys.argv[1]
                                    subject = sys.argv[2]
                                    body = sys.argv[3]
                                    print("to")
                                    print( to )
                                    print("subject")
                                    print( subject )
                                    print("body")
                                    print( body )
                                    from_ = 'zabbix@localhost.localdomain'
                                    message = textwrap.dedent(f"""\
                                        From: zabbix@localhost.localdomain
                                        To: {to}
                                        Subject: {subject}
                                    
                                        {body}""")

                                    smtp = smtplib.SMTP('localhost')
                                    smtp.sendmail(from_, to, message)
                                    smtp.close()
                                sudo chown zabbix:zabbix ${edit}
                                sudo chmod +x ${edit}
                                ls -l ${edit}
                    メディアタイプを追加します:  #// スクリプトを指定します
                        メニュー: Zabbix >> 管理 >> メディアタイプ >> メディアタイプの作成（右上）
                        名前: mail script  #// メディアのタイプ名になります
                        タイプ: スクリプト
                        スクリプト名: mail.sh  #// ファイル名
                        スクリプトパラメータ:  #// 通常、下記のまま指定
                            - {ALERT.SENDTO}
                            - {ALERT.SUBJECT}
                            - {ALERT.MESSAGE}
                            #ref: https://www.zabbix.com/documentation/current/en/manual/appendix/macros/supported_by_location
                        追加 ボタン:
                    ユーザーのメディアを設定します:  #// 送信元のユーザーと送信先に関する設定
                        メニュー: Zabbix >> 管理 >> ユーザー >> Admin >> メディア（タブ）>> 追加
                        タイプ: mail script
                        送信先: vagrant@localhost.localdomain  #// サンプル
                            #// 送信先の近くにある 追加 をクリックすると複数の送信先を登録できます
                        追加 ボタン（右下）:
                        更新 ボタン（左下）: 押し忘れないこと
                    テストします:
                        #search: Zabbix mail test
        テンプレート: #keyword: Zabbix template  #// アイテムやトリガーをまとめたもの。ホストのスーパークラスに相当
            表示:  #search: Zabbix template menu
            テンプレートのインポート: Zabbix >> Configuration（上）>> Templates >> Import（右上）>>
                ファイルの選択 >> zbx_export_templates.xml >> Import（左下） #// 10秒ほど待つ。結果は左上に表示
            サンプル:  #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: Zabbix template
            リファレンス:  #ref: https://www.zabbix.com/documentation/5.0/en/manual/xml_export_import/templates
        アプリケーション: #keyword: Zabbix application  #// 主なアイテムのグループ
            追加: #keyword: create Zabbix application
                アプリケーションの一覧画面から追加する場合:
                    アプリケーションの作成（右上）:
                アイテムの画面から追加する場合:
                    アプリケーションの作成（中央）:
        マクロ: #keyword: Zabbix macro
            公式: #ref: https://www.zabbix.com/documentation/current/en/manual/config/macros
            参照の書式: |  #// $ は { の右にあることに注意
                {$__MacroName__}  
            サンプル:
                外部チェックで呼び出すスクリプトにマクロを指定します:
                    #search: Zabbix macro in external check
            ユーザー定義マクロ:
                表示: Zabbix >> 設定 >> ホスト（または）テンプレート >>（特定のホストまたはテンプレート）>> マクロ タブ
                オーバーライド:
                    ホストと、そのホストに関連付けられたテンプレートの両方で同じ名前のマクロが定義されている場合、
                    ホストに近い定義内容が採用されます。
                グローバル マクロ: Zabbix >> 管理 >> 一般設定 >> マクロ（右上のドロップダウン内）
            定義済みマクロ:
                #ref: https://www.zabbix.com/documentation/current/en/manual/appendix/macros/supported_by_location
        メンテナンス モード: #keyword: Zabbix maintenance mode
            概要: メンテナンス モードでは、ホスト/トリガーに対する問題がエスカレーション(problem escalations)されなくなります。
                たとえば、メンテナンスをしているときに問題を検出したとしても、メールや Slack への通知させないようにします。
                #ref: https://www.zabbix.com/documentation/current/en/manual/maintenance
            表示: Zabbix >> Configuration（タブ）>> Mainteinance（タブ）  #search: Zabbix maintenance menu
            データ収集ありのモード:
            データ収集なしのモード:
            タイムゾーン:
                デフォルト:
                    Zabbix 4.0 の Docker コンテナーのデフォルトでは、PHP のタイムゾーン Europe/Riga (UTC+3) が使われます。
                    #search: PHP time zone
                構成:
                    DB (PostgreSQL) に入っている maintenances の active_since Unix time と、curl (API) で取得できる active_since Unix time は同じ値です。
                    WebUI で表示される maintenances の active_since は Windows のタイムゾーンの設定を変えても変わりません。ダッシュボードの時計は変わります。
    Zabbix web application:  #keyword: Zabbix web application, Zabbix front end, Zabbix console GUI  #// フロントエンド
        _: ここはメニューのみ, 重要度順, バージョン 5.0
        URL: #ref: http://__ZabbixServer__/zabbix
        メニュー (Zabbix 6): #keyword: Zabbix 6 WebUI
            データ収集:
                ホスト:  #keyword: Zabbix6 host menu
                    アイテム, トリガー, グラフ, ...
                メンテナンス（の一覧）: #keyword: Zabbix6 maintenance menu  #// メンテナンス期間
                    #search: Zabbix maintenance mode
        メニュー (Zabbix 4) : #keyword: Zabbix 4 WebUI
            監視データ: #keyword: Zabbix monitoring
                ダッシュボード:  #// 監視データの一覧
                ホスト: #keyword: Zabbix host monitoring data  #// 監視対象の監視結果。設定は、設定（←メニューのグループ）にあります
                    インターフェース: #// IP アドレスとポート
                    エージェントの状態: #// 緑色＝正常, 赤色＝異常
                    最新データ: #// CPU 使用率, メモリー使用率など
                        関連 >> 現在の値を取得します: #search: read Zabbix item
                    グラフ: #// 最新データのグラフ
            設定: #keyword: Zabbix configuration,  Zabbix settings
                ホスト（の一覧）: #keyword: Zabbix host configuration  #// 監視対象となる Windows や Linux などの設定
                    （概要）: アイテム タブなどは、テンプレートから継承するアイテムなども表示されます。
                        その場合、アイテム名の左にテンプレート名が表示されます。
                    ホスト: #keyword: Zabbix host menu
                        例: Zabbix server
                        表示: 設定 >> ホスト >> 名前（にホスト名の一部を入力）>> 適用 >>（ホスト名：1列目）
                            #// 見つからないときは #search: Zabbix search not found
                    アイテム: #keyword: Zabbix item menu  #search: Zabbix item  #// 監視項目
                        キーの例: system.cpu.util,  system.cpu.load
                        表示: 設定 >> ホスト >> アイテム（表の3列目）>> 名前（にアイテム名の一部を入力）>> 適用 >>（アイテム名：1列目）
                    トリガー: #keyword: Zabbix trigger menu  #// 警告（の一覧）, 警告の発生条件
                        例: High CPU utilization (over {$CPU.UTIL.CRIT}% for 5m)
                        表示:
                            Zabbix 5: 設定 >> ホスト >> トリガー（表の4列目）>> 名前（にトリガー名の一部を入力）>> 適用 >>（トリガー名：1列目）
                            Zabbix 4: 設定 >> ホスト >> Reset ボタン（中央）>>（任意のホストの）トリガー >>
                                ホスト（右上）＝ALL（最上）>> Name でソート >>（トリガー名）>> Parent triggers
                        説明: #search: Zabbix trigger
                        通知先: 監理 メニュー >> メディアタイプ  #search: Zabbix media type
                    関連するテンプレート: #// 継承する親のテンプレート
                        表示: 設定 >> ホスト >> テンプレート >> （テンプレート名：1列目）
                        #// ブラウザーの新しいタブで表示されます
                テンプレート（の一覧）: #keyword: Zabbix template menu  #// 監視内容, 監視内容の設定集, ホストのスーパークラスに相当
                    （検索）: 名前
                    テンプレート: #search: Zabbix template
                        例: Template OS Linux by Zabbix agent
                        表示: （テンプレートの一覧画面）>> 名前（にテンプレート名の一部を入力）>> 適用 >>（テンプレート名：1列目）
                    アイテム: #// テンプレートに定義されたアイテム
                    トリガー: #// テンプレートに定義されたトリガー
                    関連するホスト: #// テンプレートを使っているホスト
                    関連するテンプレート: #// スーパークラスのスーパークラスに相当
                        表示: （テンプレートの画面）>>（テンプレート名）タブ >> テンプレートとのリンク タブ >> （テンプレート名：1列目）
                        #// ブラウザーの新しいタブで表示されます
                ホストグループ（の一覧）: #keyword: Zabbix host group menu  #// ホストおよびテンプレートのグループ, ブラウズ用
                    ホストグループ: #search: Zabbix host group
                        例: Zabbix servers, Virtual machines
                        表示: （ホストグループの一覧画面）>> 名前（にホストグループ名の一部を入力）>> 適用 >>（ホストグループ名：1列目）
                    （一覧表）:
                        ホスト, テンプレート: 数字はホストグループが持っているホストやテンプレートの数です。
                            数字が無いときは、持っていません。
                        メンバー:
                            灰色: テンプレート
                            緑や赤: ホスト
                メンテナンス（の一覧）: #keyword: Zabbix4 maintenance menu  #// メンテナンス期間
                    #search: Zabbix maintenance mode
            管理: #keyword: Zabbix administration
                メディアタイプ（の一覧）: #keyword: Zabbix media type  #// 警告先のサービス。メールや SMS など
                    設定:
                        Email: #keyword: Zabbix e-mail
                            SMTPサーバー: mail.example.com から変更してください
                    テスト:
                        （メディアタイプの一覧画面）>> テスト（メディアの行の最も右）
            スクリプト: #keyword: Zabbix administration script
                Zabbix 6.0: #ref: https://www.zabbix.com/documentation/6.0/en/manual/web_interface/frontend_sections/administration/scripts
                Zabbix 2.0: #ref: https://www.zabbix.com/documentation/2.0/en/manual/web_interface/frontend_sections/administration/scripts
    API:  #keyword: Zabbix API
        概要:
            管理画面上で行う各種操作を管理画面を使用せずに行える。
            ユーザー、ホスト、アイテム（CPU usage など）、トリガーの作成や取得などができます。
            JSON-RPC というプロトコルを用いて HTTP で Zabbix フロントエンドにアクセスして、Zabbix を操作することができます。
            ansible には community.zabbix モジュールがあります。
        参考:
            API リファレンス:  #ref: https://www.zabbix.com/documentation/2.0/en/manual/appendix/api/api
            非公式解説:  #ref: https://www.sraoss.co.jp/technology/zabbix/introduction/03-3rdstep/
        サンプル curl コマンド:  #keyword: Zabbix API curl
            ログインします:  #keyword: Zabbix API user.login
                (@control): |
                    curl -X GET -i -d '{"jsonrpc": "2.0", "auth": null, "id": 1,
                        "method": "user.login",
                        "params": {
                            "username": "Admin",
                            "password": "zabbix"
                    }}' -H "Content-Type: application/json-rpc" http://zabbix1/zabbix/api_jsonrpc.php
                    zabbix_auth="__ReturnedAuthentication__"
                    zabbix_session_ID=1
                    zabbix_session_ID=$(( $zabbix_session_ID + 1 ))
                #// 環境によっては ____/zabbix/api_jsonrpc.php ではなく ____/api_jsonrpc.php の場合もあります
                #// Zabbix 4 以前？は、username ではなく user です。
            ログアウトします:  #keyword: Zabbix API user.logout
                (@control): |
                    curl -X GET -i -d '{"jsonrpc": "2.0", "auth": "'${zabbix_auth}'", "id": '${zabbix_session_ID}',
                        "method": "user.logout",
                        "params": {
                    }}' -H "Content-Type: application/json-rpc" http://zabbix1/zabbix/api_jsonrpc.php
                    zabbix_session_ID=$(( $zabbix_session_ID + 1 ))
                期待される出力:
                    {"jsonrpc":"2.0","result":true,"id":____}
        サンプル.php: |
            <?php
            require 'ZabbixApi.class.php';
            try {

                $api = new ZabbixApi('http://localhost/zabbix/api_jsonrpc.php', 'Admin', 'zabbix');

                $res = $api->apiinfoVersion();
                var_dump($res);
            } catch (Exception $e) {
                echo $e->getMessage() . "\n";
            }
            ?>
        ホスト:  #keyword: Zabbix API host
            ホスト名からホストID を調べます:
                host.get hostid: |  #search: Zabbix API curl  #ref: https://www.zabbix.com/documentation/2.0/en/manual/appendix/api/host/get
                    "method": "host.get",
                    "params": {
                        "output": ["hostid"],
                        "filter": {
                            "host": [
                                "Zabbix server"
                            ]
                        }
                    },
                出力例:  #keyword: Zabbix API output filter example
                    {"jsonrpc":"2.0","result":[{"hostid":"10084"}],"id":3}
            ホスト名からホストの情報を調べます:
                host.get: |  #search: Zabbix API curl  #ref: https://www.zabbix.com/documentation/2.0/en/manual/appendix/api/host/get
                    "method": "host.get",
                    "params": {
                        "output": "extend",
                        "filter": {
                            "host": [
                                "Zabbix server"
                            ]
                        }
                    },
                出力例:
                    {"jsonrpc":"2.0","result":[{"hostid":"10084","proxy_hostid":"0","host":"Zabbix server","status":"0","disable_until":"0",
                    "error":"","available":"1","errors_from":"0","lastaccess":"0",
                    "ipmi_authtype":"-1","ipmi_privilege":"2","ipmi_username":"","ipmi_password":"","ipmi_disable_until":"0","ipmi_available":"0",
                    "snmp_disable_until":"0","snmp_available":"0",
                    "maintenanceid":"0","maintenance_status":"0","maintenance_type":"0","maintenance_from":"0",
                    "ipmi_errors_from":"0","snmp_errors_from":"0","ipmi_error":"","snmp_error":"",
                    "jmx_disable_until":"0","jmx_available":"0","jmx_errors_from":"0","jmx_error":"",
                    "name":"Zabbix server","flags":"0","templateid":"0","description":"",
                    "tls_connect":"1","tls_accept":"1","tls_issuer":"","tls_subject":"","tls_psk_identity":"","tls_psk":"",
                    "proxy_address":"","auto_compress":"1"}],"id":2}
        ホスト グループ:  #keyword: Zabbix API host group
            名前からグループID を調べます:
                hostgroup.get: |  #search: Zabbix API curl  #ref: https://www.zabbix.com/documentation/2.0/en/manual/appendix/api/hostgroup/get
                    "method": "hostgroup.get",
                    "params": {
                        "output": "extend",
                        "filter": {
                            "name": [
                                "Templates/Databases"
                            ]
                        }
                    },
                出力例:
                    {"jsonrpc":"2.0","result":[{"groupid":"13","name":"Templates/Databases","internal":"0","flags":"0"}],"id":2}
            ホスト一覧:  #ref: ${typrm_files}/ref/VMWare-AI.yaml#label: host list API from AI
        監視データ: #keyword: Zabbix API history.get
            (@control): |
                curl -X GET -i -d '{"jsonrpc": "2.0", "auth": "'${zabbix_auth}'", "id": '${zabbix_session_ID}',
                    "method": "history.get",
                    "params": {
                        "output": "extend", "time_from": 1745593200, "time_till": 1745679599, "history": 3, "itemids": [1111, 2222],
                        "sortfield": "time", "sortorder": "ASC"
                }}' -H "Content-Type: application/json-rpc" http://zabbix1/zabbix/api_jsonrpc.php
                zabbix_session_ID=$(( $zabbix_session_ID + 1 ))
            注意:
                - もし、データが無ければ、histories に格納されません
                - 値が 0 のデータがあれば、histories に値 0 が格納されます
                - history（型）が違うと格納されません
        テンプレート:  #keyword: Zabbix API template
            テンプレート名からテンプレートID を調べます:
                template.get: |  #search: Zabbix API curl  #ref: https://www.zabbix.com/documentation/2.0/en/manual/appendix/api/template/get
                    "method": "template.get",
                    "params": {
                        "output": ["templateid"],
                        "filter": {
                            "host": [
                                "Template App Zabbix Agent"
                            ]
                        }
                    },
                出力例:
                    {"jsonrpc":"2.0","result":[{"templateid":"10050"}],"id":5}
            テンプレート名からテンプレートの情報を調べます:
                template.get: |  #search: Zabbix API curl  #ref: https://www.zabbix.com/documentation/2.0/en/manual/appendix/api/template/get
                    "method": "template.get",
                    "params": {
                        "output": "extend",
                        "filter": {
                            "host": [
                                "Template App Zabbix Agent"
                            ]
                        }
                    },
                出力例:
                    {"jsonrpc":"2.0","result":[{"proxy_hostid":"0","host":"Template App Zabbix Agent","status":"3","disable_until":"0",
                    "error":"","available":"0","errors_from":"0","lastaccess":"0",
                    "ipmi_authtype":"-1","ipmi_privilege":"2","ipmi_username":"","ipmi_password":"","ipmi_disable_until":"0","ipmi_available":"0",
                    "snmp_disable_until":"0","snmp_available":"0",
                    "maintenanceid":"0","maintenance_status":"0","maintenance_type":"0","maintenance_from":"0",
                    "ipmi_errors_from":"0","snmp_errors_from":"0","ipmi_error":"","snmp_error":"",
                    "jmx_disable_until":"0","jmx_available":"0","jmx_errors_from":"0","jmx_error":"",
                    "name":"Template App Zabbix Agent","flags":"0",
                    "templateid":"10050","description":"",
                    "tls_connect":"1","tls_accept":"1","tls_issuer":"","tls_subject":"","tls_psk_identity":"","tls_psk":"",
                    "proxy_address":"","auto_compress":"1"}],"id":4}
        アイテムの一括登録:
            参考: 7. アイテムの一括登録  https://www.sraoss.co.jp/technology/zabbix/introduction/03-3rdstep/
            サンプル: |
                // CPU usage アイテムを作成
                $res = $api->itemCreate( array( 'name' => 'CPU usage (API)',
                                                'key_' => 'system.cpu.util[,user,avg1]',
                                                'hostid' => $hostid,
                                                // type 0: Zabbix エージェント
                                                'type' => 0,
                                                // value_type 0: 浮動小数
                                                'value_type' => 0,
                                                'delay' => 30,
                                            ) );
                var_dump($res);

                // Load average アイテムを作成
                $res = $api->itemCreate( array( 'name' => 'Load average (API)',
                                                'key_' => 'system.cpu.load[]',
                                                'hostid' => $hostid,
                                                'type' => 0,
                                                'value_type' => 0,
                                                'delay' => 30,
                                            ) );
                var_dump($res);
        メンテナンス:
            maintenance.create:  #search: Zabbix API curl  #ref: https://www.zabbix.com/documentation/6.4/en/manual/api/reference/maintenance/create
                リクエスト: |
                    "method": "maintenance.create",
                    "params": {
                        "name": "Sunday maintenance",
                        "active_since": 1358844540,
                        "active_till": 1390466940,
                        "groupids": [
                            "2"
                        ],
                        "timeperiods": [
                            {
                                "timeperiod_type": 3,
                                "every": 1,
                                "dayofweek": 64,
                                "start_time": 64800,
                                "period": 3600
                            }
                        ]
                    },
        応用:
            複数の出力を要求します:
                filter の場合:
                    書式: |  #focus: __Value1__, __Value2__
                        "filter": {
                            "__FieldName__": [
                                "__Value1__",
                                "__Value2__"
                            ]
                        }
                search の場合:  #search: Zabbix API or
            ワイルドカードなどでテンプレート名を検索します:
                完全一致: #// filter
                    filter: |  #focus: filter
                        "method": "template.get",
                        "params": {
                            "output": ["templateid"],
                            "filter": {
                                "host": [
                                    "Template App HTTP Service"
                                ]
                            }
                        },
                    出力例:
                        #// Template App HTTP Service にマッチした場合の例
                        {"jsonrpc":"2.0","result":[{"templateid":"10094"}],"id":8}
                部分一致: #// search  #ref: https://devlog.arksystems.co.jp/2021/04/13/14285/
                    search: |  #focus: search
                        "method": "template.get",
                        "params": {
                            "output": ["templateid"],
                            "search": {
                                "host": [
                                    "HTTP"
                                ]
                            }
                        },
                    出力例:
                        #// Template App HTTP Service と Template App HTTPS Service にマッチした場合の例
                        {"jsonrpc":"2.0","result":[{"templateid":"10094"},{"templateid":"10095"}],"id":10}
                大文字小文字区別:  #// 区別しません
                    search: |  #focus: search
                        "method": "template.get",
                        "params": {
                            "output": ["templateid"],
                            "search": {
                                "host": [
                                    "http"
                                ]
                            }
                        },
                    出力例:
                        #// Template App HTTP Service と Template App HTTPS Service にマッチした場合の例
                        {"jsonrpc":"2.0","result":[{"templateid":"10094"},{"templateid":"10095"}],"id":10}
                ワイルドカード: #// 接頭辞や接尾辞  #ref: https://devlog.arksystems.co.jp/2021/04/13/14285/
                    基本:
                        searchWildcardsEnabled: |  #focus: searchWildcardsEnabled, search, *
                            "method": "template.get",
                            "params": {
                                "output": ["templateid"],
                                "searchWildcardsEnabled": true,
                                "search": {
                                    "host": [
                                        "* proxy"
                                    ]
                                }
                            },
                        出力例:
                            #// Template App Zabbix Proxy と Template App Remote Zabbix proxy にマッチした場合の例
                            {"jsonrpc":"2.0","result":[{"templateid":"10048"},{"templateid":"10262"}],"id":26}
                    1つの文字列の中に複数の *:
                        "* proxy": Template App Remote Zabbix proxy にマッチ
                        "* Remote * proxy": Template App Remote Zabbix proxy にマッチ
                        "Remote * proxy": Template App Remote Zabbix proxy にマッチしない
                    複数の文字列:
                        searchByAny: |  #// searchByAny が無いとマッチしません
                            "method": "template.get",
                            "params": {
                                "output": ["templateid"],
                                "searchWildcardsEnabled": true,
                                "searchByAny": true,
                                "search": {
                                    "host": [
                                        "* Remote * proxy",
                                        "* HTTP *"
                                    ]
                                }
                            },
                        出力例:
                            #// Template App HTTP Service と Template App Remote Zabbix proxy にマッチした場合の例
                            {"jsonrpc":"2.0","result":[{"templateid":"10094"},{"templateid":"10262"}],"id":27}
                and 条件:  #ref: https://devlog.arksystems.co.jp/2021/04/13/14285/
                    search: |  #focus: Zabbix, Remote  #// 追加オプションなし
                        "method": "template.get",
                        "params": {
                            "output": ["templateid"],
                            "search": {
                                "host": [
                                    "Zabbix", "Remote"
                                ]
                            }
                        },
                    出力例:
                        #// Template App Remote Zabbix proxy と Template App Remote Zabbix server にマッチし
                        #// Template App Zabbix Agent にマッチしない場合の例
                        {"jsonrpc":"2.0","result":[{"templateid":"10261"},{"templateid":"10262"}],"id":12}
                or 条件: #keyword: Zabbix API or  #ref: https://devlog.arksystems.co.jp/2021/04/13/14285/
                    searchByAny: |  #focus: searchByAny, SNMPv1, SNMPv2
                        "method": "template.get",
                        "params": {
                            "output": ["templateid"],
                            "searchByAny": true,
                            "search": {
                                "host": [
                                    "Generic SNMPv1", "Generic SNMPv2"
                                ]
                            }
                        },
                    出力例:
                        #// Template Module Generic SNMPv1 と Template Module Generic SNMPv2 にマッチした場合の例
                        {"jsonrpc":"2.0","result":[{"templateid":"10203"},{"templateid":"10204"}],"id":15}
            出力項目をフィルタリングします:  #keyword: Zabbix API output filter
                書式: |
                    "output": ["__FieldName__"],
                #search: Zabbix API output filter example
    設定ファイル:
        サーバー:
            サービス: #keyword: zabbix_server.conf  #ref: /etc/zabbix/zabbix_server.conf
                公式: #ref: https://www.zabbix.com/documentation/2.2/en/manual/appendix/config/zabbix_server
                編集: sudo vi /etc/zabbix/zabbix_server.conf
                設定項目:
                    AlertScriptsPath: #keyword: Zabbix AlertScriptsPath
                        インストール直後の値: /usr/lib/zabbix/alertscripts
                        省略時の値: /usr/local/share/zabbix/alertscripts
                        スクリプト実行: #search: Zabbix alert script
                    ExternalScripts: #keyword: Zabbix ExternalScripts
                        インストール直後の値: /usr/lib/zabbix/externalscripts
                        省略時の値: /usr/local/share/zabbix/externalscripts
                        スクリプト実行: #search: Zabbix external check
            エクスポート・インポート: #keyword: Zabbix export import
                公式: #ref: https://www.zabbix.com/documentation/current/en/manual/xml_export_import
                XML などのファイルにエクスポートします:
                    #// Zabbix 4.0 は XML のみ。6.0 は XML, JSON, YAML
                    エクスポートする種類の一覧画面を開きます:  #// すべての種類を一度にエクスポートすることはできません
                        設定 メニュー: ホスト グループ, テンプレート, ホスト
                        （その他のメニュー）: ネットワーク マップ, 画面
                            #ref: https://www.zabbix.com/documentation/4.0/en/manual/xml_export_import/maps
                    エクスポートする行を選択します: #// すべて選択することもできますが、ページネーションがあるので注意
                    エクスポート ボタン（下）:
                全設定を新しいサーバーに移動します:
                    データベースをコピーします
                    #ref: https://www.zabbix.com/forum/zabbix-help/50603-export-configuration-to-a-new-installation
        Zabbix エージェント:  #search: Zabbix agent  #ref: /etc/zabbix/zabbix_agentd.conf
            公式: #ref: https://www.zabbix.com/documentation/2.2/en/manual/appendix/config/zabbix_agentd
            パス: sudo vi /etc/zabbix/zabbix_agentd.conf
            設定項目:
                Server: Zabbix サーバーの IP アドレス または DNS で解決できる名前
            Zabbix エージェント:
                #search: Zabbix agent
        MIB: #search: MIB file  #// ミブ ファイル  #ref: https://www.zabbix.com/documentation/5.4/en/manual/config/items/itemtypes/snmp/mibs
    トラブルシューティング (Zabbix):
        - #// ログ
            監視データ, 障害:
                #search: Zabbix monitoring
            ログ ファイル:
                sudo less /var/log/zabbix/zabbix_server.log
                sudo less /var/log/maillog
            アクション ログ:
                Zabbix >> レポート >> アクションログ
        - #// Zabbix サーバーが動作していません
            ケース1:
                手順: systemctl status zabbix-server
                エラー: inactive
            ケース2:
                手順: Zabbix フロントエンドを開く
                エラー: Zabbix サーバーが動作していません
            対処A:
                ログを確認します:
                    less /var/log/zabbix/zabbix_server.log
            対処B:
                SELinux の設定をします:
                    #search: Zabbix SELinux
        - #// Incorrect default charset for Zabbix database: "utf8mb3" instead "UTF8".
            手順: Zabbix WebUI のデータベースのページを入力
            エラー: |
                Incorrect default charset for Zabbix database: "utf8mb3" instead "UTF8".
            対処:
                MySQL のバージョンを古くします  #search: yum install old version
        - #// Cannot bind socket to "/var/run/zabbix/zabbix_server_lld.sock"
            手順: systemctl restart zabbix-server
            エラー: |
                - cannot start LLD manager service: Cannot bind socket to "/var/run/zabbix/zabbix_server_lld.sock": [13] Permission denied.
                - cannot start LLD manager service: Cannot bind socket to "/var/run/zabbix/zabbix_server_lld.sock": [98] Address already in use.
            対処:
                SELinux の設定をします:
                    #search: Zabbix SELinux
        - #// 検索しても見つからない。ホストやテンプレートなどに共通
            #keyword: Zabbix search not found
            手順: たとえば、（ホストの一覧画面）>> 名前（にホスト名の一部を入力）>> 適用
            エラー: |
                データがありません。
            対処:
                - リセット ボタン（適用 ボタンの右）を押して、検索条件を再入力します
                - グループ（右上）を正しく選びます
        - #// エージェントから監視データを取得できない
            手順:
                Zabbix 5: アイテムのメニューからテストを選んだとき
                Zabbix 4: Zabbix >> 設定 >> ホスト >> アイテム（列）>> エラー
                    または
                    監視データ >> 最新データ >> ｛ 最新のチェック時刻 ＝ インターバルの時間より古すぎる, 最新の値（列）＝ 空欄 }
            エラー: |
                Received empty response from Zabbix Agent. Assuming that agent dropped connection because of access permissions
            対処A:
                Zabbix エージェントをインストールします  #search: install Zabbix5 agent CentOS7
            対処B:
                zabbix_agentd.conf の Server を設定します  #search: zabbix_agentd.conf
        - #// グラフ タブ に表示されない
            手順: Zabbix >> 最新データ >> グラフ
            対処: Zabbix >> 設定 >> ホスト >> グラフ
        - #// 障害発生メールを受信できない
            手順: 障害を発生させます  #search: Zabbix mail  #// >> テスト
            ケースA:  #// アクション ログ で 
                エラー:
                    - Zabbix >> レポート >> アクションログ >> ステータス:
                        失敗
                    - Zabbix >> レポート >> アクションログ >> 情報:
                        No media defined for user.
                対処:
                    管理 >> ユーザー >> Admin >> メディア（タブ）をチェックします
                    #search: Zabbix mail
            ケースB:  #// 送信先ユーザー名が間違っている場合
                エラー:
                    sudo less /var/log/maillog : |  #// 下記は成功していますがユーザー名に注意
                        Apr 11 11:11:11 localhost postfix/smtpd[4073]: connect from localhost[::1]
                        Apr 11 11:11:11 localhost postfix/smtpd[4073]: 15B864048000: client=localhost[::1]
                        Apr 11 11:11:11 localhost postfix/cleanup[4076]: 15B864048000: message-id=<20220411044645.15B864048000@localhost.localdomain>
                        Apr 11 11:11:11 localhost postfix/qmgr[798]: 15B864048000: from=<zabbix@zabbix1.localdomain>, size=684, nrcpt=1 (queue active)
                        Apr 11 11:11:11 localhost postfix/smtpd[4073]: disconnect from localhost[::1]
                        Apr 11 11:11:11 localhost postfix/local[4077]: 15B864048000: to=<zabbix@localhost.localdomain>, relay=local, delay=0.08, delays=0.05/0.02/0/0.01, dsn=2.0.0, status=sent (delivered to mailbox)
                        Apr 11 11:11:11 localhost postfix/qmgr[798]: 15B864048000: removed
                対処:
                    送信先のメールアドレスを修正します
                    #search: Zabbix mail
        - #// API コール Session terminated, re-login, please.
            手順: API コール  #search: Zabbix API
            エラー: |
                "jsonrpc":"2.0","error":{"code":-32602,"message":"Invalid params.","data":"Session terminated, re-login, please."},"id":____}
            対処:
                Zabbix API コールに指定した auth を正しくしてください
監視システムの比較:
    - Consul は内部的に Serf を利用しています  https://recruit.gmo.jp/engineer/jisedai/blog/consul-orchestration/
    - Nagios , Zabbix などは、中央集権型の監視システム  https://recruit.gmo.jp/engineer/jisedai/blog/consul-orchestration/
    - Sense は RabbitMQ サーバが単一障害点になるため独自に冗長化を行う工夫が必要でした  https://recruit.gmo.jp/engineer/jisedai/blog/consul-orchestration/
    - Consul は Gosship プロトコルや Consensus プロトコルを利用し耐障害性を考慮
セットアップ スクリプト:
    install-vm.sh: #keyword: Linux install-vm.sh  #glossary: Linux install-vm.sh
        VMBackUpPath:  #// VM のイメージのバックアップの置き場所
            install-vm.sh の中で定義されています
        VMGroup, VmGroupDefault:  #// VirtualBox のグループ名
古いサーバーの停止: #keyword: shutdown old server,  サーバー 停止  #// 拠点の撤退など
    停止させる前のチェック:
        nginx などの アクセス ログ を過去数日～数か月分を見て、アクセスが無いことを確認します
文書設定: #settings:
    __GitLabUser__: takakiriy1
    __GitLabAcount__: Takakiriy
    __Reposiroty__: first
    __PAT__: __PAT__
    __ProjectName__: centos7
