#Character Encoding: "WHITE SQUARE" U+25A1 is □.
#keyword: Database.yaml, DB
手順, 試す:
    DB Fiddle: #keyword:  #ref: https://www.db-fiddle.com/  >>  Load Example（上）
        基本サンプル:  #keyword: DB Fiddle first example
            Schema SQL: |
                CREATE TABLE TableA (
                    id INT,
                    name CHAR(8) );
                INSERT INTO TableA (id, name)
                VALUES
                    (1, "A"),
                    (2, "B");
            Query SQL: |
                SELECT * FROM TableA;
            結果: |
                id
                ----
                1
                2
    検索: #search: SQL SELECT
        最も大きい値をもつレコード: #search: SQL SELECT MAX
    追加: #search: SQL INSERT
SQL文:  #keyword: SQL, SQL文
    参考 >> SQL Tutorial: #ref: https://www.w3schools.com/sql/default.asp  >> ブラウザーの検索機能で SQL のキーワードを検索
    標準SQL:
        SQL99:  #ref: https://atmarkit.itmedia.co.jp/fnetwork/tokusyuu/01sql99/sql99_1a.html
    基本:  #search: SQL SELECT
    文法:
        コメント: | #keyword: SQL comment
            -- __Comment__    #// -- の右に空白が必要です
            { __Comment__ }
            /* __Comment__ */
        データ:
            型: #keyword: SQL type  #// カラムやデータの型
                整数:
                    INT: 32ビット整数  -2147483648 ～ 2147483647
                    BIGINT: 64ビット整数  -2^63 ～ 2^63-1
                文字:
                    CHAR(n): CHAR(255) など
                    VARCHAR(n):
                参考:
                    Oracle:  #ref: https://docs.oracle.com/cd/F19136_01/sqlrf/Data-Types.html#GUID-A3C0D836-BADB-44E5-A5D4-265BA5968483
                    MySQL:  #ref: https://dev.mysql.com/doc/refman/8.0/ja/integer-types.html
                    SQL Server:  #ref: https://learn.microsoft.com/en-us/sql/t-sql/data-types/int-bigint-smallint-and-tinyint-transact-sql?view=sql-server-ver16
        関数: #keyword: SQL function
            定義済み関数:
                #ref: https://docs.oracle.com/cd/F19136_01/sqlrf/Single-Row-Functions.html#GUID-B93F789D-B486-49FF-B0CD-0C6181C5D85C
            サブクエリ, 副問合せ: #keyword:
                _:  別のSELECT文の句に埋め込まれたSELECT文。通常WHERE句、HAVING句、FROM句などで使用されます。
                WITH 句: #keyword: SQL WITH  #// サブクエリに名前を付けます
                    サンプル:
                        WITH max_quantities AS (
                            SELECT product_ID, MAX(count) AS max_quantity
                            FROM TableA
                            GROUP BY product_ID
                        )
        リテラル >> エスケープ:
            方法: シングル クォート は 2つ並べるように置き換えます
                ''
            O'Reilly のリテラル: 'O''Reilly'
        スタイル:  #keyword: SQL style  #// SQL コーディング規約
            大文字小文字:
                予約語と関数は大文字、変数は小文字:
                    採用: MySQL 8
                    #// 最近は予約語に色が付くのであまり必然性がなくなってきた
                大文字スタイル:
                    予約語も変数も大文字
                小文字スタイル:
            キャメル ケース と スネーク ケース:
                スネークケースが基本
            省略形:
                _: 文の中で定義する変数は単語の省略形にします
                サンプル: |  #focus: t, mq
                    WITH max_quantities AS (
                        SELECT product_ID, MAX(count) AS max_quantity
                        FROM TableA
                        GROUP BY product_ID
                    )
                    SELECT t.product_ID, t.price, t.count
                        FROM TableA t
                        INNER JOIN max_quantities mq
                        ON t.product_ID = mq.product_ID AND t.count = mq.max_quantity;
        参考:
            Oracle:  #ref: https://docs.oracle.com/cd/F19136_01/sqlrf/
    コマンド, 概念:  #glossary: SQL
        データベース:  #search: MySQL database
        テーブル: #search: MySQL table  #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#mysql_table
            カラムを追加します:  #search: MySQL ALTER TABLE ADD
        キー: #keyword: SQL key
            プライマリ キー: #keyword: primary key  #ref: ${programming}/検索技術、DB/SQL/SQL.svg#primary_key
            外部キー: #keyword: foreign key,  外部キー制約  #ref: ${programming}/検索技術、DB/SQL/SQL.svg#foreign_key
                書式: | #keyword: SQL FOREIGN KEY REFERENCES
                    CREATE TABLE  __ChildTableName__
                        `__FieldNameInThisTable__` INTEGER UNSIGNED NOT NULL,
                        CONSTRAINT `__ConstraintName__`
                            FOREIGN KEY __ForeinKeyName__ ( __FieldNameInThisTable__ )
                            REFERENCES  __ParentTableName__( __ForeinKeyInChildTable__ );
                参照動作: #keyword: SQL  #glossary: SQL
                    ON DELETE CASCADE: | #// 連動して関連するテーブル内のレコードを削除します
                        CONSTRAINT `__ConstraintName__`
                            ...
                            ON DELETE CASCADE
                    ON UPDATE CASCADE: 連動して関連するテーブル内のレコードを更新します
            複合主キー: #keyword: composite primary key  #// 2つのフィールドで一意に識別します
                注意: 外部キーやAPIで利用する場合には適しません
                SQLAlchemy によるサンプル: |  #focus: primary_key  #// primary_key=True を 2箇所に書くだけです
                    class Child(Base):
                        __tablename__ = 'children'
                        parent_id = Column(Integer, ForeignKey('parents.id'), primary_key=True)
                        child_id = Column(Integer, primary_key=True)
                類似:
                    一意制約: #keyword: unique constraint  #// 2つのフィールドの値の両方を含む ID フィールド
            サロゲート キー: #keyword: surrogate key
                _: field1 = "A123", field2 = "B456" の場合、id = "A123-B456" のように サロゲート キー を作ります。
                クエリのサンプル:
                    SELECT CONCAT(field1, '-', field2) AS id FROM your_table;
            複合ID:
                field1 と field2 の組み合わせが一意である場合、それを基に生成した一意の id を格納
        クエリ:  #search: SQL SELECT
        スキーマ:  #search: MySQL ALTER TABLE
        タイムゾーン:  #keyword: DB タイムゾーン
            MySQL:
                タイムゾーン:
                    SHOW VARIABLES LIKE 'time_zone';
                システムのタイムゾーン:  #// プロセス？
                    SHOW VARIABLES LIKE 'system_time_zone';
            PostgreSQL:
                SHOW TIMEZONE;
    参考 >> Snap Note: #// SELECT, USE, SHOW, DROP  #ref: ${programming}/検索技術、DB/SQL/SQL.svg#sql_structure
    その他: #search: MySQL
MySQL:  #keyword: #ref: http://www.mysql.com/
    Snap Note:  #ref: ${programming}/検索技術、DB/SQL/MySQL.svg
    手順:
        インストール: #keyword: install MySQL
            Docker 版: #keyword: install MySQL Docker
                Docker を WSL2 にインストールします:  #search: install Docker for WSL2
                MySQL の Dockerfile を含むプロジェクトを WSL2 にコピーして MySQL を起動します:
                    #ref: ${GitHub}/MyPrivateCode/docker/docker_centos7_mysql  #keyword: docker_centos7_mysql
                    Dockerfile:  #snip:  #ref: ${GitHub}/MyPrivateCode/docker/docker_centos7_mysql/Dockerfile
                        FROM mysql:8.0
                        ARG http_proxy
                        ARG https_proxy

                        ENV MYSQL_ROOT_PASSWORD Pass55##

                        RUN useradd -m user1
                        USER user1
                初期データの作成:  #search: MySQL initial data
            Ansible あり >> CentOS に MySQL をインストールします:  #keyword: install MySQL for CentOS with Ansible
                Ansible の コントロール ノード に MySQL をインストールする場合:
                    - #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/playbooks/mysql_server.yml
                    - #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/single_vm_ansible/GoCD/playbooks/mysql_client.yml
                Ansible の コントロール ノード と MySQL ノードを作る場合:
                    #search: install Ansible project
                    #// ただしプロジェクトは #search: ansible_vagrant MySQL_1_multi_vm_ansible
            Ansible なし >> CentOS に MySQL をインストールします:  #keyword: install MySQL for CentOS without Ansible
                #// MySQL は最新
                設定: #settings:
                    OS: CentOS8
                    __MySQL_RootPassword__: Pass55!!
                    CentOS8: #if: $settings.OS == CentOS8
                        __MySQL_RPM__: https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm  #// 手順の中で決まります
                        __yum__: yum
                    CentOS7: #if: $settings.OS == CentOS7
                        __MySQL_RPM__: https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm  #// 手順の中で決まります
                        __yum__: yum
                CentOS のバージョンをメモします:
                    bash:
                        cat /etc/redhat-release
                    #// CentOS 8 には MySQL 本体はプリインストール済みですが mysql コマンドは使えません
                MySQL の最新バージョンを調べます:  #keyword: MySQL newest version
                    #// CentOS のバージョンによって異なります。Rocky Linux の場合でも RHEL 版と互換性があります
                    - https://dev.mysql.com/downloads/repo/yum/ >> Download >>
                        No thanks, just start my download （を右クリック）>> リンクのコピー
                    - __MySQL_RPM__: https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm
                        #template: __MySQL_RPM__
                    - サンプル:
                        - https://dev.mysql.com/get/mysql84-community-release-el9-1.noarch.rpm
                        - https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm
                        - https://repo.mysql.com//mysql80-community-release-el7-7.noarch.rpm
                コンテナーを使わない場合:  #// MySQL をインストールした OS が MySQL サーバーになるとき
                    CentOS 8 の場合、デフォルトの MySQL を無効にします:
                        - sudo dnf -y module disable mysql
                    MySQL をインストールします:
                        - 下記は yum または dnf のどちらかを使います:
                            __yum__: yum  #template: : __yum__
                        - sudo yum -y localinstall https://dev.mysql.com/get/mysql80-community-release-el8-1.noarch.rpm
                            #template: __yum__ -y localinstall __MySQL_RPM__
                        - sudo yum check-update   #template: __yum__
                        - sudo yum info mysql-community-server  #// パッケージの情報を表示します  #template: __yum__
                        - sudo yum -y install mysql-community-server  #// 約2分  #template: __yum__
                        - sudo yum -y install mysql-community-devel   #template: __yum__
                    MySQL のバージョンを確認します:
                        - mysqld --version
                    MySQL を起動します:
                        - sudo systemctl start mysqld.service
                        - systemctl status mysqld.service  #// 起動してるか確認 active (running) なら OK
                            #// Q キーで終了
                    サーバー起動時にMySQL自動起動するように設定します:
                        - sudo systemctl enable mysqld.service
                    MySQL の root ユーザーの仮パスワードを確認します:
                        - sudo cat /var/log/mysqld.log | grep root@localhost  #// すぐ下で入力するのでメモは不要です
                    安全な設定をします:
                        mysql_secure_installation :  #// 最後の : は入力不要
                            Enter password for user root: ____  #// 上記で確認した仮パスワード
                            New password: Pass55!!  #template: __MySQL_RootPassword__
                            Change the password for root ?: y
                            New password(2): Pass55!!  #template: __MySQL_RootPassword__
                            Do you wish to continue with the password provided?: y
                            Remove anonymous users?: y
                            Disallow root login remotely?: y
                            Remove test database and access to it?: y
                            Reload privilege tables now?: y
                    （不要になったら）MySQL を自動起動しないようにします:
                        - sudo systemctl disable mysqld.service
                    （不要になったら）MySQL を終了します:
                        - sudo systemctl stop mysqld.service
                        - systemctl status mysqld.service  #// 起動してないか確認 inactive (dead)) なら OK
                コンテナーの中で動かす場合:  #// MySQL をインストールした OS が MySQL サーバーのコンテナーを使うとき
                    MySQL を終了します:
                        - sudo systemctl disable mysqld.service
                        - sudo systemctl stop mysqld.service
                （不要になったら）アンインストールします:
                    - rpm -qa | grep mysql  #// インストールされている MySQL のシンボルを表示します
                    - sudo yum remove __MySQL_Symbol__  #// 表示されたシンボルを __MySQL_Symbol__ に指定します
                参考:
                    - https://dev.mysql.com/downloads/repo/yum/
                    - https://castleobj.com/centos7-mysql57/
                    - https://qiita.com/nooboolean/items/7efc5c35b2e95637d8c1
            dnf yum:
                Rocky Linux 8:
                    sudo yum install -y  mysql-server
                    mysqld --version
                    書きかけ
        関連 >> CentOS Docker コンテナーを作ります:  #search: Docker CentOS
        文字コードを UTF-8 に設定します:  #keyword: MySQL UTF-8
            一覧: |
                mysql> show variables like "chara%";
                +--------------------------+--------------------------------+
                | Variable_name            | Value                          |
                +--------------------------+--------------------------------+
                | character_set_client     | latin1                         |
                | character_set_connection | latin1                         |
                | character_set_database   | utf8mb4                        |
                | character_set_filesystem | binary                         |
                | character_set_results    | latin1                         |
                | character_set_server     | utf8mb4                        |
                | character_set_system     | utf8                           |
                | character_sets_dir       | /usr/share/mysql-8.0/charsets/ |
                +--------------------------+--------------------------------+
            参照:
                select @@character_set_database, @@collation_database;
            設定:
                #// 以下のいずれか
                mysql> SET NAMES:
                    SET NAMES 'utf8mb4'
                docker-compose.yml:
                    services:
                        mysql:
                            image: mysql:8.0
                            environment:
                                -   "LANG=utf8"
            値の例:
                - utf8, utf8_bin
                - utf8mb3, utf8md3_bin
                - utf8mb4, utf8md4_bin
            参考:
                #ref: https://dev.mysql.com/doc/refman/5.6/ja/charset-connection.html
                #ref: https://qiita.com/koyo-miyamura/items/4d1430b9086c5d4a58a5
        バージョン:  #keyword: mysql version
            参照 >> インストールされているバージョンを参照します:
                MySQLが入ったサーバー内:
                    mysqld --version
            公式リリース日:  #keyword: mysql release date
                最新版:
                    https://www.mysql.com/downloads/  >> MySQL Community (GPL) Downloads >> MySQL Yum Repository
                    #// 無くなった → https://dev.mysql.com/ >> MySQL Blogs（右下）>> Announcing __Date__ Releases featuring MySQL __Version__
                過去のバージョン:
                    https://downloads.mysql.com/archives/community/
        起動待ち: #keyword: MySQL wait for up
            #search: WaitForUpMySQL
        初期データの作成: #keyword: MySQL initial data
            Docker イメージ版 MySQL の場合:  #keyword: /docker-entrypoint-initdb.d/*.sql, docker-entrypoint.sh
                Docker をインストールします:
                    #search: install MySQL Docker
                データベースやテーブルの作成や初期データの作成をする SQL 文を .sql ファイルに書きます:
                    場所:
                        (@container) /docker-entrypoint-initdb.d/*.sql
                        #ref: https://qiita.com/moaikids/items/f7c0db2c98425094ef10
                    サンプル:  #keyword: MySQL SQL example
                        CREATE DATABASE  db1;
                        CREATE TABLE db1.table1 (id INT, name CHAR(8));
                        INSERT  db1.table1  (id, name)  values  (1, "Taro");
                        INSERT  db1.table1  (id, name)  select COALESCE(MAX(id),0)+1, "Jiro" from db1.table1;
                    参考:
                        表示する >> サンプル: |
                            mysql> SELECT * FROM db1.table1;
                            +------+------+
                            | id   | name |
                            +------+------+
                            |    1 | Taro |
                            |    2 | Jiro |
                            +------+------+
                        削除する >> サンプル:
                            DROP TABLE db1.table1;
                            DROP DATABASE  db1;
                （2回目以降）初期化するときは Docker のボリュームを削除します:
                    docker volume rm __VolueName__
                    #search: docker volume rm
                MySQL の Docker を起動すると、初期データが作られます:
                    #search: docker-compose up
                しくみ: #focus: docker-entrypoint-initdb.d,  docker volume rm
                    /docker-entrypoint-initdb.d フォルダーを volumes に設定してください:
                        docker-compose.yml: |
                            services:
                                mysql:
                                    image: mysql:8.0
                                    volumes:
                                    - "____:/docker-entrypoint-initdb.d:ro"
                    MySQL Docker イメージのデフォルトの動作:
                        /usr/local/bin/docker-entrypoint.sh を実行します:
                            /var/lib/mysql フォルダーがある場合:  #// docker volume rm を実行したら /var/lib/mysql フォルダーも無くなります
                                /docker-entrypoint-initdb.d フォルダーの中の .sql ファイルを実行します:
        コピー, バックアップ: #keyword: MySQL back up
            コピーとバックアップの違い: | #keyword: MySQL コピーとバックアップの違い
                -    | コピー        | バックアップ
                ---- | ------------- | ------------------
                GTID | コピーしない  | コピーする
            mysqldump コマンド: #keyword: mysqldump,  mysqldump example  #// データを追加する SQL 文を出力します  #ref: https://dev.mysql.com/doc/refman/8.0/ja/mysqldump.html
                データベースをコピーします:  #search: MySQL コピーとバックアップの違い
                    #ref: ${GitHub}/MyPrivateCode/docker/docker_centos7_mysql_copy/tasks.sh#// Back up and restore  #keyword: docker_centos7_mysql_copy
                テーブルをコピーします: #keyword: copy MySQL table
                    コピーします:  #// mysqldump コマンド  #search: MySQL コピーとバックアップの違い
                        コピー元: #keyword: mysqldump tables
                            コマンド: |  #// __Database__ は第1引数、__TableName1__ は第2引数、__TableName2__ は第3引数 ... です
                                -   mysqldump  --user __MySqlUser__ --password="__Password__"  --all-databases  >  __Folder__/mysql_YYYYMMDD.sql
                                -   mysqldump  --user __MySqlUser__ --password="__Password__"  __Database__  __TableName__  >  __Folder__/table_YYYYMMDD.sql
                                -   mysqldump  --user __MySqlUser__ --password="__Password__"  __Database__  __TableName1__  __TableName2__  >  __Folder__/table_YYYYMMDD.sql
                            --set-gtid-purged=OFF: GTID の情報をダンプから除外します。バックアップではなくコピーするときは通常指定します
                            __TableName__: 省略すると全テーブル
                            オプション: #search: mysqldump options
                        table_YYYYMMDD.sql ファイルを転送します:
                            scp など  #search: Linux scp
                        コピー先:
                            mysql --user __MySqlUser__ --password=__Password__  __Database__  <  table_YYYYMMDD.sql
                        （補足）バックアップ サーバー への転送について:
                            バックアップ サーバー の MySQL のデータはレプリケーションによって自動更新されます
                オプション: #keyword: mysqldump options  #glossary: mysqldump
                    --host:
                        Docker コンテナーの外から接続する場合:
                            ネットワーク アクセス する場合:
                                mysql --host 127.0.0.1  --user "root" --password="__MySqlRootPassword__"
                                #// 127.0.0.1 を localhost に変えると接続できません
                            コンテナー内で実行する場合:
                                docker exec -it mysql-1  mysql  --user "root" --password="my-secret-pw"
                    --port:  #search: mysqldump --host
                関連 >> バックアップ・リストアします, 整合性を取ります:  #// 推奨  #search: Percona XtraBackup  #// マスターとスレーブで同じデータにします
            物理的なファイルコピー:  #// データ量が多い場合、MySQL のバージョンを変えない場合
            バックアップ（商用版のみ）:
            レプリケーション:
        リストア: #keyword: MySQL restore  #// 全 DB のリストア
            共通:
                A と B を開きます: |
                        (PowerShell) code --remote ssh-remote+mysql-A_ssh_config  home/user1/mysql
                        (@A:bash) read -s -p "Enter password: "  MYSQL_ROOT_PASSWORD  #ref: https://____
                        (PowerShell) code --remote ssh-remote+mysql-B_ssh_config  home/user1/mysql
                        (@B:bash) read -s -p "Enter password: "  MYSQL_ROOT_PASSWORD  #ref: https://____
                    #template-at(-4): ssh-remote+__HostA_SshConfig__  __Project__
                    #template-at(-4): #ref: __PasswordURL__
                    #template-at(-4): ssh-remote+__HostB_SshConfig__  __Project__
                    #template-at(-4): #ref: __PasswordURL__
                B の既存データのバックアップ: |
                        (@B:bash) mysqldump  --user root  --password="${MYSQL_ROOT_PASSWORD}"  --all-databases > /var/tmp/mysql-B.example.com_YYYYMMDD.sql  ||  echo "ERROR"
                    #template: __MysqlDumpCommand__  --user root
                    #template-at(-2): > /var/tmp/__HostB_FQDN___YYYYMMDD.sql
                #// 以下に続きます
            --add-drop-database なしの場合:  #// 上書きリストア
                #// 続き
                L で リストアする .sql ファイル を作る:  #// --set-gtid-purged=OFF --add-drop-database なし
                        (@A:bash) mysqldump  --user root  --password="${MYSQL_ROOT_PASSWORD}"  --all-databases > /var/tmp/mysql-A.example.com_YYYYMMDD.sql  ||  echo "ERROR"
                    #template: __MysqlDumpCommand__  --user root
                    #template-at(-2): > /var/tmp/__HostA_FQDN___YYYYMMDD.sql
                scp で転送する: |
                        scp  "mysql-A_ssh_config:/var/tmp/mysql-A.example.com_YYYYMMDD.sql"  "mysql-B_ssh_config:/var/tmp"
                    #template: "__HostA_SshConfig__:/var/tmp/__HostA_FQDN___YYYYMMDD.sql"  "__HostB_SshConfig__:/var/tmp"
                R で上書きリストアする: |  #// 入力ファイル名が変わります。リストア先の GTID は一時的に削除されます
                        #// mysql> STOP SLAVE;  はここでは省略
                        (@B:bash) mysql  --user root  --password="${MYSQL_ROOT_PASSWORD}"  --execute "RESET MASTER;"
                            #// Delete all GTID
                        (@B:bash) mysql  --user root  --password="${MYSQL_ROOT_PASSWORD}" < /var/tmp/mysql-A.example.com_YYYYMMDD.sql
                        #// mysql> CHANGE MASTER TO ...  はここでは省略
                        #// mysql> START SLAVE  はここでは省略
                    #template-at(-5): __MysqlCommand__  --user root
                    #template-at(-4): __MysqlCommand__  --user root
                    #template-at(-5): < /var/tmp/__HostA_FQDN___YYYYMMDD.sql
            --add-drop-database ありの場合:  #// 削除してリストア
                #// 未確認。エラーになります。Access to system schema 'mysql' is rejected.
                #ref: https://dev.mysql.com/doc/refman/8.0/ja/mysqldump.html#option_mysqldump_add-drop-database
                #// 続き
                A で「DROP（削除）してからリストアする .sql ファイル」を作る:  #// --set-gtid-purged=OFF --add-drop-database あり
                        (@A:bash) mysqldump  --user root  --password="${MYSQL_ROOT_PASSWORD}"  --set-gtid-purged=OFF --add-drop-database --all-databases > /var/tmp/mysql-A.example.com_with_drop_YYYYMMDD.sql  ||  echo "ERROR"
                    #template: __MysqlDumpCommand__  --user root
                    #template-at(-2): > /var/tmp/__HostA_FQDN___with_drop_YYYYMMDD.sql
                scp で転送する: |
                        scp  "mysql-A_ssh_config:/var/tmp/mysql-A.example.com_with_drop_YYYYMMDD.sql"  "mysql-B_ssh_config:/var/tmp"
                    #template: "__HostA_SshConfig__:/var/tmp/__HostA_FQDN___with_drop_YYYYMMDD.sql"  "__HostB_SshConfig__:/var/tmp"
                B でリストアする: |  #// 入力ファイル名が変わります
                        (@B:bash) mysql  --user root  --password="${MYSQL_ROOT_PASSWORD}" < /var/tmp/mysql-A.example.com_with_drop_YYYYMMDD.sql
                            ERROR 3552 (HY000) at line 1017: Access to system schema 'mysql' is rejected.
                    #template-at(-2): __MysqlCommand__  --user root  --password="${MYSQL_ROOT_PASSWORD}" < /var/tmp/__HostA_FQDN___with_drop_YYYYMMDD.sql
            設定: #settings:
                __HostA_SshConfig__: mysql-A_ssh_config
                __HostA_FQDN__: mysql-A.example.com
                __HostB_SshConfig__: mysql-B_ssh_config
                __HostB_FQDN__: mysql-B.example.com
                __MysqlCommand__: mysql
                __MysqlDumpCommand__: mysqldump
                __Project__: home/user1/mysql
                __PasswordURL__: https://____
        レプリケーション: #keyword: MySQL replication  #// マスターのサーバーとスレーブのサーバーでデータを同期します
            （SQL文）: #search: MySQL replication SQL
            ヘルス チェック: #keyword: MySQL replication health check
                スレーブ側で:
                    mysql> SHOW SLAVE STATUS \G
                        Last_IO_Error が表示されないこと
                        Empty でないこと
                #search: mysql>
            現在マスターかスレーブか: #keyword: MySQL master slave
                スレーブ ステータス:
                    Orchestrator WebUI の場合: サーバーのコンフィグに Master（相手）があるとスレーブ（自分）です。
                        スレーブ サーバー でサーバーのコンフィグの Master が マスター サーバー の __FQDN__:__Port__ であること。
                    mysql> の場合: SHOW SLAVE STATUS \G コマンドを実行して Empty でなければスレーブです。
                        スレーブ サーバー で Master_Host が マスター サーバー の FQDN であること。
                ルーティング:
                    MySQL へのリクエストが届くサーバーがマスターです。
                    VIP などによってルーティングされます。
                    #search: Virtual IP
                Read only: #keyword: MySQL read only
                    方針: 通常、マスターの read only をオフに、スレーブの read only をオンにします
                    Orchestrator WebUI の場合:
                        表示: サーバーのコンフィグ >> Read only
                        変更: サーバーのコンフィグ >> Set read-only ボタン  #// 即時切り替わります
                    mysql> の場合:
                        表示: SHOW VARIABLES LIKE 'read_only';
                        変更: SET GLOBAL read_only=0;   --// 0=off, 1=on
                GTID based replication:
                    Orchestrator WebUI の場合:
                        マスター: false
                        スレーブ: true
                co master: #keyword: replication co master  #// 複数のサーバーが同時にマスター（書き込み可能）として動作するレプリケーション構成
                    SHOW SLAVE STATUS \G で複数のサーバーがレプリカのとき（設定が表示されるとき）、co master です
            レプリケーション ステータス: #keyword: MySQL replication status
                #ref: https://dev.mysql.com/doc/refman/8.0/ja/replica-sql-thread-states.html
                バイナリ ログ の状態: #keyword: MySQL binary log
                    バイナリ ログ の位置を確認します: #keyword: MySQL log position  #// MySQL への ライト アクセス が多いときは値が一致しないかもしれません
                        master 側: |
                            mysql> SHOW MASTER STATUS \G
                            *************************** 1. row ***************************
                            |              File: mysql-bin.000004
                            |          Position: 18824
                        slave 側: |  #// slave 側が認識している master 側のログの位置
                            mysql> SHOW SLAVE STATUS \G
                            |     Master_Log_File: mysql-bin.000004
                            | Read_Master_Log_Pos: 18824
                    参考: #ref: https://changineer.info/server/mysql/mysql_replication_recovery.html#toc5
                リレー ログ の状態: #keyword: MySQL relay log
                    同期状態を確認します:
                        slave 側:
                            - mysql> SHOW PROCESSLIST;  #// PROCESS と入力しますが表示される内容はスレッドの一覧です。MySQL ではスレッドをしばしば「プロセス」と呼びます。
                            - State = Slave has read all relay log; waiting for more updates または
                                    Replica has read all relay log; waiting for more updates なら、リレーログはすべて処理を完了しています
                    リレー ログ とは:  #ref: https://dev.mysql.com/doc/refman/8.0/ja/replica-logs-relaylog.html
                        - スレーブ側で生成されます
                        - リレー ログ をすべてリードしてデータベースの処理が実行されたら、同期が完了します
                        - バイナリ ログ と同じ形式です。mysqlbinlog コマンドが使えます
                マスター側のステータス: | #keyword: SHOW MASTER STATUS;  #// スレーブ側でも実行できます
                    mysql> SHOW MASTER STATUS \G
                        *************************** 1. row ***************************
                        |              File: mysql-bin.000003
                        |          Position: 293
                        |      Binlog_Do_DB:
                        |  Binlog_Ignore_DB:
                        | Executed_Gtid_Set:
                        | 1 row in set (0.00 sec)
                スレーブ側のステータス: | #keyword: SHOW SLAVE STATUS \G
                    mysql> SHOW SLAVE STATUS \G
                        |       Master_Log_File: mysql-bin.000003
                        |   Read_Master_Log_Pos: 1058
                        |        Relay_Log_File: mysql-relay.000004
                        |         Relay_Log_Pos: 829
                        | Relay_Master_Log_File: mysql-bin.000003
                        |   Exec_Master_Log_Pos: 839
                        |        Until_Log_File:
                        |         Until_Log_Pos: 0
                        |    Master_SSL_CA_File:
                        |      Master_Info_File: /var/lib/mysql3/master.info
                        |      Slave_IO_Running: Connecting  #// Connecting のときは、まだ応答を待っている可能性があります
            マルチマスター モード:  #keyword: MySQL multi master mode
                参考: https://qiita.com/tikin1415/items/87b7e7a7090f1496572d
                オンにする: mysql> SELECT group_replication_switch_to_multi_primary_mode();
                オフにする: mysql> SELECT group_replication_switch_to_single_primary_mode();
                現在のモード: mysql> SELECT * FROM performance_schema.replication_group_members;
                    MEMBER_ROLE がすべて PRIMARY ならオン
            本番レベルの設定:  #ref: https://qiita.com/park-jh/items/34e6434d71e685a48f07
            MySQL Router:
                参考:
                    - サンプル: https://qiita.com/tikin1415/items/87b7e7a7090f1496572d
                    - 構成図: https://blog.s-style.co.jp/2020/10/6689/
                公式: https://dev.mysql.com/doc/mysql-router/8.0/en/mysql-router-conf-options.html
                /etc/mysqlrouter/mysqlrouter.conf :  #keyword: /etc/mysqlrouter/mysqlrouter.conf
                    routing_strategy:
                        first-available: なるべく１箇所に集中させる(?)
                        round-robin: なるべく分散させる(?)
            GTIDs and Group Replication: #keyword:  #ref: https://dev.mysql.com/doc/refman/8.0/en/group-replication-gtids.html
                概要:
                    トランザクションを正確に追跡します
                    #search: バックアップ ポリシー
            Orchestrator など: #search: openark Orchestrator
            同期の負荷の見積もり:  #// 1100MB なら問題ない
                バイナリ ログ から:  #// バイナリ ログ の容量から見積もる場合
                    バイナリ ログ と リレー ログ の昨日からの合計を比較  #search: MySQL log-bin
        マイグレーション: #keyword: MySQL migration
            #search: MySQL ALTER TABLE
    機能:
        レプリケーション: #search: MySQL replication
        HA:  #// （用語）高可用性化するシステム。 HA化（高可用性化）。「レプリケーション」が一般的な様子
            #search: 高可用性
    画面:
        MySQL VSCode 拡張機能: #keyword: MySQL VSCode extension
            Database Client 製, 旧 Weijan Chen (cweijan) 製:  #ref: https://marketplace.visualstudio.com/items?itemName=cweijan.vscode-mysql-client2
                対応:
                    DB: MySQL, MariaDB, PostgreSQL, SQLite, SQL Server, Oracle, DuckDB, ClickHouse, JDBC
                    その他: SH, Docker, Redis, ElasticSearch, MongoDB, S3, FTP, Kafka, RabbiMQ, Loki, Redshift, Snowflake, Neo4j, Zookeeper
                    #search: Elasticsearch VSCode extension
                料金:  #ref: https://database-client.com/#/plan
                    無料版: 最大 3接続
                    有料版: $23/年
                インストール:
                    VSCode >> Extensions ビュー（左）>> MySQL（と入力）>> MySQL (Weijan Chen) >> Install
                接続: #keyword: connect MySQL cweijan  #// MySQL サービス と接続し、テーブルなどを一覧します
                    MySQL サービス を起動します:
                        #search: install MySQL
                    Connection ページ:
                        メニュー: VSCode >> Database ビュー（左）>> ＋（ビューの右上）
                        Server Type: MySQL
                        Host: 127.0.0.1
                        Port: 3306
                        Username: root  #// ←サンプル
                        Password: ____  #// 実験用の漏洩していいものを入力します
                        Save ボタン:
                        #// Database ビュー にツリーが追加されます
                表示内容:
                    テーブルの内容: ページネーションされています
                    __MySqlServer__:__Port__:
                        __DataBaseName__:
                            Tables:
                                __TableName__:
                                    Columns:
                                        __ColumnIcon__ __ColumnName__:
                                            #↓ 説明
                                            __ColumnIcon__:
                                                鍵: Index
                                                青い箱: Nullable
                                                赤い箱: NotNull
                                                リンク: 外部キー
                                    Index:
                                        PRIMARY:  #// __KeyName__ __Algorithm__
                編集:  #// レコードの内容を変更します。UPDATE コマンド相当
                    編集する項目を表示します:
                        VSCode >> Database ビュー（左）>>（ツリーの中）
                    値を入力します:
                        複数の項目を入力できます
                    MySQL に保存します:
                        Save ボタン（チェック マーク：上）
            Jun Han 製: #ref: https://qiita.com/ymasaoka/items/aa03323bbac7e7c5f1be
            Oracle 製: #ref: https://dev.mysql.com/doc/mysql-shell-gui/en/mysql-shell-for-vscode-setup.html
                #// 接続できません
                メニュー: MySQL ビュー（左）>> DATABASE CONNECTIONS（の右にマウスを合わせる）>> …（右端）>>
                    Launch Welcome Wizard >> Next（下） >> Next（下）>> Reload VS Code Window
    コマンド:
        SQL, MySQL コマンド（SQL ステートメント）: #keyword: mysql>, MySQL client, MySQL command, MySQL statement shell prompt mysql>
            #// ここは、コマンドのセットアップやログインなど。コマンドの内容は #search: MySQL concepts
            関連 >> SQL 文:  #search: MySQL  >> 概念
            参考:
                8.0: #ref: https://dev.mysql.com/doc/refman/8.0/en/
                    MySQL コマンドの検索: （左）
                    ドキュメントの検索: （上）
                5.6: #ref: https://dev.mysql.com/doc/refman/5.6/ja/sql-syntax.html >> （検索ボックス）（左上）
                #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#mysql_command
            特殊文字:
                ％: ワイルドカード
                #: コメント
            起動 >> 基本: mysql  --user "__UserName__"  [--host __HostName__][--socket=____]  [-p  __DatabaseName__]  --password  #snip:  #search: start MySQL command
            起動 >> mysql コマンドライン ツール の起動:  #keyword: start MySQL command,  MySQL CLI
                （必要なら）MySQL client をインストールします:
                    mysql-community-client:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_orchestration-with-group/roles/mysql-client/tasks/main.yml
                （必要なら）サーバーを起動します:
                    Docker内: #search: MySQL shell in docker  #// Docker 内で実行する場合でも docker run -p オプションで localhost:3306 を開くことができます
                シェルから:
                    基本: mysql  --user "__UserName__"  [--host __HostName__][--socket=____]  [-p  __DatabaseName__]  --password
                    __HostName__: 127.0.0.1 など  #// localhost では接続できません。--socket が使えるかもしれません
                    パスワードをコマンドラインに含めるとき: --password="____"  #// 最後のパラメーターにしないとパスワードを指定できません
                    パスワードを環境変数に入れる場合:
                        read -s -p "Enter password> "  MYSQL_ROOT_PASSWORD
                        mysql __Parameters__ --password="${MYSQL_ROOT_PASSWORD}"
                    #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#root_user
                サンプル: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_orchestration-with-group/README.yaml#MySQL command shell
                疎通確認:
                    ping の場合:  #search: ping
                    telnet の場合:
                        telnet m1100l-local.vmlocal.com 3306
                            8.0.15  )|nQ^□h:r5sB(>Z6caching_sha2_password^CConnection closed by foreign host.
                        telnet m1100r-local.vmlocal.com 3306
                            8.0.15:U3<Q!□FWEdb#]N@kcaching_sha2_password^CConnection closed by foreign host.
                    #search: MySQL ERROR 1141
                権限との関係:
                    MySQL の権限が全く無い（初期状態の）ユーザーでもログインはできます。
                環境変数の参照: #keyword: MySQL CLI environment variable
                    基本: 参照できません。シェルから実行するときに、シェルの機能で環境変数が使えます
                    シェルから実行時:  #search: MySQL shell redirect to the file
                    シークレットを扱う場合:  #search: input password
            ログイン、root ユーザー: #keyword: MySQL login  #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#mysql_command
                パスワードを指定します:
                関連: #search: start MySQL command
            表示形式:
                \G:  #keyword: MySQL \G (/Gではない）  #// フィールドを縦に並べてテーブルを表示します
                    \G ありの場合: |
                        mysql> select * from site where code='370' \G;
                        *************************** 1. row ***************************
                        .  code: 370
                        .  status: 60
                        1 row in set (0.00 sec)
                    \G なしの場合: |  #// 表形式で表示します
                        mysql> select * from site where code='370';
                        +------+--------+
                        | code | status |
                        +------+--------+
                        | 370  |     60 |
                        +------+--------+
                        1 row in set (0.00 sec)
                pager:  #keyword: MySQL pager
                    現在の設定を表示します:
                        mysql> pager
                    デフォルトの設定に戻します:
                        mysql> nopager
                    less を使います:  #// バイナリでも表示が崩れません
                        mysql> pager less -S;  #search: MySQL authentication_string
            シェルから実行, ファイルに保存:  #keyword: MySQL shell redirect to the file  #keyword: run MySQL command
                SQL 文を実行します:
                    docker MySQL (@bash):
                        - docker exec -it __ContainerName__  mysql  --user "____" --password="____"  __DatabaseName__  --execute "select * from db1.table1;"
                        - docker exec -it __ContainerName__  mysql  -u "____" -p="____"  __DatabaseName__  -e "select * from db1.table1;"
                        - docker exec -it __ContainerName__  mysql  -u "____" -p="____"  __DatabaseName__  -e 'insert into  table  (name, point)  values  ("John", 60);'  #// " や ' に注意
                ファイルに保存します:
                    コンテナーを使っていない場合:
                        mysql  --user "____" --password="____"  __DatabaseName__  -e"__SQL__;" > _output.txt
                    コンテナーを使っている場合:  #// 未確認
                        docker exec -it __ContainerName__  mysql  --user "____" --password="____"  __DatabaseName__  -e "__SQL__;"  > _output.txt
                ファイルに書かれた SQL 文を実行します:  #keyword: MySQL command shell
                    コンテナーを使っている場合:
                        (@CentOS7):
                            docker exec -it __ContainerName__  mysql  --user "____" --password="____"  __DatabaseName__  -e "$(cat __SQL_LocalPath__)"
                        文字化けする場合:
                            character_set_client を utf8mb4 にします  #search: MySQL UTF-8
            バイナリ: #search: MySQL Blob binary
            レプリケーション: #keyword: MySQL replication SQL  #// スレーブ サーバー を起動します
                START REPLICA コマンド: #keyword: MySQL START REPLICA command
                    公式: https://dev.mysql.com/doc/refman/8.0/ja/start-replica.html
                START SLAVE コマンド:  #// MySQL 8.0 以降は START REPLICA コマンドへ  #keyword: MySQL START SLAVE command
                    #// 設定は、CHANGE MASTER TO コマンド
                    公式:
                        - https://dev.mysql.com/doc/refman/5.6/ja/start-slave.html
                        - https://dev.mysql.com/doc/refman/8.0/ja/start-slave.html
                    関連: #search: Ansible start slave
                SHOW MASTER STATUS コマンド:  #search: MySQL SHOW MASTER STATUS
                SHOW SLAVE STATUS コマンド:  #search: MySQL SHOW SLAVE STATUS
                SHOW REPLICA STATUS コマンド: #keyword: MySQL SHOW REPLICA STATUS, MySQL SHOW SLAVE STATUS
                    公式: https://dev.mysql.com/doc/refman/8.0/ja/replication-administration-status.html
                    #search: SHOW SLAVE STATUS \G
                FLUSH TABLES WITH READ LOCK コマンド:  #keyword: FLUSH TABLES WITH READ LOCK;  #// 全データベースの書き込みを禁止。リードはできます
                #search: MySQL master slave
        mysql:  #search: start MySQL command
        mysql_config: #keyword:
            インストール:
                CentOS7: sudo yum install -y mariadb-devel  #ref: https://stackoverflow.com/questions/49666481/mysql-config-not-found-with-mysql-community-on-centos-7
                Ubuntu12.04: sudo apt-get install libmysqlclient-dev  #ref: https://stackoverflow.com/questions/7475223/mysql-config-not-found-when-installing-mysqldb-python-interface
        サービス起動時 コマンド: #keyword: MySQL start options, MySQL Server System Variables
            docker-compose に指定する方法:
                下記 command を編集し、docker と MySQL にアクセスするバックエンドを起動しなおします: |  #focus: command
                    docker-compose.yml ファイル:
                        services:
                            mysql:
                                image: mysql:8.0
                                command: '--wait-timeout=28800'
                公式:
                    Using Options to Set Program Variables: https://dev.mysql.com/doc/refman/8.0/en/program-variables.html
        mysqladmin コマンド: #keyword: mysqladmin
            公式: https://dev.mysql.com/doc/refman/5.6/ja/mysqladmin.html
            書式の基本:
                (@db) $ mysqladmin __Command__  --user "__UserName__"  --password
            mysqladmin flush-hosts:  #keyword: mysqladmin flush-hosts
                shell: (@db) $ mysqladmin flush-hosts  --user "__UserName__"  --password
                __UserName__: flush-hosts の権限を持つユーザー
            関連 >> 各種コマンドがある場所:
                /usr/local/mysql/bin/mysqladmin
                #// mysql コマンドがある場所と同じ
        mysqlbinlog コマンド:  #search: mysqlbinlog
        mysqldump コマンド:  #search: mysqldump
            サンプル:  #search: copy MySQL table
            -u, --user __MySqlUser__: ダンプする処理を実行する MySQL ユーザー
            -p, --password="__Password__": MySQL ユーザー のパスワード。イコールは必須です
            --set-gtid-purged=OFF: GTID の情報をダンプから除外します。バックアップではなくコピーするときは通常指定します
                #search: MySQL コピーとバックアップの違い
            --add-drop-database:
    概念, 構成: #keyword: MySQL concepts
        データベース: #keyword: MySQL database
            サンプル:  #search: MySQL SQL example
            一覧: show databases;  #keyword: MySQL show databases
            選択: use __Database__;
            作成: #keyword: MySQL create database
                書式: create database  __DataBaseName__;
                公式: #ref: https://dev.mysql.com/doc/refman/8.0/en/create-database.html
                character set:  #ref: https://dev.mysql.com/doc/refman/8.0/en/create-database.html
                collate:  #ref: https://dev.mysql.com/doc/refman/8.0/en/create-database.html
            削除: drop database  __DataBaseName__;   #keyword: MySQL drop database  #// スキーマも無くなるため、CREATE TABLE が必要です
            文字コード:
                関連 >> 環境変数に設定する文字コード:  #search: MySQL UTF-8
                参照:
                    SELECT default_character_set_name FROM information_schema.SCHEMATA WHERE schema_name = "__DataBaseName__";
                    #ref: https://stackoverflow.com/questions/1049728/how-do-i-see-what-character-set-a-mysql-database-table-column-is
                設定:
                    alter database __DataBaseName__ character set __CharacterSet__;
                値の例:
                    [utf8mb3, utf8mb4]
            その他: #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#database
        テーブル: #keyword: MySQL table  #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#mysql_table
            サンプル:  #search: MySQL SQL example
            一覧: show tables;
            CREATE TABLE: #keyword: MySQL CREATE TABLE
                書式:
                    -   CREATE TABLE __DataBaseName__.__NewTableName__ (__FieldName__ __FieldType__);
                    -   create table __DataBaseName__.__NewTableName__ (__FieldName__ __FieldType__);
                    -   CREATE TABLE __DataBaseName__.__NewTableName__ (__FieldName__ __FieldType__, __FieldName__ __FieldType__);
                    -   desc __DataBaseName__.__NewTableName__;
                サンプル:
                    CREATE TABLE db1.new_table (dummy TINYINT UNSIGNED);
                    desc db1.new_table;
                初期データ付き:  #serach: DB Fiddle first example
                    CREATE TABLE TableA (
                        id INT,
                        name CHAR(8) );
                    INSERT INTO TableA (id, name)
                    VALUES
                        (1, "A"),
                        (2, "B");
                削除:
                    DROP TABLE db1.table1;
                    #// 関連  #search: SQL DELETE
                型変更:  #search: MySQL ALTER TABLE
                参考 >> 型: #search: MySQL data type
            SELECT: #keyword: SQL SELECT  #ref: ${programming}/検索技術、DB/SQL/SQL.svg#SELECT
                書式:
                    -   SELECT __OutputFieldNameCSV__  FROM __TableName__;
                    -   select __OutputFieldNameCSV__  from __TableName__;
                    -   SELECT __OutputFieldNameCSV__  FROM __TableName__  WHERE __FieldName__ = __Value__;
                __OutputFieldNameCSV__: |
                    - *
                    - id, name
                WHERE:
                    単体: WHERE __FieldName__ = __Value__;
                    And 条件: WHERE __FieldName1__ = __Value1__ AND __FieldName2__ = __Value2__;
                    Or 条件:  WHERE __FieldName1__ = __Value1__ OR __FieldName2__ = __Value2__;
                バイナリ (MySQL): #search: MySQL select binary
                ORDER BY, ソート:
                    - ORDER BY field1  #// field1 カラムで昇順
                    - ORDER BY update DESC  #// update カラムで降順
                GROUP BY: #keyword:
                    概要:
                        集約関数と一緒に使われ、グループ分けする条件を指定します。
                        たとえば、都道府県ごとに顧客がいる数を求めるときに、グループ分けする条件として都道府県を指定します。
                    サンプル:  #focus: GROUP BY
                        #// Country ごとに Customer がいる数
                        SELECT COUNT(CustomerID), Country
                            FROM Customers
                            GROUP BY Country;
                MAX: #keyword: SQL SELECT MAX  #// 最も大きい値をもつレコード
                    Schema SQL: |
                        CREATE TABLE TableA (
                            product_ID CHAR(8),
                            price INT,
                            count INT );
                        INSERT INTO TableA (product_ID, price, count)
                        VALUES
                            ("A", 100, 1),
                            ("A", 100, 3),
                            ("B", 150, 4),
                            ("B", 150, 2),
                            ("A", 100, 2);
                    Query SQL: |
                        SELECT product_ID, MAX(count)
                            FROM TableA
                            GROUP BY product_ID
                    結果: |
                        product_ID	MAX(count)
                        ----------------------
                        A	3
                        B	4
                JOIN など: #keyword: SQL JOIN
                    #ref: ${my_images}/2024/SQLベン図.jpeg
                    OUTER JOIN など:  #ref: ${programming}/検索技術、DB/SQL/SQL講座 pursue.ne.jp.svg#join
            INSERT:  #keyword: SQL INSERT
                ID を自動設定する場合:  #keyword: MySQL insert autoincrement
                    insert  __TableName__  (__Column1__, __Column2__, ...)  select COALESCE(MAX(__ID_Column__),0)+1, __Value2__, ... from __TableName__;
                ID を指定する場合, ID が無い場合:
                    insert into __TableName__  (__Column1__, __Column2__, ...)  values  (__Value1__, __Value2__, ...);
                値の書き方:  #keyword: SQL value
                    into: 無くてもいい？
                    __Column1__ の例: id, name, datetime
                    __Value1__ の例: 123, 'string', '2020-12-03 12:00:00', true
                #// ' の代わりに " も使えます。 シェルから実行するときの " や ' について  #search: run MySQL command
            UPDATE:  #keyword: SQL UPDATE
                書式: update __Table__ set __UpdatingFieldName__ = '__NewValue__'  where  __SearchingFieldName__ = __KeyValue__;
                値の書き方:  #search: SQL value
            DELETE:  #keyword: SQL DELETE
                レコード 1つ:  #// 1つのレコード、または、条件にマッチする全てのレコード
                    delete from __TableName__  where  __SearchingFieldName__ = __KeyValue__;
                    #// __KeyValue__ がリテラルの場合、" " で囲みます
                    #// 外部キーによって関連するレコードも削除されます（外部キーの設定による）
                レコード 全部:  #// 1つのテーブルの全レコード。スキーマはそのまま残ります
                    truncate table __TableName__;
                        #// 出力メッセージに含まれる数字は、削除した行数ではなく常に 0 です。
                        #// Query OK, 0 rows affected (0.08 sec)
                テーブル 1つ:
                    drop table __TableName__;
                論理削除: #search:
            ALTER TABLE: #keyword: MySQL ALTER TABLE  #// スキーマ変更
                型を変更します:
                    変更前の状況:
                        CREATE TABLE `configuration` (
                            `code` CHAR(16) PRIMARY KEY,
                            `config` BLOB(65535) NOT NULL
                        );
                    変更:
                        ALTER TABLE `configuration` MODIFY `config` BLOB(16777215) NOT NULL;
                カラムを追加します: #keyword: MySQL ALTER TABLE ADD
                    ALTER TABLE `configuration`
                        ADD `email`    CHAR(16) DEFAULT '(no email)'   AFTER `code`,
                        ADD `ex_code`  CHAR(16) DEFAULT '(no ex code)' AFTER `email`;
            SHOW CREATE TABLE: #keyword: MySQL SHOW CREATE TABLE  #// スキーマ表示
                SHOW CREATE TABLE __TableName__;
                #// ALTER TABLE による変更内容も含めたスキーマが表示されます
            集約関数: #keyword: SQL aggregate functions
                COUNT(), MAX(), MIN(), SUM(), AVG()
            コピー: #search: copy MySQL table
        スキーマ: #keyword: MySQL schema
            表示: desc __TableName__;
            型: #keyword: MySQL data type
                数値:  #ref: https://dev.mysql.com/doc/refman/8.0/en/numeric-type-syntax.html
                    BIT: 1 to 64
                    TINYINT: -128 to 127
                    TINYINT UNSIGNED: 0 to 255
                日時:  #ref: https://dev.mysql.com/doc/refman/8.0/en/date-and-time-types.html
                    よくあるカラム:
                        createdAt カラム: #keyword: createdAt,  created at,  created-at
                        updatedAt カラム: #keyword: updatedAt,  updated at,  updated-at
            sys: #keyword: MySQL sys schema  #ref: https://dev.mysql.com/doc/refman/5.7/en/sys-schema.html
                デフォルトでインストールされます
            キー: #keyword: MySQL key
                #search: SQL key
        ドライバー: #keyword: MySQL drivers
            Python:
                MySQL Connector/Python:  #keyword: MySQL Connector/Python,  mysql-connector-python
                    概要:
                        MySQL の公式ドライバー
                        外部ライブラリに依存しません
                    インストール:
                        pip install mysql-connector-python
                    コード:
                        from sqlalchemy import create_engine
                        engine = create_engine("mysql+mysqlconnector://ユーザー名:パスワード@ホスト名/データベース名")
                PyMySQL: #keyword:
                    概要:
                        MySQLdb の代わり。ただし、すべて Python で作られています。 libmysqlclient を参照しません。
                    インストール:
                        pip install pymysql
                    コード:
                        from sqlalchemy import create_engine
                        engine = create_engine("mysql+pymysql://ユーザー名:パスワード@ホスト名/データベース名")
                MySQLdb: #keyword:
                    MySQLdb は C で実装された Python 2 モジュールで、libmysqlclient にリンクしています。
                    MySQLdb の代わりに PyMySQL を使用できます。ただし、PyMySQL はすべて Python。
                    #ref: https://stackoverflow.com/questions/71168895/why-libmysqlclient-21-dylib-is-needed-on-local-with-only-mysql5-7-running
                libmysqlclient.so: #keyword:
                    概要:
                        pip install mysqlclient
                    libmysqlclient と MySQL のバージョン関係:  #keyword: libmysqlclient version
                        /usr/mysql/8.0.26/lib/libmysqlclient.so.21.1.26
                        /usr/mysql/5.7.35/lib/libmysqlclient.so.20.3.22
                        /usr/mysql/5.6.51/lib/libmysqlclient.so.18.1.0
                        /usr/mysql/5.5.62/lib/libmysqlclient.so.18.0.0
                        /usr/mysql/5.1.73/lib/mysql/libmysqlclient.so.16.0.0
                        /usr/mysql/5.0.96/lib/mysql/libmysqlclient.so.15.0.0
        日時:  #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#mysql_command_date
        Blob, binary, varbinary, MessagePack: #keyword: MySQL Blob binary
            表示, select: #keyword: MySQL select binary  #// 以下のいずれか
                - select __Field__ from __Table__ where __Field__='__Value__';  #// 一部文字化けしますが表示されます
                - select to_base64(__Field__) from __Table__;  #keyword: MySQL to_base64  #ref: https://dev.mysql.com/doc/refman/5.6/ja/string-functions.html#function_to-base64
                - select hex(__Field__) from __Table__;        #keyword: MySQL hex  #ref: https://dev.mysql.com/doc/refman/5.6/ja/string-functions.html#function_hex
                - select unhex(__Field__) from __Table__;      #keyword: MySQL unhex  #ref: https://dev.mysql.com/doc/refman/5.6/ja/string-functions.html#function_unhex
            insert: #// 未確認
                insert into test2(str1, str2) values unhex('f1234567890abcdef1234567890abcde')
                    #ref: https://qiita.com/satio_koibuti/items/7f379920bfa11a0b9a50
            BLOB バイナリ, BLOB 文字列:
                TINYBLOB: 最大 255 バイト
                BLOB: 最大 65,535 バイト
                MEDIUMBLOB: 最大 16,777,215 バイト  #// BLOB(16,777,215)
                LONGBLOB: 最大 4,294,967,295 バイト
                #// BLOBG のサイズを変更するマイグレーションはかなり時間がかかる場合があります
                #ref: https://dev.mysql.com/doc/refman/8.0/ja/storage-requirements.html#data-types-storage-reqs-strings
            バイナリ型:
                BINARY 型: #// 固定長バイナリ
                VARBINARY 型: #// 可変長バイナリ
                MessagePack 形式: #// DB の型ではありません  #keyword: MySQL MessagePack
                    格納方法: 固定長バイナリ型、または、可変長バイナリ型で格納します
            保存します:  #// フィールドの値をファイルに保存します
                コマンド例:
                    mysql  --user "____" --password="____"  __DatabaseName__  -e"select ... \G;" | \
                    sed '1d;1d' |  awk -F'[ ]' '{print $NF}' | xxd -r -p > _out.pack
                参考:
                    ファイルに保存:  #search: MySQL shell redirect to the file
                    Hex 形式からバイナリに変換します: #search: Linux hex xxd
                    JSON に変換します: #search: MessagePack JSON
                    #ref: https://qiita.com/murakami_akippa/items/9c9363a96b4ac3eb0981
        ユーザー, 認証:  #keyword: MySQL user
            操作:  #// ユーザー管理
                一覧: #// ユーザーを一覧します:  #keyword: list MySQL user
                    基本: |
                        mysql> SELECT user, host FROM mysql.user;
                            | user             | host        |
                            +------------------+-------------+
                            | mysql.infoschema | localhost   |
                            | mysql.session    | localhost   |
                            | mysql.sys        | localhost   |
                            | root             | localhost   |
                    認証文字列付き一覧: #search: MySQL authentication_string  #// パスワード等のハッシュ
                作成: #keyword: create MySQL user,  MySQL CREATE USER
                    基本:
                        書式: mysql> CREATE USER '__MySqlUser__'@'__ClientHostName__' IDENTIFIED BY '__UserPassword__';
                        補足:
                            - IDENTIFIED BY '__UserPassword__' を省略するとパスワードなしになります
                            - root ユーザーはパスワードなしにできません
                            - __ClientHostName__ を localhost 以外に設定すると、
                                __ClientHostName__ のホストからアクセスするユーザーとして
                                localhost の mysql.user テーブルに登録されます
                    認証プラグインを指定する場合: #keyword: MySQL authentication plug in
                        #focus: WITH  #// MySQL 8.0
                        書式: mysql> CREATE USER '__MySqlUser__'@'__ClientHostName__'  IDENTIFIED WITH __PlugIn__ BY '__UserPassword__';
                            #// WITH と BY を逆に指定できません。 ... IDENTIFIED WITH BY '__UserPassword__' __PlugIn__; はエラーになります
                        __PlugIn__: caching_sha2_password | mysql_native_password
                    パスワードを入力しない場合:  #// パスワードの代わりに認証文字列（ハッシュ）を指定します
                        MySQL 8.0:  #// AS
                            #// 未確認
                            CREATE USER '__MySqlUser__'@'__ClientHostName__' IDENTIFIED WITH 'caching_sha2_password' AS '__AuthenticationString__';
                            #// 注意 認証プラグインが caching_sha2_password のときは、authentication_string がバイナリで表示されるため、コピペではできないかもしれません
                            #search: MySQL authentication_string
                        MySQL 5.7:  #// IDENTIFIED BY PASSWORD
                            #// 未確認
                            CREATE USER '__MySqlUser__'@'__ClientHostName__' IDENTIFIED BY PASSWORD '__AuthenticationString__';
                            #search: MySQL authentication_string
                        #ref: https://mita2db.hateblo.jp/entry/2020/11/12/225014
                削除: #keyword: delete MySQL user,  MySQL DROP USER
                    mysql> DROP USER '__MySqlUser__'@'__ClientHostName__';
            認証シーケンス: #keyword: MySQL authentication sequence
                1回目: |
                    クライアント                         サーバー
                        |                                   |
                        |-------- 接続要求 ---------------->|
                        |                                   |
                        |<------- ソルト送信 ---------------|
                        |                                   |
                        |-------- ハッシュ応答 ------------>|
                        |                                   |
                        |<--- 認証結果（成功/失敗）---------|
                2回目以降: |
                    クライアント                         サーバー
                        |                                   |
                        |-------- 接続要求 ---------------->|
                        |                                   | ← キャッシュ検索
                        |<------- 4バイトの乱数 ------------|
                        |                                   | ← XOR演算による軽量な暗号化
                        |-------- XOR暗号化応答 ----------->|
                        |                                   | ← 高速検証
                        |<------- 認証完了 -----------------|
                キャッシュが無効になるタイミング: #keyword: MySQL discard authentication cache
                    - サーバー再起動後
                    - FLUSH PRIVILEGES実行後
                    - メモリ不足でキャッシュが破棄された場合
            ハッシュ値, 認証文字列, ユーザーの鍵: #keyword: MySQL authentication_string  #// MySQL サーバー にのみ持つ
                内容, 場所:
                    （初回のみ必要なら）(@mysql-1.example.com) : mysql> pager less -S;  --// less を使って表示させることで、文字化けを無くします
                        #// 戻すときは mysql> nopager;  #// ではない？   #search: MySQL pager
                    (@mysql-1.example.com): |
                        mysql> SELECT user, host, plugin, authentication_string  FROM mysql.user  WHERE user = "__MySqlUser__";   --//  OR user = "__User2__";
                            | user    | host                | plugin                | authentication_string                          |
                            +---------+---------------------+-----------------------+------------------------------------------------+
                            | root    | localhost           | caching_sha2_password | $A$005$OW^M'^BC.=^S^0000000000000000008jsPGhq5 |
                            | replica | mysql-1.example.com | mysql_native_password | *915B000000000000000000000000000000006B80      |
                            | replica | mysql-2.example.com | mysql_native_password | *915B000000000000000000000000000000006B80      |
                    #// host は __ClientHostName__
                    #// サーバーごとそれぞれに持っています。おそらくレプリケーションの対象外（未確認）
                設定:
                    #search: create MySQL user
                    #search: delete MySQL user
                認証プラグイン:  #keyword: MySQL 認証プラグイン
                    認証プラグインの種類: [ caching_sha2_password, mysql_native_password ]  #// __AuthenticationPlugin__  #keyword: caching_sha2_password, mysql_native_password
                        #// 種類名は鍵と一緒に保存されます:  #search: MySQL authentication_string
                    デフォルトの認証プラグイン:  #keyword: default_authentication_plugin, default-authentication-plugin
                        設定を表示します: mysql> show variables like 'default_authentication_plugin';
                        設定します:
                            /etc/my.cnf : |
                                default-authentication-plugin=__AuthenticationPlugin__
                            restart ?:
                    ユーザーが使う認証プラグイン:
                        設定を表示します: mysql> select user, host, plugin from mysql.user where user = '__MySqlUser__';
                        設定を変更します: mysql> alter user '__MySqlUser__'@'__Host__' identified with __AuthenticationPlugin__ by '__UserPassword__';
                    警告を抑制します: #keyword: MySQL 認証プラグイン 警告   #// mysql_native_password は非推奨ですという警告を抑制します
                        ログ: |  #search: MySQL log-error
                            [Warning] [MY-013360] [Server] Plugin mysql_native_password reported: ''mysql_native_password' is deprecated and will be removed in a future release. Please use caching_sha2_password instead
                        抑制する設定:  #search: suppress MySQL warning
            ssl-mode:  #search: MySQL ssl-mode  #// どこまで厳密に検証するかどうか
            サーバーの鍵, 設定ファイル:
                (@server) /etc/my.cnf または /etc/mysql/my.cnf : |
                    [mysqld]
                    ssl-ca=/path/to/ca.pem                 #// 認証局の証明書
                    ssl-cert=/path/to/server-cert.pem      #// server certificate   サーバーの公開証明書
                    ssl-key=/path/to/server-key.pem        #// サーバーの秘密鍵（非公開）ユーザーの鍵ではない
                (@client) /etc/mysql/my.cnf または ~/.my.cnf : |
                    [client]
                    ssl-mode=REQUIRED        #search: MySQL ssl-mode
                    ssl-ca=/path/to/ca.pem   #// 認証局の証明書
                ssl-mode: #keyword: MySQL ssl-mode  #// 通信の暗号化方法
                    DISABLED: 平文
                    PREFERRED: SSL/TLSを使うが、使えないときは平文 （デフォルト）
                    REQUIRED: SSL/TLSを使う。自己署名証明書でもOK
                    VERIFY_CA: REQUIRED + CA証明書で検証
                    VERIFY_IDENTITY: VERIFY_CA + サーバー名の検証
            関連 >> 認可:  #search: MySQL grant
        権限, 認可:  #keyword: MySQL grant,  MySQL grant 権限 認可
            一覧 >> 全権限一覧:  #keyword: MySQL privileges
                SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN,
                PROCESS, FILE, REFERENCES, INDEX, ALTER,
                SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE,
                REPLICATION SLAVE, REPLICATION CLIENT,
                CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE,
                CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE, CREATE ROLE, DROP ROLE
                #// 上記は ALL PRIVILEGES の結果
                #// 補足: https://dev.mysql.com/doc/refman/5.6/ja/grant.html
            表示:  #// ユーザーの権限を表示します
                SHOW GRANTS コマンド: #keyword: SHOW GRANTS FOR
                    コマンド:
                        - mysql> FLUSH PRIVILEGES;  #search: FLUSH PRIVILEGES
                        - mysql> SHOW GRANTS FOR '__MySqlUser__';  #または
                        - mysql> SHOW GRANTS FOR '__MySqlUser__'@'__ClientHostName__';
                    出力例: |
                        ***** 1. row *****
                        Grants for __MySqlUser__@__ClientHostName__: GRANT __Privileges__ ON *.* TO `__MySqlUser__`@`__ClientHostName__`
                    #// 権限が多いと複数の row に分けて表示されます
                    #// 現在の設定が表示されます（メモリーに入っています）
                テーブル: #glossary:
                    注意: 現在の設定（メモリーに入っている設定）と異なる場合があります。FLUSH PRIVILEGES; でテーブルの内容が現在の設定に反映されます
                    mysql.user:
                        アカウント情報のみ:  
                            - SELECT user, host  FROM mysql.user;  #search: list MySQL user
                            - SELECT user, host, plugin, authentication_string  FROM mysql.user  WHERE User="root";  #search: MySQL authentication_string
                        全部: |  #// mysql> SELECT * from mysql.user  WHERE User="root";
                            |                     Host: m1100r-local.vmlocal.com
                            |                     User: slog-counter
                            |              Select_priv: N
                            |              Insert_priv: N
                            |              Update_priv: N
                            |              Delete_priv: N
                            |              Create_priv: N
                            |                Drop_priv: N
                            |              Reload_priv: N
                            |            Shutdown_priv: N
                            |             Process_priv: N
                            |                File_priv: N
                            |               Grant_priv: N
                            |          References_priv: N
                            |               Index_priv: N
                            |               Alter_priv: N
                            |             Show_db_priv: N
                            |               Super_priv: N
                            |    Create_tmp_table_priv: N
                            |         Lock_tables_priv: N
                            |             Execute_priv: N
                            |          Repl_slave_priv: N
                            |         Repl_client_priv: N
                            |         Create_view_priv: N
                            |           Show_view_priv: N
                            |      Create_routine_priv: N
                            |       Alter_routine_priv: N
                            |         Create_user_priv: N
                            |               Event_priv: N
                            |             Trigger_priv: N
                            |   Create_tablespace_priv: N
                            |                 ssl_type: 
                            |               ssl_cipher: 
                            |              x509_issuer: 
                            |             x509_subject: 
                            |            max_questions: 0
                            |              max_updates: 0
                            |          max_connections: 0
                            |     max_user_connections: 0
                            |                   plugin: mysql_native_password
                            |    authentication_string: *23DF_______________________________706E
                            |         password_expired: N
                            |    password_last_changed: 2024-04-01 00:00:00
                            |        password_lifetime: NULL
                            |           account_locked: N
                            |         Create_role_priv: N
                            |           Drop_role_priv: N
                            |   Password_reuse_history: NULL
                            |      Password_reuse_time: NULL
                            | Password_require_current: NULL
                            |          User_attributes: NULL
                    mysql.db: | #keyword: mysql.db
                        |                  Host: ____
                        |                    Db: ____
                        |                  User: ____
                        |           Select_priv: Y
                        |           Insert_priv: N
                        |           Update_priv: N
                        |           Delete_priv: N
                        |           Create_priv: N
                        |             Drop_priv: N
                        |            Grant_priv: N
                        |       References_priv: N
                        |            Index_priv: N
                        |            Alter_priv: N
                        | Create_tmp_table_priv: N
                        |      Lock_tables_priv: N
                        |      Create_view_priv: N
                        |        Show_view_priv: N
                        |   Create_routine_priv: N
                        |    Alter_routine_priv: N
                        |          Execute_priv: N
                        |            Event_priv: N
                        |          Trigger_priv: N
                    mysql.tables_priv: |
                        未調査
                    mysql.columns_priv: |
                        未調査
                    mysql.procs_priv: |
                        未調査
            設定 >> GRANT コマンド:  #// 権限を指定してユーザーを作成します、またはユーザーの権限を更新します  #keyword: MySQL GRANT command
                MySQL 8.0 以降: #// ユーザーの権限を更新します。ユーザーがいないとエラーになります
                MySQL 5.x 以前: #// ユーザーがいなければユーザーを作成し、ユーザーがいればユーザーの権限を更新します
                公式: https://dev.mysql.com/doc/refman/5.6/ja/grant.html
                サンプル >> 基本:
                    コマンド:
                        #// ユーザーが無ければ作ってから  #search: MySQL CREATE USER
                        mysql>  GRANT __PrivilegesCSV__  ON __DB_Name__.__TableName__  TO '__MySqlUser__'@'__ClientHostName__';
                        mysql>  GRANT ...
                        mysql>  FLUSH PRIVILEGES;
                    __PrivilegesCSV__:
                        ALL PRIVILEGES: すべての権限
                        ALL: ALL PRIVILEGES と同じ
                        その他: SELECT | INSERT | UPDATE | DELETE など多数  #search: MySQL privileges
                    __DB_Name__: データベース名、または *
                    __TableName__: テーブル名、または *
                    __ClientHostName__: クライアントのホスト名、または %（localhost は含まない？）、または一部に %（例： 192.168.33.% ）
                    WITH GRANT OPTION: これを指定したとき、指定した権限を他のユーザーにも与える権限を与えます。指定しなければ与えません
                    FLUSH PRIVILEGES; : #keyword:
                        GRANT コマンドやテーブルの内容などを現在の設定に反映します
                    IDENTIFIED BY '__UserPassword__':  #keyword: MySQL IDENTIFIED BY
                        MySQL 8.0: 使えません。ユーザーの作成を別途行ってください
                            CREATE USER '__MySqlUser__'@'__ClientHostName__' IDENTIFIED BY '__UserPassword__';
                            GRANT __PrivilegesCSV__  ON __DB_Name__.__TableName__  TO '__MySqlUser__'@'__ClientHostName__';
                        MySQL 5.x 以前: 使えます
                サンプル >> レプリケーション ユーザー:
                    参考: https://qiita.com/rerorero/items/1f06cc8db9c469191289#2-2-レプリケーションを開始する
                    マスター ホスト で実行するコマンド:
                        - mysql>  GRANT REPLICATION SLAVE  ON *.*  TO '__ReplicationUser__'@'%' IDENTIFIED BY '__ReplicationUserPassword__';
                    スレーブ ホスト で実行するコマンド:
                        - mysql>  CHANGE MASTER  TO  MASTER_HOST='__ServerName__', MASTER_PORT=3306,
                            MASTER_USER='__ReplicationUser__', MASTER_PASSWORD='__ReplicationUserPassword__', MASTER_AUTO_POSITION=1;
                        - mysql>  START SLAVE;
            削除 >> REVOKE コマンド:  #// 権限を削除します  #keyword: MySQL REVOKE command
                サンプル >> 基本:
                    コマンド: mysql>  GRANT __PrivilegesCSV__  ON `__DB_Name__`.`__TableName__`  FROM '__MySqlUser__'@'__ClientHostName__'
            CHANGE MASTER TO コマンド: #keyword: MySQL CHANGE MASTER TO command,  CHANGE MASTER TO  #// レプリケーションの レプリカ サーバー に設定します
                #// 現在のサーバー（スレーブまたはレプリカとも呼ばれる）がマスターサーバーからデータをレプリケート（コピー）する方法を設定します。
                #// MySQL 8.0 でも CHANGE PRIMRY TO コマンドは存在しません
                公式:
                    - https://dev.mysql.com/doc/refman/8.0/ja/change-master-to.html
                    - https://dev.mysql.com/doc/refman/5.6/ja/change-master-to.html
                サンプル:
                    mysql> CHANGE MASTER TO
                        MASTER_HOST='__ServerName__',
                        MASTER_PORT=3306,
                        MASTER_USER='__ReplicationUserInMasterServer__',
                        MASTER_PASSWORD='__PasswordOfReplicationUserInMasterServer__',
                        MASTER_AUTO_POSITION=1;
                サンプルの説明:
                    __ReplicationUserInMasterServer__: マスター サーバーにいるレプリケーションを行う専用の MySQL ユーザー（を作ること）
                    MASTER_AUTO_POSITION=1: GTID ベースのレプリケーションプロトコルを使用
                関連: #search: Ansible change master to
            関連 >> 認証:  #search: MySQL user
        サーバー, mysqld:
            Linux プロセスの状態: sudo systemctl status mysqld
            server_id: #keyword: MySQL server_id,  MySQL server-id  #// MySQL サーバーの ID
                表示: mysql> SHOW VARIABLES LIKE 'server_id';  #search: mysql>
                変更:
                    my.cnf : |
                        [mysqld]
                        server-id = 1
                    再起動: sudo systemctl restart mysqld
                    ヘルス チェック: #search: MySQL replication health check
        レプリケーション: #search: MySQL replication
            SQL, MySQL本体:  #// MySQL 本体のレプリケーション機能
                サンプル: $HOME\GitProjects\GitHub\MyPrivateCode\ansible_vagrant\multi_vm_ansible\branch_mysql_replica
                #search: MySQL replication
            Orchestrator (percona, openark): #keyword: percona Orchestrator,  orchestrator,  openark Orchestrator,  MySQL Orchestrator  #// MySQL replication topology management and HA
                公式:
                    #ref: https://github.com/percona/orchestrator  #// 引き続き先だが開発中らしい
                    #ref: https://github.com/openark/orchestrator  #// 2001年の version 3.2.6 が最新。アーカイブされました
                概要:  #// レプリケーション管理ツール
                    MySQL の高可用性およびレプリケーション管理ツールであり、サービスとして実行され、
                    コマンド ライン アクセス、HTTP API、および Web インターフェイスを提供します
                手順, 機能:
                    インストールします:
                        サンプル:
                            参考: https://qiita.com/rerorero/items/1f06cc8db9c469191289
                            Vagrant プロジェクト:  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_orchestration-with-group/README.yaml
                            PostMasterFailoverProcesses:
                                /etc/orchestrator.conf.json#PostMasterFailoverProcesses の詳細は
                                    https://qiita.com/rerorero/items/1f06cc8db9c469191289#recovery-hooks
                            /etc/my.cnf@db1,db2,db3:
                                log-slave-updates: フェールオーバーによりマスターに昇格可能な設定
                        ダウンロード:
                            URL: https://github.com/openark/orchestrator/releases
                            orchestrator-3.2.5-1.x86_64.rpm:                            32bit  #// 通常これ
                            orchestrator_3.2.5_amd64.deb:                               64bit
                            orchestrator-3.2.5-linux-amd64.tar.gz:              tar.gz  64bit
                            orchestrator-sysv-3.2.5-1.x86_64.rpm:               SysV    32bit
                            orchestrator-sysv-3.2.5_amd64.deb:                  SysV    64bit
                            orchestrator-cli-3.2.5-1.x86_64.rpm:         CLI            32bit
                            orchestrator-cli_3.2.5_amd64.deb:            CLI            64bit
                            orchestrator-cli-sysv-3.2.5-1.x86_64.rpm:    CLI    SysV    32bit
                            orchestrator-cli-sysv-3.2.5_amd64.deb:       CLI    SysV    64bit
                            orchestrator-client-3.2.5-1.x86_64.rpm:      Client         32bit
                            orchestrator-client_3.2.5_amd64.deb:         Client
                            orchestrator-client-sysv-3.2.5-1.x86_64.rpm: Client SysV    32bit
                            orchestrator-client-sysv-3.2.5_amd64.deb:    Client SysV    64bit
                    リセットします: #keyword: reset Orchestrator  #// クラスターが無い状態に戻します
                        Orchestrator WebUI >> Home メニュー >> Status >>
                            Reset hostname resolve cache
                            Reload configuration
                            Reelect
                        Orchestrator WebUI >> Clusters メニュー >> Dashboard（サーバーが無いこと）
                        #search: add Orchestrator MySQL host
                    MySQL ホストを追加します: #keyword: add Orchestrator MySQL host
                        手順:
                            メニュー: Orchestrator WebUI >> Clusters メニュー >> Discover
                            host name: ホスト名 または FQDN
                            Submit ボタン:
                            #// スレーブ側を Discover する必要はありません。
                            #// 少し待ってから Dashboard をリロードするとスレーブ側が表示されます
                        しくみ:
                            orchestrator のホストから、MySQL のホストのポート（デフォルトは 3306）が拒否されないようにします:
                            orchestrator という名前の MySQL ユーザーで MySQL にログインします:
                                mysql  --user "orchestrator"  --host __MySqlServer__  --password
                                #search: start MySQL command
                    Dashboard を表示します: #search: orchestrator Dashboard
                    Healthy, 正常性確認: #keyword: MySQL Orchestrator 正常性確認
                        メニュー: Orchestrator WebUI >>（クラスター名）
                        左側のアイコン列のうち、最も上のアイコン:
                            青色の (i): 正常
                            黄色の (!): 異常  #// 異常があれば右上にも (!) が表示され、クリックすると詳細が表示されます
                        discoverInstance 処理: #keyword: MySQL Orchestrator discoverInstance
                            処理内容の予想:  #// Claude AI の回答
                                フェーズ1:  #// 接続確立（MySQLConnectTimeoutSeconds）
                                    処理内容: TCP接続の確立
                                    制御パラメータ: MySQLConnectTimeoutSeconds
                                    典型的な時間: 1-3秒
                                    関連する処理:
                                        TCP接続の確立
                                        SSL/TLSハンドシェイク（使用している場合）
                                        MySQL認証プロセス
                                フェーズ2:  #// ヘルスチェック（ReasonableInstanceCheckSeconds）
                                    処理内容: 基本的な応答確認
                                    制御パラメータ: ReasonableInstanceCheckSeconds  
                                    典型的な時間: 5-10秒
                                    関連する処理:
                                        sql-- 基本的なヘルスチェッククエリ
                                        SELECT 1;
                                        SELECT @@server_id;
                                フェーズ3:  #// 詳細情報収集（MySQLDiscoveryReadTimeoutSeconds）
                                    処理内容: トポロジ情報の詳細収集
                                    制御パラメータ: MySQLDiscoveryReadTimeoutSeconds
                                    典型的な時間: 10-30秒
                                    関連する処理:
                                        sql-- 詳細なトポロジ情報収集クエリ
                                        SHOW SLAVE STATUS;
                                        SHOW MASTER STATUS;
                                        SHOW PROCESSLIST;
                                        SELECT * FROM performance_schema.replication_group_members;  -- Group Replication用
                                        -- その他多数のメタデータクエリ
                    Recovery機能:  #// トポロジの回復, マスターが自動的に切り替わります。Orchestrator の主機能
                        #ref: https://github.com/openark/orchestrator/blob/master/docs/topology-recovery.md
                        概要: MySQL が動いているマスター（サーバー）がダウンした時に自動的にスレーブをマスターに昇格させる機能です
                        できること: レプリケーションの再構築
                        別途必要なこと:
                            アプリケーションから MySQL へのルーティング:
                        master 切り替え:
                            条件: |  #search: (ChatGPT4) orchestrator が MySQL の master を切り替えるのはどんなときでしょうか
                                `orchestrator` は、MySQL のトポロジー管理ツールで、レプリケーションやフェイルオーバーのプロセスを自動化します。
                                MySQL の master（マスター）を切り替える主なシチュエーションは以下のとおりです。
                                    1. フェイルオーバー: もしマスターサーバーがダウンした場合や、障害が発生した場合、
                                        orchestrator は自動的にフェイルオーバーを実行し、代わりになるレプリカサーバーを新たなマスターサーバーに昇格させます。
                                        これによりダウンタイムが最小限に抑えられます。
                                    2. メンテナンス: サーバーのメンテナンスやアップグレードのために、マスターサーバーを一時的にオフラインにする必要がある場合、
                                        orchestrator は一時的に別のレプリカサーバーをマスターに昇格させ、メンテナンスが完了するまでその役割を担います。
                                    3. 負荷分散: システムのパフォーマンスを最適化するため、負荷が高いマスターサーバーを別のレプリカサーバーに切り替えることがあります。
                                        orchestrator は、レプリカサーバーの状況を監視し、負荷分散が適切かどうかを判断し、必要に応じてマスターサーバーを切り替えます。
                                    4. トポロジーの変更: レプリケーショントポロジーを変更する必要がある場合、例えばマルチマスター設定に変更する場合や、
                                        特定のデータセンター内でマスターサーバーを移動する場合、orchestrator を使ってマスターサーバーを切り替えることができます。
                                これらのシチュエーションに対応するため、orchestrator はマスターとレプリカ間のレプリケーション状況を監視し、適切なタイミングでマスターの切り替えを行います。
                            検出方法:
                                検出は MySQL の機能で行っているらしい:
                                    #ref: https://github.com/openark/orchestrator/blob/master/docs/configuration-failure-detection.md#mysql-configuration
                                    slave_net_timeout など   #search: MySQL SET GLOBAL  #search: my.cnf
                                説明: |  #search: (ChatGPT4) orchestrator はフェイルオーバーをどのように検出していますか
                                    orchestratorは、フェイルオーバーを検出するために、以下の方法でMySQLサーバーの状態とレプリケーショントポロジーを監視しています。
                                        ポーリングによる検出: orchestratorは定期的に（デフォルトでは数秒ごとに）各MySQLサーバーに接続し、
                                            サーバーの状態やレプリケーション関連の情報を取得します。サーバーの状態やレプリケーションが正常でない場合、
                                            orchestratorはフェイルオーバーが発生していると判断します。
                                        サーバーのヘルスチェック: orchestratorはMySQLサーバーのヘルスチェックを行い、サーバーが応答しているかどうかを確認します。
                                            サーバーがダウンしているか、レスポンスが遅い場合、orchestratorはフェイルオーバーが発生していると判断します。
                                        レプリケーションの遅延検出: orchestratorは、マスターサーバーとレプリカサーバー間のレプリケーション遅延を監視します。
                                            遅延が一定のしきい値を超えると、orchestratorはフェイルオーバーが必要な状況であると判断します。
                                        デッドマスター検出: orchestratorは、レプリカサーバーがマスターサーバーからのデータの読み取りや更新ができない状態を検出します。
                                            このような状況が発生すると、orchestratorはマスターサーバーがダウンしているか、障害が発生していると判断し、フェイルオーバーを開始します。
                                    これらの監視方法により、orchestratorはMySQLのフェイルオーバーを効果的に検出し、適切なタイミングでマスターサーバーの切り替えを行います。
                                    ただし、検出方法やパラメータは、orchestratorの設定によってカスタマイズできるため、特定の環境や要件に合わせて調整することができます。
                            リカバリー, フェールオーバー:  #ref: https://github.com/openark/orchestrator/blob/master/docs/configuration-recovery.md
                        フック:  #ref: https://mita2db.hateblo.jp/entry/2021/02/16/005058
                画面:
                    Dashboard を表示します: #keyword: orchestrator Dashboard
                        orchestrator WebUI >> Clusters メニュー >> Dashboard
                ログ: #keyword: openark Orchestrator log
                    CLI:
                        WebUI:
                            Audit メニュー >> Failure detection:
                                概要として残すとよいでしょう
                            Audit メニュー >> Recovery:  #// jourcelctl と同じ
                                journalctl の以下の接頭辞がある行と同じ内容です: |
                                    INFO topology_recovery:
                        journalctl:  #// 重要
                            sudo journalctl -u orchestrator --no-pager  --since "2025-01-01 00:00:00" --until "2025-01-01 00:06:00"  | less
                        orchestrator.log:
                            sudo tail -f /var/log/orchestrator.log
                    WebUI:
                        Audit タブ >> General, Failure detection など  #// Audit の中のメニュー項目は表示の切り替えだけなので心配しなくて構いません
                概念, 構成:
                    Orchestrator:
                        Orchestrator用 データベース:  #// SQLite インスタンス、または MySQLインスタンス
                            状態を保存するために、Orchestrator用の データベース インスタンス が必要になります
                    MySQL ホスト:
                        マスター:
                        スレーブ:
                ファイル: #keyword: orchestrator files
                    .conf.json:  #ref: /opt/orchestrator/orchestrator.conf.json  設定ファイル  #glossary: openark Orchestrator
                        公式:  #ref: https://github.com/openark/orchestrator/blob/master/go/config/config.go
                        PostFailoverProcesses:
                            フェールオーバーしたあとに実行するコマンドの配列（スクリプト相当）。
                            ここで VIP のスイッチなどを行います
                        DeadMaster 判定関連:  #glossary: openark Orchestrator
                            InstancePollSeconds:  #// チェック間隔。デフォルト値 = 5秒（未確認）
                                #search: WARNING discoverInstance exceeded
                                #search: MySQL Orchestrator discoverInstance
                            MySQLConnectTimeoutSeconds:  #// MySQL接続タイムアウト。デフォルト値 = 2秒（未確認）
                            ReasonableInstanceCheckSeconds:  #// SELECT文のインスタンスの応答速度の閾値。DeadMaster 判定に使われる。デフォルト値 = 5秒（未確認）
                            ReasonableReplicationLagSeconds:  #// レプリケーション遅延の許容時間。DeadMaster 判定に使われない。デフォルト値 = 10～30秒？（未確認）
                            MySQLDiscoveryReadTimeoutSeconds:  #// 詳細情報収集タイムアウト。デフォルト値 = 10秒（未確認）
                            MySQLTopologyReadTimeoutSeconds:  #// MySQL トポロジ読み取りタイムアウト。デフォルト値 = 600秒（未確認）
                            RecoveryPollSeconds:  #// 復旧処理の実行間隔。デフォルト値 = （未確認）
                            DeadInstancePollSecondsMax:  #// デッドインスタンス読み取り試行間の最大遅延。デフォルト値 = 300秒（未確認）
                            FailureDetectionPeriodBlockMinutes:  #// 障害検出の猶予期間。デフォルト値 = 
                            DeadInstancePollSecondsMultiplyFactor:  #// デッドインスタンスの読み取り時間計算における増加係数。デフォルト値 = 1（未確認）
                            UnreachableMasterWithLaggingReplicasDetectionSeconds:  #// 到達不能マスターと遅延レプリカの検出タイミング
                            RecoveryPeriodBlockSeconds:  #// 連続したリカバリを回避するためのブロック期間
                コード:
                    hooks:  #ref: https://github.com/openark/orchestrator/blob/master/docs/configuration-failure-detection.md#hooks
                トラブルシューティング:
                    - #// リセットしたい  #search: reset Orchestrator
                    - #// エラーの調査
                        Failure detection:
                            orchestrator WebUI >> Audit メニュー >> Failure detection >> Analysys（の項目）>> Related recovery
                        Logs:
                            orchestrator WebUI >> Clusters メニュー >>（最も下）>>（ホスト名の右）＞＞ ボタン
                    - #// WARNING discoverInstance exceeded InstancePollSeconds for __Master__:3306, took 10.0034s
                        #keyword: WARNING discoverInstance exceeded
                        ログ: |
                            WARNING discoverInstance exceeded InstancePollSeconds for __Master__:3306, took 10.0034s
                        状況:
                            discoverInstance 処理が 10.0034s かかり、設定値 InstancePollSeconds を超えました。
                        対処:
                            InstancePollSeconds の設定値を、ログに書かれた時間×1.5～3倍に変更します  #// 未確認
                            #search: InstancePollSeconds
                            #search: MySQL Orchestrator discoverInstance
                    - #// db1 を discover しても、localhost が見つかってしまう
                        手順: discover cluster
                        エラー: db1 を discover しても、localhost が見つかってしまう
                        対処: /etc/orchestrator.conf.json#MySQLTopologyUser
                            に指定した MySQL ユーザーは orc サーバーに作らないでください
                    - #// x509: certificate
                        手順: http://orc:3000/api/discover/db1/3306  (Discover)
                        エラー: |
                            x509: certificate is valid for MySQL_Server_8.0.25_Auto_Generated_Server_Certificate, not __DB_ServerName__
                        対処:
                            orc サーバーから db1 サーバーに MySQL shell の接続ができるようにしてください
                    - #// errant gtid  #keyword: Orchestrator errant gtid. Orchestrator Problem: errant gtid
                        手順: orchestrator WebUI >> Clusters メニュー >> Dashboard >> errant gtid（エラー：右上）
                        原因:
                            スレーブにマスターとは異なるトランザクションが存在しています。
                        対処A:  #// 未確認
                            Errant GTID を特定します:
                                コマンド: slave 側 mysql> SHOW SLAVE STATUS \G
                                Errant GTID: Executed_Gtid_Set にあって Retrieved_Gtid_Set に無い GTID
                                補足:
                                    Executed_Gtid_Set と Retrieved_Gtid_Set の両方にある GTID:
                                        受信して実行したトランザクションなので対処は不要です


                        対処B:  #// 強制解除。データの同期がとれていないまま復帰する可能性があります
                            ホストの情報を開きます:
                                orchestrator WebUI >> Clusters メニュー >> Dashboard >>
                                    （ホスト名）>>（スレーブ側の赤い歯車）>>（GTID errant の行、GTID purged の下の行、Fix：右の）▼ >>
                                    Reset master
                        #ref: ${typrm_files}/ref/Database-AI.yaml#label: errant gtid
                    - #// The most recent failure being Worker 1 failed executing transaction
                        ログ: |
                            Coordinator stopped because there were error(s) in the worker(s).
                            The most recent failure being: Worker 1 failed executing transaction '__UUID__:1'
                            at source log mysql-bin.000001, end_log_pos 919.
                            See error log and/or performance_schema.replication_applier_status_by_worker table for more details about this failure or others, if any.
                        対処:
                            ログの位置がマスターとスレーブでほぼ同じにします:
                                #search: MySQL log position
                            （書きかけ）リストアする？:
                    - 脆弱性: #ref: https://cve.report/software/openark/orchestrator
            MHA: #keyword: MHA  #// Google 製 MySQL レプリケーション
                URL: https://code.google.com/archive/p/mysql-master-ha/
                参考: https://kenoha.hatenablog.com/entry/2016/12/16/062855
            mysqlfailover:
                概要: MySQL に入っているフェールオーバー対応
        バックアップ:  #search: MySQL back up
        関数:
            MAX と LAST_INSERT_ID:  #keyword: MySQL MAX,  MySQL LAST_INSERT_ID
                指定したテーブルのフィールド（列）の中の最大値:
                    select MAX(__FieldName__) from __TableName__;
                直前に insert したテーブルの auto_increment が付いたフィールドの値:
                    select LAST_INSERT_ID();
                autoincrement する ID を自動設定する insert:
                    #search: MySQL insert autoincrement
            COALESCE:  #// 最初の NULL 以外の値を返します。NULL を返したときの値を指定します
                - COALESCE(__Value1__, __Value2__)
                - COALESCE(__Value1__, __Value2__, ...)
        変数:  #keyword: MySQL variables
            共通:
                - 変数名の大文字小文字は区別しません
                - /etc/my.cnf ファイルにも指定できるようです（未確認）
            参照 >> 変数の値を表示します:
                - mysql>: show variables;
                - mysql>: show variables like '__VariableNamePrefix__%';
                - mysql>: SHOW GLOBAL VARIABLES LIKE 'log_error_suppression_list';    #keyword: MySQL SHOW GLOBAL VARIABLES LIKE
            設定 >> MySQL定義の変数を設定します:
                セッション中だけ設定する場合 >> mysql>: set __Name__=__Value__;
                グローバル変数: SET GLOBAL log_error_suppression_list = 'MY-013360';    #keyword: MySQL SET GLOBAL
                my.cnf: |  #// アンダーバーとハイフンの違いに注意
                        [mysqld]
                        log-error-suppression-list='MY-013360'
                    #search: change my.cnf
                補足: ON または OFF の値をとるときに 1 または 0 を指定することもできます
            Server System Variables: #ref: https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html
                サンプル:  #// binlog_row_event_max_size  #ref: https://dev.mysql.com/doc/refman/8.0/ja/replication-options-binary-log.html
                    コマンド行形式: #keyword: MySQL コマンド行形式
                        --binlog-row-event-max-size=#
                    システム変数: #keyword: MySQL システム変数
                        binlog_row_event_max_size (≥ 8.0.14)
        ネットワーク設定:  #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#network
    ログ: #keyword: MySQL log
        error ログ, --log-error: #keyword: MySQL log-error,  MySQL error  #// サーバーから出力されるエラーメッセージ
            ログ:
                /var/log/mysqld.log:  #// ←サンプル。my.cnf の log-error の値
            場所:
                ファイル:  #// ファイルに出力します
                    my.cnf:
                        log-error=/var/log/mysqld.log
                syslog:
                    my.cnf: |
                        [mysqld_safe]
                        syslog
            警告を抑制します: #keyword: suppress MySQL warning
                変数に設定する場合:
                    使えるバージョン:
                        MySQL 8.0.13 (8.0.30?) ～
                        MySQL 8.3.0 でも使えます
                    コマンド:  #search: MySQL command
                        read -s -p "Enter password> "  MYSQL_ROOT_PASSWORD
                        mysql  --socket=_____  --user "root"  --password="${MYSQL_ROOT_PASSWORD}"  -e"SET GLOBAL log_error_suppression_list = 'MY-013360';"
                        mysql  --socket=_____  --user "root"  --password="${MYSQL_ROOT_PASSWORD}"  -e"SHOW GLOBAL VARIABLES LIKE 'log_error_suppression_list';"
                    再起動した場合:
                        SET GLOBAL による設定は再起動しても戻りません
                ファイルに設定する場合:
                    使えるバージョン:  #ref: https://repost.aws/questions/QUc_APXlzaTY6Ml73KEjRZwg/support-for-log-error-suppression-list-in-mysql8-parameter-groups
                        MySQL 8.0.13 (8.0.30?) ～ 8.0.33(?) で使える。
                        MySQL 8.0.39 では使えないが 1回しか警告は出ない
                        MySQL 8.3.0 では使える
                    抑制する設定: | #keyword: log_error_suppression_list  #search: /etc/my.cnf
                        [mysqld]
                        log_error_suppression_list='MY-013360'
            クリアします: #keyword: MySQL clear log-error  #// ディスクの使用量を減らします
                （必要なら）フラッシュします:
                    mysql> FLUSH ERROR LOGS;
                サイズを 0 にします:
                    truncate --size 0  /var/log/mysqld.log
                #// ファイルの削除は良くありません
        SlowQuery ログ: #keyword: MySQL slow_query_log  #// 処理に時間のかかったクエリ
            ログ:
                /usr/local/mysql/data/slow.log:  #// ←サンプル。my.cnf の slow_query_log_file の値
            場所と設定:
                my.cnf: |
                    slow_query_log                     # slow queryログの有効化
                    slow_query_log_file=/usr/local/mysql/data/slow.log    # ファイルパス
                    long_query_time=5                  # 記録条件。5秒以上処理に時間がかかったクエリを記録します
                    log-queries-not-using-indexes      # インデックスが使用されていないクエリをログに出力
        詳細ログ: #keyword: MySQL general_log  #// 詳細な情報を記録。すべての操作
            ログ:
                general.log:  #// ←サンプル。my.cnf の general_log_file の値
            場所と設定:
                my.cnf: |
                    [mysqld]
                    general_log                                         #// 詳細ログ有効化
                    general_log_file=/usr/local/mysql/data/general.log  #// ファイルパス
        バイナリ ログ: #keyword: MySQL log-bin  #// 更新SQL文（バイナリ形式）
            ログ:  #ref: https://dev.mysql.com/doc/refman/8.0/ja/binary-log.html
                master-bin.index:  #// ← index ファイル のサンプル。my.cnf の log-bin-index の値
                    （ファイル名）
                master-bin.000000:
                    （ログ）  #search: mysqlbinlog
                mysqlbinlog コマンド:  #keyword: mysqlbinlog  #// バイナリ ログ の内容を表示します
                    表示: mysqlbinlog __BinLogFile__
                    GTID で検索する場合:  #// 下記はすべての バイナリ ログ を処理するため重たくなる可能性があります
                        - cat  ____/mysql-bin.index  |  xargs  mysqlbinlog  |  grep -F "'__GTID__'"  -B 3 -A 3 -n  #// 前後3行、行番号付き表示
                        - cat  ____/mysql-bin.index  |  xargs  mysqlbinlog  |  less -N  #// 行番号付き表示
                    出力例: |  #focus: #240101,  __TableName__  #// 下記は、かなり端折っています
                        SET @@SESSION.GTID_NEXT= '91d3903b-cedd-11ee-9c8c-00505688bbbe:1'/*!*/;
                        # at 234
                        #240101 00:00:00 server id 1234  end_log_pos __Num__ CRC32 0x________      Query   thread_id=40112 exec_time=0     error_code=0
                        SET @@session.pseudo_thread_id=40112/*!*/;
                        #240101 00:00:00 server id 1234  end_log_pos __Num__ CRC32 0x________      Table_map: `__DB_Name__`.`__TableName__` mapped to number __Num__
                        #240101 00:00:00 server id 1234  end_log_pos __Num__ CRC32 0x________      Update_rows: table id 366 flags: STMT_END_F
                        BINLOG '
                        ____   BINLOG は他の行に書かれている内容のバイナリです
                        '/*!*/;
                    #ref: https://dev.mysql.com/doc/refman/8.0/ja/mysqlbinlog.html
                    #ref: https://dev.mysql.com/doc/refman/8.0/ja/binary-log.html
                    出力内容:
                        イベント:  #// CRC の値の右。
                            （検索）: Source Code Documentation  https://dev.mysql.com/doc/dev/mysql-server/latest/  の右上に
                                __EventName__ または __EventName___event を入力して検索するとヒットします
                            Query:
                            Table_map:
                            Update_rows:
                    オプション:
                        フィルタリング: #keyword: mysqlbinlog filter
                            --database:	指定のデータベースのみ表示します。テーブル名は grep でフィルタリングします
                            --server-id: 指定の ID のサーバーのみ表示します
                            --start-datetime: タイムスタンプの範囲の開始日時 "2005-12-25 11:25:56" 形式
                            --stop-datetime: タイムスタンプの範囲の終了日時
                            --offset: ログの最初の N エントリをスキップ
                            --start-position: 引数以上の位置を持つ最初のイベントから。end_log_pos の値がフィルタリングの対象です。（試すと違うみたい）
                                #240516 00:00:00 server id 123  end_log_pos 5471143 CRC32 0x111174d2  Table_map: `monthly_report`.`monthly_report` mapped to number 111
                            --stop-position: 引数以上の位置を持つ最初のイベントでバイナリログのデコードを停止。
                                範囲ではなく特定の end_log_pos を検索するときは、--start-position と同じ値を指定します（範囲を指定しないと全体像は見えないらしい）
            場所と設定:  #ref: https://dev.mysql.com/doc/refman/8.0/ja/replication-options-binary-log.html
                my.cnf ファイル: |
                    [mysqld]
                    log-bin=master-bin          #// バイナリログのベース名
                    log-bin-index=master-bin    #// バイナリログのファイル名を記録したindexファイル名
                log-bin-index:
                    デフォルトでは、--log-bin オプションと拡張子 .index を使用してバイナリログファイルに指定された値と同じ場所とベース名を持ちます。
        debug ログ, --debug:  #// 開発者向けのトレースログ
        #ref: https://qiita.com/toshihirock/items/a97d174be68f485fbbf2
    ファイル:
        /etc/my.cnf: #keyword: /etc/my.cnf  #ref: ${programming}/検索技術、DB/SQL/MySQL.svg#etc_my_cnf
            公式:
                #ref: https://dev.mysql.com/doc/refman/8.0/ja/option-files.html
                Server System Variables:  #ref: https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html
                Server Command Options:  #ref: https://dev.mysql.com/doc/refman/8.0/en/server-options.html
            検索のしかた:
                my.cnf の basedir の仕様は、
                Server Command Options から --basedir をブラウザーのページ内検索で検索するか
                Server System Variables から basedir をブラウザーのページ内検索で検索します。
            basedir:
            システム変数: #search: MySQL システム変数
        /etc/my.cnf.d/: /etc/my.cnf.d/ フォルダー内の .cnf（Windows なら .ini）も設定ファイルです
            ただし、/etc/my.cnf の !includedir /etc/my.cnf.d によります
        data/: #keyword: MySQL datadir, MySQL data folder  #ref: https://dev.mysql.com/doc/refman/8.0/ja/data-directory.html
            場所:
                my.cnf:
                    datadir=__FolderPath__
                mysql CLI:  #// mysql コマンドライン ツール を使う場合
                    mysql> SHOW VARIABLES LIKE 'datadir';
    トラブルシューティング(MySQL):  #keyword: trouble shooting MySQL
        - #// Error: Unable to find a match: mysql-community-client
            手順: sudo dnf install -y  mysql-community-client
            エラー: |
                Error: Unable to find a match: mysql-community-client
            対処:
                #search: MySQL newest version
        - #// 依存モジュール, ドライバー  #search: MySQL drivers
        - #// Warning: (1300, "Invalid utf8mb4 character string: '___Code___'")
            手順: pymysql の query など
            ログ: |
                .venv/lib/python3.7/site-packages/pymysql/cursors.py:170: Warning: (1300, "Invalid utf8mb4 character string: 'D6FE63'")
            対処:
                無視してください。
            AI の回答: |
                他の重要な警告まで抑制したくないかによる
                import warnings
                import pymysql

                # 特定の警告を無視する
                warnings.filterwarnings('ignore', category=pymysql.Warning)

                # または、より具体的に指定する場合
                warnings.filterwarnings('ignore', message='Invalid utf8mb4 character string:.*')

                # データベース接続の例
                connection = pymysql.connect(
                    host='localhost',
                    user='user',
                    password='password',
                    db='database',
                    charset='utf8mb4',
                    # バイナリカラムを使用する場合は以下のオプションを追加
                    binary_prefix=True
                )

                # カーソルの作成時に以下のように設定することでも対応可能
                cursor = connection.cursor(pymysql.cursors.DictCursor)
        - #// エラー, The most recent failure being Worker 1 failed executing transaction:
            ログ:
                Orchestrator >> config dialog: |
                    Coordinator stopped because there were error(s) in the worker(s).
                    The most recent failure being: Worker 1 failed executing transaction '__UUID__:1'
                    at source log mysql-bin.000001, end_log_pos 919.
                    See error log and/or performance_schema.replication_applier_status_by_worker table for more details about this failure or others, if any.
                MySQL:
                    （特になし）
            対処:
                バイナリ ログ の位置がマスターとスレーブでほぼ同じことを確認します  #search: MySQL log position
        - #// エラー, The GTID set sent by the replica:
            手順:
                mysql> CHANGE MASTER TO
            ログ: |
                Got fatal error 1236 from source when reading data from binary log: 'Cannot replicate because the source purged required binary logs.
                Replicate the missing transactions from elsewhere, or provision a new replica from backup. Consider increasing the source's binary log expiration period.
                The GTID set sent by the replica is '', and the missing transactions are
            対処:
                GTID_PURGED を設定してリカバーします
        - #// ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)  #keyword: MySQL Access denied for user
            手順: mysql ログイン
            エラー: |
                - ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)
                - ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)
            対処:
                ユーザー名とパスワードとホストを再確認してください
            補足: | #keyword: (using password: NO)
                using password: NO は、クライアントがパスワードを入力しなかったことを示しています
        - #// ERROR 1130 (HY000): Host 'mysql-1.example.com' is not allowed to connect to this MySQL server
            手順: mysql ログイン
            エラー: |
                ERROR 1130 (HY000): Host 'mysql-1.example.com' is not allowed to connect to this MySQL server
            対処:
                ERROR 1141 と同じです  #search: MySQL ERROR 1141
        - #// ERROR 1141 (42000): There is no such grant defined for user '__MySqlUser__' on host '__ClientHostName__'  #keyword: MySQL ERROR 1141
            手順: SHOW GRANTS FOR '__MySqlUser__'@'__ClientHostName__' \G
            エラー: |
                ERROR 1141 (42000): There is no such grant defined for user '__MySqlUser__' on host '__ClientHostName__'
            対処A:  #// 名前を再確認します
                mysql.user テーブルを表示します:
                    - root ユーザー で mysql にログインします  #search: start MySQL command
                    - mysql> SELECT user, host FROM mysql.user WHERE user="__MySqlUser__";  #search: list MySQL user
                __MySqlUser__ と __ClientHostName__ が正しいことを確認してください:
                    #// mysql.user テーブルの __ClientHostName__ が % のとき、localhost には一致しません。（他もそうかもしれません）
            対処B:  #// フラッシュします
                mysql> FLUSH PRIVILEGES;
                #search: FLUSH PRIVILEGES
            補足:
                大文字小文字の違いについて:
                    -   mysql.user テーブル の host に小文字で書かれていて、エラーメッセージに大文字が書かれている環境においても、
                        小文字を指定することで、リモート ログイン や、レプリケーションなどはできます。
                    -   CREATE USER コマンドで大文字のホストを指定しても小文字でテーブルに登録されます
                    #// Linux MySQL 8.0
        - #// ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (13)
            手順: mysql ログイン
            エラー: |
                ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (13)
            対処:
                mysql コマンドを実行するユーザーが使えるパーミッションであることを確認します
                ls -l '/tmp/mysql.sock'
        - #// ERROR 2003 (HY000): Can't connect to MySQL server on 'mysql.example.com' (101)
            手順: mysql ログイン
            エラー: |
                ERROR 2003 (HY000): Can't connect to MySQL server on 'mysql.example.com' (101)
            対処:
                接続先のサーバー名を再確認してください
        - #// ERROR 1396 (HY000): Operation CREATE USER failed
            手順: mysql> CREATE USER
            エラー: |
                ERROR 1396 (HY000): Operation CREATE USER failed for 'root'@'localhost'
            対処A: ユーザーを削除していいなら、削除します  #search: MySQL DROP USER
            原因: すでにユーザーが存在しています
        - #// ERROR 3546 (HY000) at line 26: @@GLOBAL.GTID_PURGED cannot be changed: the added gtid set must not overlap with @@GLOBAL.GTID_EXECUTED
            手順: (bash) mysql ____ < ____.sql  #// 上書きリストア
            エラー: |
                ERROR 3546 (HY000) at line 26: @@GLOBAL.GTID_PURGED cannot be changed: the added gtid set must not overlap with @@GLOBAL.GTID_EXECUTED
            対処:
                GTID を削除してからリストアします:  #// リストアすると GTID もリストアされるようです
                    mysql> RESET MASTER;
                    (bash) mysql ____ < ____.sql
        - #// unable to connect to database root
            手順: MySQL 初期化
            ログ: |  #focus: unable to connect to database root
                fatal: [__Host__]: FAILED! => {"changed": false, "msg": "unable to connect to database, check login_user and login_password are correct or __Home__/.my.cnf has the credentials. Exception message: (1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")"}
                fatal: [__Host__]: FAILED! => {"changed": true, "cmd": ["mysql", "--defaults-file=my.cnf", "-u", "root", "--connect-expired-password", "-e", "ALTER USER 'root'@'localhost' IDENTIFIED BY '____';"], "delta": "0:00:00.042486", "end": "2025-02-07 16:32:55.666195", "msg": "non-zero return code", "rc": 1, "start": "2025-02-07 16:32:55.623709", "stderr": "ERROR 2002 (HY000): Can't connect to local MySQL server through socket 'mysql.sock' (2)", "stderr_lines": ["ERROR 2002 (HY000): Can't connect to local MySQL server through socket 'mysql.sock' (2)"], "stdout": "", "stdout_lines": []}
            対処:
                datadir を削除して再初期化します: |
                    systemctl stop mysqld
                    rm -rf mysql/data  #search:  MySQL datadir
                    mysqld --initialize-insecure
        - #// error connecting to master - retry-time: 60  retries: __Count__, Error_code: MY-002061  #keyword: MySQL error retry-time
            手順: mysql ログイン、または、SHOW SLAVE STATUS
            エラー:
                mysql ログイン: |
                    [ERROR] [MY-010584] [Repl] Slave I/O for channel '': error connecting to master
                    'repl@mysql-2:3306' - retry-time: 60  retries: 1, Error_code: MY-002061
                SHOW SLAVE STATUS: |
                        Last_IO_Errno: 2005
                        Last_IO_Error: error connecting to master 'repl@m1100L-local.net:3306' - retry-time: 60  retries: __Count__
                    #// __Count__ の部分は増えていきます
            対処:
                __MySqlUser__ と __ClientHostName__ が正しいことを確認してください
                    #search: MySQL ERROR 1141
        - #// Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work
            手順: CHANGE MASTER TO した後の SHOW SLAVE STATUS
            エラー: |
                Last_IO_Errno: 13117
                Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the --replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it).
            対処A:
                CHANGE MASTER TO の MASTER_HOST に自分以外を指定します
            対処B:
                server_id が衝突していないか確認します  #search: MySQL server_id
        - #// keyword: mysql: [Warning] Using a password on the command line interface can be insecure."
            手順: mysql --password=__Password__  __Parameters__
            エラー: |
                mysql: [Warning] Using a password on the command line interface can be insecure."
            対処:  #keyword: mysql CLI password
                bash の場合:  #search: bash variables in command
                    MYSQL_PWD=__Password__  mysql  __Parameters__
                docker exec の場合:
                    export MYSQL_PWD="${RootPassword}"
                    docker exec -it --env MYSQL_PWD  __Container__  mysql  __Parameters__
        - #// (2003, \"Can't connect to MySQL server on 'control.example.com' ([Errno 111] Connection refused)\")"
            手順: |
                Ansible のホストノードである control.example.com から次の mysql_user task を実行するとエラーになります。
                -   name: create user2 user
                    mysql_user:
                        login_host: "control.example.com"
            エラー: |
                "msg": "unable to connect to database, check login_user and login_password are correct or /var/lib/jenkins/.my.cnf has the credentials. Exception message: (2003, \"Can't connect to MySQL server on 'control.example.com' ([Errno 111] Connection refused)\")"
            対処:
                login_host に MySQL があるサーバー名を指定してください。
        - #// (1130, u\"control' is not allowed to connect to this MySQL server\")"}
            手順: |
                Ansible のホストノードである control.example.com から次の mysql_user task を実行するとエラーになります。
                -   name: create user2 user
                    mysql_user:
                        login_host: "db1.example.com"
            エラー: |
                "msg": "unable to connect to database, check login_user and login_password are correct or /var/lib/jenkins/.my.cnf has the credentials. Exception message: (1130, u\"control' is not allowed to connect to this MySQL server\")"}
            対処:
                mysql.user テーブルをチェックします  #search: MySQL user
        - #// ImportError: libmysqlclient.so.21: cannot open shared object file: No such file or directory
            手順: Python の import _mysql 文  #keyword: MySQL Python libmysqlclient trouble
            エラー: |
                ImportError: libmysqlclient.so.18: cannot open shared object file: No such file or directory
            対処A: |
                LD_LIBRARY_PATH を正しく設定します
                .so ファイルのパスは ldd コマンドで確認します。
            対処B: |
                見つからない .so に依存している.親の .so のバージョンを正しくします。
                下記の場合、_mysql.cpython-37m-x86_64-linux-gnu.so のバージョンを正しくします。
                .so ファイルのパスは ldd コマンドで確認します。 ただし、LD_LIBRARY_PATH を正しく設定しておきます。
                #search: libmysqlclient.so
            対処C: |
                libmysqlclient.so.18 ファイルの内容を file コマンドでチェックします。 #search: Linux file command
                broken symbolic link to ____ の場合、シンボリックリンクを修正します。
                違う arch の場合、置き換えます。
            サンプル:
                ファイル構成:  #focus: libmysqlclient.so
                    MySQLdb/__init__.py: |  #ref: lib/python3.7/site-packages/MySQLdb/__init__.py
                        from . import _mysql    #// load _mysql.cpython-37m-x86_64-linux-gnu.so
                    MySQLdb/_mysql.cpython-37m-x86_64-linux-gnu.so: #keyword:
                        コマンド: #keyword: ldd example
                            ldd "MySQLdb/_mysql.cpython-37m-x86_64-linux-gnu.so"
                        出力:  #// 依存するバージョンは開発環境によって異なります
                            ...
                            libmysqlclient.so.21 => /usr/lib64/mysql/libmysqlclient.so.21 (0x00007fe391c9c000)
                            ...
                        出力形式:
                            各行: __FileName__ => __FullPath__ (__ReservedSoAddress__)
                            __ReservedSoAddress__: マップされる予定のアドレス。プロセスからロードされるまで実際にはマッピングされません
                        構成:
                            mysqlclient (Python パッケージ)
                                └─ _mysql.so (C拡張モジュール)
                                    └─ libmysqlclient.so (MySQL C クライアントライブラリ)
                                        └─ libssl.so.10 (OpenSSL 1.0.x) ← ここで要求される
                    libmysqlclient.so.18:
        - #// mysql_real_escape_string_quote
            手順: Python libmysqlclient ロード時
            エラー: |
                MySQLdb/_mysql.cpython-37m-x86_64-linux-gnu.so: undefined symbol: mysql_real_escape_string_quote
            対処:
                MySQL client のバージョンを MySQL サーバーのバージョンに合わせます  #search: MySQL Python libmysqlclient trouble
        - #// Too many open files   #keyword: MySQL Too many open files
            手順: サービス稼働中
            エラー: |
                [ERROR] [MY-010283] [Server] Error in accept: Too many open files
            対処:
                open_files_limit を増やす
                #ref: https://iserversupport.com/blog/mysql-error-accept-many-open-files/
        - #// Public key for mysql-community-client-plugins-8.0.28-1.el7.x86_64.rpm is not installed
            手順:
                (@host) Git bash:
                    ./run_playbook.sh
            エラー: |
                Importing GPG key 0x_____:
                    :
                Public key for mysql-community-client-plugins-8.0.28-1.el7.x86_64.rpm is not installed
                    :
            対処:
                コマンドの場合: sudo rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022
                Ansible の場合:  #search: ansible rpm_key
        - #// Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock'
            手順: mysql  --user "__UserName__" --password  [--host __HostName__]  [-p  __DatabaseName__]
            エラー: |
                ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)
            対処:
                MySQL が起動中です。1分ほど待ってから再実行してください。
        - #// Lost connection to MySQL server during query
            手順: テスト実行時や高負荷時
            エラー: |
                - Lost connection to MySQL server during query
                - sqlalchemy.exc.OperationalError: (MySQLdb._exceptions.OperationalError) (2013, 'Lost connection to MySQL server during query')
            対処:
                以下のオプションを調整します:
                    - wait_timeout
                    - max_allowed_paket
                    - innodb_buffer_pool_size
                    #search: MySQL start options
                または、ディスクの容量不足になっていないか確認します:
        - #// master and slave have equal MySQL server ids;
            手順: mysql> START GROUP_REPLICATION;
            エラー: |
                [ERROR] [MY-013117] [Repl] Slave I/O for channel '': Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids;
                these ids must be different for replication to work (or the --replicate-same-server-id option must be used on slave but this does not always make sense; 
                please check the manual before using it). Error_code: MY-013117
            対処: |  #keyword: /var/lib/mysql/auto.cnf
                #snote: %UserProfile%\GitProjects\GitHub\MyPrivateCode\ansible_vagrant\multi_vm_ansible\branch_orchestrator
                rm /var/lib/mysql/auto.cnf
                RESET SLAVE ALL
            補足:  #keyword: MySQL Server UUID, performance_schema.replication_group_members MEMBER_ID
                Server UUID:
                    - /var/lib/mysql/auto.cnf に書かれています
                    - mysql> select * from performance_schema.replication_group_members;
                        の MEMBER_ID 列に表示されます
        - #// The server is not configured properly to be an active member of the group.
            手順: セカンダリー サーバーで mysql> START GROUP_REPLICATION
            エラー: |
                "ERROR 3092 (HY000) at line 1: The server is not configured properly to be an active member of the group.
                Please see more details on error log."
                または
                Can't start group replication on secondary member with single-primary mode while asynchronous replication channels are running.
            対処: |
                すべてのサーバーに mysql> START GROUP_REPLICATION; を実行してください
        - #// Operation ALTER USER failed
            手順: mysql> ALTER USER
            エラー: |
                mysql: [Warning] Using a password on the command line interface can be insecure.",
                "ERROR 1396 (HY000) at line 1: Operation ALTER USER failed for 'rpl_user'@'%'"
            対処: |
                Ansible を使うときは、mysql_user モジュールで一度に権限を設定してください
        - #// Unknown system variable 'group_replication_bootstrap_group'
            手順: SET GLOBAL group_replication_bootstrap_group=ON;
            エラー: |
                ERROR 1193 (HY000) at line 1: Unknown system variable 'group_replication_bootstrap_group'
            対処:
                sudo systemctl restart mysqld
        - #// Error on opening a connection to 192.168.33.103:33061 on local port: 33061.'
            手順: (@セカンダリー サーバー) START GROUP_REPLICATION;
            エラー: |
                ERROR 3092 (HY000) at line 1: The server is not configured properly to be an active member of the group. Please see more details on error log.
                $ sudo cat /var/log/mysqld.log
                    [ERROR] [MY-011735] [Repl] Plugin group_replication reported: '[GCS] Error on opening a connection to 192.168.33.103:33061 on local port: 33061.'
                mysql> select * from performance_schema.replication_group_members;
                    MEMBER PORT == NULL
            対処: |
                (@プライマリー サーバー) SET GLOBAL group_replication_bootstrap_group=ON;
                (@プライマリー サーバー) START GROUP_REPLICATION;
                (@プライマリー サーバー) SET GLOBAL group_replication_bootstrap_group=OFF;
            参考: https://ngyuki.hatenablog.com/entry/2018/07/02/072619
            補足: MySQL 8.0 でも認証プラグイン caching_sha2_password を使わずにレプリケーションができます
        - #// blocked because of many connection errors
            手順: mysql> SHOW SLAVE STATUS\G
            エラー: |
                error connecting to master '__ResponsingUser__@__ResponsingHost__:3306' - retry-time: ____ retries: ____ message: Host '__RequestingHost__'
                is blocked because of many connection errors; unblock with 'mysqladmin flush-hosts'
            対処A:
                __ResponsingHost__ で MySQL shell にログインして SHOW SLAVE STATUS\G を実行してください
            対処B:
                __ResponsingHost__ で mysqladmin flush-hosts を実行してください  #serach: mysqladmin flush-hosts
        - #// You are not allowed to create a user with GRANT
            手順: mysql grant コマンド実行時
            エラー: |
                You are not allowed to create a user with GRANT
            対処:
                説明: MySQL 8.0 では GRANT コマンドでユーザーを同時に作ることはできません。
                    ユーザーを作ってから権限を設定してください
                参考: https://www7390uo.sakura.ne.jp/wordpress/archives/456
                サンプル:
                    mysql> create user 'guro'@'localhost' identified by 'avava';
                    Query OK, 0 rows affected (0.14 sec)

                    mysql> grant all on *.* to 'guro'@'localhost' with grant option;
                    Query OK, 0 rows affected (0.19 sec)

                    mysql> flush privileges;
                    Query OK, 0 rows affected (0.22 sec)
        - #// You have an error in your SQL syntax
            手順: mysql command 実行時
            エラー: |
                You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '__Near__' at line __Line__
            対処A:
                MySQL のバージョンによって文法が違います。
                #search: MySQL IDENTIFIED BY
            対処B:
                - __Near__ と __Line__ は無視してください  #// https://php1st.com/1493
        - #// Access denied for user 'root'
            手順: shell> mysql  --user "root" --password  --host __HostName__
            エラー: |
                Access denied for user 'root'@'__HostName__' (using password: YES)
            対処:
                - mysql コマンドの --host オプションは指定しないでください
                - __HostName__ のシェルで実行してください
        - #// caching_sha2_password  Authentication requires secure connection
            手順: MySQL にログイン
            エラー: |
                Authentication plugin 'caching_sha2_password' reported error: Authentication requires secure connection.
            対処:
                サンプルを参考にプロジェクトを作り直してください: |
                    %UserProfile%\GitProjects\GitHub\MyPrivateCode\ansible_vagrant\multi_vm_ansible\branch_mysql_replica
            参考:
                - https://yoku0825.blogspot.com/2018/10/mysql-80cachingsha2password-ssl.html
                - https://blog.s-style.co.jp/2020/03/5861/
MySQL のレプリケーション:  #search: MySQL replication
SQL WebUI:
    phpMyAdmin: #keyword:  #// MySQL の WebUI の 1つ
        画面イメージ: #ref: https://locallhost.me/assets/img/pages/phpmyadmin.jpg
        #ref: https://ja.wikipedia.org/wiki/PhpMyAdmin
    HeidiSQL: #keyword:  #// 多くの DBMS に対応
        #ref: https://www.heidisql.com/
    DBeaver: #keyword:  #// 多くの DBMS に対応
        #ref: https://dbeaver.io/
    Hue: #ref: https://jp.gethue.com/
Percona XtraBackup: #keyword:  #// データベースに負荷をかけないバックアップおよび履歴
    公式: #ref: https://github.com/percona/percona-xtrabackup
    手順:
        レプリケーションの整合性をとります: #keyword: XtraBackup Synchronize  #// XtraBackup を使って、マスターとスレーブで同じデータにします
            必要性: マスターに障害が発生して旧スレーブ側に書き込みが行われた場合、レプリケーションを再設定しても整合性は取れません。
                バックアップとリストアが必要です。
                なお、問題のトランザクションを手動で修正する方法もあるようです。
    コマンド: #keyword: xtrabackup  #glossary:
        xtrabackup --backup:  #// バックアップを取ります。バックアップ中の差分も取ります。ただし、--prepare するまで使えません
            #ref: https://docs.percona.com/percona-xtrabackup/innovation-release/create-full-backup.html
            #// データベースが稼働中でも使えます
            #// 数GB〜数TBで数分〜数時間。バックアップの内容はこのコマンドが終了した時点の内容になります
        xtrabackup --prepare:  #// バックアップを完成させます。バックアップ中の差分（redo log）も合わせて各種整合性をとります
            #ref: https://docs.percona.com/percona-xtrabackup/innovation-release/prepare-full-backup.html
            #// データベースが稼働中でも使えます
            #// 通常は数分程度
            #// --backup で定時バックアップを取り、最新バックアップを --prepare で作るという運用ができます
        xtrabackup --copy-back:  #// リストアします
            #ref: https://docs.percona.com/percona-xtrabackup/innovation-release/restore-a-backup.html
            #// 数GB〜数TBで数分〜数時間
        オプション:
            --target-dir:  #// バックアップを作る場所、バックアップがある場所
                xtrabackup --backup  --target-dir=/data/backups/
    （関連）:  #search: mysqldump
SQLite: #keyword:  #// 軽量SQL DB
    手順 >> インストール:  #search: try_SQLAlchemy
    .db ファイルを Visual Studio Code で開きます:  #keyword: SQLite VSCode
        SQLite の拡張機能インストールします:
            VSCode >> Extensions（左）>> SQLite（と入力）>> Install
        開きます: |
            VSCode >> F1 キー >> SQLite: Open Database >>（.db ファイルを指定）>> Explorer（左上）
            SQLITE EXPLORER（左下）>>（ファイル名）>> テーブル名 >> ▲（テーブル名の右）
        最新の情報に更新します:
            テーブル名 >> ▲（テーブル名の右）
            #// 更新されるタイミングは SQLAlchemy なら session.commit() を呼び出したときです
PostgreSQL: #keyword:  #ref: https://www.postgresql.org/  #// 読み方は「ポスト グレス キューエル」。「ポストグレス」は世界的な略称。「ポスグレ」は日本での略称
    公式マニュアル:
        最新: #ref: https://www.postgresql.org/docs/
        9.6: #ref: https://www.postgresql.org/docs/9.6/index.html
    psql: #keyword:  #// PostgreSQL のシェル  #ref: https://www.postgresql.org/docs/9.6/app-psql.html
        ログイン, ログアウト相当:
            (@CentOS7):
                - docker ps -a  #// __ContainerName__ を調べる
                - winpty docker exec -it __ContainerName__  //bin/bash  #// winpty は Windows の Git bash の場合のみ必要
            (@Docker):
                - psql -U __UserName__
                - psql -U __UserName__  -d __DataBaseName__
            (@PostgreSQL):
                - \quit  #// psqlから抜けます
            (@Docker)_:
                - exit
            参考: #ref: https://www.postgresql.org/docs/9.6/app-psql.html >> SQL コマンドの入力
    データベース:  #keyword: PostgreSQL database
        一覧: \l  #keyword: PostgreSQL show databases  #search: psql
        切り替え: \c __DataBaseName__  または  \connect __DataBaseName__
        削除:
            psql を使う場合: DROP DATABASE name;  #ref: https://www.postgresql.jp/document/9.6/html/manage-ag-dropdb.html
            Docker のボリュームを削除する場合: #search: docker volume rm
    テーブル:
        一覧: \dt
MongoDB: #keyword:
    インストール:
        公式: #ref: https://docs.mongodb.com/manual/installation/
        MongoDB Atlas の場合: #// クラウド上に DB を配置する場合
            公式:
                MongoDB Atlas: #keyword:  #ref: https://www.mongodb.com/atlas/database
                MongoDB Drivers >> Node.js >> Quick Start :  #ref: https://docs.mongodb.com/drivers/node/current/quick-start/
            #// 2022-01-21
            Node.js をインストールします:  #search: install Node.js
            git をインストールします:  #search: install git
            サンプル プロジェクト をダウンロードします:
                Dock >> ターミナル:
                    - cd ~/Desktop
                    - git clone https://github.com/mongodb-university/js-starter.git
                    - cd js-starter  #// __Project__ とします
                    - npm install
            MongoDB のクラスターを作ります: #// Atlus UI を使って MongoDB Atlas クラウドの中にデータベースを作ります
                公式: #ref: https://docs.atlas.mongodb.com/getting-started/?tck=docs_driver_nodejs&_ga=2.97312351.1150412021.1642738357-762444909.1642738357
                サインアップします:
                    https://www.mongodb.com/atlas/database >> Try Free（やや下へスクロールして中央にある緑色のボタン） >>
                    （メールアドレスなどを入力します）>>（受信したメールを開きます）>> Verify Email
                サインインします:
                    https://www.mongodb.com/atlas/database >> Sign In（右上）（Chrome の場合、アカウントの入力は不要です）
                クラスターを作ります:
                    URL: https://cloud.mongodb.com/v2/1234567890abcdefghijklmn#clusters  #template: __MongoUI_URL__
                    Build a Database ボタン（中央）:
                    （Free Shared）Create ボタン（右下）:
                    Cloud Provider & Region など: （変更なし）
                    Create Cluster ボタン（右下）:
                    1:
                        How would you like to authenticate your connection?: Username and Password
                        Username: user1  #template: __MongoUser__
                        Password: pass1  #template: __MongoPass__
                        Create User ボタン:
                    2:
                        Where would you like to connect from?: My Local Environment
                        Add My Current IP Address ボタン:
                    Finish and Close ボタン（右下）:
                    Go to Database ボタン:  #// 表示されないかも？
                サンプル データ セット をデータベースに追加します:
                    Cluntor0 >> Collection >> Load Sample Dataset
            MongoDB Atlus に接続してデータを取得します:
                クラスターの URL をコピーします:
                    Atlus UI の Database メニューを選びます:
                        URL: https://cloud.mongodb.com/v2/1234567890abcdefghijklmn#clusters  #template: __MongoUI_URL__
                    Connect ボタン（Cluster0 の右：中央）:
                    Connect your application ボタン（中央）:
                    1　Select your driver and version:
                        DRIVER: Node.js
                        VERSION: 4.0 or later
                    2 Add your connection string into your application code:
                        Include full driver code example: チェックなし
                        クラスターの URL の部分をメモします:
                            __MongoClusterURL__: cluster0.abcde.mongodb.net  #template: __MongoClusterURL__
                    Close ボタン:
                    参考 >> コピーされる内容:
                        - |
                            mongodb+srv://user1:<password>@cluster0.rltzs.mongodb.net/myFirstDatabase?retryWrites=true&w=majority
                        - |
                            const { MongoClient } = require('mongodb');
                            const uri = "mongodb+srv://user1:<password>@cluster0.rltzs.mongodb.net/myFirstDatabase?retryWrites=true&w=majority";
                            const client = new MongoClient(uri, { useNewUrlParser: true, useUnifiedTopology: true });
                            client.connect(err => {
                                const collection = client.db("test").collection("devices");
                                // perform actions on the collection object
                                client.close();
                            });
                __Project__/index.js を作ります: |  #// サンプル データ セット の内容が変わっていたら、クエリーの内容を変更してください。
                    const { MongoClient } = require("mongodb");

                    const uri =
                        "mongodb+srv://user1:pass1@cluster0.abcde.mongodb.net?retryWrites=true&writeConcern=majority";
                            // #template-at(-1): mongodb+srv://__MongoUser__:__MongoPass__@__MongoClusterURL__?retry

                    const client = new MongoClient(uri);

                    async function run() {
                        try {
                            await client.connect();

                            const database = client.db('sample_mflix');
                            const comments = database.collection('comments');

                            // Query for a movie that has the title 'Back to the Future'
                            const query = { name: "Mercedes Tyler" };
                            const comment = await comments.findOne(query);

                            console.log(comment);
                        } finally {
                            // Ensures that the client will close when you finish/error
                            await client.close();
                        }
                    }

                    run().catch(console.dir);
                実行します:
                    (bash):
                        cd  __Project__
                        node index.js
            データベースとクラスターを削除します:
                URL: https://cloud.mongodb.com/v2/1234567890abcdefghijklmn#clusters  #template: __MongoUI_URL__
                メニュー: …（Cluster0 の右端）>> Terminate
                Enter cluster name: 
                Terminate ボタン:
            参考: #ref: https://qiita.com/n0bisuke/items/4d4a4599ee7ce9cf4fd9
        Community Edition, macOS の場合:
            #ref: https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/
    設定: #settings:
        __MongoUI_URL__: https://cloud.mongodb.com/v2/1234567890abcdefghijklmn
        __MongoUser__: user1
        __MongoPass__: pass1
        __MongoClusterURL__: cluster0.abcde.mongodb.net
mycli: #keyword:  #// MySQL, #ref: https://www.mycli.net/
    バージョン: 最新版は 2018 年の v1.16.0  #// 20245-01-07 確認  #ref: https://www.mycli.net/category/blog
    手順:
        ファイルに書かれた SQL の実行: mysql コマンドでもできます  #search: MySQL shell redirect to the file
sqlc: #keyword:  #// Go の ORマッパー。SQL から構造体を作ります
SQLAlchemy: #keyword:  #// Python 用、汎用 SQL DB API。sqlarchemy ではない
    公式: #ref: https://www.sqlalchemy.org/library.html
    手順:
        インストール >> try_SQLAlchemy:  #keyword:
            作成済みプロジェクト: #ref: ${GitHub}/MyPrivateCode/try_SQLAlchemy
            pipenv をインストールします:  #search: pipenv Windows install
            プロジェクトを新規作成します:  #search: pipenv projects
                #PowerShell
                mkdir  try_SQLAlchemy
                cd     try_SQLAlchemy
                ${env:PIPENV_VENV_IN_PROJECT} = 1
                pipenv --python 3
                pipenv --venv
                pipenv install
                pipenv install sqlalchemy
                code  "."
            __Project__/1_engine.py : |  #ref: https://zenn.dev/myuki/books/02fe236c7bc377/viewer/16fd5a#接続
                from sqlalchemy import create_engine
                engine = create_engine('sqlite:///sample.db', echo=False)
                print(engine)
            launch.json ファイルを作ります:  #// __Project__/.vscode/launch.json
                - Run アイコン（虫） >> create a launch.json file >> Python file
                - 必要なら "program" の右をデバッグ開始する Python ファイルのパスに置き換えます。${file} は開いているファイルになります
            ブレークポイントを張ります: .py ファイルの行番号の左をクリック
            デバッグ開始:
                #// 下記のどちらかを行います
                - F5 キー
                - Run アイコン（虫） >> Start Debugging ボタン（左上の緑色の三角）
            参考: #search: pipenv projects
        CRUD 操作:  #search: SQLAlchemy CRUD
    機能:
        脆弱性対策:
            SQL インジェクション: 基本的に対策済み。ただし、execute で bind parameter を使わないと脆弱性がある可能性があります。
            安全な execute: #keyword: SQLAlchemy safe execute
                bind parameter を使います: |
                    db.my_session.execute(
                        text("UPDATE client SET musicVol = :mv, messageVol = :ml"),
                        {'mv': music_volume, 'ml': message_volume}
                    )
                #ref: https://stackoverflow.com/questions/29208847/sqlalchemy-raw-query-and-parameters
                #ref: https://stackoverflow.com/questions/48870227/is-sql-injection-protection-built-into-sqlalchemys-orm-or-core
                query メソッドを使います:  #search: SQLAlchemy query
        モック: #ref: https://pypi.org/project/alchemy-mock/
            #ref: https://stackoverflow.com/questions/50621689/python-sqlalchemy-mocking
    コード:
        サンプル: |  #// 未確認  #search: SQLAlchemy execute
            from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, select, insert, update, delete
            from sqlalchemy.sql import text

            # メタデータオブジェクトの作成
            metadata = MetaData()

            # テーブル定義
            users = Table(
                'users', 
                metadata,
                Column('id', Integer, primary_key=True),
                Column('name', String(50), nullable=False),
                Column('email', String(120), unique=True, nullable=False)
            )

            def main():
                # データベース接続
                engine = create_engine('sqlite:///sample.db')
                
                # テーブルの作成
                metadata.create_all(engine)
                
                # 接続の確立
                with engine.connect() as connection:
                    # データの挿入
                    insert_stmt = insert(users).values(
                        name='山田太郎',
                        email='yamada@example.com'
                    )
                    connection.execute(insert_stmt)
                    
                    # 複数レコードの一括挿入
                    connection.execute(insert(users), [
                        {'name': '佐藤花子', 'email': 'sato@example.com'},
                        {'name': '鈴木一郎', 'email': 'suzuki@example.com'}
                    ])
                    
                    # データの検索
                    select_stmt = select(users)
                    result = connection.execute(select_stmt)
                    print("\n全ユーザーの取得:")
                    for row in result:
                        print(f"ID: {row.id}, 名前: {row.name}, メール: {row.email}")
                        
                    # 条件付き検索
                    select_stmt = select(users).where(users.c.name == '山田太郎')
                    result = connection.execute(select_stmt)
                    print("\n特定ユーザーの検索:")
                    for row in result:
                        print(f"ID: {row.id}, 名前: {row.name}, メール: {row.email}")
                    
                    # データの更新
                    update_stmt = update(users).where(
                        users.c.name == '山田太郎'
                    ).values(
                        email='yamada.taro@example.com'
                    )
                    connection.execute(update_stmt)
                    
                    # データの削除
                    delete_stmt = delete(users).where(users.c.name == '佐藤花子')
                    connection.execute(delete_stmt)
                    
                    # トランザクションの例
                    with connection.begin():
                        # トランザクション内の処理
                        connection.execute(
                            insert(users).values(
                                name='田中次郎',
                                email='tanaka@example.com'
                            )
                        )

            if __name__ == '__main__':
                main()
        O/R マッピング: #keyword: SqlAlchemy O/R mapping
            DBエンジン (create_engine):  #// サーバー名、データベース名などを含みます
                コード: |
                    from sqlalchemy import create_engine
                    engine = create_engine("{dialect}+{driver}://{username}:{password}@{host}:{port}/{database}?charset={charset_type})
                引数例:
                    mysql://user:password@localhost/test_db
                        #template__: mysql://__User__:__Password__@__Host__/__Database__
            Base (declarative_base): |  #// テーブルのスーパークラス
                from sqlalchemy.ext.declarative import declarative_base
                Base = declarative_base()
            サーバー: create_engine に指定します
            データベース: create_engine にデータベース名を指定します
            テーブル:
                表: |  #// スキーマの定義
                    from sqlalchemy.schema import Column
                    from sqlalchemy.types import Integer, String

                    class User(Base):
                        __tablename__ = "user"  # テーブル名を指定
                        user_id = Column(Integer, primary_key=True)
                        first_name = Column(String(255))
                型: #keyword: SQLAlchemy types  #// 表の中のフィールドの型
                    Integer:
                    String(__Length__):
                    Binary(), LargeBinary(__Length__): |
                            |        type           |   MySQL (.sql) | 
                            | --------------------- | -------------- |
                            | ?                     |      BLOB(255) |
                            | Binary()              |    BLOB(65535) |
                            | LargeBinary(16777215) | BLOB(16777215) |
                            |                       | or MEDIUMBLOB  |
                        #search: MySQL Blob binary
            クラシカルな方式:
                SqlAlchemy.Table: #keyword:
                    サンプル: |
                        special_user = SqlAlchemy.Table(
                            'special_user',
                            metadata,
                            SqlAlchemy.Column('id', SqlAlchemy.Integer(), primary_key=True),
                            SqlAlchemy.Column('code', SqlAlchemy.String()),
                    SQL との対応関係:  #// SQL に合わせて SqlAlchemy のコードを書く必要があります
                        AUTO_INCREMENT, PRIMARY KEY:
                            SQL: |
                                `id` INTEGER UNSIGNED AUTO_INCREMENT PRIMARY KEY,
                            SqlAlchemy: |
                                SqlAlchemy.Column('id', SqlAlchemy.Integer(), autoincrement=True, primary_key=True),
                        NOT NULL:
                            SQL: |
                                `create_date` DATETIME NOT NULL,
                            SqlAlchemy: |
                                SqlAlchemy.Column('create_date', SqlAlchemy.DateTime, nullable=False),
                        DEFAULT CURRENT_TIMESTAMP:
                            SQL: |
                                `create_date` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
                            SqlAlchemy: |
                                SqlAlchemy.Column('create_date', SqlAlchemy.DateTime, nullable=False, server_default='CURRENT_TIMESTAMP'),
                        DATETIME と TIMESTAMP:
                            TIMESTAMP:  #// タイムゾーン付き。JST になるわけではありません
                                SQL: |
                                    `create_date` TIMESTAMP,
                                SqlAlchemy: |
                                    from sqlalchemy_utc import UtcDateTime
                                    SqlAlchemy.Column('create_date', UtcDateTime()),
                            DATETIME:
                                SQL: |
                                    `create_date` DATETIME,
                                SqlAlchemy: |
                                    SqlAlchemy.Column('create_date', SqlAlchemy.DateTime),
                        FOREIGN KEY:  #search: SQL FOREIGN KEY REFERENCES
                            SQL: |  #focus: __FieldNameInThisTable__, __ParentTableName__, __ForeinKeyInChildTable__
                                CREATE TABLE  __ChildTableName__
                                    ...
                                    `__FieldNameInThisTable__` INTEGER UNSIGNED NOT NULL,
                                    CONSTRAINT `__ConstraintName__`
                                        FOREIGN KEY __ForeinKeyName__ ( __FieldNameInThisTable__ )
                                        REFERENCES  __ParentTableName__( __ForeinKeyInChildTable__ );
                            SqlAlchemy: |
                                ____  = SqlAlchemy.Table(
                                    ...
                                    SqlAlchemy.Column(
                                        '__FieldNameInThisTable__',
                                        SqlAlchemy.Integer(),
                                        SqlAlchemy.ForeignKey('__ParentTableName__.__ForeinKeyInChildTable__'),
                                    ),
                    SQL に設定しない属性:
                        default:
                            SqlAlchemy.Column('code', SqlAlchemy.String(), default='(no code)'),
                SqlAlchemyOrm.mapper: | #keyword:
                    SqlAlchemyOrm.mapper(
                        SpecialUser,
                        special_user,
                        properties={
                            'id': special_user.c.id,
                            'code': special_user.c.code,
                            'server_certificates': SqlAlchemyOrm.relationship(ServerCertificate,
                SqlAlchemyOrm.relationship: #keyword:
                    コード: （上記）
                    ユーザー コード サンプル: |
                        user = session.query(SpecialUser).first()
                        print(user.code)
                        print(user.server_certificates.name)
                    外部キーの有無の差:
                        外部キーがある場合の server_certificates のリード: 関連する適切なレコードになります
                        外部キーが無く、配列の場合: server_certificates 配列は session.commit() で保存できます。
                        relationship が無い場合: session.add(server_certificates); session.commit() で保存できそうです（未確認）
                サンプル コード: |  #// Claude AI より   #search: SQLAlchemy query
                    from sqlalchemy import Table, Column, Integer, String, MetaData, create_engine
                    from sqlalchemy.orm import mapper, sessionmaker

                    # エンジンとメタデータの作成
                    engine = create_engine('mysql://user:password@localhost/test_db')
                    metadata = MetaData()

                    # テーブル定義
                    users = Table('users', metadata,
                        Column('id', Integer, primary_key=True),
                        Column('name', String(50)),
                        Column('email', String(120)),
                        Column('age', Integer)
                    )

                    # モデルクラスの定義
                    class User:
                        def __init__(self, name=None, email=None, age=None):
                            self.name = name
                            self.email = email
                            self.age = age

                        def __repr__(self):
                            return f"<User(name='{self.name}', email='{self.email}', age={self.age})>"

                    # マッピングの設定
                    mapper(User, users)

                    # セッションの作成
                    Session = sessionmaker(bind=engine)
                    session = Session()

                    # サンプルクエリの実行
                    def sample_queries():
                        # データの挿入
                        new_user = User(name='田中太郎', email='tanaka@example.com', age=30)
                        session.add(new_user)
                        session.commit()

                        # 全ユーザーの取得
                        all_users = session.query(User).all()
                        print("全ユーザー:", all_users)

                        # 条件付き検索
                        young_users = session.query(User).filter(User.age < 35).all()
                        print("35歳未満のユーザー:", young_users)

                        # 特定の名前で検索
                        tanaka = session.query(User).filter_by(name='田中太郎').first()
                        print("田中さん:", tanaka)

                        # ORDER BY を使用した検索
                        ordered_users = session.query(User).order_by(User.age.desc()).all()
                        print("年齢順（降順）:", ordered_users)

                        # COUNT の使用
                        user_count = session.query(User).count()
                        print("ユーザー総数:", user_count)

                    # テーブル作成（初回のみ）
                    metadata.create_all(engine)
                デフォルト値: #keyword: SqlAlchemy.Table default
                    SqlAlchemy.Table: |  #// default は、レコードのオブジェクトの属性の値が None のときに設定される値です
                        special_user = SqlAlchemy.Table(
                            ...
                            SqlAlchemy.Column('id', SqlAlchemy.Integer(), primary_key=True, default='(no ct code)'),
                    レコードのオブジェクト: |  #// デフォルト値を設定したら、Python の仕様上、それ以降の属性にはデフォルト値が必須です
                        @dataclass(repr=False)
                        class MyTable:
                            id: Optional[str] = None
                            name: Optional[str] = None

                        obj = MyTable(name="aaa")
                    （ボツ記録）SQL のスキーマにデフォルト値を設定することはできません:
                        MySQL のスキーマに設定したデフォルト値が入るようにするには:
                            - スキーマの中のカラムが NULL 許容のときにカラムを指定しなかったとき
                            - スキーマの中のカラムが NOT NULL のときに NULL を指定すると MySQL がエラーを吐きます
                            - なので、Python の @dataclass が属性無しをサポートしていないため MySQL のスキーマに設定したデフォルト値は必ず使われません
                        デフォルト値なしの属性をデフォルト値ありの属性の下に書くことは、Python の仕様上できません: |  #focus: None
                            @dataclass(repr=False)
                            class MyTable:
                                id: Optional[str] = None
                                name: Optional[str]

                            obj = MyTable(name="aaa")
                        属性の削除はできません: |  #focus: del  #// 下記で削除できるはずだが None が入っている
                            @dataclass(repr=False)
                            class MyTable:
                                id: Optional[str] = None
                                name: Optional[str]

                                def __post_init__(self):
                                    if self.id is None:
                                        del self.__dict__['id']
                                            または
                                        delattr(self, 'id')
        操作: #keyword: SQLAlchemy CRUD  #// Create Read Update Delete
            テーブルを作ります:  #// スキーマを元に、データベースの中に作ります
                Base.metadata.create_all(engine)
            セッション (sessionmaker): |
                from sqlalchemy.orm import sessionmaker
                SessionClass = sessionmaker(engine)

                session = SessionClass()
            Create (add):  #ref: ${GitHub}/MyPrivateCode/try_SQLAlchemy/s3_create.py#session.add
                user_a = __TableClassName__(first_name="first_a", last_name="last_a", age=20)
                session.add(user_a)
                session.commit()
            Read (query):  #keyword: SQLAlchemy query
                #// メソッド チェーン で書くことができます
                引数:  #// 出力カラムを指定します
                    クラス:
                        コード: session.query(__TableClassName__)
                        対応する SQL: SELECT * ____
                    属性:
                        コード: session.query(__TableClassName__.__AttributeName1__, __TableClassName__.__AttributeName2__, __TableClassName__.__AttributeName3__)
                        対応する SQL: SELECT __AttributeName1__, __AttributeName2__, __AttributeName3__  ____
                #↓ 基本
                first:  #// 1つだけレコードを取得します
                    record = session.query(__TableClassName__).first()
                    #// 0件の場合、user は None になります
                all: |  #// すべて（複数）のレコードを取得します
                    for r in session.query(__TableClassName__).order_by(__TableClassName__.id):  #// .all() 不要？
                        print(r.id, r.name, r.birthday, r.address, r.deptcode)
                filter: #keyword: SQLAlchemy filter
                    完全一致: |
                        record = session.query(__TableClassName__).filter(__TableClassName__.name == "田中太郎").first()
                        print(f"名前が田中太郎: {record.name if record else 'なし'}")
                    数値比較: |
                        records = session.query(__TableClassName__).filter(__TableClassName__.age == 30).all()
                        records = session.query(__TableClassName__).filter(__TableClassName__.age > 30).all()
                        #search: SQLAlchemy record ID
                    日付比較:
                        最新: #search: SQLAlchemy order_by
                    And, Or:  #// and_ は import によっては sqlalchemy.and_
                        records = session.query(__TableClassName__).filter(and_(__TableClassName__.age >= 25, __TableClassName__.age <= 35)).all()
                        records = session.query(__TableClassName__).filter(or_(__TableClassName__.age < 25, __TableClassName__.age > 35)).all()
                        records = session.query(__TableClassName__).filter(not_(__TableClassName__.is_active)).all()
                #↓ 順序、結合
                order_by: #keyword: SQLAlchemy order_by,  SQLAlchemy sort
                    昇順: session.query(__TableClassName__).order_by(__Field__)
                    降順: session.query(__TableClassName__).order_by(__Field__.desc())
                    複数: session.query(__TableClassName__).order_by(__FieldA__, __FieldB__)
                    最新: session.query(__TableClassName__).order_by(__TableClassName__.datetime_column.desc()).first()
                join: |
                        user = session.query(User).join(Partner)
                    #// 外部キーを使って JOIN します
                #↓ カラム、属性
                id: | #keyword: SQLAlchemy record ID  #ref: ${GitHub}/MyPrivateCode/try_SQLAlchemy/s4_CRUD.py#filter(User.id == 2)   #ref: https://zenn.dev/myuki/books/02fe236c7bc377/viewer/18c884
                    user2 = session.query(User).filter(User.id == 2).first()
                    print(user2.name, user2.address)
            Update:  #ref: ${GitHub}/MyPrivateCode/try_SQLAlchemy/s4_CRUD.py:csv#user2.address =, session.commit()
                user2 = session.query(User).filter(User.id == 2).first()
                print(user2.name, user2.address)
                user2.address = "Tokyo"
                session.commit()
            Delete:  #ref: ${GitHub}/MyPrivateCode/try_SQLAlchemy/s4_CRUD.py#user2.delete()
                user2 = session.query(User).filter(User.id == 2)
                user2.delete()
                session.commit()
            SQL 文, execute: | #keyword: SQLAlchemy execute
                session.execute("SELECT * FROM users WHERE id = :id", {"id": 1})
    参考: #ref: https://qiita.com/ariku/items/75799665acd09520bed2
Flyway: #keyword: Flyway, .sql file  #// マイグレーション。データベースの バージョン コントロール
    公式: #// https://flywaydb.org/
        読み方:
            サンプル: https://flywaydb.org/documentation/command/undo
            コマンドラインの説明を表示させます:
                Usage（最下）の Command-line タブ >> How to __Command__ in the Command-line Tool
    手順、サンプル:
        サンプル >> info, migrate:
            参考: #ref: https://qiita.com/rhirabay/items/13ecaafaee51dc768384
            プロジェクト: #search: Flyway Linux VirtualBox
            データベースを作ります:
                sample という名前にしてください。以後その名前を使うためです
                #search: MySQL database
            MySQL サーバーに flyway がアクセスできることを確認します:
                __Project__/flyway.conf: |
                    # 接続情報
                    flyway.url=jdbc:mysql://192.168.33.101:3306/sample
                    flyway.user=mysql_user
                    flyway.password=Pass4444
                接続に成功したときの実行の様子: |  #// -X オプションを付けると詳細に表示されます
                    $ cd __Project__
                    $ flyway info
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    ----------------------------------------
                    Flyway Teams features are enabled by default for the next 27 days. Learn more at https://flywaydb.org/?ref=v7.11.0_teams
                    ----------------------------------------
                    Schema version: << Empty Schema >>

                    +----------+---------+-------------+------+--------------+-------+----------+
                    | Category | Version | Description | Type | Installed On | State | Undoable |
                    +----------+---------+-------------+------+--------------+-------+----------+
                    | No migrations found                                                       |
                    +----------+---------+-------------+------+--------------+-------+----------+
                パスワードを間違えたときの実行の様子: |
                    $ flyway info -password=bad
                    ERROR: 
                    Unable to obtain connection from database (jdbc:mysql://192.168.33.101:3306/sample) for user 'mysql_user': Access denied for user 'mysql_user'@'192.168.33.105' (using password: YES)
                    -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                    SQL State  : 28000
                    Error Code : 1045
                    Message    : Access denied for user 'mysql_user'@'192.168.33.105' (using password: YES)

                    Caused by: java.sql.SQLException: Access denied for user 'mysql_user'@'192.168.33.105' (using password: YES)
                .sql ファイルを認識したときの様子: |  #keyword: Flyway panding
                    $ flyway info -X
                    +-----------+---------+----------------------+------+--------------+---------+----------+
                    | Category  | Version | Description          | Type | Installed On | State   | Undoable |
                    +-----------+---------+----------------------+------+--------------+---------+----------+
                    | Versioned | 1.0     | create sample1 table | SQL  |              | Pending | No       |
                    | Versioned | 1.1     | create sample2 table | SQL  |              | Pending | No       |
                    +-----------+---------+----------------------+------+--------------+---------+----------+
                マイグレーションします: |  #keyword: Flyway migrate example
                    $ flyway migrate
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    Successfully validated 2 migrations (execution time 00:00.036s)
                    Creating Schema History table `sample`.`flyway_schema_history` ...
                    Current version of schema `sample`: << Empty Schema >>
                    Migrating schema `sample` to version "1.0 - create sample1 table"
                    Migrating schema `sample` to version "1.1 - create sample2 table"
                    Successfully applied 2 migrations to schema `sample`, now at version v1.1 (execution time 00:00.215s)

                    $ flyway info
                    WARNING: This version of Flyway is out of date. Upgrade to Flyway 7.11.1:https://flywaydb.org/documentation/learnmore/staying-up-to-date/?ref=v7.11.0_cmd-line
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    Schema version: 1.1

                    +-----------+---------+----------------------+------+---------------------+---------+----------+
                    | Category  | Version | Description          | Type | Installed On        | State   | Undoable |
                    +-----------+---------+----------------------+------+---------------------+---------+----------+
                    | Versioned | 1.0     | create sample1 table | SQL  | 2021-07-12 09:10:43 | Success | No       |
                    | Versioned | 1.1     | create sample2 table | SQL  | 2021-07-12 09:10:43 | Success | No       |
                    +-----------+---------+----------------------+------+---------------------+---------+----------+
                アンドゥします >> マイグレーションを1つ戻します: |  #// アンドゥする .sql ファイルが必要です  #search: flyway undo  #keyword: Flyway undo example
                    $ flyway undo
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    Current version of schema `sample`: 1.1
                    Undoing migration of schema `sample` to version 1.1 - create sample2 table
                    Successfully undid 1 migration to schema `sample`, now at version v1.0 (execution time 00:00.299s)

                    $ flyway info
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    Schema version: 1.0

                    +-----------+---------+----------------------+----------+---------------------+---------+----------+
                    | Category  | Version | Description          | Type     | Installed On        | State   | Undoable |
                    +-----------+---------+----------------------+----------+---------------------+---------+----------+
                    | Versioned | 1.0     | create sample1 table | SQL      | 2021-07-12 09:10:43 | Success | Yes      |
                    | Versioned | 1.1     | create sample2 table | SQL      | 2021-07-12 09:10:43 | Undone  |          |
                    | Undo      | 1.1     | create sample2 table | UNDO_SQL | 2021-07-12 09:30:05 | Success |          |
                    | Versioned | 1.1     | create sample2 table | SQL      |                     | Pending | Yes      |
                    +-----------+---------+----------------------+----------+---------------------+---------+----------+

                    $ #// undo したら、それに関連する V____.sql, U___.sql ファイルを削除しても、将来マイグレーションできます。
                    $ mv sql/V1_1__create_sample2_table.sql  sql/_V1_1__create_sample2_table.sql
                    $ mv sql/U1_1__create_sample2_table.sql  sql/_U1_1__create_sample2_table.sql
                    $ flyway info
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    Schema version: 1.0

                    +-----------+---------+----------------------+----------+---------------------+---------+----------+
                    | Category  | Version | Description          | Type     | Installed On        | State   | Undoable |
                    +-----------+---------+----------------------+----------+---------------------+---------+----------+
                    | Versioned | 1.0     | create sample1 table | SQL      | 2021-07-12 09:10:43 | Success | Yes      |
                    | Versioned | 1.1     | create sample2 table | SQL      | 2021-07-12 09:10:43 | Undone  |          |
                    | Undo      | 1.1     | create sample2 table | UNDO_SQL | 2021-07-12 09:30:05 | Future  |          |
                    +-----------+---------+----------------------+----------+---------------------+---------+----------+

                    #// 次の手順のために戻します
                    $ mv sql/_V1_1__create_sample2_table.sql  sql/V1_1__create_sample2_table.sql
                    $ mv sql/_U1_1__create_sample2_table.sql  sql/U1_1__create_sample2_table.sql
                データベースを初期状態に戻します: |  #keyword: flyway clean example  #search: flyway clean
                    $ flyway clean 
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    Successfully dropped pre-schema database level objects (execution time 00:00.003s)
                    Successfully cleaned schema `sample` (execution time 00:00.028s)
                    Successfully dropped post-schema database level objects (execution time 00:00.005s)
                    
                    $ flyway info
                    Flyway Teams Edition 7.11.0 by Redgate
                    Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                    Schema version: << Empty Schema >>

                    +-----------+---------+----------------------+------+--------------+---------+----------+
                    | Category  | Version | Description          | Type | Installed On | State   | Undoable |
                    +-----------+---------+----------------------+------+--------------+---------+----------+
                    | Versioned | 1.0     | create sample1 table | SQL  |              | Pending | Yes      |
                    | Versioned | 1.1     | create sample2 table | SQL  |              | Pending | Yes      |
                    +-----------+---------+----------------------+------+--------------+---------+----------+
                マイグレーションの実行が失敗したとき:  #search: flyway repair  #keyword: Flyway failed example
                    失敗するような .sql ファイルに変更します:
                        __Project__/sql/V1_1__create_sample2_table.sql :  #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_MySQL_Flyway/sql/V1_1__create_sample2_table.sql
                            変更前: create table sample2 (
                            変更後: create table sample1 (
                            変更内容: テーブル名が重複しているエラーが発生するようにします
                    実行します: |  #// Failed 状態になります
                        $ flyway migrate
                        Flyway Teams Edition 7.11.0 by Redgate
                        Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                        Successfully validated 4 migrations (execution time 00:00.039s)
                        Creating Schema History table `sample`.`flyway_schema_history` ...
                        Current version of schema `sample`: << Empty Schema >>
                        Migrating schema `sample` to version "1.0 - create sample1 table"
                        Migrating schema `sample` to version "1.1 - create sample2 table"
                        ERROR: Migration of schema `sample` to version "1.1 - create sample2 table" failed! Please restore backups and roll back database and code!
                        ERROR: 
                        Migration V1_1__create_sample2_table.sql failed
                        -----------------------------------------------
                        SQL State  : 42S01
                        Error Code : 1050
                        Message    : Table 'sample1' already exists
                        Location   : sql/V1_1__create_sample2_table.sql (/vagrant/sql/V1_1__create_sample2_table.sql)
                        Line       : 1
                        Statement  : create table sample1 (
                        id varchar(10) primary key,
                        name varchar(10)
                        )

                        Caused by: 
                        Migration V1_1__create_sample2_table.sql failed
                        -----------------------------------------------
                        SQL State  : 42S01
                        Error Code : 1050
                        Message    : Table 'sample1' already exists
                        Location   : sql/V1_1__create_sample2_table.sql (/vagrant/sql/V1_1__create_sample2_table.sql)
                        Line       : 1
                        Statement  : create table sample1 (
                        id varchar(10) primary key,
                        name varchar(10)
                        )

                        Caused by: java.sql.SQLSyntaxErrorException: Table 'sample1' already exists

                        $ flyway info
                        Flyway Teams Edition 7.11.0 by Redgate
                        Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                        Schema version: 1.1

                        +-----------+---------+----------------------+------+---------------------+---------+----------+
                        | Category  | Version | Description          | Type | Installed On        | State   | Undoable |
                        +-----------+---------+----------------------+------+---------------------+---------+----------+
                        | Versioned | 1.0     | create sample1 table | SQL  | 2021-07-12 09:46:42 | Success | Yes      |
                        | Versioned | 1.1     | create sample2 table | SQL  | 2021-07-12 09:46:42 | Failed  | No       |
                        +-----------+---------+----------------------+------+---------------------+---------+----------+
                マイグレーションの失敗を修復します:  #search: flyway repair  #keyword: Flyway repair example
                    成功するような .sql ファイルに変更します:
                        __Project__/sql/V1_1__create_sample2_table.sql :
                            変更前: create table sample1 (
                            変更後: create table sample2 (
                            変更内容: 既存のテーブル名と重複しないようにします
                    実行します: |  #// flyway repair してから flyway migrate します
                        $ flyway repair
                        Flyway Teams Edition 7.11.0 by Redgate
                        Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                        Successfully repaired schema history table `sample`.`flyway_schema_history` (execution time 00:00.053s).
                        Manual cleanup of the remaining effects of the failed migration may still be required.

                        $ flyway info
                        Flyway Teams Edition 7.11.0 by Redgate
                        Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                        Schema version: 1.0

                        +-----------+---------+----------------------+------+---------------------+---------+----------+
                        | Category  | Version | Description          | Type | Installed On        | State   | Undoable |
                        +-----------+---------+----------------------+------+---------------------+---------+----------+
                        | Versioned | 1.0     | create sample1 table | SQL  | 2021-07-12 09:46:42 | Success | Yes      |
                        | Versioned | 1.1     | create sample2 table | SQL  |                     | Pending | Yes      |
                        +-----------+---------+----------------------+------+---------------------+---------+----------+

                        $ flyway migrate
                        Flyway Teams Edition 7.11.0 by Redgate
                        Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                        Successfully validated 4 migrations (execution time 00:00.066s)
                        Current version of schema `sample`: 1.0
                        Migrating schema `sample` to version "1.1 - create sample2 table"
                        Successfully applied 1 migration to schema `sample`, now at version v1.1 (execution time 00:00.219s)

                        $ flyway info
                        Flyway Teams Edition 7.11.0 by Redgate
                        Database: jdbc:mysql://192.168.33.101:3306/sample (MySQL 8.0)
                        Schema version: 1.1

                        +-----------+---------+----------------------+------+---------------------+---------+----------+
                        | Category  | Version | Description          | Type | Installed On        | State   | Undoable |
                        +-----------+---------+----------------------+------+---------------------+---------+----------+
                        | Versioned | 1.0     | create sample1 table | SQL  | 2021-07-12 09:46:42 | Success | Yes      |
                        | Versioned | 1.1     | create sample2 table | SQL  | 2021-07-12 09:54:05 | Success | Yes      |
                        +-----------+---------+----------------------+------+---------------------+---------+----------+
        インストール:
            ❗注意: プロキシのある環境では Flyway の CLI が遅すぎて使いものになりません。
                プロキシのない環境にインストールしてください。 #search: flyway slow time out
            Linux on VirtualBox:  #keyword: Flyway Linux VirtualBox
                プロジェクト: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_MySQL_Flyway
            Windows:
                ダウンロードします: https://flywaydb.org/documentation/usage/commandline/ >>
                    Windows の zip >> Skip to Download
                展開します: 例 #ref: ${HOME}/Downloads/flyway-7.11.0
            Linux:
                公式情報: wget など  https://flywaydb.org/documentation/usage/commandline/
        補足: データの操作は Flyway の管理外にしたほうがよいかもしれません
    ファイル (Flyway): #glossary:
        flyway.conf:
            サンプル: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_MySQL_Flyway/flyway.conf
            -configFiles オプションを省略したとき:
                以下のいずれかのファイルを参照します:
                    - __InstallFolder__/conf/flyway.conf
                    - ${HOME}/flyway.conf
                    - ./flyway.conf
            -configFiles オプションの例:
                flyway -configFile=conf/flyway.config
        ____.sql:  #// マイグレーションを定義するファイル  #keyword: Flyway .sql file
            置き場所の例: __Project__/sql/V1_1__create_sample2_table.sql
            .sql ファイルを認識したときの様子:  #search: Flyway panding
            create table のサンプル:  #search: Flyway failed example
            create table を undo するサンプル:  #search: flyway undo
            データベースを作ります:
                #// Flyway では SQL の CREATE DATABASE 相当の実行はできませんが、他の方法があります
                MySQL: #search: MySQL initial data
                参考:
                    データベースを作る代わりにスキーマを作れるらしいが不明:
                        #ref: https://stackoverflow.com/questions/19791019/how-to-create-a-database-with-flyway
                        #ref: https://flywaydb.org/documentation/configuration/parameters/createSchemas
                        #ref: https://flywaydb.org/documentation/concepts/migrations.html#schema-creation
    コマンド (Flyway): #keyword: flyway command  #glossary:
        flyway info:  #// 現在の状態、Pending状態などを表示します
            Pending 状態の表示例: #search: Flyway panding
        flyway migrate:  #// DB のスキーマの更新など、.sql ファイルの内容を実行します
            書式: flyway migrate
            サンプル: #search: Flyway migrate example
            -skipExecutingMigrations オプション:  #// 実行しないでベースラインを最新にします
                コマンド例: flyway -skipExecutingMigrations="true" migrate
                公式: https://flywaydb.org/documentation/configuration/parameters/skipExecutingMigrations
            flyway_schema_history テーブル:  #keyword:
                flyway migrate を実行すると、MySQL などの中のそれぞれのデータベースに
                管理用の flyway_schema_history テーブルが作られます。
                データベースを削除(drop database)すると、flyway_schema_history テーブルも削除されます。
            関連 >> アンドゥ:  #search: flyway undo
        flyway validate:  #// ローカルのマイグレーションファイルが適用されているかチェックします
            詳細:
                flyway コマンドを実行するフォルダーにある マイグレーション ファイル のチェックサムと、
                適用対象のデータベースの flyway_schema_history テーブルに記録されているチェックサムを比較します。
            参考:
                公式: https://flywaydb.org/documentation/command/validate
                Flyway 4.2の仕組み、使い方を学ぶ: https://qiita.com/rubytomato@github/items/d1746585451ff0ba917c#11マイグレーションファイルの検証
        flyway clean:  #// スキーマを初期状態に戻します  #❗️ データを復旧できるローカルでの開発時以外は使うと危険です
            書式: flyway clean
            サンプル:  #search: Flyway clean example
        flyway undo:  #// マイグレーションを1つ戻します
            注意: #❗️
                最新の .sql ファイルを削除して flyway migrate を実行するようなアンドゥはしないでください:
                    #ref: ${typrm_files}/ref/Database-AI.yaml#label: flyway undo
                アンドゥする .sql ファイルが必要です:
                    サンプル:
                        sql/U1_1__create_sample2_table.sql :
                            drop table sample2;
                アンドゥしたらアンドゥした記録が追加されてしまいます:
                    サンプル:  #search: Flyway undo example
            書式: flyway undo
            サンプル:  #search: Flyway undo example
            マイグレーションを2つ戻します: flyway undo を 2回実行します
            Community Edition での flyway undo:  #keyword: flyway undo migration
                説明: Community Edition では flyway undo コマンドが使えません。
                    しかし、キャンセルするようなマイグレーションを追加することで代用できます。
                管理内でする場合（推奨）: #// .sql ファイルで undo するマイグレーションを追加する場合
                    キャンセルする .sql ファイルを作ります:
                        sql/V1_2__cancel_create_sample2_table.sql :
                            drop table sample2;
                    マイグレーションします:
                        - flyway info     #search: flyway info
                        - flyway migrate  #search: flyway migrate
                    さらに続きます:
                管理外でする場合:  #keyword: flyway undo message migration
                    #// mysql commandline tools などで undo して、メッセージのマイグレーションを追加する場合:
                    ❗注意:
                        - 次回のマイグレーションで警告されることがあります  #search: Flyway validate failed
                        - 警告から復旧(flyway repair)されたら、マイグレーションできます。
                            たとえば、CREATE TABLE をアンドゥした後、同じ名前で CREATE TABLE できることは確認済みです 2021-07-15
                    管理外で実行した内容を記録したコメントだけの .sql ファイルを作ります:
                        sql/V1_2__cancel_create_sample2_table.sql : |
                            /*
                            Comment:
                                Modified by commands in mysql commandline tool
                                If next migration may be failed validation, do flyway repair command
                            */
                    マイグレーションします:
                        - flyway info     #search: flyway info
                        - flyway migrate  #search: flyway migrate
                    さらに続きます:
                共通:
                    （必要なら）.sql ファイルの削除:
                        もし、コードのリポジトリや dev 環境以外に undo と undo 対象の migrate を
                        残したくない場合は、.sql ファイルを削除しても構いません。
                        flyway info コマンドでは Success の代わりに Future や Missing と表示されますが、
                        問題ありません。次のマイグレーションを作れます。
        flyway repair:  #// Failed 状態を Pending 状態に戻します  #keyword:
            補足: Failed 状態のときは flyway migrate コマンドを実行することができません。
            書式: flyway repair
            サンプル:
                #search: Flyway failed example
                #search: Flyway repair example
        flyway baseline:  #❗️未確認  #// 手動で DB を変更したときなど、ベースライン（現在位置）を変更します
            書式: flyway -baselineVersion=__Vesion__ baseline
            __Vesion__: flyway info コマンドで表示される Version。例 1.0.0
        共通オプション:
            -configFile:  #search: flyway.conf
            -password:  #// flyway.conf に設定してある MySQL ユーザーのパスワード
                flyway -password=${FLYWAY_PASSWORD} info
    トラブルシューティング:
        - #// ERROR: Validate failed: Detected applied migration not resolved locally: 1.0.0.01
            手順: flyway migrate
            ログ: |
                ERROR: Validate failed: Detected applied migration not resolved locally: 1.0.0.01
            対処:
                flyway.locations の設定を正しくしてください。
        - #// Validate failed: Migrations have failed validation  #keyword: Flyway validate failed
            手順: flyway migrate コマンド
            エラー: |
                ERROR: Validate failed: Migrations have failed validation
                Migration checksum mismatch for migration version 3.1.0.05
                -> Applied to database : 165359299
                -> Resolved locally    : 1151055691. Either revert the changes to the migration, or run repair to update the schema history.
                Need more flexibility with validation rules? Learn more: https://flywaydb.org/custom-validate-rules/?ref=v7.11.1
            原因:
                Flyway の管理外でデータベースのスキーマが変えられたことを検出したため
                #search: flyway undo message migration
            対処:
                flyway undo や、undo する flyway migrate の代わりに、Flyway の管理外でアンドゥを正しくできていたときは、
                flyway repair コマンドを実行します
        - #// Detected failed migration
            手順: flyway migrate コマンド
            エラー: |
                ERROR: Validate failed: Migrations have failed validation
                Detected failed migration to version 3.1.0.01 (Try create teble). Please remove any half-completed changes then run repair to fix the schema history.
                Need more flexibility with validation rules? Learn more: https://flywaydb.org/custom-validate-rules/?ref=v7.11.1
            対処:
                flyway repair コマンド
        - #// No migrations found  
            手順: flyway info
            エラー: No migrations found
            対処A:
                -X オプションを付けて実行することで、詳細が表示されます: flyway info -X
            対処B:
                - .sql ファイルの名前を正しくしてください
                - 先頭は大文字の V です。ただし、設定によって異なるので flyway info -X で確認してください
                - バージョンの右はアンダーバー２つです
                - 正しい例: V1_0__create_sample1_table.sql
        - #// Unable to connect to the database
            手順: flyway info -X など
            エラー: |
                ERROR: Unexpected error
                org.flywaydb.core.api.FlywayException: Unable to connect to the database. Configure the url, user and password!
            対処:
                flyway.conf ファイルがあるフォルダーに カレント フォルダー を移動してからコマンドを実行してください。
        - #// WARNING: This version of Flyway is out of date. Upgrade to Flyway 8.1.0
            手順: flyway info -X など
            エラー: |
                WARNING: This version of Flyway is out of date. Upgrade to Flyway 8.1.0
            対処:
                無視できます:
                バージョンを変更する場合:
                    MySQL_Flyway の場合: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_MySQL_Flyway
                        インストールするバージョンの設定を変更します:
                            __Project__/playbooks/flyway/roles/install_flyway/defaults/main.yml :
                                flyway_install_version: 8.1.0
                        Ansible を実行してインストールします:
                            ./run_playbook.sh
        - #// flyway コマンドの起動が遅いとき  #keyword: flyway slow time out
            通常の速さ:
                flyway --version: 4秒
                flyway info: 7秒
            対処法A:
                プロキシのない LAN の環境で実行します。
            対処法B:  #// 未解決
                flyway --version でさえ遅いときは
                FLYWAY_EDITION=community  flyway --version のように環境変数を設定します。
                原因は、flyway スクリプトの中で ライセンス チェック しているところが遅いためです。
                ただし、flyway info も遅いので、それを解決しないと使い物にならないでしょう。
SchemaSpy: #keyword: SchemaSpy, スキーマ
    SchemaSpy の Docker イメージを使って、データベースのスキーマを解析します:
        参考: https://qiita.com/A-Kira/items/d5b7f7088f244641938e
        設定: #settings:
            __DockerHostOS_IPAddress__: 192.168.56.102
            __SchemaSpyWebPort__: 8088
            __DatabaseUser__: root
            __DatabasePass__: my-secret-pw
            __DatabaseName__: contract  #// テーブルの集まりとしてのデータベース名。データベース エンジンの名前ではない
            __MainTableName__: contract
            __SchemaSpyDebugOption__: jar -debug  #// "jar -debug" or "jar"
            __TimeZone__: Asia/Tokyo
            __MySQLConnectorJDBCTar__: https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.24.tar.gz
            __MySQLConnectorJDBCName__: mysql-connector-java-8.0.24
            __SchemaSpyTar__: https://github.com/schemaspy/schemaspy/releases/download/v6.1.0/schemaspy-6.1.0.jar
        JDBC の MySQL コネクターの最新バージョンを調べます:
            メニュー: https://www.mysql.com/jp/products/connector/ >> JDBC Driver for MySQL (Connector/J) ダウンロード
            Select Operating System: Platform Independent
            TAR Archive Download ボタン:
            操作: No thanks, just start my download. （を右クリック） >> リンクのコピー
            メモします:
                __MySQLConnectorJDBCTar__: https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.24.tar.gz  #template: __MySQLConnectorJDBCTar__
                __MySQLConnectorJDBCName__: mysql-connector-java-8.0.24  #template: __MySQLConnectorJDBCName__
        SchemaSpy の最新バージョンを調べます:
            メニュー: https://github.com/schemaspy/schemaspy/releases >> schemaspy-____.jar （を右クリック） >> リンクのコピー
            メモします:
                __SchemaSpyTar__: https://github.com/schemaspy/schemaspy/releases/download/v6.1.0/schemaspy-6.1.0.jar  #template: __SchemaSpyTar__
        __Project__/docker/docker-compose.schemaspy.yml :
            version: "3"
            services:
                nginx:  #// 任意の名前
                    image: nginx  #// nginx の Docker イメージをダウンロードして使います。ビルドは不要です
                    ports:
                        - "8088:80"  #// : の左側が nginx Web サーバーにアクセスするときに指定するポート番号  #template: __SchemaSpyWebPort__
                    volumes:
                        - ./schemaspy/html:/usr/share/nginx/html  #// : の左側が HTML を入れる Docker のホスト OS のパス
                    environment:
                        - TZ=Asia/Tokyo  #template: __TimeZone__
                schemaspy:  #// 任意の名前
                    image: treetips/schemaspy-mysql
                    build: ./schemaspy
                    volumes:
                        - ./schemaspy/html:/app/html:rw  #// : の左側が HTML を入れる Docker のホスト OS のパス
                        - ./schemaspy/schemaspy.properties:/app/schemaspy.properties:ro
                    environment:
                        - LANG=ja_JP.UTF-8
                        - TZ=Asia/Tokyo  #template: __TimeZone__
                    working_dir: "/app"
                    command: "java -jar schemaspy.jar -debug"  #template: "java -jar schemaspy.__SchemaSpyDebugOption__"
        __Project__/docker/schemaspy/Dockerfile : |
            FROM openjdk:8u121-jdk-alpine

            ENV DRIVER_URL  https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.24.tar.gz
                #template: __MySQLConnectorJDBCTar__
            ENV DRIVER_NAME mysql-connector-java-8.0.24
                #template: __MySQLConnectorJDBCName__
            ENV APP_URL     https://github.com/schemaspy/schemaspy/releases/download/v6.1.0/schemaspy-6.1.0.jar
                #template: __SchemaSpyTar__

            WORKDIR /app

            RUN apk --update add graphviz ttf-dejavu && \
                apk --update add --virtual .builddep tzdata wget libressl && \
                cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime && \
                wget ${DRIVER_URL}  &&  tar xvf  ${DRIVER_NAME}.tar.gz &&  cp  ${DRIVER_NAME}/${DRIVER_NAME}.jar . && \
                    mv ${DRIVER_NAME}.jar  mysql-connector-java.jar  && \
                wget -O schemaspy.jar ${APP_URL} && \
                ls && \
                apk del .builddep && \
                rm -rf /var/cache/apk/*

            #template-at(-8): __TimeZone__
        __Project__/docker/schemaspy/schemaspy.properties : |
            schemaspy.t=mysql
                # type of database. Run with -dbhelp for details
            schemaspy.dp=/app/mysql-connector-java.jar
            schemaspy.host=192.168.56.102
                #template: __DockerHostOS_IPAddress__
            schemaspy.port=3306
                #// database port
            schemaspy.db=contract
                #template: __DatabaseName__
            schemaspy.u=root
                #template: __DatabaseUser__
            schemaspy.p=my-secret-pw
                #template: __DatabasePass__
            schemaspy.o=/app/html
                # output dir to save generated files
            schemaspy.s=contract
                #template: __MainTableName__
        bash:
            cd  "__Project__/docker"
            docker-compose  -f docker-compose.schemaspy.yml  up  --build
        ブラウザーで開きます:
            http://192.168.56.102:8088/
                #template: __DockerHostOS_IPAddress__:__SchemaSpyWebPort__
Elasticsearch: #keyword:  #// 検索は #search: ElasticSearch query
    概要: #// JSON 全文検索エンジン。
        説明:
            データベースのレコードに相当するものをドキュメントと呼んでいます。
            シャーディングしてサーバーをクラスター化できます。
        公式:
            トップ: #ref: https://www.elastic.co/jp/
            バージョン: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/es-release-notes.html
        ライセンス:
            Apache License 2.0から、商用サービス化を制限する「Server Side Public License」（SSPL）と
            「Elastic License」のデュアルライセンスへ変更
            https://www.publickey1.jp/blog/21/awselasticelasticsearchkibanaaws.html
        概念構造:
            クラスター:  #search: ElasticSearch cluster
                ノード:  #search: ElasticSearch cat nodes
                    シャード:  #search: ElasticSearch health shards
            インデックス:  #search: ElasticSearch index
                ドキュメント:  #search: ElasticSearch document
                    個々のドキュメント:
                        フィールド:
                            値:
            テンプレート:
                インデックス テンプレート:  #search: ElasticSearch Index Templates
                コンポーネント テンプレート:  #search: ElasticSearch component templates
                マッピング テンプレート: #search: ElasticSearch mapping template
            アナライザー:
        脆弱性情報: #ref: https://www.elastic.co/jp/community/security
    参考: #ref: ${programming}/文字/文字列関数.svg#ElasticSearch
        https://agency-star.co.jp/column/elasticsearchとは？基礎と使い方をわかりやすく解説！デ/
    手順、サンプル、インストール: #keyword: ElasticSearch steps
        インストール:
            プロジェクト:
                クラスター環境: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ElasticSearch_cluster
            基本 >> Docker:  #// for Windows  #keyword: ElasticSearch Docker
                公式: https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
                Docker をインストールします:  #search: Docker install
                ElasticSearch サーバーを起動します:
                    公式:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
                    docker-compose を使わない場合:  #keyword: start ElasticSearch Docker
                        シェル:  #// Git bash
                            #// ❗ 注意: 約 8GB のメモリーを必要とします。
                            新しい bash:
                                ElasticSearch 7 の場合:
                                    - （初回のみ）docker pull docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                                    - docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                                ElasticSearch 6 の場合:
                                    - （初回のみ）docker pull docker.elastic.co/elasticsearch/elasticsearch:6.8.2
                                    - docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:6.8.2
                            別の bash:
                                - curl -X GET "localhost:9200/_cat/nodes?v=true&pretty"  #search: ElasticSearch cat nodes
                                    #// & は " " の中に入れてください
                    docker-compose を使う場合:
                        仮想メモリーのサイズを 262144 以上に増やします:
                            #search: Docker for Windows sysctl vm.max_map_count
                        ./docker-compose.yml ファイルを作ります: | #// es02, es03 は動作失敗
                            version: '2.2'
                            services:
                                es01:
                                    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                                    environment:
                                        -   "node.name=es01"
                                        -   "cluster.initial_master_nodes=es01"
                                        -   "cluster.name=elastic-search-cluster"
                                        -   "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dhttp.proxyHost=http://proxy.____.jp -Dhttp.proxyPort=8080 -Dhttps.proxyHost=http://proxy.____.jp -Dhttps.proxyPort=8080"
                                    ulimits:
                                        memlock:
                                            soft: -1
                                            hard: -1
                                    volumes:
                                        -   data01:/usr/share/elasticsearch/data
                                    ports:
                                        -   9200:9200
                                    networks:
                                        -   elastic
                                # es02:
                                #     image: docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                                #     environment:
                                #         -   "node.name=es02"
                                #         -   "cluster.name=elastic-search-cluster"
                                #         -   "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dhttp.proxyHost=http://proxy.____.jp -Dhttp.proxyPort=8080 -Dhttps.proxyHost=http://proxy.____.jp -Dhttps.proxyPort=8080"
                                #     ulimits:
                                #         memlock:
                                #             soft: -1
                                #             hard: -1
                                #     volumes:
                                #         -   "data02:/usr/share/elasticsearch/data"
                                #     ports:
                                #         -   9202:9200
                                #     networks:
                                #         -   elastic
                                # es03:
                                #     image: docker.elastic.co/elasticsearch/elasticsearch:7.13.3
                                #     environment:
                                #         -   "node.name=es03"
                                #         -   "cluster.initial_master_nodes=es01"
                                #         -   "cluster.name=elastic-search-cluster"
                                #         -   "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dhttp.proxyHost=http://proxy.____.jp -Dhttp.proxyPort=8080 -Dhttps.proxyHost=http://proxy.____.jp -Dhttps.proxyPort=8080"
                                #     ulimits:
                                #         memlock:
                                #             soft: -1
                                #             hard: -1
                                #     volumes:
                                #         -   data01:/usr/share/elasticsearch/data
                                #     ports:
                                #         -   9203:9200
                                #     networks:
                                #         -   elastic

                            volumes:
                                data01:
                                    driver: local
                                data02:
                                    driver: local

                            networks:
                                elastic:
                                    driver: bridge
                        プロキシ環境にいる場合:
                            変更前:
                                - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
                            変更後:
                                - "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dhttp.proxyHost=____ -Dhttp.proxyPort=____ -Dhttps.proxyHost=____ -Dhttps.proxyPort=____"
                        コンテナーを起動します:
                            #Git bash
                            - cd  __Project__
                            - docker-compose up -d
                            #// もし、vm.max_map_count が少ないエラーになったら増やします  #search: Docker for Windows sysctl vm.max_map_count
                ドキュメントを登録・一覧します:
                    Git bash の場合: |  #keyword: ElasticSearch bash add step,  ElasticSearch bash query list get
                        #// インデックス logs-my_app-default の中に登録します  #search: ElasticSearch bash add
                        curl -X POST http://localhost:9200/logs-my_app-default/_doc  -H "Content-Type:application/json" -d '{
                                "@timestamp": "2099-05-06T16:21:15.000Z",
                                "event": {
                                    "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
                                }
                            }'
                            #// ____ "result":"created" ____ と表示されます

                        #// インデックス logs-my_app-default の中を一覧します  #search: ElasticSearch bash list document
                        curl -X GET http://localhost:9200/logs-my_app-default/_search  -H "Content-Type:application/json" -d '{
                                "query": {
                                    "match_all": { }
                                },
                                "sort": [
                                    {
                                        "@timestamp": "desc"
                                    }
                                ]
                            }'
                    PowerShell の場合: |  #// ❗ body 付き GET メソッドが使えません  #search: ElasticSearch PowerShell add,  ElasticSearch PowerShell query list get
                        Invoke-WebRequest -Method Post http://localhost:9200/logs-my_app-default/_doc  -Headers @{"Content-type"="application/json"} -Body '{
                                "@timestamp": "2099-05-06T16:21:15.000Z",
                                "event": {
                                    "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
                                }
                            }'
                            #// StatusDescription : Created と表示されます

                        #// 下記は Invoke-WebRequest によって GET メソッドに Body を指定できないというエラーになります
                        Invoke-WebRequest -Method Get http://localhost:9200/logs-my_app-default/_search  -Headers @{"Content-type"="application/json"} -Body '{
                                "query": {
                                    "match_all": { }
                                },
                                "sort": [
                                    {
                                        "@timestamp": "desc"
                                    }
                                ]
                            }'
            ダウンロード URL を探します:
                RPM の ダウンロード URL:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/rpm.html#install-rpm
                    例:
                        - https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.10.1-x86_64.rpm  #// 2023-09-20 に確認
                        - https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.1.rpm  #// 2022-01-11 に確認
                Past Releases page: https://www.elastic.co/downloads/past-releases
                Past Releases page にたどりつくメニュー:
                    https://www.elastic.co/jp/ >> 製品（タブ）>> Elasticsearch >> ダウンロードして使いはじめる（無料トライアルを始めるの下）>>
                    Getting Started with Elasticsearch >> Elasticsearchをダウンロードする >> yum, dnf, or zypper 
                    Install Elasticsearch with RPM >> Past Releases page
                Products: Elasticsearch
                Versions: ____
                Download ボタン:
                RPM などのボタン:
            kuromoji プラグイン >> Docker:  #keyword: kuromoji  #// 日本語解析プラグインをイストールします。日本語で検索できるようになります
                公式:
                    https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-kuromoji.html#analysis-kuromoji
                    https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-kuromoji-tokenizer.html
                手順:  #// ElasticSearch と kuromoji プラグインをインストールして、日本語のドキュメントを登録・検索します
                    参考: https://qiita.com/suzukil/items/5ffe3c29cbb1cdb9da41
                    Docker for Windows をインストールします:  #search: Docker for Windows
                    ElasticSearch のコンテナーを作り、プラグインをインストールします:
                        プロジェクト フォルダー を作ります:
                            #Git bash
                            - mkdir ~/Desktop/try_kuromoji
                            - cd    ~/Desktop/try_kuromoji  #// __Project__ とします
                            #// または  code ~/Desktop/try_kuromoji で VSCode >> Terminal（メニュー）>> New Terminal >> Git bash
                        仮想メモリーのサイズを 262144 以上に増やします:
                            #search: Docker for Windows sysctl vm.max_map_count
                        ./docker-compose.yml ファイルを作ります:  #// シングル コア クラスター 設定  #keyword: single core ElasticSearch docker-compose.yml
                            共通部分: |
                                version: '2.2'
                                services:
                                    es01:
                                        image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
                                        container_name: es01
                                        environment:
                                            - node.name=es01
                                            - cluster.name=es-docker-cluster
                                            - cluster.initial_master_nodes=es01
                                            - bootstrap.memory_lock=true
                                            - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
                                        ulimits:
                                            memlock:
                                                    soft: -1
                                                    hard: -1
                                        volumes:
                                            - data01:/usr/share/elasticsearch/data
                                        ports:
                                            - 9200:9200
                                        networks:
                                            - elastic

                                volumes:
                                    data01:
                                        driver: local

                                networks:
                                    elastic:
                                        driver: bridge
                            プロキシ環境にいる場合:
                                変更前:
                                    - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
                                変更後:
                                    - "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dhttp.proxyHost=____ -Dhttp.proxyPort=____ -Dhttps.proxyHost=____ -Dhttps.proxyPort=____"
                        コンテナーを起動します:
                            #Git bash
                            - cd  __Project__
                            - docker-compose up -d
                            #// もし、vm.max_map_count が少ないエラーになったら増やします  #search: Docker for Windows sysctl vm.max_map_count
                        コンテナーに root ユーザーでログインします:
                            #Git bash
                            - docker-compose ps  #// で表示された Name 列の ID を __ContainerID__ とします
                            - docker exec  -it __ContainerID__  bash
                            #// 参考  #search: Docker container login
                        コンテナー内:
                            kuromoji をインストールします:
                                - bin/elasticsearch-plugin install analysis-kuromoji
                                - exit
                        コンテナーを再起動します:
                            #Git bash
                            - docker ps  #// で表示された CONTAINER ID 列の値を __ContainerID__ とします
                            - docker restart __ContainerID__
                        プラグインを認識していることを確認します:
                            Git bash:
                                - curl http://localhost:9200/_nodes/plugins?pretty | grep kuromoji
                            該当箇所付近（grep しなかったとき）: |
                                "plugins" : [
                                    {
                                    "name" : "analysis-kuromoji",
                            "?pretty オプション":  #// 出力される JSON を整形します  #keyword: ?pretty
                    インデックスを追加します:  #keyword: ElasticSearch add index example
                        curl -X PUT "http://localhost:9200/museum?pretty"  #// museum がインデックス名です
                    インデックスを一覧します:  #keyword: ElasticSearch list index/indices example
                        コマンド: |
                            curl -X GET "http://localhost:9200/_cat/indices?v&pretty"   #// ?v&pretty は表示を少し詳細にします
                                health status index                                       uuid  pri  rep  docs.count  docs.deleted  store.size  pri.store.size  （APIの出力）
                                health status index                                               uuid                 pri rep   count   del    size  pri-size  （本書の省略名）
                                ------------------------------------------------------------------------------------------------------------------------------
                                green  open   slog-asm_ltm-eventlog-waf78870444-20241009-0001     bczudxmfTUa1kzMxFlllxw 1 1       28      0   76.7kb   38.3kb
                        ノード当たりの使用量:  #search: ElasticSearch index disk size
                            pri-size (pri.store.size)
                            3台のノードがあり、レプリカ数が 1の場合、store.size は pri.store.size の約2倍になります
                    ドキュメントを複数追加します:  #search: ElasticSearch _bulk
                        #// インデックスが無くでも追加できます
                        code ./sample.json : |  #// ファイルが必要です  #search: shell JSON Invalid UTF-8
                            { "index" : {  } }
                            {"pref_id": "13", "city_id": "13101", "name": "国立美術館東京国立近代美術館","location": [139.7547383, 35.6905368]}
                            { "index" : {  } }
                            {"pref_id": "13", "city_id": "13106", "name": "上野の森美術館", "location": [139.7747384, 35.7127347]}
                        bash: |
                            curl -X POST "http://localhost:9200/museum/_bulk" -H "Content-Type:application/json" --data-binary @sample.json
                        参考:
                            index: #// https://stackoverflow.com/questions/45792309/bulk-api-malformed-action-metadata-line-3-expected-start-object-but-found
                    ドキュメントを一覧します:
                        curl -X GET "http://localhost:9200/museum/_search?pretty"  #// museum がインデックス名です
                    ドキュメントを検索します:  #search: ElasticSearch query
                    ドキュメントを検索して一部のフィールドだけ表示します: #keyword: ElasticSearch _source
                        _source に指定する場合: |
                            curl -X  POST  http://localhost:9200/museum/_search?pretty  -H "Content-Type:application/json" -d '{
                                "query": {
                                    "match": {
                                        "city_id": "13106"
                                    }
                                },
                                "_source":  [
                                    "pref_id",
                                    "city_id"
                                ]
                            }' > _output.json
                        fields に指定する場合: |
                            curl -X  POST  http://localhost:9200/museum/_search?pretty  -H "Content-Type:application/json" -d '{
                                "query": {
                                    "match": {
                                        "city_id": "13106"
                                    }
                                },
                                "fields": [
                                    "pref_id",
                                    "city_id"
                                ],
                                "_source": false
                            }' > _output.json
                        参考: #// 公式  https://www.elastic.co/guide/en/elasticsearch/reference/current/search-fields.html
                    フィールドを CSV 形式にします:
                        curl を実行している OS が Windows の場合:  #search: ConvertFrom-Json
                        curl を実行している OS が Linux の場合:  #search: Linux jq
            バージョン一覧:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/release-notes-6.8.23.html
                EOL:  #// サポート終了  #ref: https://www.elastic.co/jp/support/eol
                #ref: https://www.elastic.co/jp/downloads/past-releases#elasticsearch
                #ref: https://github.com/elastic/elasticsearch/releases
                #ref: https://www.elastic.co/jp/support/matrix  #// ←時間がかかるが見える
                RHEL8:   Elasticsearch 7.7.x .. 8.10.x ..
                CentOS8: Elasticsearch 7.7.x .. 7.17.x  #// 8 はサポートしていません
                CentOS7: Elasticsearch 5.2.x .. 8.10.x ..
                CentOS6: Elasticsearch 5.2.x .. 7.x.x
                Elasticsearch 8.x: Java 11 以上
                Docker >> ES7: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.0 まで
            バージョンアップします:  #keyword: ElasticSearch upgrade  #// ローリング アップグレード
                公式:
                    インタラクティブ アップグレード ガイド: #keyword: ElasticSearch interractive upgrade guide  #ref: https://www.elastic.co/jp/upgrade_guide
                    ElasticSearch のアップグレード: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/setup-upgrade.html
                    version 6 の完全なクラスター再始動アップグレード: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/restart-upgrade.html
                手順 >> version 6.x => 6.y (x<y):  #// X-pack なし
                    プロジェクト: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ElasticSearch_cluster
                    Back up your data:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.7/modules-snapshots.html
                        自分が試した内容:
                            クラスターを構成します（Vagrant の場合）: #search: ElasticSearch cluster
                            バックアップを構成します(NFS): #search: ElasticSearch back up
                            アップグレードします:  #search: Upgrade Elasticsearch to 6.x
                            バックアップを無効にします: #search: disable ElasticSearch back up
                        公式の内容:
                            スナップショット:  #// バックアップ ファイル のこと。差分  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.7/modules-snapshots.html
                            リポジトリ: #// スナップショットの置き場所
                                場所を設定します: |
                                    PUT /_snapshot/my_backup
                                    {
                                        "type": "fs",
                                        "settings": {
                                            "location": "my_backup_location"
                                        }
                                    }
                                場所を表示します: GET /_snapshot/my_backup
                                状態: GET /_snapshot/_status
                            バックアップ:
                                API: PUT /_snapshot/my_backup/snapshot_2?wait_for_completion=true
                                進行状況: GET /_snapshot/my_backup/snapshot_1
                            リストア:
                                POST /_snapshot/my_backup/snapshot_1/_restore
                    Check the Elasticsearch deprecation log:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.7/settings.html#deprecation-logging
                        不適切なバージョンではないことを確認します
                    Upgrade Elasticsearch to 6.x:  #keyword:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.7/rolling-upgrades.html
                        自分が試した内容:  #keyword: ElasticSearch upgrade 6.6 to 6.8
                            node1, node2, node3 のそれぞれについて１つずつ:
                                シャード割り当てを無効にします:  #// ノードのシャードはクラスター内の他のノードに複製されます
                                    (@node1): |  #keyword: cluster.routing.allocation.enable
                                        curl -X PUT "http://localhost:9200/_cluster/settings?pretty"  -H "Content-Type:application/json" -d '{
                                            "persistent": {
                                                "cluster.routing.allocation.enable": "primaries"
                                            }
                                        }'
                                    #template-at(-5): http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                    #// "acknowledged" : true と表示されること
                                不要なインデックス作成を停止し、同期されたフラッシュを実行します:
                                    #// フラッシュすると早くアップグレードできます
                                    (@node1): |
                                        curl -X POST "http://localhost:9200/_flush/synced?pretty"
                                    #template: curl -X POST "http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                    #// total と successful の値が等しいこと、または、failed が 0 であること
                                （スキップ）実行中の機械学習ジョブをすべて停止します:  #// X-pack を使っていないためスキップ
                                    下記はエラーになった:
                                        (@node1): |
                                            curl -X POST "http://localhost:9200/_ml/set_upgrade_mode?enabled=true&pretty"
                                        #template: curl -X POST "http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                対象のノードにログインして ElasticSearch をシャットダウンします:
                                    (@localhost): |  #template: __ElasticS_Node1__
                                        sudo systemctl stop elasticsearch
                                シャットダウンしたノードをアップグレードします: #// 起動はまだしません
                                    RPM をダウンロードします:
                                        cd  /home/vagrant/Downloads
                                        curl -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.8.22.rpm
                                    RPM をインストールします:
                                        sudo yum install -y /home/vagrant/Downloads/elasticsearch-6.8.22.rpm
                                プラグインをアップグレードします:  #search: elasticsearch-plugin
                                    (@node1):
                                        -   sudo /usr/share/elasticsearch/bin/elasticsearch-plugin list
                                        -   sudo /usr/share/elasticsearch/bin/elasticsearch-plugin remove __PlugInName__
                                        -   sudo /usr/share/elasticsearch/bin/elasticsearch-plugin install __PlugInName__
                                アップグレードしたノードを起動します:
                                    (@localhost):  #template: __ElasticS_Node1__
                                        -   sudo systemctl start elasticsearch
                                        -   sudo systemctl daemon-reload
                                        -   sudo systemctl status elasticsearch
                                        -   curl -X GET "http://localhost:9200/_cat/nodes?v"
                                                #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                                #// ログイン中（localhost）の IP アドレスが表示されるまで待ちます  #template: __ElasticS_Node1__
                                    以下はしなくてよい:
                                        -   curl -X GET "http://localhost:9200/_cluster/health/?level=shards&pretty"
                                                #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                            #// yellow でもよい？
                                シャード割り当てを再度有効にします:
                                    (@node1): |
                                        curl -X PUT "http://localhost:9200/_cluster/settings?pretty"  -H "Content-Type:application/json" -d '{
                                            "persistent": {
                                                "cluster.routing.allocation.enable": null
                                            }
                                        }'
                                    #template-at(-5): http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                ノードが回復するまで待ちます:
                                    (@node1): |
                                        curl -X GET "http://localhost:9200/_cat/health?v"
                                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                    #// green になるまで待ちます
                            （スキップ）機械学習ジョブを再開します:  #// X-pack を使っていないためスキップ
                        公式の内容:
                            シャード割り当てを無効にします:
                                補足: ノードのシャードはクラスター内の他のノードに複製されます
                                API: |
                                    PUT _cluster/settings
                                    {
                                        "persistent": {
                                            "cluster.routing.allocation.enable": "primaries"
                                        }
                                    }
                            不要なインデックス作成を停止し、同期されたフラッシュを実行します。 (オプション):
                                #// フラッシュすると早くアップグレードできます
                                POST _flush/synced
                            実行中の機械学習ジョブをすべて停止します:
                                POST _ml/set_upgrade_mode?enabled=true
                            単一ノードをシャットダウンします:
                                sudo systemctl stop elasticsearch.service
                            シャットダウンしたノードをアップグレードします:
                                RPM をインストールします。起動はまだしません
                            プラグインをアップグレードします:
                                elasticsearch-plugin remove __PlugInName__
                                elasticsearch-plugin install __PlugInName__
                            アップグレードしたノードを起動します:
                                sudo systemctl start elasticsearch.service
                                GET _cat/nodes
                            シャード割り当てを再度有効にします: |
                                PUT _cluster/settings
                                {
                                    "persistent": {
                                        "cluster.routing.allocation.enable": null
                                    }
                                }
                            ノードが回復するまで待ちます: |
                                GET _cat/health?v
                            別のクラスターに対して以上を全て行います:
                                ノードが回復し、クラスターが安定してから。
                            機械学習ジョブを再開します:
                                POST _ml/set_upgrade_mode?enabled=false
                ElasticSearch の更新はダウンタイム0だが完了まで時間がかかりそう: #keyword: ElasticSearch upgrade long time
                    700GB で 1時間以上: #ref: https://discuss.elastic.co/t/several-hours-for-elasticsearch-upgrade/90670
                    10時間近くかかりました: #ref: https://samirbehara.com/2020/07/23/aws-elasticsearch-version-upgrade-from-6-2-to-7-1/
                    Amazon OpenSearch Service: #ref: https://aws.amazon.com/jp/premiumsupport/knowledge-center/opensearch-domain-upgrade/
                    ダウンタイム0 なら ver6.8 ノードを ver5.6 クラスターに接続: #ref: https://stackoverflow.com/questions/64566542/elasticsearch-upgrade-with-huge-data
                elasticsearch.yml の移植:  #search: elasticsearch.yml porting
            アンインストール: #keyword: ElasticSearch uninstall
                関連 >> データ フォルダー:  #search: ElasticSearch data folder
                Elasticsearch を停止します:
                    sudo systemctl stop elasticsearch など
                elasticsearch.yml の内容をバックアップします:  #// 後でフォルダーの場所を調べるのに使います
                    elasticsearch.yml
                Elasticsearch をアンインストールします:
                    RPM でインストールした場合:
                        yum remove (?)
                データ フォルダー やモジュールを削除します:
                    #// 削除する場所は elasticsearch.yml の設定によって異なります
                    rm -rf  /var/lib/elasticsearch/*
                    rm -rf  /var/log/elasticsearch/*
                    rm -rf  /var/etc/elasticsearch/*
                    rm -rf  /usr/share/elasticsearch/*
                全ノードで データ フォルダー を削除します:
                    rm -rf ____  #// 上記
        検索, クエリー:  #keyword: ElasticSearch query
            curl でドキュメントを検索します:  #keyword: ElasticSearch search,  ElasticSearch curl document
                一覧:  #search: ElasticSearch document
                    -   curl -X GET "http://localhost:9200/__IndexName__/_search?pretty"
                    -   curl -X GET "http://localhost:9200/__IndexName__/_search?pretty&size=99"  #// size を省略すると size=10 と同じ動きになります
                    #search: ElasticSearch bash list document
                検索, フィールド指定あり:  #keyword: ElasticSearch query --data-binary
                    bash: | #keyword: ElasticSearch curl _search  #// 下記の _tmp_parameter.json ファイル を作ってから実行してください
                        curl -X GET "http://localhost:9200/__IndexName__/_search?pretty" -H "Content-Type:application/json" --data-binary @_tmp_parameter.json
                    完全一致: #keyword: ElasticSearch match
                        ./_tmp_parameter.json: |  #search: ElasticSearch curl _search
                            {"query": {"match": { "name": "国立" }}}
                        keyword type の場合:  #search: ElasticSearch keyword type
                            注意: 国立 で検索すると 国立大学 などで登録したドキュメントにはヒットしません。
                                全体が一致するとヒットします
                        text type の場合:  #search: ElasticSearch text type
                            注意: 単語が検索対象になります。
                                国立 で検索すると 国立-大学 などで登録したドキュメントにヒットします。
                                ハイフン(-)などは単語の区切りとして "国立" と "大学" がキーワードになります。
                                国立-大学 で検索すると 国立-大学 で登録したドキュメントにはヒットしません。
                    正規表現:
                        ./_tmp_parameter.json: |  #search: ElasticSearch curl _search
                            {"query": {"regexp": { "name": ".*国立.*" }}}
                        注意:
                            検索対象の全体に一致するように正規表現を指定してください  #search: ElasticSearch match
                    フレーズ: |  #keyword: ElasticSearch match_phrase
                            {"query": {"match_phrase": { "name": "国立" }}}
                        #// 未確認
                    AND 条件: |  #keyword: ElasticSearch and  #// 下記は name = "国立-大学" で登録したドキュメントにもヒットします
                            {"query": {"bool": {
                                "must": [
                                    {"match": {"__FieldNameA__": "国立"}},
                                    {"match": {"__FieldNameB__": "大学"}}
                        #search: ElasticSearch curl _search
                    集約, aggs:  #keyword: ElasticSearch aggs
                        注意: キー(下記 curl の場合の key_b など)が空欄のときは集約されません
                        curl の場合:  #focus: key_a,  a111,  key_c
                            _: 検索結果を key_a.key_b.key_c の構成で表示します
                            _tmp_parameter.json: |  #search: ElasticSearch curl _search
                                {
                                    "query": {
                                        "bool": {
                                            "must": [
                                                {
                                                    "terms": {
                                                        "key_a": [
                                                            "a111",
                                                            "a222"
                                                        ]
                                                    }
                                                }
                                            ]
                                        }
                                    },
                                    "aggs": {
                                        "key_a": {
                                            "terms": {
                                                "field": "key_a"
                                            },
                                            "aggs": {
                                                "key_b": {
                                                    "terms": {
                                                        "field": "key_b"
                                                    },
                                                    "aggs": {
                                                        "key_c": {
                                                            "terms": {
                                                                "field": "key_c"
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    },
                                    "size": 0
                                }
                            出力: |
                                {
                                    "took" : 5,
                                    "timed_out" : false,
                                    "_shards" : {
                                        "total" : 1,
                                        "successful" : 1,
                                        "skipped" : 0,
                                        "failed" : 0
                                    },
                                    "hits" : {
                                        "total" : 1,
                                        "max_score" : 0.0,
                                        "hits" : [ ]
                                    },
                                    "aggregations" : {
                                        "key_a" : {
                                            "doc_count_error_upper_bound" : 0,
                                            "sum_other_doc_count" : 0,
                                            "buckets" : [
                                                {
                                                    "key" : "a111",
                                                    "doc_count" : 1,
                                                    "key_b" : {
                                                        "doc_count_error_upper_bound" : 0,
                                                        "sum_other_doc_count" : 0,
                                                        "buckets" : [
                                                            {
                                                                "key" : 12345678,
                                                                "doc_count" : 1,
                                                                "key_c" : {
                                                                    "doc_count_error_upper_bound" : 0,
                                                                    "sum_other_doc_count" : 0,
                                                                    "buckets" : [
                                                                        {
                                                                            "key" : "10.100.100.222",
                                                                            "doc_count" : 1
                                                                        }
                                                                    ]
                                                                }
                                                            }
                                                        ]
                                                    }
                                                }
                                            ]
                                        }
                                    }
                                }
                        Python ElasticSearch DSL の場合:  #search: aggs elasticsearch_dsl
                全文検索: |  #search: ElasticSearch curl _search
                        {"query": {"simple_query_string": {
                            "query":"__Keyword__",
                            "analyze_wildcard": true,
                            "default_operator":"AND"
                    #ref: https://stackoverflow.com/questions/30917043/elasticsearch-searching-with-hyphens
            単語の区切り: #keyword: ElasticSearch separator
                概要: text type のフィールドは、-（ハイフン）などで自動的に単語に分けられ、検索対象は単語になります  #search: ElasticSearch text type
                区切り文字: -, /  #// 他にもあるかもしれません
                区切り文字ではない文字: .
            include と exclude の両方に指定した場合: #keyword: ElasticSearch include exclude
                exclude が優先されます。
                Terms Aggregation、Rare Terms Aggregation、Significant Terms Aggregationなど、複数の集約タイプで共通して適用されます。
                #ref: https://www.elastic.co/docs/reference/aggregations/search-aggregations-bucket-terms-aggregation#:~:text=When%20both%20are%20defined
            Go 言語: #search: ElasticSearch olivere Search
        クラスターを構成します: #keyword: set up ElasticSearch cluster
            手順:
                #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ElasticSearch_cluster/README.yaml
            プロジェクト:
                #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ElasticSearch_cluster/playbook.yml
            参考:
                6.8: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/discovery-settings.html
                最新: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-settings.html
                Vagrant環境にElasticsearchのCluster構成を作る: #ref: https://shepherdmaster.hateblo.jp/entry/2014/05/06/195021
                Elasticsearch5系 クラスタ構成構築手順: #ref: https://qiita.com/Esfahan/items/3c07bfbb57c7098e9531
                Elasticsearchクラスタ環境を構築する: #ref: https://qiita.com/mkyz08/items/583c5d731a308fa89723
        クラスターを終了します:
            #// 以下は未確認
            クラスター内のすべてのノードを確認します:
            新しいデータの書き込みを停止します:
            各ノードで以下のコマンドを実行して、ノードをシャットダウンします:
                curl -X POST "http://localhost:9200/_shutdown"
                curl -X GET "localhost:9200/_cluster/health?pretty"
            または、Elasticsearchのインストールディレクトリで以下のコマンドを実行します:
                ./bin/elasticsearch-cli shutdown
            すべてのノードが正常にシャットダウンされたことを確認します:
            必要に応じて、オペレーティングシステムレベルでElasticsearchプロセスを停止します:
        バックアップを構成します: #keyword: ElasticSearch back up
            バックアップを構成します:
                クラスターを構成します（Vagrant の場合）: #search: ElasticSearch cluster
                バックアップする内容を確認します:
                    ステータスが green になっていること確認します:
                        (@node1):
                            curl -X GET "http://localhost:9200/_cluster/health/?level=shards&pretty"
                                #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                            #// curl: (7) Failed connect to node1:9200; Connection refused が表示されるときは、1分待ってください
                                #keyword: ElasticSearch Connection refused
                    ドキュメントを一覧します:
                        (@node1): |
                            curl -X GET http://localhost:9200/logs-my_app-default/_search?pretty
                                #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__
                    インデックスがないエラーになる場合:
                        バックアップするドキュメントのサンプルを追加します:
                            (@node1): |
                                curl -X POST "http://localhost:9200/logs-my_app-default/_doc?pretty"  -H "Content-Type:application/json" \
                                -d '{
                                    "@timestamp": "2099-05-06T16:21:15.000Z",
                                    "event": {
                                        "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
                                    }
                                }'
                            #template-at(-7): http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__
                            #// 追加したら一覧を再確認します
                スナップショットのリポジトリを設定します:
                    スナップショットの設定が既にあるか確認します:
                        curl -X GET "http://localhost:9200/_snapshot?pretty"
                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__
                        #// { } と出力されたら、スナップショットの設定はありません
                    共有フォルダーを作ります:  #// リポジトリのフォルダーになります
                        NFS で共有フォルダーを作ります:
                            #// node1 を NFS サーバー、node2, 3 を NFS クライアントにします
                            #search: NFS
                        所有者が elasticsearch ユーザーであることを確認します:
                            sudo ls -la  "/var/log/elasticsearch/shared_repository"
                                #template: "__ElasticS_RepositoryPath__"
                            #// 所有者が elasticsearch:elasticsearch ユーザーであること  #template: __ElasticS_User__:__ElasticS_Group__
                            #// すべてのノードで同じパスに共有フォルダーがあること
                    path.repo プロパティを設定します:  #keyword: ElasticSearch path.repo
                        node1, node2, node3 のそれぞれについて１つずつ:
                            elasticsearch.yml の path.repo プロパティを設定します:
                                elasticsearch.yml ファイルを開きます:
                                    sudo vi "/etc/elasticsearch/elasticsearch.yml"
                                        #template: sudo vi "__ElasticS_SettingFile__"
                                追加内容: |
                                    path.repo: ["/var/log/elasticsearch/shared_repository"]
                                #template: path.repo: ["__ElasticS_RepositoryPath__"]
                            ElasticSearch を再起動します:  #// path.repo プロパティを反映させます
                                再起動を開始します:
                                    sudo systemctl restart elasticsearch  #template: __ElasticS_ServiceName__
                                再起動の完了を待ちます:
                                    ステータスが green になったことを別のノードで確認します:  #// 別のノードとは、再起動したノードとは異なるノードです
                                        (@node2 など): curl -X GET "http://localhost:9200/_cluster/health/?level=shards&pretty"
                                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                        #// curl: (7) Failed connect to node1:9200; Connection refused が表示されるときは、1分待ってください
                            次のノードを設定します:
                    _snapshot/my_backup を作ります:  #template: _snapshot/__ElasticS_SnapShotName__
                        すでにあるか確認します:
                            (@node1): |
                                curl -X GET "http://localhost:9200/_snapshot?pretty"
                                    #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/_snapshot?pretty"
                            #// あるときの出力例: {"my_backup":{"type":"fs","settings":{"location":"/var/log/elasticsearch/repository/my_backup"}}}
                        作ります:
                            (@node1): |
                                curl -X PUT "http://localhost:9200/_snapshot/my_backup?pretty"  -H "Content-Type:application/json" -d '{
                                    "type": "fs",
                                    "settings": {
                                        "location": "/var/log/elasticsearch/shared_repository/my_backup"
                                    }
                                }'
                            #template-at(-6): "http://__ElasticS_Node1__:__ElasticS_HttpPort__/_snapshot/__ElasticS_SnapShotName__?pretty"
                            #template-at(-4): "__ElasticS_RepositoryPath__/__ElasticS_SnapShotName__"
                            #// "acknowledged" : true と表示されること
                            #// path.repo because this setting is empty エラーが出たときは #search: path.repo because this setting is empty
                        #// 以上ですべてのノードに対して設定されます
                バックアップします:
                    公式: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.6/modules-snapshots.html
                    バックアップします:
                        curl -X PUT "http://localhost:9200/_snapshot/my_backup/snapshot_1?pretty&wait_for_completion=true"
                            #template: curl -X PUT "http://__ElasticS_Node1__:__ElasticS_HttpPort__/_snapshot/__ElasticS_SnapShotName__/__ElasticS_SnapshotRevision__?pretty&wait_for_completion=true"
                            #// "state" : "SUCCESS", と表示されること
                            #// 後日バックアップをとるときは __ElasticS_SnapshotRevision__ を変更してください
                    バックアップを一覧します:  #keyword: ElasticSearch list back up
                        curl -X GET "http://localhost:9200/_snapshot/my_backup/_all?pretty"
                            #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/_snapshot/__ElasticS_SnapShotName__/_all?pretty"
            バックアップを無効にします: #keyword: disable ElasticSearch back up  #// バックアップのデータは削除しません
                _snapshot/my_backup を無効にします:  #// スナップショットのリポジトリを無効にします
                    すでに無効であるか確認します:
                        (@node1): |
                            curl -X GET "http://localhost:9200/_snapshot?pretty"
                                #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/_snapshot?pretty"
                        #// 無効のときの出力例: { }
                    無効にします:
                        (@node1): |
                            curl -X DELETE "http://localhost:9200/_snapshot/my_backup?pretty"
                        #template: "http://__ElasticS_Node1__:__ElasticS_HttpPort__
                        #// "acknowledged" : true と表示されること
                    #// 以上ですべてのノードに対して設定されます
                共有フォルダーを無効にします:  #search: disbale NFS
            バックアップを一覧します:  #search: ElasticSearch list back up
            リストアします:  #// バージョン 5 のバックアップは バージョン 6 にリストアできます #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.7/modules-snapshots.html
                バックアップのスナップショットを一覧します:
                    #search: ElasticSearch list back up
                消していい内容であることを確認します:
                    - curl -X GET "http://localhost:9200/_cat/indices?v&pretty" 
                        #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    - curl -X GET "http://localhost:9200/logs-my_app-default/_search?pretty"
                        #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__/_search?pretty"
                すべてのインデックスを削除します:  #// インデックスの中のすべてのドキュメントも削除します
                    curl -X DELETE "http://localhost:9200/*?pretty"
                        #template: curl -X DELETE "http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                リストアします:
                    (@node1): |
                        curl -X POST "http://localhost:9200/_snapshot/my_backup/snapshot_1/_restore?pretty&wait_for_completion=true"  -H "Content-Type:application/json" -d '{
                            "indices": "*"
                        }'
                    #template-at(-3): curl -X POST "http://__ElasticS_Node1__:__ElasticS_HttpPort__/_snapshot/__ElasticS_SnapShotName__/__ElasticS_SnapshotRevision__
                リストアした内容を確認します:
                    curl -X GET "http://localhost:9200/_cat/indices?v&pretty" 
                        #template: curl -X GET "http://__ElasticS_Node1__:__ElasticS_HttpPort__/
            参考:
                公式:
                    Elastic Stack 6.x Upgrade Guide: #ref: https://www.elastic.co/jp/upgrade_guide >>
                        #// Let's Go! >> 6.n, No, (no check) >> (X-pack) No >> No (I don't have 2.x indices)
                    Snapshot And Restore: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.7/modules-snapshots.html
                    Rolling upgrades: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.7/rolling-upgrades.html
                その他:
                    #ref: https://qiita.com/nakazii-co-jp/items/908b6a44e41f176abb8f
        処理時間を計測します: #keyword: ElasticSearch load  #// ドキュメントのバックアップ時間と ElasticSearch のバージョンアップ時間
            ドキュメントの大量登録:
                プロジェクト: #ref: ${GitHub}/MyPrivateCode/ansible_vagrant/multi_vm_ansible/branch_ElasticSearch_cluster/make_documents.sh
                使う負荷試験ツール:
                    logzio/elasticsearch-stress-test:
                        #ref: https://github.com/logzio/elasticsearch-stress-test
                        動作内容:
                            いくつかのテンプレート プールに、それぞれ 5種類のドキュメント ？
                            ドキュメントにフィールドなし
                            ランダムに選んだドキュメントを10個設定
                            プールからインデックスを選択し、プールからドキュメント * バルク サイズを選択してインデックスを作成
                            ドキュメントの生成は実行前に処理される
                大量のドキュメントの場合:
                    動作に必要なサイズを確保します:
                        メモリー:
                            control: 1664MB
                            node1, node2, node3: 3200MB
                            メモ: node1～3 を 3072MB に変更してもしなくても 1024KB ぐらいメモリーをスワップします
                    （必要なら）使用率のウォッチを開始します:
                        ストレージ:
                            node1, node2, node3:
                                df
                        メモリー:
                            control, node1, node2, node3:
                                - free  #// swap used が 0 であること
                                - vmstat -w -t 5
                    負荷試験ツールをインストールします: |
                        cd  __ParentOfTestProject__
                        git clone  https://github.com/logzio/elasticsearch-stress-test
                        cd  elasticsearch-stress-test
                        sudo yum install python-pip -y
                        sudo pip install -r ./requirements.txt
                    実行します:
                        curl -X GET "http://node1:9200/_cluster/health?pretty"
                        python elasticsearch-stress-test.py  --es_address node1  --indices 4  --documents 5  --clients 5  --seconds 120  --no-cleanup
                        python elasticsearch-stress-test.py  --es_address node1  --indices 1  --documents 1  --clients 3  --seconds 120  --max-fields-per-document 10  --max-size-per-field 100 --no-cleanup
                        python elasticsearch-stress-test.py  --es_address node1  --indices 3  --documents 3  --clients 3  --seconds 120  --max-fields-per-document 40  --max-size-per-field 100 --no-cleanup
                            #// ドキュメント数で終わるオプションは無さそう
                    プロセスが Killed された場合:
                        メモリーを増やします
                    計測項目例:
                        #// 実行時に --no-cleanup オプションを指定しなかったらドキュメントは増えません
                        大量のドキュメントの場合:
                            ドキュメント数:
                                curl -X GET "http://node1:9200/_cat/count?v=true"
                            容量:
                                df:
                                    df
                                ElasticSearch:
                                    curl http://node1:9200/_stats/store?pretty | head -n 15
                1つのドキュメントの場合:
                    （同上）
            関連: ElasticSearch >> パフォーマンス
        Go 言語サンプル: #keyword: install ElasticSearch Go  #// olivere/elastic, ElasticSearch Docker for Windows
            #search: ElasticSearch for Go language
            ElasticSearch サーバーをインストールして起動します:  #search: ElasticSearch Docker
            Go 言語をインストールします:  #search: install Go VSCode
            パッケージを使う場合:  #keyword: try_go ElasticSearch  #ref: ${GitHub}/Trials/go/try_go/example/elastic_search
                try_go フォルダーをコピーまたはダウンロードします
                #// 以下に続きます
            パッケージを使わない場合:
                __go_src__/elastic_test.go: |  #search: ElasticSearch olivere
                    package main

                    import (
                        "context"
                        "errors"
                        "fmt"
                        "testing"

                        elastic "gopkg.in/olivere/elastic.v5"
                    )

                    func main1() error {
                        client, err := elastic.NewClient(
                            elastic.SetURL("http://localhost:9200"),
                            elastic.SetSniff(false))
                        fmt.Println(client, err)
                        return err
                    }

                    func main2() error {
                        goContext := context.Background()

                        elasticSearch, err := elastic.NewClient(
                            elastic.SetURL("http://localhost:9200"),
                            elastic.SetSniff(false))
                        if err != nil {
                            return err
                        }
                        elasticSearch.Start()
                        defer elasticSearch.Stop()

                        // CreateIndex
                        _, err = elasticSearch.CreateIndex("my-index").Do(goContext)
                        if err != nil {
                            return err
                        }

                        // Add a document to the index
                        _, err = elasticSearch.Index().Index("my-index").Type("my-type").Id("my-id").
                            BodyJson(Vertex{X: 1, Y: 2}).
                            Do(goContext)
                        if err != nil {
                            return err
                        }

                        // List up IndexNames
                        indexNames, err := elasticSearch.IndexNames()
                        if err != nil {
                            return err
                        }
                        for _, indexName := range indexNames {
                            fmt.Printf("%s\n", indexName)
                        }

                        indices, err := elasticSearch.CatIndices().Do(goContext)
                        if err != nil {
                            return err
                        }
                        for _, index := range indices {
                            fmt.Printf("> %s\n", index.Index) // same as indexName
                        }
                        return nil
                    }

                    func main3() error {
                        goContext := context.Background()

                        elasticSearch, err := elastic.NewClient(
                            elastic.SetURL("http://localhost:9200"),
                            elastic.SetSniff(false))
                        if err != nil {
                            return err
                        }
                        elasticSearch.Start()
                        defer elasticSearch.Stop()

                        // Delete a document
                        if false {
                            _, err = elasticSearch.Delete().Index("my-index").Type("my-type").Id("my-id").Do(goContext)
                            if err != nil {
                                return err
                            }
                        }

                        // DeleteIndex
                        _, err = elasticSearch.DeleteIndex("my-index").Do(goContext)
                        if err != nil {
                            return err
                        }
                        return nil
                    }

                    type Vertex struct {
                        X int
                        Y int
                    }

                    var target = "main1"

                    func TestElasticSearch(t *testing.T) {
                        var err error = nil
                        if target == "main1" {
                            err = main1()
                        } else if target == "main2" {
                            err = main2()
                        } else if target == "main3" {
                            err = main3()
                        } else {
                            err = errors.New("Unknown target")
                        }
                        if err != nil {
                            panic(err)
                        }
                    }
                必要な Go パッケージをインストールします:
                    サンプル: #// シェル
                        go get gopkg.in/olivere/elastic.v5
                #// 以下に続きます
            実行します:
                TestElasticSearch 関数の定義の上にある run test がある場合:
                    それをクリックします
                無い場合:
                    .go ファイルを開いて F5 キーを押します
                #// ElasticSearch のサーバーと接続できなかったらエラーになります
            インデックスとドキュメントを追加するサンプルを実行します:
                __go_src__/elastic_test.go: |
                    var target = "main2"
                実行します:
                インデックスを一覧します:
                    #// シェル
                    curl -X GET "http://localhost:9200/_cat/indices?v&pretty"   #// ?v&pretty は表示を少し詳細にします
                ドキュメントを一覧します:
                    #// シェル
                    curl -X GET http://localhost:9200/my-index/_search?pretty
            インデックスとドキュメントを削除するサンプルを実行します:
                __go_src__/elastic_test.go: |
                    var target = "main3"
                実行します:
                インデックスを一覧します:
                    #// シェル
                    curl -X GET "http://localhost:9200/_cat/indices?v&pretty"
            参考: ElasticSearch for Go言語  #search: ElasticSearch for Go language
    画面:
        Elasticsearch VSCode 拡張機能: #keyword: Elasticsearch VSCode extension
            Database Client 製:
                #// MySQL VSCode 拡張機能 に統合されています  #search: MySQL VSCode extension
                接続:  #search: connect MySQL cweijan
                    Elasticsearch サービス を起動します:
                    Connection ページ:
                        メニュー: VSCode >> Database ビュー（左）>> ＋（ビューの右上）
                        Server Type: Elasticsearch
                        URL: http://localhost:9200
                        Save ボタン:
    コマンド:  #glossary:
        curl:
            コマンド テンプレート:  #search: ElasticSearch cURL template
            ノード一覧:  #search: ElasticSearch cat nodes
            ドキュメントを検索:  #search: ElasticSearch search
        elasticsearch-keystore:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-keystore.html
        elasticsearch-plugin:  #ref: https://www.elastic.co/guide/en/elasticsearch/plugins/6.8/listing-removing-updating.html
            - sudo /usr/share/elasticsearch/bin/elasticsearch-plugin  list
            - sudo /usr/share/elasticsearch/bin/elasticsearch-plugin  install  __PlugInName__  #// 更新するときは remove と install をします
            - sudo /usr/share/elasticsearch/bin/elasticsearch-plugin  remove  __PlugInName__
    API: #keyword: ElasticSearch API
        http://localhost:9200/__IndexName__/?pretty
        http://localhost:9200/__IndexName__/_settings?pretty
        http://localhost:9200/__IndexName__/_mapping?pretty
        http://localhost:9200/__IndexName__/_count
        http://localhost:9200/__IndexName__/_search?pretty
        http://localhost:9200/__IndexName__/_doc?pretty
        http://localhost:9200/__IndexName__/_doc/__ID__
        http://localhost:9200/__IndexName__/_bulk?pretty
        http://localhost:9200/_bulk?pretty
        http://localhost:9200/_cat/count?v=true
        http://localhost:9200/_all/_search?pretty
        http://localhost:9200/_cat/indices?v&pretty
        http://localhost:9200/_template/
        http://localhost:9200/_template/__TemplateName__
        http://localhost:9200/_analyze?pretty
        http://localhost:9200/_cat/nodes?v=true
        http://localhost:9200/_nodes/plugins?pretty
        http://localhost:9200/_cluster/health
        http://localhost:9200/_cluster/health/?level=shards&pretty
        http://localhost:9200/_cluster/settings?pretty
        http://localhost:9200/_cat/shards
        http://localhost:9200/_flush/synced?pretty
        http://localhost:9200/_snapshot?pretty
        http://localhost:9200/_ml/set_upgrade_mode?enabled=true&pretty
        http://localhost:9200/_shutdown
    構成, 概念:
        クラスター:  #//🌟 #keyword: ElasticSearch cluster  #// クラスター、サーバー、ノードの生存確認
            クラスター:
                クラスターの状態を表示します: #keyword: ElasticSearch /_cluster/health,  ElasticSearch status green
                    表示コマンド: |
                        curl -X GET "http://localhost:9200/_cluster/health?pretty"  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                            {
                                "cluster_name" : "db_local-1",
                                "status" : "green",
                                "timed_out" : false,
                                "number_of_nodes" : 5,
                                "number_of_data_nodes" : 5,
                                "active_primary_shards" : 5,
                                "active_shards" : 10,
                                "relocating_shards" : 0,
                                "initializing_shards" : 0,
                                "unassigned_shards" : 0,
                                "delayed_unassigned_shards" : 0,
                                "number_of_pending_tasks" : 0,
                                "number_of_in_flight_fetch" : 0,
                                "task_max_waiting_in_queue_millis" : 0,
                                "active_shards_percent_as_number" : 100.0
                            }
                    ステータス red, yellow:
                        - #// status - red  #keyword: ElasticSearch status red  #// プライマリシャードに問題あり。即座な対応が必要
                            手順: curl -X GET "http://node1:9200/_cluster/health/?level=shards&pretty" 
                            エラー: |
                                status - red
                            対処:
                                - |  #// disable  "status - red"
                                    curl -X PUT "http://node1:9200/_cluster/settings?pretty"  -H "Content-Type:application/json" -d '{
                                        "transient":{"cluster.routing.allocation.enable":"none"}
                                    }'
                                - |  #// enable
                                    curl -X PUT "http://node1:9200/_cluster/settings?pretty"  -H "Content-Type:application/json" -d '{
                                        "transient":{"cluster.routing.allocation.enable":"all"}
                                    }'
                        - #// status - yellow  #keyword: ElasticSearch status yellow  #// プライマリは正常だがレプリカに問題。ただし、1台構成のクラスターの場合、yellow で良い
                            手順: curl -X GET "http://node1:9200/_cluster/health/?pretty"
                            エラー: |
                                status: "yellow"
                            対処A:
                                - "cluster.routing.allocation.enable": "primaries" #// yellow になります
                                - "cluster.routing.allocation.enable": null #// green になります
                                #search: cluster.routing.allocation.enable
                            対処B, unassigned_shards:
                                unassigned_shards を表示します:
                                    curl -X GET "http://node1:9200/_cluster/health?pretty"
                                1 以上なら 0 に減るまで待ちます:
                    正常確認方法: |
                        curl -X GET "http://localhost:9200/_cluster/health?pretty"
                            "relocating_shards": 0,        // 再配置中のシャード。 減っていき、0 になれば良い
                            "initializing_shards": 0,      // 初期化中のシャード。 減っていき、0 になれば良い
                            "unassigned_shards": 0,        // 未割り当てシャード。 減っていき、0 になれば良い。ただし、1台構成のクラスターの場合、減らなくてよい
                クラスター UUID: #keyword: ElasticSearch cluster UUID
                    クリア:
                        #// シングル ノード クラスター を構成してしまったときなど、クラスター UUID がそれぞれのノードで一度決まってしまったら、
                        #// データのフォルダーを全消去しなければ クラスター UUID を同じ値に変更できません。
                        elasticsearch.yml の path.data に書かれたパスのフォルダーを削除します。
                設定:  #search: ElasticSearch default /_cluster/settings
            ノード:
                ノード（サーバー）の情報を表示します: | #keyword: ElasticSearch nodes
                    $ curl -X GET http://localhost:9200/    #// 環境によっては localhost からアクセスできません。サーバー名でアクセスしてください
                        #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    {
                        "name" : "es01",
                        "cluster_name" : "es-docker-cluster",
                        "cluster_uuid" : "k5vFtXmQQ8W8_m0pacG1Aw",
                        "version" : {
                        "number" : "7.10.1",
                        "build_flavor" : "default",
                        "build_type" : "docker",
                        "build_hash" : "1c34507e66d7db1211f66f3513706fdf548736aa",
                        "build_date" : "2020-12-05T01:00:33.671820Z",
                        "build_snapshot" : false,
                        "lucene_version" : "8.7.0",
                        "minimum_wire_compatibility_version" : "6.8.0",
                        "minimum_index_compatibility_version" : "6.0.0-beta1"     
                        },
                        "tagline" : "You Know, for Search"
                    }
                ノードを一覧します:  #// シャーディングされているので、複数台のノードで１つのデータベースになります
                    コマンド: |  #keyword: ElasticSearch cat nodes,  ElasticSearch /_cat/nodes  #// 環境によっては localhost からアクセスできません。サーバー名でアクセスしてください
                        $ curl -X GET http://localhost:9200/_cat/nodes?v=true  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
                        10.146.203.38 24           97          0   0.04    0.27    0.27     mdi       *      server1
                        10.146.203.37 35           91          0   0.03    0.04    0.05     mdi       -      server2
                        10.146.203.39 46           97          1   0.00    0.01    0.05     mdi       -      server3
                    公式: https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-nodes.html
                    v=true オプション: 出力にヘッダーがつきます
                マスター ノード, データ ノード: #keyword: ElasticSearch master node  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/modules-node.html
                    アクティブ マスター ノード: #keyword: ElasticSearch active master node  #// 必ず 1台
                        _cat/nodes で * が付くノード  #search: ElasticSearch cat nodes
                    マスター候補ノード, マスター適格ノード: #keyword: ElasticSearch master eligible node  #// デフォルト
                        node.master: true
                        node.data: false
                        node.ingest: false
                    データ ノード: #keyword: ElasitcSearch data node  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/modules-node.html#data-node
                        node.master: false 
                        node.data: true 
                        node.ingest: false 
                        node.ml: false 
                        cluster.remote.connect: false 
                        クライアントからの接続先にもなれます:
                            #ref: https://www.elastic.co/jp/blog/how-to-configure-elasticsearch-cluster-better >> クライアントアプリからの接続先はマスターノード
                    コーディネーティング ノード: #keyword: ElasitcSearch  coodinating node
                        _: クライアントからリクエストを受け取って、ノード間の調整を行うノードです。
                            すべてのノードが コーディネーティング ノード になれます
                            #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html >> Every node is implicitly a coordinating node.
                        クライアントの設定:
                            全てのノードをクライアントの設定に一覧する必要はありません。
                            どんな設定でも全てのノードは コーディネーティング ノード であり、クライアントから受け取ったリクエストはクラスター内の別のノードに転送するなど調整します。
                            コーディネーティング ノード を経由する分、性能的にあまり良くないと思いますが、
                            専用 コーディネーティング ノード を作れることから、それほど大きく性能が落ちることはないと思います。
                            追加ノードへの書き込みができているなら動作確認もできていることになります。
                            #ref: https://stackoverflow.com/questions/66649669/elasticsearch-how-coordinating-node-works
                            #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#coordinating-node
                        専用 コーディネーティング ノード:
                            データを保持しない, マスターになれない, インデックス操作のみを担当
                            #ref: https://stackoverflow.com/questions/66649669/elasticsearch-how-coordinating-node-works
                    インジェスト ノード: #keyword: ElasticSearch ingest node
                サーバー数（ノード数）を増やします: #keyword: ElasticSearch server count
                    概要:
                        - 一般にサーバー数は奇数になるように増やします  #ref: ${typrm_files}/ref/Database-AI.yaml#label: ElasticSearch server count
                        - シャード数はサーバー数の倍数にします
                        - 関連 >> ディスクの使用量:  #search: ElasticSearch disk size
                    検出:  #keyword: ElasticSearch zen discovery  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/modules-discovery-zen.html
                        zen discovery:  #// ElasticSearch 6 まで
                        ユニキャスト検出:  #// Unicast discovery  #ref: https://www.elastic.co/jp/blog/how-to-configure-elasticsearch-cluster-better >> zen.ping.unicast.hosts
                            elasticsearch.yml の discovery.zen.ping.unicast.hosts に設定された静的なノードのリストを使って検出します
                安全に終了させます: #keyword: ElasticSearch _shutdown
                    シャードを他のノードへ移動させます:
                        終了するノードの名前 __NodeName__ を調べます:  #search: ElasticSearch cat nodes
                            curl -X GET http://localhost:9200/_cat/nodes?v=true
                                #// 最も右の列
                        シャードをすべて退避し、シャードが追加されないようにします: | #keyword___: exclude ElasticSearch shade
                            curl -X PUT "localhost:9200/_cluster/settings?pretty" -H 'Content-Type: application/json' -d'{
                                "transient" : {
                                    "cluster.routing.allocation.exclude._name" : "__NodeName__"
                                }
                            }'
                        シャード数を表示して、0 になるまで待ちます:  #search: ElasticSearch /_cat/allocation
                            curl -X GET "localhost:9200/_cat/allocation?v"
                    クラスターが status green であることを確認します:  #search: ElasticSearch /_cluster/health
                        curl -X GET "localhost:9200/_cluster/health?pretty"
                    1つのノードの Elasticsearch サービスを終了します: |
                        systemctl stop elasticsearch  #// root ユーザーで
                        systemctl status elasticsearch
                            #// inactive
                    number_of_nodes が減っていることを確認します:  #search: ElasticSearch /_cluster/health
                        curl -X GET "localhost:9200/_cluster/health?pretty"
                    （参考）古い方法:
                        curl -X GET "http://localhost:9200/_nodes/__NodeName__/_shutdown?pretty"
                            #// _shutdown API は elasticsearch 2.x で削除されました
                            #ref: https://stackoverflow.com/questions/17191539/how-to-stop-shut-down-an-elasticsearch-node
            シャード: #keyword: ElasticSearch shade
                プライマリ シャード: #keyword: ElasticSearch primary shade
                レプリカ シャード: #keyword: ElasticSearch replica shade
                    バックアップ、兼、読み取り。
                    追加のレプリカは、さらなる冗長性と読み取りキャパシティーを提供します。
                    5 個のプライマリシャードと 1 個のレプリカがあるインデックスの場合、各インデックス作成リクエストは 10 個のシャードにタッチします。
                数:  #search: ElasticSearch primary replica shade
                    設計: #keyword: ElasticSearch shade count
                        検索が多い場合: 各シャードが 10～30 GiB になるようにシャード数を設定します
                        記録が多い場合: 各シャードが 30～50 GiB になるようにシャード数を設定します
                        #ref: https://docs.aws.amazon.com/ja_jp/opensearch-service/latest/developerguide/bp.html
                        #search: ElasticSearch primary shade
                        #search: ElasticSearch replica shade
                    数を減らします: #// 調査中
                        エラー: | #ref: active_shards, 3000, shards
                            /usr/lib/python2.7/site-packages/elasticsearch/connection/base.py:200:
                                ElasticsearchWarning: In a future major version, this request will fail
                                because this action would add [6] total shards, but this cluster currently has
                                [3036]/[3000] maximum shards open. Before upgrading,
                                reduce the number of shards in your cluster or adjust
                                the cluster setting [cluster.max_shards_per_node].
                            warnings.warn(message, category=ElasticsearchWarning)
                            [vagrant@localhost vagrant]$ curl -X GET "http://node1:9200/_cluster/health?pretty" 
                                "cluster_name" : "my-elasticsearch-cluster",
                                "status" : "green",
                                "timed_out" : false,
                                "number_of_nodes" : 3,
                                "number_of_data_nodes" : 3,
                                "active_primary_shards" : 1734,
                                "active_shards" : 3468,
                                "relocating_shards" : 0,
                                "initializing_shards" : 0,
                                "unassigned_shards" : 0,
                                "delayed_unassigned_shards" : 0,
                                "number_of_pending_tasks" : 0,
                                "number_of_in_flight_fetch" : 0,
                                "task_max_waiting_in_queue_millis" : 0,
                                "active_shards_percent_as_number" : 100.0
                        参考:
                            opster: #ref: https://opster.com/guides/elasticsearch/data-structuring/elasticsearch-reduce-shards/
                                新しく作成するインデックスのシャード数:
                                    プライマリ シャードの数: デフォルトでは、インデックスあたり 5 つの プライマリ シャード
                                    5 つのプライマリ シャードが扱える量: 100-250GB
                                    インデックス テンプレート: index.number_of_shards = 1  #// インデックスあたり 1 つの プライマリ シャード
                                既存のインデックスの場合:
                            stack overflow: #ref: https://stackoverflow.com/questions/56280771/elasticsearch-how-can-i-reduce-the-number-of-primary-shards
                                大きなデータがある場合(100 GB以上):
                                    複数の プライマリ シャード に分けます  #// 複数のノードに配置するため
                                データが小さい場合:  #// 合計 インデックス サイズ が少ない（数GBの）場合
                                    シャードを１つにしたほうが性能が良くなります
                配置:  #search: ElasticSearch primary replica shade  #// レプリカは別のノードに配置されます
                状態を表示:  #keyword: ElasticSearch health shards
                    #// 注意：インデックスが多いと応答メッセージが大量になります
                    health: |
                        curl -X GET "http://localhost:9200/_cluster/health/?level=shards&pretty"   #// & は " " の中に入れてください
                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    状態: |
                        curl -X GET "http://localhost:9200/_cat/shards"
                                #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                            __IndexName__ __Num__ __PrimaryOrReplica__ STARTED 13642  __Size__
                    設定の表示:
                        curl -X GET "http://localhost:9200/_cluster/settings&pretty"
            データ フォルダー: #keyword: ElasticSearch data folder,  ElasticSearch data directory
                場所:
                    デフォルト:
                        /var/lib/elasticsearch
                    設定:
                        elasticsearch.yml 設定ファイルの path.data
                削除:  #// データベースを初期化します
                    Elasticsearch を停止します:
                        sudo systemctl stop elasticsearch など
                    データ フォルダー を削除します:
                        rm -rf __DataFolder__/*
                    全ノードで データ フォルダー を削除します:
                        rm -rf __DataFolder__/*
                    （必要なら）再インストールします:
                        sudo apt-get purge elasticsearch
                        sudo apt-get install elasticsearch
                    関連 >> アンインストール:  #search: uninstall Elasticsearch
            ディスクの使用量: #keyword: ElasticSearch disk size,  ElasticSearch disk 使用量
                各ノードの使用量:
                    サンプル: #keyword: ElasticSearch /_cat/allocation
                        $ curl --silent "http://localhost:9200/_cat/allocation?v"
                            shards  disk.indices  disk.used  disk.avail  disk.total  disk.percent  host          ip            node
                                14         548kb      6.5gb      51.8gb      58.3gb            11  10.00.100.11  10.00.100.11  es1_9200
                                14       734.3kb      6.5gb      51.8gb      58.3gb            11  10.00.100.12  10.00.100.12  es2_9200
                                14       742.4kb      6.5gb      51.8gb      58.3gb            11  10.00.100.13  10.00.100.13  es3_9200
                    shards: シャード数。 レプリカ数 1の場合、たとえば、
                        es1_9200 ノードに プライマリ シャード 1つと
                        es2_9200 ノードに レプリカ シャード 1つで
                        計 2つ
                    disk.indices: ElasticSearch の使用量。/_cat/indices の pri-size の合計  #search: ElasticSearch list index/indices example
                    disk.used  disk.avail  disk.total, disk.percent: ノードのディスク使用量。df コマンドの出力と同じです
                インデックスの使用量: #keyword: ElasticSearch index disk size
                    表示:  #search: ElasticSearch list index/indices example
                        #snip:
                            pri-size
                            # curl -X GET "http://localhost:9200/_cat/indices?v&pretty"
                            #     health status index                                               uuid                 pri rep   count   del    size  pri-size
                            #     ------------------------------------------------------------------------------------------------------------------------------
                            #     green  open   slog-asm_ltm-eventlog-waf78870444-20241009-0001     bczudxmfTUa1kzMxFlllxw 1 1       28      0   76.7kb   38.3kb
                    計算:  #keyword: ElasticSearch primary replica shade
                        3ノードクラスターで、シャード数 1、レプリカ数 1の場合:
                            各シャードは、プライマリ シャード（number_of_shards）1つと レプリカ(number_of_replicas) 1つで、計 2つ
                            これらが3ノードに分散配置される。
                            ただし、同じインデックスではドキュメントが大量にあっても同じノードにしかできません。
                                P R -
                            別のインデックスでは、
                                - P R
                            別のインデックスでは、
                                R - P
                        5ノードクラスターでシャード数 2、レプリカ数 2の場合:
                            同じインデックスでも分散配置されますが、ノードごとの役割（P と R と無し）が変わることはありません
                                P - R - -
                                - P - R -
                                P - - R -
                                - P R - -
                            別のインデックスでは、
                                - R - - P
                                P - R - -
                                - - R - P
                                P R - - -
                        配置の単位:
                            プライマリシャード数: 1
                            レプリカ数: 1
                                この場合、ノード数が何台あっても、ドキュメントが大量にあっても、そのインデックスのデータは2台のノードにしか格納されません：
        インデックス: #keyword: ElasticSearch index  #// ドキュメントの集まり（索引）。ドキュメントを含む インデックス テンプレート のコピー
            関連 >> インデックス テンプレート:  #// 検索キーに相当します  #serach: ElasticSearch Index Templates
            サンプル:  #// kuromoji プラグイン  #search: kuromoji
            数:
                curl -X GET "http://localhost:9200/_cat/indices" | wc --lines    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                #ref: https://stackoverflow.com/questions/65285633/get-total-number-of-indices-in-elasticsearch-cluster
            一覧:  #// インデックスを一覧します  #keyword: ElasticSearch list index/indices
                -   curl -X GET "http://localhost:9200/_cat/indices?v&pretty" | sort -k 3   #// ?v は表示を少し詳細にします  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                -   curl -X GET "http://localhost:9200/_cat/indices/log-*?pretty"     #// ワイルドカード指定        
                - サンプル:  #search: ElasticSearch list index/indices example      
            構成, 内容の表示:  #// インデックスの設定内容を表示します
                全体:  #// setting や mapping なども含みます
                    curl -X GET "http://localhost:9200/__IndexName__/?pretty"  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                setting: | #keyword: ElasticSearch index setting  #// number_of_shards など
                    $ curl -X GET "http://localhost:9200/__IndexName__/_settings?pretty"  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    {
                        "my-index-2022-01-31" : {
                            "settings" : {
                                "index" : {
                                    "creation_date" : "1683778008052",
                                    "number_of_shards" : "5",                     // プライマリ シャード の数
                                    "number_of_replicas" : "1",
                                    "uuid" : "fimfdafceKKd-lmuHZOTVg",
                                    "version" : {
                                        "created" : "6000499"
                                    },
                                    "provided_name" : "my-index-2022-01-31"
                mapping: #keyword: ElasticSearch mapping  #// フィールドの型など  #search: ElasticSearch type
                    コマンド: |
                        -   curl -X GET "http://localhost:9200/__IndexName__/_mapping?pretty"  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                            {
                                "my-index-2022-01-31" : {
                                    "mappings" : {
                                        "_doc" : {
                                            "properties" : {
                                                "name" : {
                                                    "type" : "text",
                                                    "fields" : {
                                                        "keyword" : {
                                                            "type" : "keyword",
                                                            "ignore_above" : 256
                                                        }
                                                    }
                                                },
                                                "phone" : {
                                                    "type" : "text",
                                                    "fields" : {
                                                        "keyword" : {
                                                            "type" : "keyword",
                                                            "ignore_above" : 256
                        -   curl -X GET "http://localhost:9200/__IndexName__/_mapping/field/__FieldName__?pretty"  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                            {
                                "my-index-2022-01-31" : {
                                    "mappings" : {
                                        "_doc" : {
                                            "properties" : {
                                                "phone" : {              #// __FieldName__ = phone の場合
                                                    "type" : "text",
                                                    "fields" : {
                                                        "keyword" : {
                                                            "type" : "keyword",
                                                            "ignore_above" : 256
                    構成の概要: #keyword: ElasticSearch index mapping abstract  #// インデックス関連の構成
                        インデックス テンプレート: |  # METHOD /_template/__TemplateName__
                            http://localhost:9200/_template/
                            http://localhost:9200/_template/__TemplateName__
                            {
                                "mappings": {
                                    ここの内容は、インデックスが新規作成されると http://localhost:9200/__Index__/_mapping にコピーされます。
                                    ここの内容を変更しても、すでに作成済みのインデックスのマッピングは変わりません。
                        インデックス:  # METHOD /__IndexName__
                            マッピング:  # METHOD /__IndexName__/_mapping
                                http://localhost:9200/__IndexName__/_mapping
                    マッピングの変更: #keyword: change ElasticSearch mapping
                        インデックスが 1日ごとに作られる場合:
                            インデックス テンプレート を変更後、次の日のインデックスのマッピングは更新されます
                        変更前の検索のエラー:  #// サブ フィールド がインデックスのマッピングに無い場合
                            エラーになるかもしれません。動作確認してください
                        特定のフィールドのみを再インデックス:
                            できるらしい
                            （型を変更することは基本的にできません）
                    サブ フィールド を持つ型: #keyword: ElasticSearch sub field  #// 1つの値に対して複数の種類のインデックスを作ることができます
                        keyword + IP 型: #keyword: ElasticSearch keyword IP type  #// IP 型は CIDR を指定して、範囲で IP アドレス を検索することができます
                            マッピング JSON: |  #search: ElasticSearch mapping
                                "__FieldName__": {
                                    "type": "keyword",         // #template_: __Type__  #// keyword, text ip, integer など  #search: ElasticSearch type
                                        "fields": {
                                            "type_ip": {       // #template_: __SubFieldName__  #// 通常、type___
                                                "type": "ip"   // #template_: __SubFieldType__
                            フィールド名: |  #// プログラミング言語のライブラリに検索キーワードと共に指定します
                                __FieldName__.type_ip          // #template_: '__FieldName__.__SubFieldName__'
                ドキュメントのインデックス: #keyword: ElasticSearch document index
                    登録の有無:  
                        ドキュメントのフィールドがインデックスに登録されているかどうかを確認する方法は、検索しかありません。
                        #search: 
                                #search: ElasticSearch separator
            追加:  #// インデックスを追加・作成します  #search: ElasticSearch add index
                デフォルトのインデックスを追加します:
                    コマンド:
                        curl -X PUT http://localhost:9200/__IndexName__  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                インデックス テンプレート にマッチしない場合:
                    概要:
                        index_patterns にマッチしない名前のインデックスを作った場合、
                        自動的にすべてのフィールドに対して mapping や setting のインデックスの内容が作られます。
                        作られたインデックスの内容は表示することができます。
                        一度作られると内容は変わらないようです（未確認）。
                    参考:
                        index_patterns:  #search: ElasticSearch  index_patterns
                        mapping:  #search: ElasticSearch  mapping
                        setting:  #search: ElasticSearch  setting
                設定を指定してインデックスを追加します:
                    コマンド: |
                        curl -X PUT http://localhost:9200/__IndexName__ -H "Content-Type:application/json" -d '  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        {
                            "settings": {
                                "number_of_shards": 1,
                                "index.number_of_replicas" : 1
                            }
                        }'
                    成功したときの表示: {"acknowledged":true,"shards_acknowledged":true,"index":"hoge_index"}
            削除: #keyword: delete ElasticSearch index  #// インデックスを削除します
                1つのインデックスを削除:
                    コマンド:  #// ドキュメントも削除されます
                        curl -X DELETE "http://localhost:9200/logs-my_app-default?pretty"
                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__?
                    成功したときの表示: {"acknowledged":true}
                スクリプトでいくつかのインデックスを削除:
                    スクリプト: |
                        #!/bin/bash

                        # このスクリプトは、ElasitcSearch に対して以下のインデックス削除手順を自動的に行います。ElasticSearch の サーバー（番号は任意）で実行してください。
                        #     1. 2秒待つ
                        #     2. ステータスが green または yellow になるまで待ちます。（チェック間隔は10秒。5分以上待ったらエラー終了）
                        #         curl --silent -X GET "http://localhost:9200/_cluster/health?pretty"   #// スクリプトの外で直接実行したときはステータスが表示されます
                        #     3. インデックスを削除します
                        #         curl --silent -X DELETE "http://localhost:9200/__IndexName__"
                        # 削除するインデックスを下記 DeleteIndex の引数に指定するように編集してから、このスクリプトを引数なしで実行してください。
                        #     削除中のインデックス名が表示されます。
                        #     存在しないインデックスなどを指定した場合などで、エラーになります。
                        #     エラーになったら続きを実行しません。
                        function  Main() {
                            ShowHelp

                            DeleteIndex  __Index__
                            DeleteIndex  __Index__
                            DeleteIndex  __Index__
                            echo  ""
                            echo  "Finish"
                        }

                        function  ShowHelp() {
                            echo  "Command of list up index:"
                            echo  '    curl -X GET "http://localhost:9200/_cat/indices?v&pretty"'
                            echo  '    curl -X GET "http://localhost:9200/_cat/count?v=true"'
                            echo  "Command of cluster health:"
                            echo  '    curl --silent -X GET "http://localhost:9200/_cluster/health?pretty"'
                        }

                        function  DeleteIndex() {
                            local  indexName="$1"
                            test  "${indexName}" != ""  ||  Error  "ERROR: indexName=${indexName}"

                            echo  "DeleteIndex  ${indexName}"

                            WaitForStatusGreen

                            local  response="$( curl --silent -X DELETE "http://localhost:9200/${indexName}" )"
                            echo  "${response}"
                            echo  "${response}" | grep -F '{"acknowledged":true}' > /dev/null  ||  Error 
                        }

                        function  WaitForStatusGreen() {
                            local  checked="false"
                            sleep 2s
                            for i in {1..30}; do 

                                curl --silent -X GET "http://localhost:9200/_cluster/health?pretty"  |  grep -E '"status" : "(green|yellow)",' > /dev/null  &&  checked="true"  &&  break
                                echo  "Wait for status green"
                                sleep 10s
                            done
                            if [ "${checked}" == "false" ]; then
                                curl --silent -X GET "http://localhost:9200/_cluster/health?pretty"
                                Error
                            fi
                        }

                        function  Error() {
                            local  errorMessage="$1"
                            if [ "${errorMessage}" == "" ]; then
                                errorMessage="ERROR"
                            fi

                            echo "${errorMessage}"  >&2
                            exit  2
                        }

                        Main
                すべてのインデックスを削除:
                    コマンド:  #// ドキュメントも削除されます
                        curl -X DELETE "http://localhost:9200/*?pretty"
                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    成功したときの表示: {"acknowledged":true}
            型: #keyword: ElasticSearch type
                keyword type:  #keyword: ElasticSearch keyword type
                    keyword type の場合の mapping の表示: |  #focus: keyword  #search: ElasticSearch mapping
                        "mappings" : {
                            "_doc" : {
                                "properties" : {
                                    "__Name__" : {
                                        "type" : "keyword",
                                        "ignore_above" : 32766
                                    },
                    #search: ElasticSearch match
                text type:  #keyword: ElasticSearch text type
                    text type の場合の mapping の表示: |  #focus: text, keyword  #search: ElasticSearch mapping
                        "mappings" : {
                            "_doc" : {
                                "properties" : {
                                    "__Name__" : {
                                        "type" : "text",
                                        "fields" : {
                                            "keyword" : {
                                                "type" : "keyword",
                                                "ignore_above" : 256
                    #search: ElasticSearch match
                ip type:
                integer type:
            ノード内の場所:  #search: ElasticSearch data folder
        ドキュメント: #keyword: ElasticSearch document  #//🌟 データベースのレコードに相当
            数:
                ドキュメント数:  #keyword: ElasticSearch document count
                    全インデックス内:
                        (bash):
                            - curl -X GET "http://node1:9200/_cat/count?v=true"
                                #// count の列を確認します  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-count.html
                            # または
                            - curl -X GET "http://localhost:9200/_cat/indices?v&pretty" | sort -k 3   #// ?v は表示を少し詳細にします  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                #// docs.count の列を確認します  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/cat-indices.html
                                #// store.size はレプリカも含めたシャードのサイズ
                        ドキュメント数？:
                            curl -X GET "http://localhost:9200/_all/_search?q=tag:nice&pretty"
                    出力例:
                        health status index               uuid                   pri rep docs.count docs.deleted store.size pri.store.size
                        green  open   logs-my_app-default AtPGX0qkTraHGynMHHjlsw   5   1          1            0      9.1kb          4.5kb
                    ❗注意 >> ./_cat/index の docs.count は概算値:
                        正確なドキュメント数: |
                            curl -X GET "http://localhost:9200/<インデックス名>/_search" -H 'Content-Type: application/json' -d'
                                {
                                    "size": 0,
                                    "track_total_hits": true     Elasticsearch v7 で必要
                                }'
                                hits.total
                    特定のインデックス内:
                        curl -X GET http://localhost:9200/__IndexName__/_count  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    ディスクサイズ:  #search: ElasticSearch index disk size
            検索、内容の一覧:  #keyword: ElasticSearch document search query,  ElasticSearch query
                参照, 内容の一覧 >> match_all:  #search: ElasticSearch search
                    全インデックスのドキュメントの内容を一覧します: #keyword: ElasticSearch bash list document
                        bash:
                            - curl -X GET "http://localhost:9200/_all/_search?pretty"   #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                            - curl -X GET "http://localhost:9200/_all/_search?pretty&size=99"   #// size を省略すると size=10 と同じ動きになります
                    特定インデックスのドキュメントの内容を一覧します: #keyword: ElasticSearch bash list index document  #search: ElasticSearch search
                        bash:
                            - curl -X GET "http://localhost:9200/__IndexName__/_search?pretty"  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                #// "_source" の項目にドキュメントの内容があります
                            - curl -X GET "http://localhost:9200/__IndexName__/_search?pretty&size=99"   #// size を省略すると size=10 と同じ動きになります
                            - curl -X GET "http://localhost:9200/__IndexName__/?pretty"  #// 型が表示されます
                        __IndexName__:
                            インデックス一覧から探します:  #search: ElasticSearch list index/indices
                                #snip:
                                    curl -X GET "http://localhost:9200/_cat/indices?v&pretty"
                    検索, フィールド指定あり:  #search: ElasticSearch query --data-binary
                    ソートして一覧します: |
                        curl -X GET http://localhost:9200/__IndexName__/_search?pretty -H "Content-Type:application/json" -d `{  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        {
                            "query": {
                                "match_all": { }
                            },
                            "sort": [
                                {
                                    "@timestamp": "desc"
                                }
                            ]
                        }`
                    GET メソッドでも body を送れます:
                        https://www.elastic.co/guide/en/elasticsearch/guide/current/_empty_search.html#get_vs_post
                        ただし、PowerShell などツールによっては送る前にエラーになります。 #search: ElasticSearch PowerShell query
                    サンプル HTTP レスポンス: |  #// hits/hits[____]._source に見つかったドキュメントがあります
                        {
                            "took": 2,
                            "timed_out": false,
                            "_shards": {
                                "total": 1,
                                "successful": 1,
                                "skipped": 0,
                                "failed": 0
                            },
                            "hits": {
                                "total": {
                                    "value": 3,
                                    "relation": "eq"
                                },
                                "max_score": null,
                                "hits": [
                                    {
                                        "_index": ".ds-logs-my_app-default-2099-05-06-000001",
                                        "_type": "_doc",
                                        "_id": "PdjWongB9KPnaVm2IyaL",
                                        "_score": null,
                                        "_source": {
                                            "@timestamp": "2099-05-06T16:21:15.000Z",
                                            "event": {
                                                "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
                                            }
                                        },
                                        "sort": [
                                            4081940742000
                                        ]
                                    },
                                    ...
                                ]
                            }
                        }
                    #search: ElasticSearch search
                完全一致 >> match:  #serach: ElasticSearch match
                部分一致 >> regexp:  #serach: ElasticSearch regexp
                集約, aggs:  #keyword: ElasticSearch aggs,  ElasticSearch Aggregations
                    公式:
                        日本語: #ref: https://www.elastic.co/guide/jp/elasticsearch/reference/current/gs-executing-aggregations.html
                        英語: #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html
                    サンプル:
                        基本: #keyword: ElasticSearch aggs first example
                            JSON: 
                                {
                                    "size": 0,
                                    "aggs": {
                                        "group_by_state": {
                                            "terms": {
                                                "field": "state.keyword"
                                }}}}
                            JSON の説明:
                                size: 検索にヒットしたドキュメントの内容を表示する数。数だけカウントするときは 0 を指定します
                                aggs: 集約関数
                                group_by_state: 出力フィールド名
                                terms: field に指定したカラムの値が一致することをグループの条件にします
                                field: グループ化する条件に使われるカラム名。 ".keyword" が必要かは不明
                        ネストする: #keyword: ElasticSearch aggs example nest
                            JSON:  #focus: aggs,  avg,  average_balance
                                {
                                    "size": 0,
                                    "aggs": {
                                        "group_by_state": {
                                            "terms": {
                                                "field": "state.keyword",
                                                "order": {
                                                    "average_balance": "desc"
                                                }
                                            },
                                            "aggs": {
                                                "average_balance": {
                                                    "avg": {
                                                        "field": "balance"
                                            }}}
                                }}}
                            JSON の説明:
                                average_balance: 出力フィールド名
                                aggs >> __Name__ >> aggs:
                                    集約関数の計算結果をカラムに追加します（未確認）。
                                    追加したカラムをソートするキーに指定することもできます。
                                avg: 平均値
                                order: ソート条件
                    フィールド:  #// 条件式の項目
                        aggs: 集約関数  #search: ElasticSearch aggs first example
                        aggs >> __FieldName__: aggs の直下のフィールド名は、出力に追加するフィールド名です。
                            aggs >> __FieldName__ の子要素全体を表す任意の名前です。
                            ソートなどに使うフィールドを指定するときに参照されます。
                            #search: ElasticSearch aggs example nest
                        size: 検索にヒットしたドキュメントの内容を表示する数。数だけカウントするときは 0 を指定します  #search: ElasticSearch aggs first example
                        terms: field に指定したカラムの値が一致することをグループの条件にします  #search: ElasticSearch aggs first example
                        avg: 平均値   #search: ElasticSearch aggs example nest
                        field: グループの条件とするカラム名  #search: ElasticSearch aggs first example
            追加:  #keyword: ElasticSearch add document
                １つ >> _doc:
                    Git bash を使う場合: #keyword: ElasticSearch bash add
                        基本(POST):  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/getting-started-index.html
                            (Git bash): |
                                curl -X POST  "http://localhost:9200/logs-my_app-default/_doc?pretty" -H 'Content-Type:application/json' -d'{
                                    "name": "John Doe"
                                }'
                                #// "result" : "created" と表示されれば成功です
                                curl -X GET  "http://localhost:9200/logs-my_app-default/_doc/1?pretty"
                            #//
                                #template-at(-6): http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__
                                #template-at(-3): http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__
                        公式の基本(PUT): #keyword: ElasticSearch update document  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/getting-started-index.html
                            (Git bash): |
                                curl -X PUT  "http://localhost:9200/logs-my_app-default/_doc/1?pretty" -H 'Content-Type:application/json' -d'{
                                    "name": "John Doe"
                                }'
                                curl -X GET  "http://localhost:9200/logs-my_app-default/_doc/1?pretty"
                            #//
                                #template-at(-5): http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__
                                #template-at(-3): http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__
                        追加するデータをコマンドに指定する場合: |
                            curl -X POST "http://node1:9200/logs-my_app-default/_doc?pretty"  -H "Content-Type:application/json" -d '{
                                "@timestamp": "2099-05-06T16:21:15.000Z",
                                "event": {
                                    "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
                                }
                            }'
                        追加するデータがファイルにある場合:  #focus: _tmp_parameter.json  #search: ElasticSearch _bulk example_1
                            code ./_tmp_parameter.json : |  #// ファイルが必要です  #search: shell JSON Invalid UTF-8
                                {"pref_id": "13", "city_id": "13105", "name": "弥生美術館","location": [139.7346787, 35.7096118]}
                            bash: |
                                curl -X POST "http://localhost:9200/logs-my_app-default/_doc"  -H "Content-Type:application/json" --data-binary @_tmp_parameter.json
                        他のサンプル:
                            #search: ElasticSearch bash add step
                    PowerShell を使う場合:  #search: ElasticSearch PowerShell add
                    サンプル HTTP リクエスト: |
                        #// インデックス logs-my_app-default の中に追加します
                        POST logs-my_app-default/_doc
                        {
                            "@timestamp": "2099-05-06T16:21:15.000Z",
                            "event": {
                                "original": "192.0.2.42 - - [06/May/2099:16:21:15 +0000] \"GET /images/bg.jpg HTTP/1.0\" 200 24736"
                            }
                        }
                複数 >> _bulk:  #search: ElasticSearch _bulk
                    基本: #keyword: ElasticSearch _bulk example_1
                        コマンド: | #// 以下のいずれか
                            curl -X POST "http://localhost:9200/_bulk?pretty"  -H "Content-Type:application/json" --data-binary @example_document.json
                            curl -X POST "http://localhost:9200/__DummyIndex__/_bulk?pretty"  -H "Content-Type:application/json" --data-binary @example_document.json
                                #template-at(-2): http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                #template-at(-2): http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        example_document.json: |
                            {"index": {"_index": "logs-my_app-default", "_type": "_doc"} }
                            {"__field__" : "__value__"}
                        #//
                            #template-at(-3): __ElasticS_Index__
                        補足:
                            __DummyIndex__ は無視され、インデックス logs-my_app-default に追加されます。
                            インデックスが無くでも追加できます。
                        ドキュメント一覧:
                            curl -X GET  "http://localhost:9200/logs-my_app-default/_search?pretty"
                                #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__/
                        インデックスとドキュメントを全削除:
                            curl -X DELETE "http://localhost:9200/logs-my_app-default?pretty"
                                #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/__ElasticS_Index__?
                    応用:
                        コマンド: |
                            curl -X POST "http://localhost:9200/_bulk?pretty"  -H "Content-Type:application/json" --data-binary @example_document.json
                                #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        example_document.json: |
                            {"index": {"_index": "logs-my_app-default", "_type": "_doc"} }
                            {"__field__" : "__value1__"}
                            {"index": {"_index": "logs-my_app-default", "_type": "_doc"} }
                            {"__field__" : "__value2__"}
                            {"index": {"_index": "logs-my_app-default", "_type": "_doc"} }
                            {"__field__" : "__value3__"}
                        #//
                            #template-at(-7): __ElasticS_Index__
                            #template-at(-6): __ElasticS_Index__
                            #template-at(-5): __ElasticS_Index__
            削除:
                削除するドキュメントの ID を確認します: |  #search: ElasticSearch document search query
                    curl -X GET http://localhost:9200/__IndexName__/_search?pretty  #// id または _id を __ID__ とします
                #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                ドキュメントを削除します:
                    bash: |
                        curl -X DELETE http://localhost:9200/__IndexName__/_doc/__ID__
                    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    成功したときの表示の一部: |
                        "result":"deleted"
                全てのドキュメントを削除します:
                    コマンド: |
                        curl -X POST "http://node1:9200/__IndexName__/_delete_by_query?conflicts=proceed&pretty" -H 'Content-Type:application/json' -d'{
                            "query": { "match_all": {} } }'
                    #// "deleted" : __Number__ が表示されたら成功です
                    参考: #ref: https://stackoverflow.com/questions/23917327/delete-all-documents-from-index-type-without-deleting-type
            mapping: #keyword: ElasticSearch mapping  #// 型情報
                コマンド: curl -X GET  "http://localhost:9200/logs-my_app-default/_mapping?pretty"
                出力: |  #focus: type
                    {
                    "__IndexName__": {
                        "mappings": {
                            "properties": {
                                "__FieldName__": {
                                    "type": "____"
            インデックス テンプレート:  #search: ElasticSearch index templates
            参考: #// Elasticsearchの基本操作（メモ）  https://qiita.com/mkyz08/items/74d6963096c060d590f7
        アナライザー:  #keyword: ElasticSearch analizer
            参考: #// Elasticsearch　Analyze APIでkuromoji形態素解析を試す  https://qiita.com/tsgkdt/items/8f6f172b1f53bd608e0a
            英文のサンプル:  #// 標準アナライザーを使って "this is a test" という文を解析します
                コマンド: |
                    curl -X GET 'http://localhost:9200/_analyze?pretty'   -H 'Content-Type:application/json' -d '    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    {
                        "analyzer" : "standard",
                        "text" : "this is a test"
                    }'
                出力例: |
                    {
                    "tokens" : [
                        {
                        "token" : "this",
                        "start_offset" : 0,
                        "end_offset" : 4,
                        "type" : "<ALPHANUM>",
                        "position" : 0
                        },
                        {
                        "token" : "is",
                        "start_offset" : 5,
                        "end_offset" : 7,
                        "type" : "<ALPHANUM>",
                        "position" : 1
                        },
                        {
                        "token" : "a",
                        "start_offset" : 8,
                        "end_offset" : 9,
                        "type" : "<ALPHANUM>",
                        "position" : 2
                        },
                        {
                        "token" : "test",
                        "start_offset" : 10,
                        "end_offset" : 14,
                        "type" : "<ALPHANUM>",
                        "position" : 3
                        }
                    ]
                    }
            日本語のサンプル:  #// kuromoji トークナイザーを使って "関西国際空港" という文を解析します
                code ./_tmp_parameter.json : |
                    {
                        "tokenizer" : "kuromoji_tokenizer",
                        "text" : "関西国際空港"
                    }
                コマンド: |
                    curl -X GET 'http://localhost:9200/_analyze?pretty' -H 'Content-Type:application/json' --data-binary @_tmp_parameter.json    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                出力例: |
                    {
                    "tokens" : [
                        {
                        "token" : "関西",
                        "start_offset" : 0,
                        "end_offset" : 2,
                        "type" : "word",
                        "position" : 0
                        },
                        {
                        "token" : "関西国際空港",
                        "start_offset" : 0,
                        "end_offset" : 6,
                        "type" : "word",
                        "position" : 0,
                        "positionLength" : 3
                        },
                        {
                        "token" : "国際",
                        "start_offset" : 2,
                        "end_offset" : 4,
                        "type" : "word",
                        "position" : 1
                        },
                        {
                        "token" : "空港",
                        "start_offset" : 4,
                        "end_offset" : 6,
                        "type" : "word",
                        "position" : 2
                        }
                    ]
                    }
        Kibana: #keyword:  #// ElasticSearch の可視化、データ分析  https://www.elastic.co/jp/kibana/
            #// ElasticSearch と連携するデータ解析・可視化プラットフォーム。
        X-pack: #keyword: ElasticSearch X-pack
            elasticsearch.yml の xpack.security.enabled など
            #ref: https://dev.classmethod.jp/articles/elastic-stack-x-pack-install/
        Logstash: #keyword:  #// Elastic 社製のデータ転送パイプライン
            構成: データ ==> Logstash (filter) ==> ElasticSearch
                #ref: https://qiita.com/nskydiving/items/0cb598de7ffb5c22424d#logstash-とは
            インストール:
                tar -xzf logstash-7.1.0.tar.gz  #ref: https://qiita.com/nskydiving/items/0cb598de7ffb5c22424d#インストール
        テンプレート:  #glossary: ElasticSearch  #keyword: ElasticSearch Templates
            #// サンプル:  #ref: ${typrm_files}/Cloud_plus.yaml#ElasticSearch Templates Exammple johtani
            Index Templates:  #// https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-templates.html
                version 2: #keyword: ElasticSearch index templates  #// Composable Index Templates
                    構成の概要:  #search: ElasticSearch index mapping abstract
                    概要:
                        インデックスを作ろうとしたときに適用されるテンプレート: 
                            Elastic Agentはこれらのテンプレートを使用してデータストリームを作成します。
                            すでにデータベースに入っているインデックスに対しては適用されません。
                            ドキュメント入れなおすか、reindex すると新しく適用されます。
                        Index Template を CRUD する API があります:
                        Component Template を0個以上持ちます:
                        インデックス: #search: ElasticSearch index
                    注意:
                        全フィールド インデックス: #keyword: ElasticSearch all field index
                            ElasticSearch で全てのフィールドにインデックスを付けることはディスクの容量を圧迫しパフォーマンスも悪くなります。
                            #ref: ${typrm_files}/ref/Database-AI.yaml#label: ElasticSearch all field index from AI
                    手順: #keyword: ElasticSearch example  #// https://qiita.com/mkyz08/items/74d6963096c060d590f7#インデックステンプレートの操作
                        インデックス テンプレート を登録します:  #// インデックスでも mapping は使える？
                            bash: |  #// "index_patterns": "index-*" のように * があると、マッチするすべてのインデックスが対象になります
                                curl -X PUT http://localhost:9200/_template/__TemplateName__ -H "Content-Type:application/json" -d '    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                {
                                    "index_patterns": "index_a",
                                    "settings": {
                                        "number_of_shards": 1
                                    },
                                    "mappings" : {
                                        "properties" : {
                                            "text_field" : {
                                                "type" : "text"
                                            },
                                            "key_field" : {
                                                "type" : "keyword"
                                            },
                                            "id" : {
                                                "type" : "long"
                                            }
                                        }
                                    }
                                }'
                            成功したときの表示: |
                                {"acknowledged":true}
                        インデックス テンプレート を一覧します:
                            bash:
                                curl -X GET http://localhost:9200/_cat/templates    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        インデックス テンプレート の内容を確認します:
                            bash:
                                curl -X GET http://localhost:9200/_template/__TemplateName__?pretty    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        ドキュメントを登録します:
                            bash: |  #// インデックス名は、インデックス テンプレート の index_patterns にマッチするように指定してください
                                curl -X POST http://localhost:9200/index_a/_doc/?pretty -H "Content-Type:application/json" -d '{    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                    "id": 1,
                                    "key_field" : "key_1",
                                    "text_field": "text_1"
                                }'
                            成功したときの表示の一部: |
                                "result" : "created"
                        インデックスの内容を表示します:
                            目的: インデックス テンプレート にマッチしたドキュメントを追加したことで、
                                インデックスの内容が作られたことを確認します。
                            mapping: |
                                curl -X GET http://localhost:9200/index_a/_mapping?pretty
                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                            setting: |
                                curl -X GET http://localhost:9200/index_a/_settings?pretty
                            #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        インデックス テンプレート を削除します: |
                            curl -X DELETE http://localhost:9200/_template/__TemplateName__
                        #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                    インデックス テンプレート:
                        基本操作:  #search: ElasticSearch index templates command
                        3ノード構成にするサンプル:  #// https://blog.johtani.info/blog/2020/12/17/index_template_v2/
                            説明: 対象のドキュメントを 3 つのシャードに分けて保存します
                            コード: |  #keyword: ElasticSearch  index_patterns
                                PUT _template/blog_num_shards
                                {
                                    "index_patterns": "blog_*",
                                    "settings": {
                                        "number_of_shards": 3
                                        "number_of_replicas": 1,
                                        "refresh_interval": "5s"
                                }}}
                            refresh_interval: #keyword: ElasticSearch  refresh_interval
                                概要: refresh 処理を開始する時間の間隔。デフォルト値は 1秒。1秒は十分すぎるほど早いです。
                                refresh 処理: #keyword: ElasticSearch  refresh
                                    メモリーにあるキャッシュの内容を更新します。
                                    インデックスの更新間隔でもあります。
                                    （おそらく、データを追加更新してから反映されるまでの最大時間）
                                    小さすぎると CPU の負荷が高くなります。
                        プロパティ: #keyword: ElasticSearch  properties
                            概要: プロパティを設定することで型をヒントに検索を高速化できるようになります。
                                プロパティに設定されていないフィールドでも ElasticSearch に保存されます。
                            コード: |
                                {
                                    "index_patterns": [
                                    ...
                                    "mappings": {
                                        "properties": {
                                            "timestamp": {
                                                "type": "date",
                                                "format": "yyyy-MM-dd HH:mm:ss"
                                            },
                                            "level": {
                                                "type": "keyword"
                                            },
                                            "message": {
                                                "type": "text"
                                            }
                        公式のサンプル: |
                            PUT _index_template/template_1
                            {
                                "index_patterns": ["te*", "bar*"],
                                "template": {
                                    "settings": {
                                        "number_of_shards": 1
                                    },
                                    "mappings": {
                                        "_source": {
                                            "enabled": true
                                        },
                                        "properties": {
                                            "host_name": {
                                                "type": "keyword"
                                            },
                                            "created_at": {
                                                "type": "date",
                                                "format": "EEE MMM dd HH:mm:ss Z yyyy"
                                            }
                                        }
                                    },
                                    "aliases": {
                                        "mydata": { }
                                    }
                                },
                                "priority": 500,
                                "composed_of": ["component_template1", "runtime_component_template"], 
                                "version": 3,
                                "_meta": {
                                    "description": "my custom"
                                }
                            }
                        フィールド:
                            index_patterns: index_patterns にマッチしたインデックスを作ろうとしたときに、このテンプレートが適用されます
                        主キー:  #keyword: ElasticSearch primary key,  ElasticSearch 主キー
                            Elasticsearch にはユーザーが選べる主キーは存在しません。
                            主キーは内部的な _id です。
                        マッピングの変更: #search: change ElasticSearch mapping
                        動的マッピング: #keyword: ElasticSearch dynamic mapping  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-mapping.html
                            新しいフィールドの自動検出と追加
                        動的フィールド マッピング:  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html
                        全フィールド インデックス:  #search: ElasticSearch all field index
                        インデックスを作らない設定:  #// 未確認
                            サンプル: |
                                "properties": {
                                    "name": {
                                        "type": "text",
                                        "index": false
                            #ref: https://discuss.elastic.co/t/mapping-properties-index-false/134706
                            #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-index.html
                            #ref: ${typrm_files}/ref/Database-AI.yaml#label: ElasticSearch all field index from AI
                        新しいフィールドが動的に追加されることを防ぐ設定:  #// 未確認
                            _: マッピングに存在しない新しいフィールドが追加された場合にエラーが発生します。以下のような設定になります。
                            サンプル: |
                                "mappings": {
                                    "dynamic": "strict",
                                        "properties": {
                            #ref: ${typrm_files}/ref/Database-AI.yaml#label: ElasticSearch all field index from AI
                    コマンド: #keyword: ElasticSearch index templates command
                        設定: #keyword: create ElasticSearch index template
                            curl -X PUT http://localhost:9200/_template/__TemplateName__ -H "Content-Type:application/json" -d ____
                            #search: ElasticSearch example
                        一覧: #keyword: list ElasticSearch index template
                            名前などメタ情報のみ:
                                コマンド:
                                    curl -X GET http://localhost:9200/_cat/templates    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                                出力例:
                                    eventlog           [eventlog-*]           0 
                                    monitoring_logging [monitoring-logging-*] 0 
                            内容も含む:
                                curl -X GET http://localhost:9200/_template?pretty    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        参照: #keyword: read ElasticSearch index template
                            curl -X GET http://localhost:9200/_template/__TemplateName__?pretty    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                        削除: | #keyword: delete ElasticSearch index template
                            curl -X DELETE http://localhost:9200/_template/__TemplateName__    #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
                version 1:  #// legacy index template  #// 非推奨  #// https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices-templates-v1.html
                    ❗ Index Template は非推奨になりました。代わりは Composable Index Templates です。
                参考: Index Template V2  https://blog.johtani.info/blog/2020/12/17/index_template_v2/
            Component Template: #keyword: ElasticSearch component templates  #ref: https://www.elastic.co/guide/en/elasticsearch/reference/7.13/indices-component-template.html
                公式:
                    PUT _component_template API:  https://www.elastic.co/guide/en/elasticsearch/reference/7.10/indices-component-template.html
                概要:
                    Index Templates (version 2) の一部をコンポーネントとしたものです:
                    Component Template を CRUD する API があります:
                Index Templates と Component Template の関係:
                    Index Templates: |
                        PUT _template/jp_simple_kuromoji
                        {
                        "index_patterns": "jp_",
                            "settings": {           #// ここの中の仕様は Component Template と共通
                    Component Template: |
                        PUT _component_template/jp_simple_kuromoji
                        {
                        "template": {
                            "settings": {           #// ここの中の仕様は Index Templates と共通
                    参考: https://blog.johtani.info/blog/2020/12/17/index_template_v2/ >> Coponent Template API
                サンプル: |
                    PUT _component_template/component_template1
                    {
                        "template": {
                            "mappings": {
                                "properties": {
                                    "@timestamp": {
                                        "type": "date"
                                    }
                                }
                            }
                        }
                    }

                    PUT _component_template/runtime_component_template
                    {
                        "template": {
                            "mappings": {
                                "runtime": { 
                                    "day_of_week": {
                                        "type": "keyword",
                                        "script": {
                                            "source": "emit(doc['@timestamp'].value.dayOfWeekEnum.getDisplayName(TextStyle.FULL, Locale.ROOT))"
                                        }
                                    }
                                }
                            }
                        }
                    }
            Mapping Template:  #keyword: ElasticSearch mapping template
                参考: https://qiita.com/harukasan/items/4ec517d8d96f557367e1#mapping-templateを使う
                サンプル:
                    すでにドキュメントがあるとき:  #// インデックスを追加・変更できません
                        curl -X DELETE "http://node1:9200/map_1?pretty"
                    マッピング テンプレート を追加します:
                        コマンド: |
                            curl -X PUT "http://node1:9200/map_1?pretty"  -H "Content-Type:application/json" -d'{
                                "mappings": {
                                    "map_1": {
                                        "properties": {
                                            "id" : {
                                                "type" : "long"
                                            }
                                        }
                                    }
                                }
                            }'
                        template から始まるものとは違うようです。下記はエラーになります:
                            コマンド: |
                                curl -X PUT "http://node1:9200/map_1?pretty"  -H "Content-Type:application/json" -d'{
                                    "template": {
                                        "mappings": {
                                            "properties": {
                                                "id" : {
                                                    "type" : "long"
                                                }
                                            }
                                        }
                                    }
                                }'
                            エラー: |
                                "type" : "illegal_argument_exception",
                                "reason" : "unknown setting [index.template.mappings.properties.id.type] please check that any required plugins are installed, or check the breaking changes documentation for removed settings"
                マッピング テンプレート（など）を表示します:
                    curl -X GET "http://node1:9200/map_1?pretty"
                未確認サンプル: |
                    {
                        "template": "*",
                        "mappings": {
                            "_default_": {
                                "_source": { "compress": true },
                                "properties" : {
                                    "request_uri" : { "type" : "string", "index" : "not_analyzed" }
                                }
                            }
                        }
                    }
    ログ: #keyword: ElasticSearch log
        journalctl:
            sudo journalctl -u elasticsearch
                #template: sudo journalctl -u __ElasticS_ServiceName__
        __ClusterName__.log:  #ref: /var/log/elasticsearch/__ClusterName__.log  #// __ClusterName__ は elasticsearch.yml の cluster.name
        path.logs 変数:
            logs のパスを調べます:
                コマンド: |
                    sudo cat /etc/elasticsearch/elasticsearch.yml | grep "\(path.logs:\)\|\(cluster.name:\)"
                        #template: sudo cat __ElasticS_SettingFile__
                出力例:
                    path.logs: /var/log/elasticsearch  #template: path.logs: __ElasticS_LogsFolder__
                    cluster.name: my-elasticsearch-cluster  #template: cluster.name: __ElasticS_ClusterName__
                ファイルを一覧します:
                    sudo ls /var/log/elasticsearch  #template: sudo ls __ElasticS_LogsFolder__
            ログを表示します:
                gc.log.0.current:  #// 容量
                    コマンド:
                        - logfo="/var/log/elasticsearch"     #template: __ElasticS_LogsFolder__
                        - sudo tail $logfo/gc.log.0.current
                    ログのサンプル: |
                        2022-01-13T04:02:10.478+0000: 29.835: Total time for which application threads were stopped: 0.0000194 seconds, Stopping threads took: 0.0000085 seconds
                        2022-01-13T04:02:10.478+0000: 29.835: Total time for which application threads were stopped: 0.0000161 seconds, Stopping threads took: 0.0000073 seconds
                        Heap
                        par new generation   total 76672K, used 32867K [0x00000000c0000000, 0x00000000c5330000, 0x00000000c5330000)
                        eden space 68160K,  35% used [0x00000000c0000000, 0x00000000c17c8dd8, 0x00000000c4290000)
                        from space 8512K, 100% used [0x00000000c4ae0000, 0x00000000c5330000, 0x00000000c5330000)
                        to   space 8512K,   0% used [0x00000000c4290000, 0x00000000c4290000, 0x00000000c4ae0000)
                        concurrent mark-sweep generation total 963392K, used 140K [0x00000000c5330000, 0x0000000100000000, 0x0000000100000000)
                        Metaspace       used 17104K, capacity 17604K, committed 17792K, reserved 1064960K
                        class space    used 1994K, capacity 2154K, committed 2176K, reserved 1048576K
                その他:
                    - logfo="/var/log/elasticsearch"
                    - cluster="my-elasticsearch-cluster"   #template: __ElasticS_ClusterName__
                    - sudo tail $logfo/${cluster}.log           
                    - sudo tail $logfo/${cluster}_access.log
                    - sudo tail $logfo/${cluster}_audit.log
                    - sudo tail $logfo/${cluster}_deprecation.log
                    - sudo tail $logfo/${cluster}_index_indexing_slowlog.log
                    - sudo tail $logfo/${cluster}_index_search_slowlog.log
        Kibana:  #search: Kibana
    ファイル:
        elasticsearch.yml:
            実験用サンプル: |
                # vi /etc/elasticsearch/elasticsearch.yml
                ### add following line
                xpack.security.enabled: false
            項目: #keyword: Elasticsearch settings  #glossary:
                設定一覧, デフォルト値一覧: #keyword: ElasticSearch default /_cluster/settings
                    curl -X GET "http://localhost:9200/_cluster/settings?include_defaults=true&pretty"
                discovery:  #// クラスター構成
                    discovery.zen.minimum_master_nodes:
                        (__CountOfMasterEligibleNodes__ / 2) + 1
                        #search: ElasticSearch master eligible node
                disk: #keyword: Elasticsearch disk settings  #// ディスクの使用量の閾値
                    公式:
                        #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/disk-allocator.html
                        #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html#disk-based-shard-allocation
                    設定手順:  #// 下記設定値はデフォルト値です  #search: ElasticSearch default /_cluster/settings
                        curl の場合: |
                            curl -X PUT "localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
                            {
                                "persistent": {
                                    "cluster.routing.allocation.disk.threshold_enabled": true,
                                    "cluster.routing.allocation.disk.watermark.low": "85%",
                                    "cluster.routing.allocation.disk.watermark.high": "90%",
                                    "cluster.routing.allocation.disk.watermark.flood_stage": "95%"
                                }
                            }'
                        elasticsearch.yml の場合: |
                            cluster.routing.allocation.disk.threshold_enabled: true
                            ...
                    .threshold_enabled:
                        - true なら、ディスクの使用量が閾値が超えたときの動作設定 low, high, flood_stage を有効にします（他にもあるかもしれません）
                        - false なら、ノードに割り当てを制限せず、シャードの移動も行われません（非推奨）
                    .low:
                        - プライマリ シャード 以外の新しいシャードをノードに割り当てなくなります
                        - 閾値のパーセントの値は df コマンドで表示されるディスク使用量と比較されます
                    .high:
                        - 閾値を下回るまで既存のシャードを他のノードに移動します
                    .flood_stage:
                        - 読み取り専用になります。どのシャードも新しく割り当てられません
                    .disk_usage:  #// Elasticsearch 6.8 では使えません
                        - ディスク使用率の重み付け
                balance: #keyword: Elasticsearch balance settings  #// シャード割り当ての重みづけ
                    公式:
                        #ref: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/shards-allocation.html#_shard_balancing_heuristics
                        #ref: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-cluster.html#shards-rebalancing-heuristics
                    設定手順:  #// 下記設定値はデフォルト値です  #search: ElasticSearch default /_cluster/settings
                        curl の場合: |
                            curl -X PUT "localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d'
                            {
                                "persistent": {
                                    "cluster.routing.allocation.balance.shard": "0.45",
                                    "cluster.routing.allocation.balance.index": "0.55",
                                    "cluster.routing.allocation.balance.threshold": "1.0"
                                }
                            }'
                        elasticsearch.yml の場合: |
                            cluster.routing.allocation.balance.shard: 0.2
                            ...
                    .shard:  #// シャード数の均等さの重み
                    .index:  #// インデックスごとのシャードの均等分散の重み
                    .threshold:  #// リバランスの閾値
                        1.0: わずかな不均衡でもリバランスを検討
                        2.0: かなりの不均衡が発生するまでリバランスを行わない
            移植: #keyword: elasticsearch.yml porting  #glossary: ElasticSearch
                discovery.zen.ping.unicast.hosts: → discovery.seed_hosts, cluster.initial_master_nodes
                discovery.zen.minimum_master_nodes: → なし？
                関連 >> バージョンアップします:  #search: ElasticSearch upgrade
        jvm.options:
        log4j2.properties:
    コード:  #// curl, Python, Go
        REST API:  #// コマンドのテンプレートなど  #keyword: ElasticSearch command
            公式: https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html
            サンプル: curl -X GET http://localhost:9200/_cat/nodes?v=true
            使い方:
                テンプレート for bash:  #// __HTTP_Method__ と __Path__ と __Part_of_JSON__ を置き換えます。入力の最後は(}')です
                    #keyword: ElasticSearch cURL template
                    JSON を指定しない場合:
                        基本: |
                            curl -X  __HTTP_Method__  http://localhost:9200/__Path__
                        JSON の出力を整形する場合: |
                            curl -X  __HTTP_Method__  http://localhost:9200/__Path__?pretty
                        表の出力にヘッダーを付ける場合: |
                            curl -X  __HTTP_Method__  http://localhost:9200/__Path__?v
                    JSON が Ascii 文字だけの場合: |
                        curl -X  __HTTP_Method__  http://localhost:9200/__Path__  -H "Content-Type:application/json" -d '{
                            __Part_of_JSON__
                        }'
                    JSON に Ascii 文字以外も含む場合:  #keyword: cURL Unicode JSON (UTF-8)
                        code ./_tmp_parameter.json : |
                            {
                                __Part_of_JSON__
                            }
                        bash: |
                            curl -X  __HTTP_Method__  http://localhost:9200/__Path__  -H "Content-Type:application/json" --data-binary @_tmp_parameter.json
                略式で書かれたサンプルと実際に入力するコマンド:
                    略式で書かれたサンプルのサンプル: |
                        GET museum/_search
                        {
                            "query": {
                                "match_all": { }
                            }
                        }
                    上記サンプルで実際に入力するコマンド for bash: |  #// 上記 テンプレート for bash を使います
                        curl -X  GET  http://localhost:9200/museum/_search  -H "Content-Type:application/json" -d '{
                            "query": {
                                "match_all": { }
                            }
                        }'
            サーバーに関する API:  #search: ElasticSearch nodes
            インデックスに関する API:  #search: ElasticSearch index
            ドキュメントに関する API:  #search: ElasticSearch document
        for Python: #keyword: ElasticSearch for Python
            公式: https://github.com/elastic/elasticsearch-py
                https://elasticsearch-py.readthedocs.io/
            参考:
                - https://qiita.com/satto_sann/items/8a63761bbfd6542bb9a2
                - https://blog.imind.jp/entry/2019/03/08/185935
            手順, インストール:
                インストール:
                    pip install elasticsearch
                追加:  #// ドキュメントを追加します。RDB 用語で言うとレコードの追加
                    ドキュメントの作成:  #// １つのドキュメントを追加します
                        参考: https://qiita.com/satto_sann/items/8a63761bbfd6542bb9a2#ドキュメントの作成
                        サンプル Python: |
                            from elasticsearch import Elasticsearch
                            student = {
                                "name": "Taro",
                                "age": 36,
                                "email": "taro@example.com"
                            }

                            es.create(index='students', id=1, body=student)
                    バルクインサート:  #// 複数のドキュメントを追加します
                        参考: https://qiita.com/satto_sann/items/8a63761bbfd6542bb9a2#バルクインサート
                        サンプル Python: |
                            from elasticsearch import Elasticsearch, helpers # bulkを使うために追加
                            es = Elasticsearch("http://localhost:9200")
                            def gendata():
                                students = [
                                    {
                                        "name": "Jiro",
                                        "age": 25,
                                        "email": "jiro@example.com"
                                    },
                                    {
                                        "name": "Saburo",
                                        "age": 20,
                                        "email": "saburo@example.com"
                                    }
                                ]

                                # bulkで扱えるデータ構造に変換します
                                for student in students:
                                    yield {
                                        "_op_type": "create",
                                        "_index": "students",
                                        "_source": student
                                    }

                            helpers.bulk(es, gendata())
                更新: |
                    student = {
                        "doc": {
                            "age": 40  #// age のみ更新
                        }
                    }

                    es.update(index="students", id=1, body=student)
                削除: |
                    es.delete(index="students", id=1)
                検索:
                    IDを指定してドキュメントを検索します:
                        参考: https://qiita.com/satto_sann/items/8a63761bbfd6542bb9a2#idを使って検索
                        サンプル Python: |
                            print(es.get_source(index="students", id=1))
                    条件に合うドキュメントを検索します:
                        参考: https://qiita.com/satto_sann/items/8a63761bbfd6542bb9a2#ドキュメントの検索
                        サンプル Python: |
                            # ageの値が20より大きいドキュメントを検索するためのクエリ
                            query = {
                                "query": {
                                    "range": {
                                        "age": {
                                            "gt": 20
                                        }
                                    }
                                }
                            }

                            result = es.search(index="students", body=query, size=3)
                            for document in result["hits"]["hits"]:
                                print(document["_source"])
                    ドキュメント数: |
                        print(es.count(index="students"))
                    存在の有無: |
                        es.exists(index="students", id=1)
                （言語共通）:  #search: ElasticSearch steps
            ElasticSearch DSL: #keyword: ElasticSearch DSL,  elasticsearch-dsl  #ref: https://elasticsearch-dsl.readthedocs.io/en/latest/#search-example
                概要: 文字列をメソッドなどに置き換えます
                適用前: |  #focus: key,  python,  max_lines
                    from elasticsearch import Elasticsearch
                    client = Elasticsearch()

                    response = client.search(
                        index="my-index",
                        body={
                            "query": {
                                "filtered": {
                                    "query": {
                                        "bool": {
                                            "must": [{"match": {"title": "python"}}],
                                            "must_not": [{"match": {"description": "beta"}}]
                                        }
                                    },
                                    "filter": {"term": {"category": "search"}}
                                }
                            },
                            "aggs" : {
                                "per_tag": {
                                    "terms": {"field": "tags"},
                                    "aggs": {
                                        "max_lines": {"max": {"field": "lines"}}
                                    }
                                }
                            }
                        }
                    )

                    for hit in response['hits']['hits']:
                        print(hit['_score'], hit['_source']['title'])

                    for tag in response['aggregations']['per_tag']['buckets']:
                        print(tag['key'], tag['max_lines']['value'])
                適用後: |  #keyword: elasticsearch_dsl
                    from elasticsearch import Elasticsearch
                    from elasticsearch_dsl import Search
                    client = Elasticsearch()

                    s = Search(using=client, index="my-index") \
                        .filter("term", category="search") \
                        .query("match", title="python")   \
                        .exclude("match", description="beta")

                    s.aggs.bucket('per_tag', 'terms', field='tags') \
                        .metric('max_lines', 'max', field='lines')

                    response = s.execute()

                    for hit in response:
                        print(hit.meta.score, hit.title)

                    for tag in response.aggregations.per_tag.buckets:
                        print(tag.key, tag.max_lines.value)
                集約:  #keyword: aggs elasticsearch_dsl  #search: ElasticSearch aggs
                    サンプル:  #// 検索結果を a.b.c の構成で表示します
                        search = Search()
                        search.aggs.bucket("a", Elastic.Aggs("terms", field="a", **size_settings))
                        search.aggs["a"].bucket("b", Elastic.Aggs("terms", field="b", **size_settings))
                        search.aggs["a"]["b"].bucket("c", Elastic.Aggs("terms", field="c", **size_settings))
                        print(f"search_dict={search.to_dict()}")
                        resp = search.execute()
                        print(resp.aggregations["a"].buckets[0]["b"].buckets[0]["c"].buckets[0].key)
                OR 条件:  #focus: python,  django
                    Q を使わない場合: |  #// 未確認
                        from elasticsearch_dsl import Search, Q
                        s = Search(index="your_index_name")
                        s = s.query("terms", {title="python", title="django"})
                    Q を使う場合: |  #// 未確認
                        from elasticsearch_dsl import Search, Q
                        s = Search(index="your_index_name")
                        q = Q("match", title="python") | Q("match", title="django")
                        s = s.query(q)
        for Go言語: #keyword: ElasticSearch for Go language
            サンプル:  #search: install ElasticSearch Go
            olivere 版: #keyword: ElasticSearch olivere  #// https://pkg.go.dev/github.com/olivere/elastic   #// ElasticSearch 7 まで
                ❗開発状況, 互換性:  #ref: ${typrm_files}/ref/Database-AI.yaml#label: ElasticSearch8 olivere
                    #ref: https://github.com/olivere/elastic?tab=readme-ov-file#releases
                手順, インストール:
                    インストール:  #search: install ElasticSearch Go
                    バージョン:
                        Elasticsearch version   Elastic version   Package URL
                        -----------------------------------------------------------------------
                        7.x                     7.0               github.com/olivere/elastic/v7
                        6.x                     6.0               github.com/olivere/elastic
                        #ref: https://github.com/olivere/elastic/blob/release-branch.v7/README.md#releases
                    Getting Started:  #ref: https://github.com/olivere/elastic#getting-started
                        complete working example for v6:  #ref: https://gist.github.com/olivere/e4a376b4783c0914e44ea4f745ce2ebf
                    検索: #keyword: ElasticSearch olivere Search
                        基本: |
                            client, err := elastic.NewClient()
                            searchResult, err := elasticSearch.Search().
                                Index("tweets-20230501").
                                Query(elastic.NewTermQuery("profile_name", "Common")).
                                Do(context.Background()) // execute
                            if err != nil {
                                panic(err)
                            }
                            fmt.Printf("Found %d logs\n", searchResult.TotalHits())
                        出力するフィールドを一部に絞る:  #search: FetchSourceContext
                        インデックスの検索: | #keyword: ElasticSearch CatIndices  #// olivere v6  #// ワイルドカードを使ってマッチするインデックスを一覧します
                            elasticSearch *elastic.Client
                            cat := elasticSearch.CatIndices()

                            cat.Index("log-a-*")
                            resp, err := cat.Do(context.Background())
                            if err != nil {
                                fmt.Println("Failed to get indices:", err)
                                return
                            }
                            esIndex := make([]string, len(resp))
                            for i, item := range resp {
                                esIndex[i] = item.Index
                            }
                        複数ワード:
                            注意: text type の ElasitcSearch は値を単語ごとに区切ってインデックスを作るため、区切り文字を含むフィールドは複数のワードを検索する必要があります
                                #search: ElasticSearch separator
                            AND 検索: #keyword: ElasticSearch olivere AND Search,  olivere Must
                                サンプル: |  #focus: Must  #search: ElasticSearch olivere Search
                                        Query(elastic.NewBoolQuery().Must(
                                            elastic.NewTermQuery("__Field1__", "__Value1__"),
                                            elastic.NewTermQuery("__Field2__", "__Value2__"),
                                        )).
                                text type サンプル: |  #search: ElasticSearch olivere Search
                                        Query(elastic.NewTermQuery("code", "c")).
                                        Query(elastic.NewTermQuery("code", "1234")).
                                    #// c-1234 にはヒットします。上記は text type の場合の AND 条件です  #search: ElasticSearch separator
                            OR 検索: #keyword: ElasticSearch olivere OR Search,  olivere Should
                                サンプル: |  #focus: Should  #search: ElasticSearch olivere Search
                                        Query(elastic.NewBoolQuery().Should(
                                            elastic.NewTermQuery("__Field1__", "__Value1__"),
                                            elastic.NewTermQuery("__Field2__", "__Value2__"),
                                        )).
                            複合検索: #keyword: olivere Should Must
                                サンプル: |  #// 1 | (2 & 3)  #focus: Should, Must  #search: ElasticSearch olivere Search
                                        Query(elastic.NewBoolQuery().Should(
                                            elastic.NewTermQuery("__Field1__", "__Value1__"),
                                            elastic.NewBoolQuery().Must(
                                                elastic.NewTermQuery("__Field2__", "__Value2__"),
                                                elastic.NewTermQuery("__Field3__", "__Value3__"),
                                            ),
                                        )).
                        範囲: |
                            now := time.Now().UTC()
                            checkStartTime := now.Add(-5 * time.Minute)
                            elastic.NewRangeQuery("timestamp").From(checkStartTime).To(now)
                        応用: |  #ref: https://gist.github.com/olivere/e4a376b4783c0914e44ea4f745ce2ebf
                            client, err := elastic.NewClient()
                            searchResult, err := elasticSearch.Search().
                                Index("tweets-20230501").
                                Query(elastic.NewTermQuery("profile_name", "Common")).  // #search: olivere Should Must
                                SortBy(elastic.NewFieldSort("date_time").Asc()). // sort by "date_time" field, ascending
                                From(0).Size(10).        // take documents 0-9
                                Pretty(true).            // pretty print request and response JSON
                                Do(context.Background()) // execute
                            if err != nil {
                                panic(err)
                            }
                            fmt.Printf("Query took %d milliseconds\n", searchResult.TookInMillis)

                            var doc DocumentType
                            for _, item := range searchResult.Each(reflect.TypeOf(doc)) {
                                if t, ok := item.(DocumentType); ok {
                                    fmt.Printf("Document %s: %s\n", t.ProfileName, t.DateTime)
                                }
                            }
                            fmt.Printf("Found %d logs\n", searchResult.TotalHits())
                            fmt.Printf("Done.\n")
                        ソート: #keyword: ElasticSearch olivere SortBy
                            書式:
                                - SortBy(elastic.NewFieldSort("date_time").Asc())
                                - SortBy(elastic.NewFieldSort("date_time").Desc())
                                - SortBy(elastic.NewFieldSort("owner").Asc(), elastic.NewFieldSort("date_time").Asc())
                                    #// owner でソート。ただし owner が同じなら date_time でソート
                                    #// 優先順位の順に指定します
                            サンプル:
                                searchResult, err := elasticSearch.Search().
                                    SortBy(elastic.NewFieldSort("date_time").Asc())
                        タイムスタンプ: #ref: ${typrm_files}/ref/Database-AI.yaml#label: ElasticSearch olivere search time stamp from AI
                    更新:
                        update: #ref: ${typrm_files}/ref/Database-AI.yaml#ElasticSearch olivere update from AI
                    （言語共通）:  #search: ElasticSearch steps
                コード, API:  #ref: https://github.com/olivere/elastic/wiki
                    FetchSourceContext: #keyword: FetchSourceContext,  ElasticSearch olivere select field  #// 出力するフィールドを一部に絞ります
                        効果: ネットワークとCPUの負荷を軽減できます
                        サンプル コード の一部: |  #ref: ${GitHub}/Trials/go/try_go/example/elastic_search/elastic_search_2_select.go#NewFetchSourceContext
                            fieldSelector := elastic.NewFetchSourceContext(true).Include("product_id", "count")
                            searchResult, err := elasticClient.Search("index-a").
                                FetchSourceContext(fieldSelector).
                    Search:  #search: ElasticSearch olivere Search  #ref: https://github.com/olivere/elastic/wiki/Search
                    Query:  #search: ElasticSearch olivere Search
                参考:
                    pkg.go.dev:  #ref: https://pkg.go.dev/github.com/olivere/elastic
                    GitHub: #ref: https://github.com/olivere/elastic
            Elastic 公式版:  #ref: https://github.com/elastic/go-elasticsearch
                参考: #// 公式のGo言語ElasticSearchクライアントについて  https://qiita.com/shiei_kawa/items/d992f7fdd4c75906ea0b
    パフォーマンス, 性能:
        考察:  #ref: ${typrm_files}/ref/Database-AI.yaml#label: ElasticSearch performance
        処理時間を計測します: #search: ElasticSearch load
    トラブルシューティング(ElasticSearch):
        - #// ERROR: Internal Server Error: /api/logs/waf0000000/stat
            手順: Python から Elasticsearch 検索をリクエスト
            ログ: |
                File "____/.venv/lib/python3.7/site-packages/urllib3/connection.py", line 180, in _new_conn
                    self, "Failed to establish a new connection: %s" % e)
                urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f303e340390>: Failed to establish a new connection: [Errno 111] Connection refused
                log.log_response ERROR: Internal Server Error: /api/logs/waf0000000/stat
            対処:
                Windows PC の再起動
            補足:
                wsl --shutdown では解決せず
        - #// セキュリティ関連の設定エラー  xpack.security.transport.ssl.keystore.secure_password,xpack.security.transport.ssl.truststore.secure_password
            手順: yum install などで ElasticSearch サービスを起動
            エラー: |
                less /var/log/elasticsearch/db_local-8.log
                    [2024-01-01T11:11:11,080][ERROR][o.e.b.Elasticsearch      ] [__NodeName__] fatal exception while booting Elasticsearch org.elasticsearch.ElasticsearchSecurityException: invalid configuration for xpack.security.transport.ssl - [xpack.security.transport.ssl.enabled] is not set, but the following settings have been configured in elasticsearch.yml : [xpack.security.transport.ssl.keystore.secure_password,xpack.security.transport.ssl.truststore.secure_password]
            対処:
                一旦セキュリティをオフにします:
                    elasticsearch.yml:
                        xpack.security.enabled: false
                        xpack.security.transport.ssl.enabled: false
                        xpack.security.http.ssl.enabled: false
                    再起動します:  #// 15秒程度で失敗することもあります
        - #// Unrecognized VM option 'UseConcMarkSweepGC'
            手順: yum install などで ElasticSearch サービスを起動
            エラー: |
                sudo journalctl -xe  -u  elasticsearch  |  cat
                    -- The start-up result is done.
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]: Aborting auto configuration because the node keystore contains password settings already
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]: Exception in thread "main" java.lang.RuntimeException: starting java failed with [1]
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]: output:
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]: error:
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]: Unrecognized VM option 'UseConcMarkSweepGC'
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]: Error: Could not create the Java Virtual Machine.
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]: Error: A fatal exception has occurred. Program will exit.
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]:         at org.elasticsearch.server.cli.JvmOption.flagsFinal(JvmOption.java:120)
                    Jan 1 11:11:11 __HostName__ elasticsearch[55082]:         at org.elasticsearch.server.cli.JvmOption.findFinalOptions(JvmOption.java:87)
            対処:  #ref: https://stackoverflow.com/questions/67259320/upgraded-eleastic-search-via-brew-now-wont-start-with-unrecognized-vm-option
                以下のようにコメントアウトします:
                    ## GC configuration
                    #-XX:+UseConcMarkSweepGC
                    #-XX:CMSInitiatingOccupancyFraction=75
                    #-XX:+UseCMSInitiatingOccupancyOnly
        - #// Exited (137)  #keyword: ElasticSearch Exited (137) EXIT(137)
            手順:
                docker-compose.yml: |
                    image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4
            原因:
                メモリー不足
            対処:
                WSL2 Linux 内のコンテナ―内の Elasticsearch の場合:
                    #search: Docker memory size
        - #// Exited (78)  #keyword: ElasticSearch Exited (78) EXIT(78)
            手順:
                docker-compose.yml: |
                    image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4
            原因:
                メモリー不足
            対処:
                sysctl -w vm.max_map_count=262144 など
                #search: vm.max_map_count
        - #// master_not_discovered_exception. クラスターを形成できない
            手順:
                -   curl -v -X GET http://__ElasticSearch__:9200/  #// 成功
                -   curl -v -X GET http://__ElasticSearch__:9200/_cat/nodes?v=true  #// タイムアウト
            エラー:
                curl のエラー出力: |
                    {"error":{"root_cause":[{"type":"master_not_discovered_exception","reason":null}],"type":"master_not_discovered_exception","reason":null},"status":503}
                elasticsearch.yml:
                    path.logs: /var/log/elasticsearch
                ログ:
                    /var/log/elasticsearch/__ClusterName__.log : |
                        [es1_9200] failed to connect to master [{es3_9200}
                        org.elasticsearch.transport.ConnectTransportException: [es3_9200][172.31.255.15:9300] handshake failed. unexpected remote node {es1_9200}
            対処:
                通信に使う接続元の NIC を指定します:  #keyword: ElasticSearch network.host
                    /local/etc/elasticsearch/elasticsearch.yml : |
                        #// network.host: ["_site_", "_local_"] 
                        network.host: 192.168.34.11     #// 接続元の NIC の IP アドレス
        - #// 起動失敗  elasticsearch.service: main process exited, code=exited, status=1/FAILURE
            手順: sudo systemctl start elasticsearch
            エラー: |
                localhost.localdomain systemd[1]: Started Elasticsearch.
                localhost.localdomain elasticsearch[27511]: OpenJDK 64-Bit Server VM warning: If the number of processors is ...ads=N
                localhost.localdomain systemd[1]: elasticsearch.service: main process exited, code=exited, status=1/FAILURE
                localhost.localdomain systemd[1]: Unit elasticsearch.service entered failed state.
                localhost.localdomain systemd[1]: elasticsearch.service failed.
            対処:
                Docker volume が共有されていた？
                #search: ElasticSearch log
        - #// format is too new. Are you trying to downgrade? You should delete and recreate it in order to downgrade.
            手順: Elasticsearch 起動
            エラー: |
                format is too new. Are you trying to downgrade? You should delete and recreate it in order to downgrade.
            対処:
                /usr/share/elasticsearch などを削除します（設定によって異なります） #search: ElasticSearch uninstall
            原因:
                Elasticsearch をダウングレードしたときに新しい Elasticsearch の内容がどこかに残っています
        - #// json_parse_exception  Unrecognized token
            手順: curl -X GET "http://localhost:9200/__Index__/_search?pretty" -H "Content-Type:application/json" --data-binary _tmp_parameter.json
            エラー: |
                {
                    "error" : {
                        "root_cause" : [
                            {
                                "type" : "json_parse_exception",
                                "reason" : "Unrecognized token '_tmp_parameter': was expecting ('true', 'false' or 'null')\n at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@7e1429dc; line: 1, column: 16]"
                            }
                        ],
                        "type" : "json_parse_exception",
                        "reason" : "Unrecognized token '_tmp_parameter': was expecting ('true', 'false' or 'null')\n at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@7e1429dc; line: 1, column: 16]"
                    },
                    "status" : 500
                }
            対処:
                --data-binary オプションの次に指定するパラメーターがファイル名の場合、先頭に @ を付けます。
                --data-binary @_tmp_parameter.json
        - #// Fielddata is disabled on text fields by default.
            手順: 検索時
            エラー: |
                'Fielddata is disabled on text fields by default. Set fielddata=true on [__FieldName__]
                    in order to load fielddata in memory by uninverting the inverted index. Note that this can however use
                    significant memory. Alternatively use a keyword field instead.'
                type=text の __FieldName__ フィールドは、デフォルトで fielddata は無効になっています。
                    理由は、転置インデックスを反転せずにフィールドデータをメモリにロードするためです。
                    ただし、これはかなりのメモリを使用する可能性があるため、キーワードフィールドを推奨します。
            対処:
                正しい インデックス テンプレート をインポートしてください。
                ドキュメントがすでに登録してあるときは、新しく作られるインデックスを使うか、reindex するか、登録しなおしてください。
            原因:
                検索内容に合っていないインデックスです。
            エラーになるサンプル: |  #focus: 256   #// keyword 256 は、インデックス テンプレート が設定されていないときに適用されるデフォルト設定です
                "__Field__" : {
                    "type" : "text",
                    "fields" : {
                        "keyword" : {
                            "type" : "keyword",
                            "ignore_above" : 256
            エラーにならないサンプル: |  #focus: 32766
                "__Field__" : {
                    "type" : "keyword",
                    "ignore_above" : 32766
        - #// status - red  #search: ElasticSearch status red
        - #// status - yellow  #search: ElasticSearch status yellow
        - #// Validation Failed: 1: type is missing;2: type is missing;3: type is missing
            手順: POST _bulk
            エラー: |
                "error" : {
                    "root_cause" : [{
                        "type" : "action_request_validation_exception",
                        "reason" : "Validation Failed: 1: type is missing;2: type is missing;3: type is missing;"
            対処:
                #search: ElasticSearch _bulk example_1
        - #// This might indicate that the store ___ is not shared between this node and the master node or that permissions on the store don't allow reading files written by the master node
            手順: バックアップします curl -X PUT "http://node1:9200/_snapshot/my_backup/snapshot_1?pretty&wait_for_completion=true"
            エラー: |
                [my_backup] [[F_3LtxXwSP-nHAtkHduQKw,
                    'RemoteTransportException[[node2][192.168.33.52:9300][internal:admin/repository/verify]]; nested: 
                RepositoryVerificationException[[my_backup] a file written by master to
                    the store [/var/log/elasticsearch/repository/my_backup] cannot be accessed
                    on the node [{node2}{F_3LtxXwSP-nHAtkHduQKw}{XGMZlAu3QEi_SDuRJogZew}{192.168.33.52}{192.168.33.52:9300}
                    {ml.machine_memory=510631936, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true}].
                This might indicate that the store [/var/log/elasticsearch/repository/my_backup] is not shared
                    between this node and the master node or that permissions on the store don't allow reading files written by the master node];'],
                [kUNO7NYGSyi41AEdZ7eNRA,
                    'RemoteTransportException[[node3][192.168.33.53:9300][internal:admin/repository/verify]]; nested: 
                RepositoryVerificationException[[my_backup] a file written by master to
                    the store [/var/log/elasticsearch/repository/my_backup] cannot be accessed
                    on the node [{node3}{kUNO7NYGSyi41AEdZ7eNRA}{xSYV4N7_Tl-UAIyq6jyzTQ}{192.168.33.53}{192.168.33.53:9300}
                    {ml.machine_memory=510631936, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true}].
                This might indicate that the store [/var/log/elasticsearch/repository/my_backup]
                    is not shared between this node and the master node or that permissions on the store don't allow reading files written by the master node];']]"}],
                snapshot  location  doesn't match any of the locations specified by path.repo because this setting is empty
            対処:
                - NFS で共有フォルダーを作ってください  #search: ElasticSearch back up
                - path.repo をすべてのノードに設定してください
        - #// java.nio.file.NoSuchFileException ____/modules/____/plugin-descriptor.properties
            手順: ElasticSearch サービスの起動
            エラー: |
                java.nio.file.NoSuchFileException: ____/elasticsearch/modules/ingest-geoip/plugin-descriptor.properties
            対処:
                modules の直下の空のフォルダーを削除します
        - #// no active connection found: no Elasticsearch node available
            手順: client, err := elastic.NewClient(elastic.SetURL("http://localhost:9200"))
            エラー: |
                no active connection found: no Elasticsearch node available
            対処:
                修正前: client, err := elastic.NewClient(elastic.SetURL("http://localhost:9200"))
                修正後: client, err := elastic.NewClient(elastic.SetURL("http://localhost:9200"), elastic.SetSniff(false))
        - #// missing required fields: [Type]
            手順: _, err = elasticClient.Index().Index("index-a").BodyJson(product).Do(context_)
            エラー: |
                missing required fields: [Type]
            対処:
                .Type("_doc") を追加します: |
                    _, err = elasticClient.Index().Index("index-a").Type("_doc").BodyJson(product).Do(context_) // For ElasticSearch v6 or earlier
            解説:
                Elasticsearchのバージョン7.x以降では、Type（以前のバージョンでは必須だったドキュメントの型）は非推奨となり、
                代わりに"_doc"を一般的に使用します。これは、インデックス内で複数のTypeを持つことが可能だった以前のバージョンとは異なり、
                バージョン7.x以降ではインデックスあたりTypeは1つだけに制限されています。
        - #// elastic: Error 400 (Bad Request): Failed to parse mapping [properties]
            手順: client.CreateIndex .BodyString(mapping)
            エラー: |
                elastic: Error 400 (Bad Request): Failed to parse mapping [properties]: Root mapping definition has unsupported parameters:  [price : {type=integer}] [product_id : {type=keyword}] [count : {type=integer}] [type=mapper_parsing_exception]
            対処:  #// type を追加します。 下記は "doc" type の場合です  #search: try_go ElasticSearch
                変更前: |  #// olivere elastic v7 用
                    mapping := `{
                        "mappings": {
                            "properties": {
                                "product_id": { "type": "keyword" },
                                "price": { "type": "integer" },
                変更後: |  #// olivere elastic v6
                    mapping := `{
                        "mappings": {
                            "doc": {
                                "properties": {
                                    "product_id": { "type": "keyword" },
                                    "price": { "type": "integer" },
        - #// curl -X GET http://localhost:9200/ で固まる
            手順: curl -X GET http://localhost:9200/  #// 接続先は docker の ElasticSearch   #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
            症状: 固まる
            対処: VM とそれにログインしている VSCode を閉じます
        - #// parse_exception request body or source parameter is required
            手順: curl -X  GET  http://localhost:9200/_analyze  #template: http://__ElasticS_Node1__:__ElasticS_HttpPort__/
            エラー: |
                {"error":{"root_cause":[{"type":"parse_exception","reason":"request body or source parameter is required"}],
                "type":"parse_exception","reason":"request body or source parameter is required"},"status":400}
            対処:
                JSON 形式のパラメーターも指定してください。指定の API（上記 _analyze）では省略できません。
        - #// illegal_argument_exception Malformed action/metadata
            手順: POST ____/_bulk
            エラー: |
                {"error":{"root_cause":[{"type":"illegal_argument_exception","reason":"Malformed action/metadata line [1],
                expected START_OBJECT or END_OBJECT but found [VALUE_STRING]"}]
            対処:
                1行ずつ交互に、インデックス、ドキュメント、インデックス、ドキュメント、…… の JSON にしてください。
                    #serach: ElasticSearch _bulk
        - #// index_not_found_exception
            手順: ElasticSearch サーバーでクエリなどをリクエストします
            エラー: |  #// 下記は、エラーメッセージの JSON を YAML に変換したものの一部です
                type: "index_not_found_exception"
                ____
                index: "logs-my_app-default"
            原因: インデックス logs-my_app-default が見つかりません
            対処A: ElasticSearch のテンプレートからインデックスを調べます
            対処B: ElasticSearch にアクセスするコードからインデックスを調べます
            メモ:
                ヘルスチェックからインデックスは分からないでしょう:
                    おそらく http://localhost:9200/_cluster/health
                    Consul >> Nodes（左上）>>（サーバー名）でヘルスチェックのコマンドを確認します
        - #// no active connection found
            手順: ElasticSearch サーバーに接続
            エラー: no active connection found
                curl -XGET 'http://localhost:9201/_cat/nodes' による生存確認は成功しますが、
                elastic.NewClient は失敗します
            参考: https://kotaroooo0-dev.hatenablog.com/entry/docker-es-network
            対処:
                SetSniff(false) を設定します。
                c, err := elastic.NewClient(elastic.SetSniff(false))
    設定: #settings:
        __ElasticS_ClusterName__: my-elasticsearch-cluster
        __ElasticS_Node1__: localhost  #// localhost, node1 or (IP address)
        __ElasticS_HttpPort__: 9200
        __ElasticS_ServiceName__: elasticsearch
        __ElasticS_SettingFile__: /etc/elasticsearch/elasticsearch.yml
        __ElasticS_LogsFolder__: /var/log/elasticsearch
        __ElasticS_RepositoryPath__: /var/log/elasticsearch/shared_repository
        __ElasticS_User__:  elasticsearch
        __ElasticS_Group__: elasticsearch
        __ElasticS_SnapShotName__: my_backup
        __ElasticS_SnapshotRevision__: snapshot_1
        __ElasticS_Index__: logs-my_app-default
    関連:
        OpenSearch,  aws OpenSearch: #search:
        Mroonga - MySQLで高速日本語全文検索:  #ref: https://gigazine.net/news/20210825-articles-search-system/
        IBM Cloud® Databases for Elasticsearch:  #ref: https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-horizontal-scaling&locale=ja
        Amazon OpenSearch Service:  #ref: https://docs.aws.amazon.com/ja_jp/opensearch-service/latest/developerguide/bp.html
Elasticsearch 関連:
    vulcanizer: #keyword:  #ref: https://github.com/github/vulcanizer
        コマンド: |
            vulcanizer health --host __OneOfHostInCluster__ --port 9200
                |     CLUSTER     | STATUS | RELOCATING | INITIALIZING | UNASSIGNED | ACTIVE % |
                +-----------------+--------+------------+--------------+------------+----------+
                | _______________ | green  | 0          | 0            | 0          | 100      |
            vulcanizer nodes --host __OneOfHostInCluster__ --port 9200
                | MASTER | ROLE |         NAME         |      IP       |  ID  |    JDK    | VERSION |
                +--------+------+----------------------+---------------+------+-----------+---------+
                | -      | mdi  | __Host1__            | 10.100.100.11 | dvEi | 1.8.0_191 | 6.8.22  |
                | *      | mdi  | __Host2__            | 10.100.100.12 | EBif | 1.8.0_191 | 6.8.22  |
                | -      | mdi  | __Host3__            | 10.100.100.13 | eAR- | 1.8.0_191 | 6.8.22  |
MinIO: #keyword:
    公式: #ref: https://min.io/
    概要: S3クラウド・ストレージ・サービスと互換性のあるオブジェクト・ストレージ・サーバー
        互換性＝AWS CLIや、AWS SDKが使える。
        1台のサーバーに保存、または 3台のサーバーに分散して（クラスターを形成して堅牢で高性能に）保存します。
        後からノードやストレージサイズを増やすことができません。
    設定: #settings:
        __FileName__: _a.txt
        __MinIO_Alias__: minioalias
        __BucketName__: bucket1
        __MinIO_ConsolePort__: 60277
        __MinIO_EndPoint__: http://localhost:9000
        __MinIO_AccessKey__: minioadmin
        __MinIO_SecretKey__: minioadmin
        __MinIO_Folder__: ${HOME}\AppData\Roaming\MinIO  #// USERPROFILE = C:\Users\____\
    手順: #// Windows へ試しにインストールします  #keyword: install MinIO
        公式: #ref: https://docs.min.io/docs/minio-client-quickstart-guide.html
        インストールします:
            MinIO サーバーをインストールします:
                minio.exe をダウンロードします:
                    最新バージョンの場合:
                        #ref: https://dl.min.io/server/minio/release/windows-amd64/minio.exe
                    他のバージョンの場合:
                        ダウンロードします:
                            #ref: https://dl.min.io/server/minio/release/windows-amd64/archive/
                        ダウンロードしたファイルを minio.exe に改名します:
                            #// 例： minio.RELEASE.2019-07-31T18-57-56Z => minio.exe
                ヘルプを表示します:
                    (PowerShell): |
                        & ${HOME}\Downloads\minio
            MinIO サーバーを起動します:
                (新しい PowerShell): |
                    - mkdir ${HOME}\AppData\Roaming\MinIO
                        #template: __MinIO_Folder__
                    - & ${HOME}\Downloads\minio server ${HOME}\AppData\Roaming\MinIO --console-address ":60277"
                        #template: __MinIO_Folder__ --console-address ":__MinIO_ConsolePort__"
                ブラウザーで MinIO のコンソール (WebUI) を表示します:  #keyword: MinIO console
                    URL: http://localhost:60277  #template: __MinIO_ConsolePort__
                    Username: minioadmin         #template: __MinIO_AccessKey__
                    Password: minioadmin         #template: __MinIO_SecretKey__
                ログを表示します:
                    MinIO console >> Tools >> Logs
            MinIO クライアント mc.exe をインストールします:  #keyword: install mc MinIO
                Windows:
                    mc.exe をダウンロードします:
                        最新バージョンの場合:
                            #ref: https://dl.min.io/client/mc/release/windows-amd64/mc.exe
                        他のバージョンの場合:
                            ダウンロードします:
                                #ref: https://dl.min.io/client/mc/release/windows-amd64/archive/
                            ダウンロードしたファイルを mc.exe に改名します:
                                #// 例： mc.RELEASE.2019-07-31T19-17-35Z => mc.exe
                    ヘルプを表示します:
                        (PowerShell): |
                            & ${HOME}\Downloads\mc
                Linux:
                    64-bit Intel:
                        インストール:
                            curl https://dl.min.io/client/mc/release/linux-amd64/mc \
                                --create-dirs \
                                -o $HOME/minio-binaries/mc
                            chmod +x $HOME/minio-binaries/mc
                        実行開始:
                            export PATH=$PATH:$HOME/minio-binaries/
                            mc --help
                公式: #ref: https://min.io/docs/minio/linux/reference/minio-mc.html#quickstart
            エイリアスを新規作成します:  #keyword: install mc alias set
                (PowerShell): |
                    & ${HOME}\Downloads\mc alias set  minioalias  http://localhost:9000  minioadmin  minioadmin
                        #template: mc alias set  __MinIO_Alias__  __MinIO_EndPoint__  __MinIO_AccessKey__  __MinIO_SecretKey__
                （書式）:  #ref: https://min.io/docs/minio/linux/reference/minio-mc/mc-alias-set.html
                    - mc alias set __Alias__  __EndPoint__
                    - mc alias set __MinIO_Alias__  __EndPoint__  __AccessKey__  __SecretKey__  --api __API_Signature__
                __API_Signature__:
                    --api オプションを省略した場合: S3v4
                （パスワードなどを環境変数に設定する場合）:
                    export MC_HOST___Alias__=https://__AccessKey__:__SecretKey__@__EndPoint__
                    #ref: https://docs.min.io/docs/minio-client-complete-guide.html >> Specify temporary host configuration through environment variable
            接続先の情報を表示します:  #keyword: MinIO mc admin info
                (PowerShell): |
                    & ${HOME}\Downloads\mc  admin info minioalias
                        #template: mc  admin info __MinIO_Alias__
                    ●  localhost:9000
                    Uptime: 33 minutes 
                    Version: 2019-08-01T22:18:54Z
                    Storage: Used 20 KiB
            バケットを一覧します:  #keyword: mc ls example
                (PowerShell): |
                    & ${HOME}\Downloads\mc  ls minioalias
                        #template: mc  ls __MinIO_Alias__
                （参考）インターネットにあるお試しサイト https://play.min.io/ にアクセスする場合: |
                    & ${HOME}\Downloads\mc  ls play
            バケットを新規作成します:  #keyword: mc mb example
                (PowerShell): |
                    & ${HOME}\Downloads\mc  mb minioalias/bucket1
                    & ${HOME}\Downloads\mc  ls minioalias
                        #template-at(-2): mc  mb __MinIO_Alias__/__BucketName__
                        #template-at(-2): mc  ls __MinIO_Alias__
            ファイルをアップロードします:  #keyword: mc cp example
                (PowerShell): |
                    echo a > _a.txt
                        #template: __FileName__
                    & ${HOME}\Downloads\mc  cp _a.txt  minioalias/bucket1
                    & ${HOME}\Downloads\mc  ls minioalias/bucket1
                        #template-at(-2): mc  cp __FileName__  __MinIO_Alias__/__BucketName__
                        #template-at(-2): mc  ls __MinIO_Alias__/__BucketName__
                    rm _a.txt
                        #template: __FileName__
            終了します:
                minio.exe が実行されているシェル >> Ctrl + C
        アンインストールします:
            minio.exe や mc.exe を削除します:
                (PowerShell): |
                    rm  ${HOME}\Downloads\minio.exe
                    rm  ${HOME}\Downloads\mc.exe
            minio.exe が使っていたフォルダーを削除します:
                (PowerShell): |
                    rm -r -fo ${HOME}\mc
                    rm -r -fo ${HOME}\AppData\Roaming\MinIO
        ファイルをアップロードします:  #search: mc cp example
    機能:
        セキュリティ関連:  #search: MinIO IAM
    コマンド >> mc, MinIO クライアント:  #keyword: mc MinIO client
        インストール: #search: install mc MinIO
        サンプル:  #// & ${HOME}\Downloads\mc  ls minioalias
            #search: install mc MinIO
            書式: mc ls __Alias__
            (PowerShell): |
                & ${HOME}\Downloads\mc  ls play
            グローバル オプション: |  #search: MinIO global option
                mc --debug ls __Alias__
        コマンド: #keyword: mc command  #glossary: MinIO
            ls: #// バケットまたはオブジェクトを一覧します
                (PowerShell): |  #search: mc ls example
                    & ${HOME}\Downloads\mc  ls minioalias/bucket1
            cp: #// アップロード・ダウンロード・コピーをします
                アップロードします:  #search: mc cp example
                    書式: mc cp __LocalFilePath__  __Alias__/__BucketName__
                    (PowerShell): |
                        & ${HOME}\Downloads\mc  cp __LocalFilePath__  minioalias/bucket1
                    フォルダーのコピー:
                        mc cp  "__Alias__/__BucketName__"  "__LocalFolderPath__"  --recursive
                        mc cp  "__LocalFolderPath__"  "__Alias__/__BucketName__"  --recursive
            mb: #// バケットを新規作成します  #search: mc mb example
                書式: mc mb __Alias__/__NewBucketName__
                (PowerShell): |
                    & ${HOME}\Downloads\mc  mb minioalias/bucket1
            rb: #// バケットを削除します
                mv rb __Alias__/__NewBucketName__
            rm: #// オブジェクトを削除します  #ref: https://min.io/docs/minio/linux/reference/minio-mc/mc-rm.html#command-mc.rm
                バケット内のすべて:  #// 空のバケットは残ります
                    mc rm  "__Alias__/__BucketName__"  --recursive
            policy:  #keyword: mc policy
                mc policy get __AliasName__/__BucketName__
            参考:
                - #ref: https://docs.min.io/docs/minio-client-complete-guide.html >> . Commands
                - #ref: https://docs.min.io/minio/baremetal/reference/minio-cli/minio-mc.html#command-quick-reference
            グローバル オプション: #keyword: MinIO global option  #// mc のどのコマンドにも指定できるオプション
                --json:  #// 出力を JSON 形式にします
                --debug:  #// デバッグ用に詳細を表示します
                    mc --debug ls play
                参考: #ref: https://docs.min.io/docs/minio-client-complete-guide.html >> Global Options
        トラブルシューティング:  #search: MinIO mc time out
    概念:
        （構造）: #keyword: MinIO 構造
            エイリアス:  #// 接続先、ホスト、エンドポイント、アクセス キー
                バケット:
                    オブジェクト:  #// ファイル
                IAM ユーザー:  #// アカウント。エイリアスと関連付けられます。つまりどのエイリアスを使うかによって権限が異なります
                    ユーザーの種類:
                        root ユーザー:
                        IAM ユーザー:
                    アクセス キー:  #// ユーザー アカウント のようなもの。IAM ユーザーだけでなく root ユーザーも持てるらしい
                    シークレット キー:  #// パスワードのようなもの
                ポリシー, IAM ポリシー:  #// アクセス制御。IAM ユーザーと関連付けられる
                    ポリシー アクション キー, 権限:  #// アカウントに対して許可または拒否の値
        ホスト, エイリアス:
            一覧: #keyword: MinIO alias list  #ref: https://min.io/docs/minio/linux/reference/minio-mc/mc-alias-list.html
                新しいバージョンの場合:
                    mc alias list
                古いバージョンの場合:  #// バージョン 2019
                    ~/.mc/config.json: |  #// 下記の myminio や myS3 がエイリアス名です
                        {
                            "version": "9",
                            "hosts": {
                                "myminio": {
                                    "url": "https://minioserver.example.net",
                                    "accessKey": "YOUR-ACCESS-KEY",
                                    "secretKey": "YOUR-SECRET-KEY",
                                    "api": "S3v4",
                                    "lookup": "auto"
                                },
                                "myS3": {
                                    "url": "https://s3.amazonaws.com",
            作成: #search: install mc alias set
        バケット:
            一覧:  #search: mc ls example
        オブジェクト:  #// ファイル
            アップロードします:  #search: mc cp example
        ユーザー, ポリシー: #keyword: MinIO IAM ポリシー
            バケット ポリシー:
                コマンド:  #search: mc policy
            root ユーザー: #keyword: MinIO root user
                アクセス キー:
                    環境変数:
                        -   MINIO_ACCESS_KEY, MINIO_SECRET_KEY
                        #// バージョンによっては
                        -   MINIO_ROOT_USER, MINIO_ROOT_PASSWORD
                権限:
                    -   root ユーザーは全ての権限を持っています
                    -   IAM ポリシーと関連付けしません
            IAM ユーザー:
                アクセス キー: #keyword: MinIO access key  #// access_key と secret_key によるログインは root ユーザーと同じです
                    保存場所:
                        ____/data/.minio.sys/config/iam/users/devuser1/
                            ├── identity.json
                            ├── policy.json
                            └── credentials.json
                    root ユーザー関連:  #search: MinIO root user
                    IAM ユーザー関連, エイリアス関連:  #search: MinIO alias list  #search: MinIO 構造
                コマンド:
                    一覧: mc admin user list __ServerAlias__
            IAM ポリシー:
                内容 >> サンプル: |  #// admin:ServerUpdate の許可
                    {
                        "Version": "2012-10-17",
                        "Statement": [
                            {
                                "Effect": "Allow",
                                "Action": [
                                    "admin:ServerUpdate"
                                ],
                                "Resource": [
                                    "arn:aws:s3:::*"
                                ]
                            }
                        ]
                    }
                コマンド: #keyword: mc admin policy
                    一覧, 内容:
                        mc admin policy list __ServerAlias__
                        mc admin policy info __ServerAlias__ __PolicyName__
                概念 >> 権限:
                    root ユーザーの権限:  #search: MinIO root user
    ログ:  #keyword: MinIO logs
        MinIO のログを取ります:  #// MinIO へリクエストした元の IP アドレスを調べます
            ログの収集を開始し、追加されたら表示します:
                mc admin trace __MinIO_Alias__ &  #// バックグラウンド ジョブ で実行します  #search: Linux job
                    #// ログが追加されるとその内容が表示されます
            mc admin trace による表示とは別途表示する場合:
                mc find __MinIO_Alias__/__Bucket__
            IP アドレスから FQDN を調べます:
                nslookup  __IP_Address__
    ファイル, 環境変数:
        DATADIR 環境変数: #keyword: MinIO DATADIR
            場所: DATADIR 環境変数に MinIO の内部フォルダーの場所を指定します
            フォルダーの内容:
                __DataDir__/__BacketName__/__ObjectName__/ フォルダー:
                    xl.meta: 管理用
                    __UUID__/part.__Num__: 内容の一部
                __DataDir__/__BacketName__/__ObjectName__ ファイル:
                    これは 古い保存形式らしい。MinIO 2019。
                    最新はフォルダーになります
    コード:
        Python:
            使われる IAM ポリシー:  #// Python で IAM ポリシーを使って MinIO を操作します
                アクセス キー に関連する IAM ポリシーが使われます  #search: MinIO access key
                #ref: ${typrm_files}/ref/Database-AI.yaml#label: MinIO IAM Python
    参考: MinIO とは？動作確認や機能、特徴などを解説 - OSSサポートのOpenStandia  https://openstandia.jp/oss_info/minio/
    トラブルシューティング:
        - #// 脆弱性情報  #ref: https://cve.report/software/minio/minio
        - #// mc コマンドを実行するとタイムアウトする  #keyword: MinIO mc time out
            手順: mc admin info local_minio
            エラー: メッセージなし。固まる
            対処:
                mc --debug admin info local_minio
        - #// mc コマンドを実行するとタイムアウトする
            手順: mc --debug admin info local_minio
            エラー: |
                <p>The following error was encountered while trying to retrieve the URL: <a href="http://
                __Host__:9000/minio/admin/v1/info">http://__Host__:9000/minio/admin/v1/info</a></p>
            対処:
                NO_PROXY="__Host__"  mc --debug admin info local_minio
        - #// Unable to initialize admin connection
            手順: mc admin info minioalias
            エラー: |
                mc.exe: <ERROR> Unable to initialize admin connection. No valid configuration found for 'minio' host alias.
            対処:
                admin info コマンドに指定するエイリアス（上記 minioalias）を正しく指定してください
        - #// S3 Requests should be sent to API port.
            エラー: |
                mc.exe: <ERROR> Unable to get service status. S3 API Request made to Console port. S3 Requests should be sent to API port.
            対処:
                mc alias set コマンドに指定するポート番号（上記9000）を正しく設定してください
        - #// 
            手順: mc ls __Alias__
            エラー: |
                mc.exe: <ERROR> Unable to list folder. Get "https://localhost:9000/": http: server gave HTTP response to HTTPS client
            対処:
                サーバーが起動しているか確認します   
Hadoop: #keyword: Hadoop,  ビッグデータ  列指向
    Apache Hadoop: #keyword:  #ref: https://hadoop.apache.org/
        HDFS: #keyword:  #// 大規模な データ セット を処理する分散 ファイル システム。 Hadoop の構成要素
            #ref: https://www.ibm.com/topics/hdfs
        歴史:
            #ref: https://oss.nttdata.com/hadoop/hadoop.html
                Google社が論文として公開した、Google社内の以下の基盤技術をオープンソースとして実装したものを利用しています:
                    - GFS  #// Google File System  Google社の分散ファイルシステム)
                    - Google MapReduce  #// Google社での分散処理技術
    Apache HBase: #keyword:  #// HDFS（ビッグデータ）に対して実行する列指向の非リレーショナル データベース管理システム
        #ref: https://www.ibm.com/topics/hbase
    Apache Hive: #keyword:  #// Hadoop ファイルシステムに格納された データの分析
        参考:
            Apache Hive 概要 / HiveQL チートシート: #ref: https://qiita.com/esakik/items/c9659e2496362b914e6d
            IBM: #ref: https://www.ibm.com/analytics/hadoop/hive
            サンプル: #ref: https://agency-star.co.jp/column/apache-hive
    HiveQL, HQL: #keyword:  #// 大規模データを扱う SQL の代わり
        参考:
            Apache Hive 概要 / HiveQL チートシート: #ref: https://qiita.com/esakik/items/c9659e2496362b914e6d
        サンプル:
            CREATE DATABASE db1;
            USE db1;
            SHOW DATABASES;
            SHOW TABLES;
            DESC __TableName__
            SELECT
                JOIN は利用できる（ただし ON 句で NOT 条件を使えない）
            CREATE TABLE ____;
            DROP TABLE;
            LOAD DATA ____;
            INSERT ____;
            行の削除  Hive version 0.14.0 以降  できるが効率が悪いのかも？
                https://stackoverflow.com/questions/17810537/how-to-delete-and-update-a-record-in-hive
            列の削除  https://stackoverflow.com/questions/34198114/alter-hive-table-add-or-drop-column
    MapReduce:
    Apache Ambari: #keyword:  #// Apache Hadoop クラスタのプロビジョニング
        #ref: https://learn.microsoft.com/ja-jp/azure/hdinsight/hdinsight-hadoop-manage-ambari
    Superset: #keyword:  #ref: https://superset.apache.org/
        SQLの結果をグラフ化
        Dockerで動く
        様々な BDMS に対応
    Zeppelin: #keyword:
        フォーム入力やバージョン管理、ノートのスケジュール実行ができる
        Sparkを中心としつつ Redshift、BigQueryなどの他データソースにも対応できるノートブック
        #ref: https://qiita.com/muterion111/items/d141557e8c551c556de6
    ファイル:
        ORC ファイル形式: #keyword:  #// Optimized Row Columnar。 BigData を扱うデータフォーマット。圧縮あり
            #ref: https://en.wikipedia.org/wiki/Apache_ORC
            #ref: https://qiita.com/kazuki-ma/items/ccaffad23deaf0321793
        Perquet ファイル形式: #keyword:
            #ref: https://github.com/apache/parquet-format
        カラムナ フォーマット: #keyword:
            #ref: https://qiita.com/kazuki-ma/items/ccaffad23deaf0321793#orc-ファイルについて
    テーブル:
        managed table: #ref: https://stackoverflow.com/questions/31310558/hive-managed-table-vs-external-table-location-directory
        external table:
SIEM, ログ監視: #keyword:  #// 「シーム」と呼ぶ。 syslog 収集、インデックス化、集計 ダッシュボード、自動処置
    参考 >> 概要:
        #ref: https://www.splunk.com/ja_jp/blog/security/siem-security-information-event-management.html
    Splunk: #keyword:
        参考 >> 概要:
            #ref: https://qiita.com/frozencatpisces/items/59703f57ce88ec936255
            #ref: https://www.ogis-ri.co.jp/column/cloud_arch/c106714.html
            #ref: https://e-words.jp/w/Splunk.html
    Grafana:
        Grafana: #keyword:  #// 視覚化ツール
            #ref: ${programming}/グラフィックス/ダッシュボード.svg#Grafana
            概要: Loki の内容を見るときにも使えます
        Loki: #keyword: Loki, Grafana Loki Logger  #// ログのストレージ
            概要: 水平展開、高可用性、マルチテナントが可能なログ集約システムです
                ElasticSearch より安定しているらしい
            参考:
                - https://tech.willgate.co.jp/entry/2020/06/23/120000
                - Grafana Loki で CloudNative なロギングをはじめよう！ https://speakerdeck.com/polar3130/lets-begin-cloud-native-logging-with-grafana-loki?slide=10
            構成:
                Promtail: #// ローカルのログファイルから Loki に転送します
                    その他使える転送エージェント: [ Fluentd, Fluent Bit ]
                Loki: #// ログにインデックスを付けて保管します
                Grafana: #// ログの可視化、検索
                logcli:  #// ログを見るコマンド
                    Loki に入っています
        Promtail: #keyword:  #// ログ送信エージェントと、メトリクスを公開するサーバ
            https://tech.willgate.co.jp/entry/2020/06/23/120000
        参考:
            Grafana+Loki+Promtailを使ってログ収集してみる:
                #ref: https://zenn.dev/mohashi/articles/5f3c043c09d14c
バックアップ:  #keyword: database backup,  database back up,  データベース バックアップ
    対応できる障害:
        ホスト障害: ディスクの破損
        破損したデータ: 停電時に発生する可能性がある
        不整合なデータ: アプリケーションや人のミスによる
    レプリカノード:
        バックアップ用の新しい専用ホスト
    バックアップ ポリシー:
        時間: 間隔（日、時）, 開始時刻, 保存する世代数（破棄する）, 目標復旧時間
        置き場所: オフサイト・ストレージ（＝クラウド）。1～2回分はローカルに置いて早くリストアできるようにし、残りはクラウドへ置く
        暗号化: GPGなど。パスワードの管理方法
        手段:
            定期バックアップ:
                物理:
                    特徴: 速い。DBMS のバージョンを変えられない
                    手段: Percona XtraBackup,  RDS/LVM スナップショット,  MySQL Enterprise Backup,  cp,  rsync
                論理:
                    特徴: SQL のダンプ。遅い。他の環境で実行しやすい
                    手段: mysqldump、mydumper、mysqlpump
            バイナリ ログ のコピー:  #// バイナリ ログ もバックアップすると、最後のトランザクションまで回復できるようになります
            増分バックアップ, 差分バックアップ:  #keyword:
                増分バックアップ: 最後の増分バックアップ以降に変更された内容
                差分バックアップ: 最後の完全バックアップ以降に変更された内容。増分バックアップよりサイズが大きくなる
                #ref: https://www.percona.com/blog/2021/01/12/mysql-backup-and-recovery-best-practices/
        容量監視:
        復元テスト: 復元の自動化
        参考:
            Percona ブログ: #ref: https://www.percona.com/blog/2021/01/12/mysql-backup-and-recovery-best-practices/
            Cyber Agent Developers ブログ:
                Amazon S3 へ: #ref: https://developers.cyberagent.co.jp/blog/archives/28454/
    論理削除: #keyword:
        すぐに削除しない:
            #// レコードを削除する処理には、ケアが必要
            - ユーザーに確認する
            - レコード名などを入力させる
            - 論理削除フラグを使い、復帰できるようにする？（直接DBを操作する運用にすることが多い）
            - 30日後に完全削除
        論理削除はやめよう:
            どういう一覧であるかをメソッドのパラメーターにしたシンプルなインターフェースを定義して、その getter を作るのが正解じゃないかなと思う
            #ref: https://x.com/Ts_Neko/status/2006640832326349079
MessagePack: #keyword: MessagePack,  msgpack
    公式: https://msgpack.org/ja.html
    概要: 詰めたJSONよりも情報密度が高く、処理が高速なバイナリ形式。
        ホームページが正しく表示されないため廃れ気味か？
    形式: #ref: https://github.com/msgpack/msgpack/blob/master/spec.md
        先頭:
            0x82 or 0x83 ?
        int:  #ref: https://github.com/msgpack/msgpack/blob/master/spec.md#int-format-family
        str:  #ref: https://github.com/msgpack/msgpack/blob/master/spec.md#str-format-family
            0xA0 + length
    Python:  #keyword: Python msgpack,  Python MessagePack
    Go:  #search: Go msgpack
DTO, DAO:  #keyword:
    DTO:  #// Data Transfer Object
        #ref: https://ja.wikipedia.org/wiki/Data_Transfer_Object
        データの集合と、それらをプログラミング言語から読み書きする手段のみからなる１つのオブジェクト。
        DTO は内部的に持つこと。クライアントには非公開。そうしないと、DTO が謎の中間モデルになってしまうためメンテナンスがほぼ不可能になります。
        HTTP のクエリーパラメーターや JSON と分けます。
        DAO をまとめたもの。
        おそらく、１つのトランザクション処理？に必要なデータを集めたもの？
        関数処理をフローのクラスで表現する場合のものが DTO なのでは？
    DAO:  #// Data Access Object
        データベースのテーブルに対応するオブジェクト。
        ビジネス ロジック から切り離すこと。
    中間 DTO の禁止: #search: middle DTO
    DTO は DDD ではどこ？:
        #ref: https://stackoverflow.com/questions/31438286/ddd-which-layer-dto-should-be-implemented
    概要図: #ref: ${my_images}/2021/jj_ch04_4.2.2_1.png
    参考:
        バージョンの差分の吸収:  #search: version up DTO DAO
        DI, Dependency Injecton: #search: 
        #ref: https://kanda-it-school-kensyu.com/java-jdbc-contents/jj_ch04/jj_0402/
ログの目的: #keyword: ログの目的  #// 傾向分析・予測、監査・実績管理、デバッグ  #ref: ${my_images}/2021/logging_purpose.png
    参考:
        - https://speakerdeck.com/polar3130/lets-begin-cloud-native-logging-with-grafana-loki?slide=10
        - https://tech.willgate.co.jp/entry/2020/06/23/120000
用語: #glossary:
    CAS, Check-And-Set, 楽観的並行性制御:  #ref: ${programming}/排他制御、プロセス/!排他制御、プロセス.svg#optimistic_concurrency_control
        手順:  #// 未検証
            カウンターを読む
            データを変数に読む
            変数の値を変更する
            変数の値をデータに書く
            カウンターを読む
            カウンターが増えていたらやり直し
            カウンターを増やす（書く）
    CRUD: #// クラッド。Create, Read, Update, Delete の略
    CSV: #// Comma Separated Values
        CSV の１行を縦に並べます: #search: VSCode CSV transpose
        strict CSV, trimmed CSV, RFC 4180: #keyword:  #// 各要素の前後に空白を入れない CSV。ダブルクオーテーションで囲むのはできる
            #// 標準は空白を入れませんが、多くのツールは自動トリム機能を提供しています
            bash:  #search: bash strict CSV
    DBMS: #// Data Base Management System。データベースのソフトウェア。MySQL, 
    DSN: #// Data Source Name  #ref: https://en.wikipedia.org/wiki/Data_source_name
    ER図:  #// Entity Relationship diagram
        #search: エンティティ, リレーション
    GTID:  #// Global Transaction ID  #// トランザクションの ID。クローンされない限り世界中で唯一。サーバー間で共有される可能性あり
        値の書式: __SourceServerUUID__:__TransactionID__
        __SourceServerUUID__: この UUID は MySQL サーバーを識別する UUID ですが、サーバー(VM イメージ)をクローンした場合、衝突する可能性があります
        __TransactionID__: これ単体は他の MySQL サーバー と衝突する可能性があります
    InnoDB:  #// MySQL と MariaDB のデータベースエンジン
        #ref: https://ja.wikipedia.org/wiki/InnoDB
    SSV: #// Space Separated Values  https://kotobank.jp/word/SSV-670468
    エンティティ: #// データベースとして表現すべき対象物
        #search: リレーション
    カーディナリティ:
        意味 a.: 行ごとに値が異なる度合い。
            たとえば、ID > 名前 >> 年齢 >> 性別
        意味 b.: 多重度
        参考: #ref: https://e-words.jp/w/カーディナリティ.html
    セマフォー:
        スロット: #// スロット＝資源。スロット数＝カウンターの最大値  #keyword: semaphore slot
    多重度: #keyword: 多重度, 1対1, 1対多, 多対1, 多対多
        multiplicity
        #search: カーディナリティ
    マイグレーション: #// データベースのスキーマのバージョンアップ  #search: Django migrate  #search: Flyway  #search: MySQL migration  #search: MySQL ALTER TABLE
    マスター: #keyword: Data base master
        〇〇マスター（テーブル）:  #ref: ${typrm_files}/ref/Database-AI.yaml#label: master table
        差別用語: #keyword: master term
    リレーション: #// エンティティの関係
    レプリケーション: #// バックアップ システム へデータを同期します  #keyword: database back up replication
        MySQL: #search: MySQL replication
